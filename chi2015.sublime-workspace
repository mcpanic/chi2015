{
	"auto_complete":
	{
		"selected_items":
		[
			[
				"backg",
				"background-color"
			],
			[
				"papersI",
				"papersInGroup"
			],
			[
				"paperId",
				"paperIdOfAuthor"
			],
			[
				"back",
				"background-color"
			],
			[
				"swap",
				"swapValues"
			],
			[
				"pref",
				"preferences"
			],
			[
				"palette_",
				"palette_content"
			],
			[
				"pre",
				"preferencesSeverityList  (variable)"
			],
			[
				"get",
				"getSeverityByType"
			],
			[
				"const",
				"constraintsList"
			],
			[
				"prefer",
				"preferencesList"
			],
			[
				"cons",
				"console"
			],
			[
				"create",
				"createConstraintObjectDisplay"
			],
			[
				"rela",
				"relationMappingList"
			],
			[
				"conflict",
				"conflictObjectMappingList"
			],
			[
				"date",
				"dateEquals  (variable)"
			],
			[
				"time",
				"timeEquals  (variable)"
			],
			[
				"or",
				"orderedDateList"
			],
			[
				"session",
				"sessionHasAward"
			],
			[
				"selec",
				"selectedConstraint"
			],
			[
				"sele",
				"selectedConstraint"
			],
			[
				"find",
				"findCellByDateTimeRoom"
			],
			[
				"is",
				"isInterrupted"
			],
			[
				"Move",
				"MoveMode"
			],
			[
				"list-",
				"list-personas"
			],
			[
				"recom",
				"recommendedList"
			],
			[
				"iS",
				"isTransactionMyChange"
			],
			[
				"isTran",
				"isTransactionMyChange"
			],
			[
				"cell",
				"findCellByID"
			],
			[
				"proposed-",
				"proposed-swap-paper"
			],
			[
				"paper-uns",
				"paper-unscheduled"
			],
			[
				"type",
				"submissionType"
			],
			[
				"unscheduled",
				"unscheduledId"
			],
			[
				"border-co",
				"border-color"
			],
			[
				"netCount",
				"netCountClass"
			],
			[
				"getS",
				"getSessionDetail"
			],
			[
				"SERVER",
				"_SERVER"
			],
			[
				"video",
				"videos_array"
			],
			[
				"formatt",
				"formatted_item"
			],
			[
				"local",
				"local_num_tools"
			],
			[
				"local_",
				"local_num_tools"
			],
			[
				"ds",
				"dsOursPostQuestions  (variable)"
			],
			[
				"interfa",
				"interface_id"
			],
			[
				"done",
				"domxml_new_doc"
			],
			[
				"timeline-",
				"timeline-bottom"
			],
			[
				"num_",
				"num_videos"
			],
			[
				"int",
				"interface_id"
			],
			[
				"la",
				"labels_array"
			],
			[
				"label",
				"labels_array"
			],
			[
				"lab",
				"labels_array"
			],
			[
				"edit-",
				"edit-label-link"
			],
			[
				"num",
				"num_rows"
			],
			[
				"ta",
				"tabs4_html"
			],
			[
				"thum",
				"thumb_html"
			],
			[
				"icon",
				"icon-chevron-up"
			],
			[
				"toggle",
				"playlist-toggle"
			],
			[
				"select-",
				"select-image"
			]
		]
	},
	"buffers":
	[
		{
			"file": "sponsoring/sponsors-of-chi2015.php",
			"settings":
			{
				"buffer_size": 5395,
				"line_ending": "Unix"
			}
		},
		{
			"file": "attending/press.php",
			"settings":
			{
				"buffer_size": 2333,
				"line_ending": "Unix"
			}
		},
		{
			"file": "program.php",
			"settings":
			{
				"buffer_size": 3292,
				"line_ending": "Unix"
			}
		},
		{
			"file": "leftbar.php",
			"settings":
			{
				"buffer_size": 9911,
				"line_ending": "Unix"
			}
		},
		{
			"contents": "Searching 214 files for \"video_previews\" (regex)\n\n/Applications/MAMP/htdocs/chi2015/js/angular/modules/full_program.js:\n    1  angular.module('chi2015_controllers').controller('full_program_controller',\n    2: 	['$scope', 'papers_factory', 'sessions_factory', 'schedules_factory', 'video_previews_factory', \"$window\", '$location', '$anchorScroll',\n    3: 	function($scope, papers_factory, sessions_factory, schedules_factory, video_previews_factory, $window,$location, $anchorScroll){\n    4  \n    5  	$scope.schedule = []\n    6  	$scope.sessions = {}\n    7  	$scope.papers = {}\n    8:     $scope.video_previews = {}\n    9  	$scope.schedule_index = 0;\n   10  \n   ..\n   51          })\n   52  \n   53:         video_previews_factory.get({}, function(data){\n   54:             $scope.video_previews = data\n   55  \n   56:             console.log($scope.video_previews)\n   57          })\n   58        })\n\n/Applications/MAMP/htdocs/chi2015/js/angular/modules/full_program_2.js:\n    2  var full_sessions;\n    3  var full_papers;\n    4: var full_video_previews;\n    5  \n    6  function check_query(objs, sessions, papers, type, search, query) {\n    .\n  225  \n  226  angular.module('chi2015_controllers').controller('full_program_controller',\n  227: 	['$scope', 'papers_factory', 'sessions_factory', 'schedules_factory', 'video_previews_factory', \"$window\", '$location', '$anchorScroll',\n  228: 	function($scope, papers_factory, sessions_factory, schedules_factory, video_previews_factory, $window, $location, $anchorScroll){\n  229  \n  230  	console.log(get_url_vars()['id'])\n  ...\n  234  	$scope.sessions = {};\n  235  	$scope.papers = {};\n  236: 	$scope.video_previews = {};\n  237  	$scope.schedule_index = 0;\n  238  	$scope.schedule_count = 0;\n  ...\n  570  \n  571  \n  572:     	video_previews_factory.get({}, function(data){\n  573      		for (var j in data.data) {\n  574      			var id = data.data[j][0]\n  ...\n  579      				'early': data.data[j][13]\n  580      			}\n  581:     			$scope.video_previews[id] = entry\n  582  	    		// console.log(entry)\n  583      		}\n  584:     		full_video_previews = $scope.video_previews\n  585      	})\n  586  \n\n/Applications/MAMP/htdocs/chi2015/js/angular/modules/main_app.js:\n  110  ])\n  111  \n  112: angular.module('chi2015_services').factory('video_previews_factory', ['$resource',\n  113      function($resource) {\n  114:     return data_link(\"video_previews\", $resource)\n  115      }])\n  116  \n\n/Applications/MAMP/htdocs/chi2015/js/data/video_previews.php:\n    1  <?php\n    2  header('Content-Type: application/json');\n    3: $file=\"video_previews_win.csv\";\n    4  $csv= file_get_contents($file);\n    5  $csv =  utf8_encode($csv);\n\n/Applications/MAMP/htdocs/chi2015/program/full-schedule.php:\n  149  											</a>\n  150  \n  151: 											<a class=\"fancybox-media fancybox.iframe\" href=\"https://www.youtube.com/watch?v={{video_previews[papers[submissions].id].yt_id}}&amp;autoplay=1\" target=\"_blank\" ng-if=\"video_previews[papers[submissions].id] !== undefined && video_previews[papers[submissions].id].early == 'TRUE'\"><img class=\"vp-paper\" src=\"<?php echo $prefix; ?>/img/program/vp_16x16.png\"/></a>\n  152  \n  153  <!-- 											<div class=\"full_schedule_keywords\" ng-if=\"papers[submissions].keyword_string.trim()!=''\">\n\n20 matches across 5 files\n\n\nSearching 1058 files for \"sungwon\" (regex)\n\n/Applications/MAMP/htdocs/chi2015/js/data/panel.csv:\n    4  \"pan119\",\"A\",\"10 Years of alt.chi: Reflections and Outlook\",\"Morgan\",\"Ames\",\"morganya@gmail.com\",\"pan0119-paper.pdf\",\"1\",\"A4\",\"\",\"\",\"Morgan G Ames, Silvia Lindtner, Barry Brown, Daniela K Rosner, Sidney S Fels, Roel Vertegaal\",\"morganya@gmail.com, silvia.lindtner@gmail.com, barry@mobilelifecentre.org, dkrosner@uw.edu, ssfels@ece.ubc.ca, roel@cs.queensu.ca\",\"6095\",\"Morgan\",\"G\",\"Ames\",\"morganya@gmail.com\",\"Intel Science and Technology Center\",\"University of California, Irvine\",\"Irvine\",\"California\",\"United States\",\"\",\"\",\"\",\"\",\"\",\"9429\",\"Silvia\",\"\",\"Lindtner\",\"silvia.lindtner@gmail.com\",\"School of Information\",\"University of Michigan\",\"Ann Arbor\",\"Michigan\",\"United States\",\"\",\"\",\"\",\"\",\"\",\"1785\",\"Barry\",\"\",\"Brown\",\"barry@mobilelifecentre.org\",\"\",\"Mobile Life @ Stockholm University\",\"Kista\",\"\",\"Sweden\",\"\",\"\",\"\",\"\",\"\",\"9749\",\"Daniela\",\"K\",\"Rosner\",\"dkrosner@uw.edu\",\"Human Centered Design & Engineering\",\"University of Washington\",\"Seattle\",\"Washington\",\"United States\",\"\",\"\",\"\",\"\",\"\",\"1763\",\"Sidney\",\"S\",\"Fels\",\"ssfels@ece.ubc.ca\",\"\",\"University of British Columbia\",\"Vancouver\",\"British Columbia\",\"Canada\",\"\",\"\",\"\",\"\",\"\",\"1095\",\"Roel\",\"\",\"Vertegaal\",\"roel@cs.queensu.ca\",\"Human Media Lab\",\"Queen's University\",\"Kingston\",\"Ontario\",\"Canada\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"Morgan G. Ames\",\"alt.chi@morganya.org\",\"To commemorate the tenth anniversary of alt.chi, two of this year’s alt.chi chairs, Ames and Lindtner, will moderate a panel with chairs from previous years to reflect on the legacy of alt.chi in the broader CHI community and discuss where the track should be headed in the future. We intend the panel to be highly interactive, incorporating the audience in discussion and debate. We encourage those with thoughts on alt.chi as well as those who want to learn more about the track, to attend and actively participate. The following questions will start the discussion: \\ 1.	What is the role of alt.chi in the CHI community, and how has it shifted across the last decade? \\ 2.	What alt.chi research papers or themes have been particularly influential or provocative? \\ 3.	What is the state of critical discourse and reflection in alt.chi? Has alt.chi been a successful venue for such work? Should it be? \\ 4.	Where is alt.chi headed, what is missing, and how could it change? \\ \",\"ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \\ \",\"alt.chi, alternative, submission models, review models, open reviewing, juried reviewing, commentary \",\"K.4.0\",\"pan0119-file1.doc\",\"\",\"\",\"\",\"To commemorate the tenth anniversary of alt.chi, chairs from this and previous years will reflect on the legacy of alt.chi and discuss where the track should be headed.\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"Feb 26 13:42\",\"\"\n    5  \"pan120\",\"A\",\"How Mobile Devices are Revolutionizing User Interaction\",\"Hwanyong\",\"Lee\",\"hwanyong.lee@knu.ac.kr\",\"pan0120-paper.pdf\",\"6\",\"letter\",\"\",\"incomplete\",\"Hwanyong Lee, Victor Erukhimov, Neil Trevett, Alon Oh-bach, Tom Olson\",\"hwanyong.lee@knu.ac.kr, victor.eruhimov@itseez.com, ntrevett@nvidia.com, alon.ohbach@samsung.com, Tom.olson@arm.com\",\"50866\",\"Hwanyong\",\"\",\"Lee\",\"hwanyong.lee@knu.ac.kr\",\"\",\"Kyungpook National University\",\"Daegu\",\"\",\"Korea, Republic of\",\"\",\"\",\"\",\"\",\"\",\"50867\",\"Victor\",\"\",\"Erukhimov\",\"victor.eruhimov@itseez.com\",\"\",\"Itsees Inc.\",\"Nizhny Novgorod\",\"\",\"Russian Federation\",\"\",\"\",\"\",\"\",\"\",\"50868\",\"Neil\",\"\",\"Trevett\",\"ntrevett@nvidia.com\",\"\",\"NVIDIA\",\"Santa Clara\",\"California\",\"United States\",\"\",\"\",\"\",\"\",\"\",\"50869\",\"Alon\",\"\",\"Oh-bach\",\"alon.ohbach@samsung.com\",\"\",\"Samsung\",\"London\",\"\",\"United Kingdom\",\"\",\"\",\"\",\"\",\"\",\"50870\",\"Tom\",\"\",\"Olson\",\"Tom.olson@arm.com\",\"\",\"ARM\",\"San Jose\",\"California\",\"United States\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"Hwanyong Lee\",\"hwanyong.lee@knu.ac.kr\",\"\",\"1. http://www.khronos.org/ \\ 2. http://petapixel.com/2013/03/14/a-starry-sea-ofcameras-at-the-unveiling-of-pope-francis/, Image credits: Photographs by Luca Bruno/AP, Michael Sohn/AP \\ 3. https://www.google.com/atap/projecttango/ \\ 4. http://developer.android.com/about/versions/lollip op.html \\ \",\"\",\"\",\"pan0120-file1.doc\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"Feb 26 14:46\",\"\"\n    6: \"pan121\",\"A\",\"Why Google cannot be the # 1 in Korea?: In Search for Critical Success Factors from Local User Experience\",\"Jinsoo\",\"Kim\",\"evlos1@gmail.com\",\"pan0121-paper.pdf\",\"6\",\"letter\",\"\",\"incomplete\",\"Jinsoo Kim, Sungeon Kim, Sungwon Beck, Kihyun Jung\",\"evlos1@gmail.com, eon.kim@navercorp.com, pj.ay@daumkakao.com, kihyun.jung@sk.com\",\"50905\",\"Jinsoo\",\"\",\"Kim\",\"evlos1@gmail.com\",\"\",\"KIPFA\",\"Seoul\",\"\",\"Korea, Republic of\",\"\",\"\",\"\",\"\",\"\",\"50906\",\"Sungeon\",\"\",\"Kim\",\"eon.kim@navercorp.com\",\"\",\"Naver Corporation\",\"Seoul\",\"\",\"Korea, Republic of\",\"\",\"\",\"\",\"\",\"\",\"50907\",\"Sungwon\",\"\",\"Beck\",\"pj.ay@daumkakao.com\",\"\",\"Daum Kakao Corp\",\"Seoul\",\"\",\"Korea, Republic of\",\"\",\"\",\"\",\"\",\"\",\"50908\",\"Kihyun\",\"\",\"Jung\",\"kihyun.jung@sk.com\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"Jinsoo Kim\",\"evlos1@gmail.com\",\"\",\"ERROR: Sorry, but we could not find the bibliography in your PDF file.  Please entry it manually. \\ \",\"\",\"\",\"pan0121-file1.doc\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"Feb 26 14:54\",\"\"\n\n/Applications/MAMP/htdocs/chi2015/js/data/papers-no-award.json:\n 19457              },\n 19458              {\n 19459:                 \"name\": \"Sungwon Beck\",\n 19460:                 \"givenName\": \"Sungwon\",\n 19461                  \"middleInitial\": \"\",\n 19462                  \"familyName\": \"Beck\",\n\n/Applications/MAMP/htdocs/chi2015/js/data/papers.json:\n 17472        \"location\" : \"Seoul, Korea\"\n 17473      }, {\n 17474:       \"name\" : \"Sungwon Beck\",\n 17475:       \"givenName\" : \"Sungwon\",\n 17476        \"middleInitial\" : \"\",\n 17477        \"familyName\" : \"Beck\",\n\n/Applications/MAMP/htdocs/chi2015/vote/chi_2015_0.1.1.json:\n    1: {\"conference\":{\"headers\":[\"name\",\"short_name\",\"description\",\"location\",\"start_day\",\"num_days\",\"utc_offset\",\"update_url\",\"webapp_base_url\",\"dropbox_sync\",\"voting\",\"reading_list\",\"schedule\",\"note\",\"pdf\",\"video\"],\"rows\":[[\"CHI 2015\",\"CHI 2015\",\"The ACM CHI Conference on Human Factors in Computing Systems\",null,1429351200,6,-36000,\"http://confapp.from.so/\",\"http://confapp.from.so/\",null,null,null,null,null,null,null]]},\"db_info\":{\"headers\":[\"version\",\"last_updated\"],\"rows\":[[\"0.1.1\",1428790901]]},\"location\":{\"headers\":[\"_id\",\"name\",\"map_x_pct\",\"map_y_pct\",\"sequence\",\"map_file\",\"map_name\"],\"rows\":[[1,\"307\",0.132537688,0.76,1,\"Level3F.jpg\",\"Level 3F\"],[2,\"308\",0.132537688,0.651428571,2,\"Level3F.jpg\",\"Level 3F\"],[3,\"401\",0.701995012,0.499189627,3,\"Level4F.jpg\",\"Level 4F\"],[4,\"402\",0.304239401,0.52350081,4,\"Level4F.jpg\",\"Level 4F\"],[5,\"403\",0.264339152,0.375202593,5,\"Level4F.jpg\",\"Level 4F\"],[6,\"317 A\",0.179020101,0.473809524,6,\"Level3F.jpg\",\"Level 3F\"],[7,\"317 BC\",0.10741206,0.473809524,7,\"Level3F.jpg\",\"Level 3F\"],[8,\"318 A\",0.177763819,0.365238095,8,\"Level3F.jpg\",\"Level 3F\"],[9,\"318 BC\",0.106155779,0.365238095,9,\"Level3F.jpg\",\"Level 3F\"],[10,\"E1/E2\",0.39321608,0.662380952,10,\"Level3F.jpg\",\"Level 3F\"],[11,\"E4\",0.39321608,0.636666667,11,\"Level3F.jpg\",\"Level 3F\"],[12,\"E5\",0.472361809,0.682380952,12,\"Level3F.jpg\",\"Level 3F\"],[13,\"E6\",0.472361809,0.636190476,13,\"Level3F.jpg\",\"Level 3F\"],[14,\"E7\",0.528266332,0.63047619,14,\"Level3F.jpg\",\"Level 3F\"],[15,\"Exhibit Hall\",0.435301508,0.34952381,15,\"Level3F.jpg\",\"Level 3F\"]]},\"person\":{\"headers\":[\"_id\",\"name\",\"last_name\",\"affiliation\"],\"rows\":[[1,\"Shaun K Kane\",\"Kane\",\"\"],[2,\"Meethu Malu\",\"Malu\",\"University of Maryland\"],[3,\"Leah Findlater\",\"Findlater\",\"University of Maryland\"],[4,\"Kristin Williams\",\"Williams\",\"University of Maryland\"],[5,\"Karyn Moffatt\",\"Moffatt\",\"McGill University\"],[6,\"Denise McCall\",\"McCall\",\"Snyder Center for Aphasia Life Enhancement\"],[7,\"Dhruv Jain\",\"Jain\",\"Massachusetts Institute of Technology\"],[8,\"Jamie Gilkeson\",\"Gilkeson\",\"Montgomery Blair High School\"],[9,\"Benjamin Holland\",\"Holland\",\"Montgomery Blair High School\"],[10,\"Ramani Duraiswami\",\"Duraiswami\",\"University of Maryland\"],[11,\"Dmitry Zotkin\",\"Zotkin\",\"University of Maryland\"],[12,\"Christian Vogler\",\"Vogler\",\"Gallaudet University\"],[13,\"Jon Froehlich\",\"Froehlich\",\"University of Maryland\"],[14,\"Simon Katan\",\"Katan\",\"Goldsmiths, University of London\"],[15,\"Mick Grierson\",\"Grierson\",\"Goldsmiths, University of London\"],[16,\"Rebecca Fiebrink\",\"Fiebrink\",\"Goldsmiths, University of London\"],[17,\"Mayank Goel\",\"Goel\",\"University of Washington\"],[18,\"Chen Zhao\",\"Zhao\",\"University of Washington\"],[19,\"Ruth Vinisha\",\"Vinisha\",\"University of Washington\"],[20,\"Shwetak N Patel\",\"Patel\",\"DUB Group\"],[21,\"Christophe Hurter\",\"Hurter\",\"\"],[22,\"Jian Zhao\",\"Zhao\",\"University of Toronto\"],[23,\"Zhicheng Liu\",\"Liu\",\"Adobe Research\"],[24,\"Mira Dontcheva\",\"Dontcheva\",\"Adobe\"],[25,\"Aaron Hertzmann\",\"Hertzmann\",\"Adobe Systems\"],[26,\"Alan Wilson\",\"Wilson\",\"Adobe\"],[27,\"Xiaotong Liu\",\"Liu\",\"The Ohio State University\"],[28,\"Han-Wei Shen\",\"Shen\",\"The Ohio State University\"],[29,\"Nan Cao\",\"Cao\",\"IBM T.J. Watson Research Center\"],[30,\"Yu-Ru Lin\",\"Lin\",\"University of Pittsburgh\"],[31,\"Liangyue Li\",\"Li\",\"Arizona State University\"],[32,\"Hanghang Tong\",\"Tong\",\"Arizona State University\"],[33,\"Fan Du\",\"Du\",\"University of Maryland\"],[34,\"Ian Oakley\",\"Oakley\",\"\"],[35,\"João Guerreiro\",\"Guerreiro\",\"Instituto Superior Técnico, Universidade de Lisboa\"],[36,\"André Rodrigues\",\"Rodrigues\",\"Faculdade de Ciências, Universidade de Lisboa\"],[37,\"Kyle Montague\",\"Montague\",\"University of Dundee\"],[38,\"Tiago Guerreiro\",\"Guerreiro\",\"University of Lisbon\"],[39,\"Hugo Nicolau\",\"Nicolau\",\"Rochester Institute of Technology\"],[40,\"Daniel Gonçalves\",\"Gonçalves\",\"Instituto Superior Técnico, Universidade de Lisboa\"],[41,\"Mark Cartwright\",\"Cartwright\",\"Northwestern University\"],[42,\"Bryan Pardo\",\"Pardo\",\"Northwestern University\"],[43,\"Robert Tubb\",\"Tubb\",\"Queen Mary University of London\"],[44,\"Simon Dixon\",\"Dixon\",\"Queen Mary University of London\"],[45,\"Ryohei Suzuki\",\"Suzuki\",\"The University of Tokyo\"],[46,\"Daisuke Sakamoto\",\"Sakamoto\",\"The University of Tokyo\"],[47,\"Takeo Igarashi\",\"Igarashi\",\"The University of Tokyo\"],[48,\"Thomas Smith\",\"Smith\",\"Newcastle University\"],[49,\"Simon J Bowen\",\"Bowen\",\"Newcastle University\"],[50,\"Bettina Nissen\",\"Nissen\",\"Newcastle University\"],[51,\"Jonathan Hook\",\"Hook\",\"University of York\"],[52,\"Arno Verhoeven\",\"Verhoeven\",\"University of Edinburgh\"],[53,\"John Bowers\",\"Bowers\",\"Newcastle University\"],[54,\"Peter Wright\",\"Wright\",\"Newcastle University\"],[55,\"Patrick Olivier\",\"Olivier\",\"Newcastle University\"],[56,\"David Shamma\",\"Shamma\",\"\"],[57,\"Motahhare Eslami\",\"Eslami\",\"University of Illinois at Urbana-Champaign\"],[58,\"Aimee N Rickman\",\"Rickman\",\"California State University, Fresno\"],[59,\"Kristen Vaccaro\",\"Vaccaro\",\"University of Illinois\"],[60,\"Amirhossein Aleyasen\",\"Aleyasen\",\"University of Illinois at Urbana-Champaign\"],[61,\"Andy Vuong\",\"Vuong\",\"University of Illinois at Urbana-Champaign\"],[62,\"Karrie G Karahalios\",\"Karahalios\",\"University of Illinois at Urbana-Champaign\"],[63,\"Kevin Hamilton\",\"Hamilton\",\"University of Illinois\"],[64,\"Christian Sandvig\",\"Sandvig\",\"University of Michigan\"],[65,\"Paul Lapides\",\"Lapides\",\"University of Calgary\"],[66,\"Apoorve Chokshi\",\"Chokshi\",\"University of Calgary\"],[67,\"Sheelagh Carpendale\",\"Carpendale\",\"University of Calgary \"],[68,\"Saul Greenberg\",\"Greenberg\",\"University of Calgary\"],[69,\"Emilee Rader\",\"Rader\",\"Michigan State University\"],[70,\"Rebecca Gray\",\"Gray\",\"Michigan State University\"],[71,\"Yong Liu\",\"Liu\",\"University of Hamburg\"],[72,\"Jayant Venkatanathan\",\"Venkatanathan\",\"University of Madeira\"],[73,\"Jorge A Goncalves\",\"Goncalves\",\"University of Oulu\"],[74,\"Evangelos Karapanos\",\"Karapanos\",\"Madeira Interactive Technologies Institute\"],[75,\"Vassilis Kostakos\",\"Kostakos\",\"University of Oulu\"],[76,\"Gary Hsieh\",\"Hsieh\",\"\"],[77,\"Scott A Hale\",\"Hale\",\"Oxford Internet Institute, University of Oxford\"],[78,\"Erik Borra\",\"Borra\",\"University of Amsterdam\"],[79,\"Esther Weltevrede\",\"Weltevrede\",\"University of Amsterdam\"],[80,\"Paolo Ciuccarelli\",\"Ciuccarelli\",\"Politecnico di Milano\"],[81,\"Andreas Kaltenbrunner\",\"Kaltenbrunner\",\"Barcelona Media\"],[82,\"David Laniado\",\"Laniado\",\"Barcelona Media\"],[83,\"Giovanni Magni\",\"Magni\",\"Politecnico di Milano\"],[84,\"Michele Mauri\",\"Mauri\",\"Politecnico di Milano\"],[85,\"Richard Rogers\",\"Rogers\",\"University of Amsterdam\"],[86,\"Tommaso Venturini\",\"Venturini\",\"Sciences Politiques\"],[87,\"Amanda Menking\",\"Menking\",\"University of Washington\"],[88,\"Ingrid Erickson\",\"Erickson\",\"Rutgers University\"],[89,\"Shilad W Sen\",\"Sen\",\"Macalester College\"],[90,\"Heather Ford\",\"Ford\",\"University of Oxford\"],[91,\"David R Musicant\",\"Musicant\",\"Carleton College\"],[92,\"Mark Graham\",\"Graham\",\"University of Oxford\"],[93,\"Oliver S Keyes\",\"Keyes\",\"Wikimedia Foundation\"],[94,\"Brent Hecht\",\"Hecht\",\"University of Minnesota\"],[95,\"Shih-Wen Huang\",\"Huang\",\"University of Washington\"],[96,\"Minhyang (Mia) Suh\",\"Suh\",\"Human Centered Design and Engineering\"],[97,\"Benjamin Mako Hill\",\"Hill\",\"University of Washington\"],[98,\"Gary Hsieh\",\"Hsieh\",\"University of Washington\"],[99,\"Wendy E Mackay\",\"Mackay\",\"\"],[100,\"Kevin Chen\",\"Chen\",\"Northwestern University\"],[101,\"Haoqi Zhang\",\"Zhang\",\"Northwestern University\"],[102,\"Sandy Claes\",\"Claes\",\"KU Leuven\"],[103,\"Niels Wouters\",\"Wouters\",\"KU Leuven\"],[104,\"Karin Slegers\",\"Slegers\",\"Social Spaces\"],[105,\"Andrew Vande Moere\",\"Moere\",\"KU Leuven\"],[106,\"Anna Luusua\",\"Luusua\",\"University of Oulu\"],[107,\"Johanna Ylipulli\",\"Ylipulli\",\"University of Oulu\"],[108,\"Marko Jurmu\",\"Jurmu\",\"University of Oulu\"],[109,\"Henrika Pihlajaniemi\",\"Pihlajaniemi\",\"University of Oulu\"],[110,\"Piia Markkanen\",\"Markkanen\",\"University of Oulu\"],[111,\"Timo Ojala\",\"Ojala\",\"University of Oulu\"],[112,\"Gunnar Harboe\",\"Harboe\",\"University of Zurich\"],[113,\"Elaine M Huang\",\"Huang\",\"University of Zurich\"],[114,\"Cosmin Munteanu\",\"Munteanu\",\"University of Toronto Mississauga\"],[115,\"Heather Molyneaux\",\"Molyneaux\",\"National Research Council Canada\"],[116,\"Wendy Moncur\",\"Moncur\",\"University of Dundee\"],[117,\"Mario Romero\",\"Romero\",\"KTH -  KUNGLIGA TEKNISKA HÖGSKOLAN\"],[118,\"Susan O'Donnell\",\"O'Donnell\",\"National Research Council of Canada\"],[119,\"John Vines\",\"Vines\",\"Newcastle University\"],[120,\"Parmit K Chilana\",\"Chilana\",\"University of Waterloo\"],[121,\"Mary P Czerwinski\",\"Czerwinski\",\"Microsoft Research\"],[122,\"Tovi Grossman\",\"Grossman\",\"Autodesk Research\"],[123,\"Chris Harrison\",\"Harrison\",\"Carnegie Mellon University\"],[124,\"Ranjitha Kumar\",\"Kumar\",\"University of Illinois at Urbana-Champaign\"],[125,\"Tapan S Parikh\",\"Parikh\",\"University of California, Berkeley\"],[126,\"Shumin Zhai\",\"Zhai\",\"Google, Inc.\"],[127,\"Aaron Quigley\",\"Quigley\",\"\"],[128,\"Kana Misawa\",\"Misawa\",\"The University of Tokyo\"],[129,\"Jun Rekimoto\",\"Rekimoto\",\"University of Tokyo / Sony CSL\"],[130,\"Cosima Rughinis\",\"Rughinis\",\"University of Bucharest\"],[131,\"Razvan Rughinis\",\"Rughinis\",\"University POLITEHNICA of Bucharest\"],[132,\"Matthew P Aylett\",\"Aylett\",\"University of Edinburgh\"],[133,\"Aaron Quigley\",\"Quigley\",\"The University of St Andrews\"],[134,\"Alexander Mirnig\",\"Mirnig\",\"University of Salzburg\"],[135,\"Alexander Meschtscherjakov\",\"Meschtscherjakov\",\"Salzburg University\"],[136,\"Daniela Wurhofer\",\"Wurhofer\",\"University of Salzburg\"],[137,\"Thomas Meneweger\",\"Meneweger\",\"University of Salzburg\"],[138,\"Manfred Tscheligi\",\"Tscheligi\",\"University of Salzburg\"],[139,\"Jeff A Johnson\",\"Johnson\",\"UI Wizards, Inc\"],[140,\"Fabio Paternò\",\"Paternò\",\"CNR-ISTI\"],[141,\"Thecla Schiphorst\",\"Schiphorst\",\"Simon Fraser University\"],[142,\"Lian Loke\",\"Loke\",\"University of Sydney\"],[143,\"Jörg Müller\",\"Müller\",\"\"],[144,\"Lining Yao\",\"Yao\",\"Massachusetts Institute of Technology\"],[145,\"Jifei Ou\",\"Ou\",\"MIT Media Lab\"],[146,\"Chin-Yi Cheng\",\"Cheng\",\"MIT\"],[147,\"Helene Steiner\",\"Steiner\",\"MIT\"],[148,\"Wen Wang\",\"Wang\",\"Massachusetts Institute of Technology\"],[149,\"Guanyun Wang\",\"Wang\",\"College of Computer Science and Technology\"],[150,\"Hiroshi Ishii\",\"Ishii\",\"MIT Media Lab\"],[151,\"Deepak R Sahoo\",\"Sahoo\",\"University of Bristol\"],[152,\"Diego Martinez Plasencia\",\"Plasencia\",\"University of Bristol\"],[153,\"Sriram Subramanian\",\"Subramanian\",\"University of Bristol\"],[154,\"Yomna Abdelrahman\",\"Abdelrahman\",\"University of Stuttgart\"],[155,\"Alireza Sahami Shirazi\",\"Shirazi\",\"University of Stuttgart\"],[156,\"Niels Henze\",\"Henze\",\"University of Stuttgart\"],[157,\"Albrecht Schmidt\",\"Schmidt\",\"University of Stuttgart\"],[158,\"John Hardy\",\"Hardy\",\"Lancaster University\"],[159,\"Christian Weichel\",\"Weichel\",\"Lancaster University\"],[160,\"Faisal Taher\",\"Taher\",\"Lancaster University\"],[161,\"John Vidler\",\"Vidler\",\"Lancaster University\"],[162,\"Jason Alexander\",\"Alexander\",\"Lancaster University\"],[163,\"Masa Ogata\",\"Ogata\",\"Keio University\"],[164,\"Masaaki Fukumoto\",\"Fukumoto\",\"Microsoft Research\"],[165,\"Lennart E Nacke\",\"Nacke\",\"\"],[166,\"Melodie Vidal\",\"Vidal\",\"Lancaster University\"],[167,\"Remi Bismuth\",\"Bismuth\",\"ISART Digital\"],[168,\"Andreas Bulling\",\"Bulling\",\"Max Planck Institute for Informatics\"],[169,\"Hans Gellersen\",\"Gellersen\",\"Lancaster University\"],[170,\"Arun Kulshreshth\",\"Kulshreshth\",\"University of Central Florida\"],[171,\"Joseph LaViola Jr.\",\"Jr.\",\"University of Central Florida\"],[172,\"Zenja Ivkovic\",\"Ivkovic\",\"University of Saskatchewan\"],[173,\"Ian Stavness\",\"Stavness\",\"University of Saskatchewan\"],[174,\"Carl Gutwin\",\"Gutwin\",\"University of Saskatchewan\"],[175,\"Steven Sutcliffe\",\"Sutcliffe\",\"University of Saskatchewan\"],[176,\"Alena Denisova\",\"Denisova\",\"University of York\"],[177,\"Paul Cairns\",\"Cairns\",\"University of York\"],[178,\"Jin Ha Lee\",\"Lee\",\"University of Washington\"],[179,\"Sungsoo (Ray) Hong\",\"Hong\",\"University of Washington\"],[180,\"Hyerim Cho\",\"Cho\",\"University of Washington\"],[181,\"Yea-Seul Kim\",\"Kim\",\"University of Washington\"],[182,\"Suranga Nanayakkara\",\"Nanayakkara\",\"\"],[183,\"Helena M Mentis\",\"Mentis\",\"University of Maryland, Baltimore County\"],[184,\"Rita Shewbridge\",\"Shewbridge\",\"University of Maryland Baltimore County \"],[185,\"Sharon Powell\",\"Powell\",\"University of Maryland School of Medicine\"],[186,\"Paul Fishman\",\"Fishman\",\"University of Maryland School of Medicine\"],[187,\"Lisa Shulman\",\"Shulman\",\"University of Maryland School of Medicine\"],[188,\"Roisin McNaney\",\"McNaney\",\"Newcastle University\"],[189,\"Madeline Balaam\",\"Balaam\",\"Newcastle University\"],[190,\"Amey Holden\",\"Holden\",\"Newcastle University\"],[191,\"Guy Schofield\",\"Schofield\",\"Newcastle University\"],[192,\"Daniel Jackson\",\"Jackson\",\"Newcastle University\"],[193,\"Mary Webster\",\"Webster\",\"Newcastle University\"],[194,\"brook galna\",\"galna\",\"Newcastle University\"],[195,\"gillian barry\",\"barry\",\"Newcastle University\"],[196,\"Dadirayi Mhiripiri\",\"Mhiripiri\",\"Newcastle University\"],[197,\"lynn rochester\",\"rochester\",\"Newcastle University\"],[198,\"Ivan Poliakov\",\"Poliakov\",\"Newcastle University\"],[199,\"Pengfei Zhang\",\"Zhang\",\"Newcastle University\"],[200,\"Diane Gromala\",\"Gromala\",\"Simon Fraser University\"],[201,\"Xin Tong\",\"Tong\",\"Simon Fraser University\"],[202,\"Amber Choo\",\"Choo\",\"Simon Fraser University\"],[203,\"Mehdi Karamnejad\",\"Karamnejad\",\"Simon Fraser University\"],[204,\"Chris D Shaw\",\"Shaw\",\"Simon Fraser University\"],[205,\"Erin Buehler\",\"Buehler\",\"University of Maryland, Baltimore County\"],[206,\"Stacy Branham\",\"Branham\",\"University of Maryland Baltimore County\"],[207,\"Abdullah Ali\",\"Ali\",\"University of Maryland Baltimore County\"],[208,\"Jeremy J Chang\",\"Chang\",\"UMBC\"],[209,\"Megan K Hofmann\",\"Hofmann\",\"Colorado State University\"],[210,\"Amy Hurst\",\"Hurst\",\"University of Maryland, Baltimore County\"],[211,\"Shaun K Kane\",\"Kane\",\"University of Colorado Boulder\"],[212,\"Jonathan Hook\",\"Hook\",\"\"],[213,\"Giovanni M Troiano\",\"Troiano\",\"University of Copenhagen\"],[214,\"Esben W Pedersen\",\"Pedersen\",\"University of Copenhagen\"],[215,\"Kasper Hornbæk\",\"Hornbæk\",\"University of Copenhagen\"],[216,\"Adrian Hazzard\",\"Hazzard\",\"The University of Nottingham\"],[217,\"Steve Benford\",\"Benford\",\"The University of Nottingham\"],[218,\"Gary Burnett\",\"Burnett\",\"The University of Nottingham\"],[219,\"Daniela K Rosner\",\"Rosner\",\"University of Washington\"],[220,\"Allison Chambliss\",\"Chambliss\",\"University of Washington\"],[221,\"Jeremy Friedland\",\"Friedland\",\"University of Washington\"],[222,\"Hidekazu Saegusa\",\"Saegusa\",\"University of Washington\"],[223,\"Tim Coughlan\",\"Coughlan\",\"The University of Nottingham\"],[224,\"Laura Carletti\",\"Carletti\",\"Horizon Digital Economy Research - University of Nottingham\"],[225,\"Gabriella Giannachi\",\"Giannachi\",\"The University of Exeter\"],[226,\"Derek McAuley\",\"McAuley\",\"University of Nottingham\"],[227,\"Dominic Price\",\"Price\",\"The University of Nottingham\"],[228,\"Cristina Locatelli\",\"Locatelli\",\"The University of Exeter\"],[229,\"Rebecca Sinker\",\"Sinker\",\"Tate\"],[230,\"John Stack\",\"Stack\",\"Tate\"],[231,\"Kening Zhu\",\"Zhu\",\"\"],[232,\"Simon T Perrault\",\"Perrault\",\"National University of Singapore\"],[233,\"Eric Lecolinet\",\"Lecolinet\",\"Telecom ParisTech – CNRS LTCI UMR 5141\"],[234,\"Yoann P Bourse\",\"Bourse\",\"Telecom ParisTech - CNRS LTCI UMR 5141\"],[235,\"Shengdong Zhao\",\"Zhao\",\"National University of Singapore\"],[236,\"Yves Guiard\",\"Guiard\",\"Telecom ParisTech – CNRS LTCI UMR 5141\"],[237,\"Themis Omirou\",\"Omirou\",\"University of Bristol\"],[238,\"Asier Marzo\",\"Marzo\",\"Public University of Navarre\"],[239,\"Sue Ann Seah\",\"Seah\",\"University of Bristol\"],[240,\"Mark Shovman\",\"Shovman\",\"Yahoo! Inc.\"],[241,\"James Bown\",\"Bown\",\"University of Abertay Dundee\"],[242,\"Andrea Szymkowiak\",\"Szymkowiak\",\"University of Abertay Dundee\"],[243,\"Kenneth C Scott-Brown\",\"Scott-Brown\",\"University of Abertay Dundee\"],[244,\"Merwan Achibet\",\"Achibet\",\"Inria\"],[245,\"Géry Casiez\",\"Casiez\",\"University of Lille\"],[246,\"Anatole Lécuyer\",\"Lécuyer\",\"Inria\"],[247,\"Maud Marchal\",\"Marchal\",\"Inria\"],[248,\"Gary Perelman\",\"Perelman\",\"IRIT, University of Toulouse\"],[249,\"Marcos Serrano\",\"Serrano\",\"IRIT-University of Toulouse\"],[250,\"Mathieu Raynal\",\"Raynal\",\"University of Toulouse\"],[251,\"Celia Picard\",\"Picard\",\"Berger-Levrault \"],[252,\"Mustapha Derras\",\"Derras\",\"LRA, Berger-Levrault\"],[253,\"Emmanuel Dubois\",\"Dubois\",\"IRIT, University of Toulouse\"],[254,\"Anirudha Joshi\",\"Joshi\",\"\"],[255,\"Aditya Vashistha\",\"Vashistha\",\"University of Washington\"],[256,\"Edward Cutrell\",\"Cutrell\",\"Microsoft Research India\"],[257,\"Gaetano Borriello\",\"Borriello\",\"University of Washington\"],[258,\"William Thies\",\"Thies\",\"Microsoft Research India\"],[259,\"Neha Kumar\",\"Kumar\",\"University of Washington\"],[260,\"Richard J Anderson\",\"Anderson\",\"University of Washington\"],[261,\"Syed Ishtiaque Ahmed\",\"Ahmed\",\"Cornell University\"],[262,\"Nusrat Jahan Mim\",\"Mim\",\"Bangladesh University of Engineering and Technology\"],[263,\"Steven J Jackson\",\"Jackson\",\"Cornell University\"],[264,\"Emeline Therias\",\"Therias\",\"Spotless Interactive\"],[265,\"Jon Bird\",\"Bird\",\"City University, London\"],[266,\"Paul Marshall\",\"Marshall\",\"University College London\"],[267,\"Emilee Rader\",\"Rader\",\"\"],[268,\"Ewa Luger\",\"Luger\",\"Microsoft Research\"],[269,\"Lachlan Urquhart\",\"Urquhart\",\"University of Nottingham\"],[270,\"Tom Rodden\",\"Rodden\",\"The University of Nottingham\"],[271,\"Michael Golembewski\",\"Golembewski\",\"The University of Nottingham\"],[272,\"Qatrunnada Ismail\",\"Ismail\",\"Indiana University\"],[273,\"Tousif Ahmed\",\"Ahmed\",\"Indiana University Bloomington\"],[274,\"Apu Kapadia\",\"Kapadia\",\"Indiana University\"],[275,\"Michael Reiter\",\"Reiter\",\"University of North Carolina\"],[276,\"Eric Gilbert\",\"Gilbert\",\"Georgia Institute of Technology\"],[277,\"SeungJun Kim\",\"Kim\",\"Carnegie Mellon University\"],[278,\"Jaemin Chun\",\"Chun\",\"Carnegie Mellon University\"],[279,\"Anind K Dey\",\"Dey\",\"Carnegie Mellon University\"],[280,\"Richard C Davis\",\"Davis\",\"\"],[281,\"Saleema Amershi\",\"Amershi\",\"Microsoft Research\"],[282,\"Max Chickering\",\"Chickering\",\"Microsoft\"],[283,\"Steven M Drucker\",\"Drucker\",\"Microsoft Research\"],[284,\"Bongshin Lee\",\"Lee\",\"Microsoft Research\"],[285,\"Patrice Simard\",\"Simard\",\"Microsoft\"],[286,\"Jina Suh\",\"Suh\",\"Microsoft\"],[287,\"Matthew Kay\",\"Kay\",\"University of Washington\"],[288,\"Julie A Kientz\",\"Kientz\",\"University of Washington\"],[289,\"Andy Cockburn\",\"Cockburn\",\"University of Canterbury\"],[290,\"Philip Quinn\",\"Quinn\",\"University of Canterbury\"],[291,\"Siddhartha Asthana\",\"Asthana\",\"Indraprastha Institute of Information Technology\"],[292,\"Pushpendra Singh\",\"Singh\",\"Indraprastha Institute of Information Technology\"],[293,\"Parul Gupta\",\"Gupta\",\"Indraprastha Institute of Information Technology\"],[294,\"Ron Wakkary\",\"Wakkary\",\"\"],[295,\"William Odom\",\"Odom\",\"Simon Fraser University\"],[296,\"Eric P Baumer\",\"Baumer\",\"Cornell University\"],[297,\"Yuzuru Tanahashi\",\"Tanahashi\",\"University of California, Davis\"],[298,\"Kwan-Liu Ma\",\"Ma\",\"University of California at Davis\"],[299,\"Mark Matthews\",\"Matthews\",\"Cornell University\"],[300,\"Jaime Snyder\",\"Snyder\",\"Cornell University\"],[301,\"Lindsay Reynolds\",\"Reynolds\",\"Cornell University\"],[302,\"Jacqueline T Chien\",\"Chien\",\"Cornell University\"],[303,\"Adam Shih\",\"Shih\",\"Cornell University\"],[304,\"Jonathan W Lee\",\"Lee\",\"Cornell University\"],[305,\"Geri Gay\",\"Gay\",\"Cornell University\"],[306,\"Dongwhan Kim\",\"Kim\",\"\"],[307,\"Lida Theodorou\",\"Theodorou\",\"Queen-Mary University of London\"],[308,\"Patrick G Healey\",\"Healey\",\"Queen Mary University of London\"],[309,\"Umer Farooq\",\"Farooq\",\"Microsoft Corporation\"],[310,\"Joseph T Munko\",\"Munko\",\"Microsoft Corporation\"],[311,\"Andrea Taylor\",\"Taylor\",\"Glasgow School of Art\"],[312,\"Lorna Bernard\",\"Bernard\",\"Moray Community Health and Social Care Partnership\"],[313,\"Hugh Pizey\",\"Pizey\",\"Glasgow School of Art\"],[314,\"Craig Whittet\",\"Whittet\",\"Glasgow School of Art\"],[315,\"Samantha Davies\",\"Davies\",\"Chubb Community Care\"],[316,\"David Hammond\",\"Hammond\",\"Chubb Community Care\"],[317,\"Julian Edge\",\"Edge\",\"Chubb Community Care\"],[318,\"Paweł Woźniak\",\"Woźniak\",\"Chalmers University of Technology\"],[319,\"Robert Valton\",\"Valton\",\"Volvo Group Telematics\"],[320,\"Morten Fjeld\",\"Fjeld\",\"Chalmers University of Technology\"],[321,\"Jonathan Lazar\",\"Lazar\",\"Towson University\"],[322,\"Simone D Barbosa\",\"Barbosa\",\"Pontifical Catholic University of Rio de Janeiro\"],[323,\"Loren Terveen\",\"Terveen\",\"\"],[324,\"Leysia Palen\",\"Palen\",\"University of Colorado Boulder\"],[325,\"Lennart E Nacke\",\"Nacke\",\"University of Ontario Institute of Technology\"],[326,\"Steve Engels\",\"Engels\",\"University of Toronto\"],[327,\"Pejman Mirza-Babaei\",\"Mirza-Babaei\",\"University of Ontario Institute of Technology\"],[328,\"David Geerts\",\"Geerts\",\"Social Spaces\"],[329,\"Pablo Cesar\",\"Cesar\",\"CWI (Centrum voor Wiskunde en Informatica)\"],[330,\"Janet C Read\",\"Read\",\"University of Central Lancashire\"],[331,\"Juan Pablo Hourcade\",\"Hourcade\",\"University of Iowa\"],[332,\"Allison Druin\",\"Druin\",\"University of Maryland\"],[333,\"Panos Markopoulos\",\"Markopoulos\",\"Eindhoven University of Technology\"],[334,\"Tilde Bekker\",\"Bekker\",\"Technische Universiteit Eindhoven\"],[335,\"Ole S Iversen\",\"Iversen\",\"University of Aarhus\"],[336,\"Daniel Russell\",\"Russell\",\"Google\"],[337,\"Jaime Teevan\",\"Teevan\",\"Microsoft Research\"],[338,\"Meredith R Morris\",\"Morris\",\"Microsoft Research\"],[339,\"Marti Hearst\",\"Hearst\",\"University of California, Berkeley\"],[340,\"Ed H Chi\",\"Chi\",\"Google, Inc.\"],[341,\"Jofish Kaye\",\"Kaye\",\"\"],[342,\"Christina Masden\",\"Masden\",\"Georgia Institute of Technology\"],[343,\"W. K Edwards\",\"Edwards\",\"Georgia Institute of Technology\"],[344,\"Julia M Mayer\",\"Mayer\",\"New Jersey Institute of Technology\"],[345,\"Starr Roxanne Hiltz\",\"Hiltz\",\"New Jersey Institute of Technology\"],[346,\"Quentin  Jones\",\"Jones\",\"New Jersey Institute of Technology\"],[347,\"Tien T Nguyen\",\"Nguyen\",\"University of Minnesota\"],[348,\"Duyen T Nguyen\",\"Nguyen\",\"Carnegie Mellon University\"],[349,\"Shamsi T Iqbal\",\"Iqbal\",\"Microsoft Research\"],[350,\"Eyal Ofek\",\"Ofek\",\"MIcrosoft Research\"],[351,\"Ionut Damian\",\"Damian\",\"Augsburg University\"],[352,\"Chiew Seng Sean Tan\",\"Tan\",\"Hasselt University - tUL - iMinds\"],[353,\"Tobias Baur\",\"Baur\",\"Augsburg University\"],[354,\"Johannes Schöning\",\"Schöning\",\"Hasselt University - tUL - iMinds\"],[355,\"Kris Luyten\",\"Luyten\",\"Hasselt University - tUL - iMinds\"],[356,\"Elisabeth Andre\",\"Andre\",\"Augsburg University\"],[357,\"Tovi Grossman\",\"Grossman\",\"\"],[358,\"Alexandru Dancu\",\"Dancu\",\"Chalmers University of Technology\"],[359,\"Stig A Nielsen\",\"Nielsen\",\"Chalmers University of Technology\"],[360,\"Kening Zhu\",\"Zhu\",\"City University of Hong Kong\"],[361,\"Ayça Ünlüer\",\"Ünlüer\",\"Chalmers University of Technology\"],[362,\"Max Witt\",\"Witt\",\"Chalmers University of Technology\"],[363,\"Catherine Hedler\",\"Hedler\",\"Chalmers University of Technology\"],[364,\"Hanna Frank\",\"Frank\",\"Chalmers University of Technology\"],[365,\"Axel Pelling\",\"Pelling\",\"Chalmers University of Technology\"],[366,\"Christian Carlsson\",\"Carlsson\",\"Chalmers University of Technology\"],[367,\"Fanny Chevalier\",\"Chevalier\",\"Inria\"],[368,\"Rubaiat Habib Kazi\",\"Kazi\",\"Autodesk Research\"],[369,\"Michael Evans\",\"Evans\",\"BBC\"],[370,\"Lianne Kerlin\",\"Kerlin\",\"British Broadcasting Corporation\"],[371,\"Caroline Jay\",\"Jay\",\"The University of Manchester\"],[372,\"Daniel Buzzo\",\"Buzzo\",\"University of the West of England\"],[373,\"Nicolo Merendino\",\"Merendino\",\"STEIM\"],[374,\"Siân E Lindley\",\"Lindley\",\"\"],[375,\"Henriette Cramer\",\"Cramer\",\"Yahoo Labs\"],[376,\"Maia L Jacobs\",\"Jacobs\",\"Georgia Institute of Technology\"],[377,\"Margot Brereton\",\"Brereton\",\"Queensland University of Technology\"],[378,\"Alessandro Soro\",\"Soro\",\"Queensland University of Technology\"],[379,\"Kate Vaisutis\",\"Vaisutis\",\"Queensland University of Technology\"],[380,\"Paul Roe\",\"Roe\",\"Queensland University of Technology\"],[381,\"Roberta M Melvin\",\"Melvin\",\"University of Manitoba\"],[382,\"Andrea Bunt\",\"Bunt\",\"University of Manitoba\"],[383,\"Erick Oduor\",\"Oduor\",\"Simon Fraser University\"],[384,\"Carman Neustaedter\",\"Neustaedter\",\"Simon Fraser University\"],[385,\"Alexis Hiniker\",\"Hiniker\",\"University of Washington\"],[386,\"Kiley Sobel\",\"Sobel\",\"University of Washington\"],[387,\"Hyewon Suh\",\"Suh\",\"University of Washington\"],[388,\"Yi-Chen Sung\",\"Sung\",\"University of Washington\"],[389,\"Charlotte P Lee\",\"Lee\",\"University of Washington\"],[390,\"Adam Fourney\",\"Fourney\",\"University of Waterloo\"],[391,\"Ryen W White\",\"White\",\"Microsoft Research\"],[392,\"Eric Horvitz\",\"Horvitz\",\"Microsoft Research\"],[393,\"Michael Rohs\",\"Rohs\",\"\"],[394,\"Andrew Fowler\",\"Fowler\",\"OHSU\"],[395,\"Kurt Partridge\",\"Partridge\",\"Google Inc.\"],[396,\"Ciprian Chelba\",\"Chelba\",\"Google, Inc.\"],[397,\"Xiaojun Bi\",\"Bi\",\"University of Toronto\"],[398,\"Tom Ouyang\",\"Ouyang\",\"Google, Inc.\"],[399,\"Keith Vertanen\",\"Vertanen\",\"Montana Tech\"],[400,\"Haythem Memmi\",\"Memmi\",\"Montana Tech\"],[401,\"Justin Emge\",\"Emge\",\"Montana Tech\"],[402,\"Shyam Reyal\",\"Reyal\",\"University of St Andrews\"],[403,\"Per Ola Kristensson\",\"Kristensson\",\"University of Cambridge\"],[404,\"Luis A. Leiva\",\"Leiva\",\"Universitat Politècnica de València\"],[405,\"Alireza Sahami\",\"Sahami\",\"University of Stuttgart\"],[406,\"Alejandro Catala\",\"Catala\",\"Universitat Politècnica de València\"],[407,\"Shaun Lawson\",\"Lawson\",\"\"],[408,\"Martin D Flintham\",\"Flintham\",\"The University of Nottingham\"],[409,\"Raphael Velt\",\"Velt\",\"The University of Nottingham\"],[410,\"Max L Wilson\",\"Wilson\",\"University of Nottingham\"],[411,\"Edward J Anstead\",\"Anstead\",\"The University of Nottingham\"],[412,\"Anthony Brown\",\"Brown\",\"The University of Nottingham\"],[413,\"Timothy Pearce\",\"Pearce\",\"The University of Nottingham\"],[414,\"James Sprinks\",\"Sprinks\",\"The University of Nottingham\"],[415,\"Franco Curmi\",\"Curmi\",\"Lancaster University\"],[416,\"Maria Angela Ferrario\",\"Ferrario\",\"Lancaster University\"],[417,\"Jon Whittle\",\"Whittle\",\"Lancaster University\"],[418,\"Florian Mueller\",\"Mueller\",\"RMIT University\"],[419,\"Tom Bartindale\",\"Bartindale\",\"Newcastle University\"],[420,\"Hwajung Hong\",\"Hong\",\"Georgia Institute of Technology\"],[421,\"Gregory D Abowd\",\"Abowd\",\"Georgia Institute of Technology\"],[422,\"Rosa I Arriaga\",\"Arriaga\",\"Georgia Institute of Technology\"],[423,\"Sameer Patil\",\"Patil\",\"\"],[424,\"Hazim Almuhimedi\",\"Almuhimedi\",\"Carnegie Mellon University\"],[425,\"Florian Schaub\",\"Schaub\",\"Carnegie Mellon University\"],[426,\"Norman Sadeh\",\"Sadeh\",\"Carnegie Mellon University\"],[427,\"Idris Adjerid\",\"Adjerid\",\"University of Notre Dame\"],[428,\"Alessandro Acquisti\",\"Acquisti\",\"Carnegie Mellon University\"],[429,\"Joshua Gluck\",\"Gluck\",\"Carnegie Mellon University\"],[430,\"Lorrie Cranor\",\"Cranor\",\"Carnegie Mellon University\"],[431,\"Yuvraj Agarwal\",\"Agarwal\",\"Carnegie Mellon University\"],[432,\"Jeffrey Warshaw\",\"Warshaw\",\"University of California at Santa Cruz\"],[433,\"Tara Matthews\",\"Matthews\",\"IBM Research - Almaden\"],[434,\"Steve Whittaker\",\"Whittaker\",\"University of California, Santa Cruz\"],[435,\"Chris Kau\",\"Kau\",\"IBM Research - Almaden\"],[436,\"Mateo Bengualid\",\"Bengualid\",\"IBM Argentina\"],[437,\"Barton A Smith\",\"Smith\",\"IBM Research - Almaden\"],[438,\"Fuming Shih\",\"Shih\",\"Massachusetts Institute of Technology\"],[439,\"Ilaria Liccardi\",\"Liccardi\",\"Massachusetts Institute of Technology\"],[440,\"Daniel Weitzner\",\"Weitzner\",\"Massachusetts Institute of Technology\"],[441,\"Yang Wang\",\"Wang\",\"National ICT Australia\"],[442,\"Liang Gou\",\"Gou\",\"Almaden\"],[443,\"Anbang Xu\",\"Xu\",\"IBM Research - Almaden\"],[444,\"Michelle X Zhou\",\"Zhou\",\"Juji Inc.\"],[445,\"Huahai Yang\",\"Yang\",\"Juji Inc.\"],[446,\"Hernan Badenes\",\"Badenes\",\"IBM\"],[447,\"Chris Quintana\",\"Quintana\",\"\"],[448,\"Yi-Chieh Lee\",\"Lee\",\"National Chiao Tung University\"],[449,\"Wen-Chieh Lin\",\"Lin\",\"National Chiao Tung University\"],[450,\"Fu-Yin Cherng\",\"Cherng\",\"National Chiao Tung University\"],[451,\"Hao-Chuan Wang\",\"Wang\",\"National Tsing Hua University\"],[452,\"Ching-Ying Sung\",\"Sung\",\"National Chiao Tung University\"],[453,\"Jung-Tai King\",\"King\",\"National Chiao Tung University\"],[454,\"Andrea Bianchi\",\"Bianchi\",\"Sungkyunkwan University\"],[455,\"So-Ryang Ban\",\"Ban\",\"Sungkyunkwan University\"],[456,\"Ian Oakley\",\"Oakley\",\"Ulsan National Institute of Science and Technology\"],[457,\"René F Kizilcec\",\"Kizilcec\",\"Stanford University\"],[458,\"Emily Schneider\",\"Schneider\",\"Stanford University\"],[459,\"Yun-En Liu\",\"Liu\",\"University of Washington\"],[460,\"Christy Ballweber\",\"Ballweber\",\"University of Washington\"],[461,\"Eleanor O'Rourke\",\"O'Rourke\",\"University of Washington\"],[462,\"Eric Butler\",\"Butler\",\"University of Washington\"],[463,\"Phonraphee Thummaphan\",\"Thummaphan\",\"University of Washington\"],[464,\"Zoran Popović\",\"Popović\",\"University of Washington\"],[465,\"Mark Blythe\",\"Blythe\",\"\"],[466,\"Stuart Reeves\",\"Reeves\",\"The University of Nottingham\"],[467,\"Sarah E Martindale\",\"Martindale\",\"The University of Nottingham\"],[468,\"Paul Tennent\",\"Tennent\",\"University of Nottingham\"],[469,\"Joe Marshall\",\"Marshall\",\"The University of Nottingham\"],[470,\"Brendan Walker\",\"Walker\",\"Aerial\"],[471,\"Anne E Bowser\",\"Bowser\",\"University of Maryland\"],[472,\"Oliver L Haimson\",\"Haimson\",\"University of California, Irvine\"],[473,\"Edward F Melcer\",\"Melcer\",\"New York University\"],[474,\"Elizabeth F Churchill\",\"Churchill\",\"Google \"],[475,\"Gary Pritchard\",\"Pritchard\",\"Newcastle University\"],[476,\"Junius Gunaratne\",\"Gunaratne\",\"New York University\"],[477,\"Oded Nov\",\"Nov\",\"New York University\"],[478,\"Harald Reiterer\",\"Reiterer\",\"\"],[479,\"Florian Block\",\"Block\",\"Harvard University\"],[480,\"James Hammerman\",\"Hammerman\",\"TERC\"],[481,\"Michael Horn\",\"Horn\",\"Northwestern University\"],[482,\"Amy Spiegel\",\"Spiegel\",\"University of Nebraska, Lincoln\"],[483,\"Jonathan Christiansen\",\"Christiansen\",\"TERC\"],[484,\"Brenda Phillips\",\"Phillips\",\"Harvard University\"],[485,\"Judy Diamond\",\"Diamond\",\"University of Nebraska State Museum\"],[486,\"E. Margaret Evans\",\"Evans\",\"University of Michigan \"],[487,\"Chia Shen\",\"Shen\",\"Harvard University\"],[488,\"Mikkel R Jakobsen\",\"Jakobsen\",\"University of Copenhagen\"],[489,\"Paul K Luff\",\"Luff\",\"King's College, London\"],[490,\"Naomi Yamashita\",\"Yamashita\",\"NTT Communication Science Laboratories\"],[491,\"Hideaki Kuzuoka\",\"Kuzuoka\",\"University of Tsukuba\"],[492,\"Christian Heath\",\"Heath\",\"King's College, London\"],[493,\"Derek Reilly\",\"Reilly\",\"Dalhousie University\"],[494,\"Andy Echenique\",\"Echenique\",\"University of California, Irvine\"],[495,\"Andy Wu\",\"Wu\",\"General Electric\"],[496,\"Anthony Tang\",\"Tang\",\"University of Calgary\"],[497,\"W. Keith Edwards\",\"Edwards\",\"Georgia Institute of Technology\"],[498,\"Ellen Yi-Luen Do\",\"Do\",\"\"],[499,\"Ron Wakkary\",\"Wakkary\",\"Simon Fraser University\"],[500,\"Markus L Schilling\",\"Schilling\",\"Simon Fraser University\"],[501,\"Matthew A Dalton\",\"Dalton\",\"Simon Fraser University\"],[502,\"Sabrina Hauser\",\"Hauser\",\"Simon Fraser University\"],[503,\"Audrey Desjardins\",\"Desjardins\",\"Simon Fraser University\"],[504,\"Xiao Zhang\",\"Zhang\",\"Simon Fraser University\"],[505,\"Henry W Lin\",\"Lin\",\"Simon Fraser University\"],[506,\"Jennifer Jacobs\",\"Jacobs\",\"Massachusetts Institute of Technology\"],[507,\"Amit Zoran\",\"Zoran\",\"MIT\"],[508,\"Austin L Toombs\",\"Toombs\",\"Indiana University Bloomington\"],[509,\"Shaowen Bardzell\",\"Bardzell\",\"Indiana University Bloomington\"],[510,\"Jeffrey Bardzell\",\"Bardzell\",\"Indiana University Bloomington\"],[511,\"Lora Oehlberg\",\"Oehlberg\",\"Inria\"],[512,\"Wesley Willett\",\"Willett\",\"INRIA\"],[513,\"Wendy E Mackay\",\"Mackay\",\"INRIA\"],[514,\"Regan L Mandryk\",\"Mandryk\",\"\"],[515,\"Mikael B. Skov\",\"Skov\",\"Aalborg University\"],[516,\"Pauline G Johansen\",\"Johansen\",\"Aalborg University Hospital\"],[517,\"Charlotte S Skov\",\"Skov\",\"Aalborg University Hospital\"],[518,\"Astrid Lauberg\",\"Lauberg\",\"Aalborg University Hospital\"],[519,\"Fadel Adib\",\"Adib\",\"MIT\"],[520,\"Hongzi Mao\",\"Mao\",\"MIT\"],[521,\"Zachary Kabelac\",\"Kabelac\",\"MIT\"],[522,\"Dina Katabi\",\"Katabi\",\"MIT\"],[523,\"Robert C Miller\",\"Miller\",\"Massachusetts Institute of Technology\"],[524,\"Teng Han\",\"Han\",\"University of Pittsburgh\"],[525,\"Xiang Xiao\",\"Xiao\",\"University of Pittsburgh\"],[526,\"Lanfei Shi\",\"Shi\",\"University of Pittsburgh\"],[527,\"John Canny\",\"Canny\",\"University of California, Berkeley\"],[528,\"Jingtao Wang\",\"Wang\",\"University of Pittsburgh\"],[529,\"Yongqiang Lyu\",\"Lyu\",\"Tsinghua University\"],[530,\"Xiaomin Luo\",\"Luo\",\"BGI (Wuhan) Translational Research Center\"],[531,\"Jun Zhou\",\"Zhou\",\"Tsinghua University\"],[532,\"Chun Yu\",\"Yu\",\"Tsinghua University\"],[533,\"Congcong Miao\",\"Miao\",\"Tsinghua University\"],[534,\"Tong Wang\",\"Wang\",\"Tsinghua University\"],[535,\"Yuanchun Shi\",\"Shi\",\"Tsinghua University\"],[536,\"Ken-ichi Kameyama\",\"Kameyama\",\"Toshiba Corp\"],[537,\"Lena Mamykina\",\"Mamykina\",\"\"],[538,\"Sean A Munson\",\"Munson\",\"University of Washington\"],[539,\"Erin Krupka\",\"Krupka\",\"University of Michigan\"],[540,\"Caroline Richardson\",\"Richardson\",\"University of Michigan\"],[541,\"Paul Resnick\",\"Resnick\",\"University of Michigan\"],[542,\"Haley MacLeod\",\"MacLeod\",\"Indiana University\"],[543,\"Kim Oakes\",\"Oakes\",\"Indiana University\"],[544,\"Danika Geisler\",\"Geisler\",\"Indiana University\"],[545,\"Kay Connelly\",\"Connelly\",\"Indiana University, Bloomington\"],[546,\"Katie Siek\",\"Siek\",\"Indiana University\"],[547,\"Jina Huh\",\"Huh\",\"Michigan State University\"],[548,\"Leslie S Liu\",\"Liu\",\"University of Washington\"],[549,\"Tina Neogi\",\"Neogi\",\"University of Washington\"],[550,\"Kori M Inkpen\",\"Inkpen\",\"Microsoft Research\"],[551,\"Wanda Pratt\",\"Pratt\",\"University of Washington\"],[552,\"Matthieu Tixier\",\"Tixier\",\"UTT\"],[553,\"Myriam Lewkowicz\",\"Lewkowicz\",\"UTT\"],[554,\"Felicia Cordeiro\",\"Cordeiro\",\"University of Washington\"],[555,\"Daniel A Epstein\",\"Epstein\",\"University of Washington\"],[556,\"Edison Thomaz\",\"Thomaz\",\"Georgia Institute of Technology\"],[557,\"Elizabeth Bales\",\"Bales\",\"University of Washington\"],[558,\"Arvind K Jagannathan\",\"Jagannathan\",\"Georgia Institute of Technology\"],[559,\"James Fogarty\",\"Fogarty\",\"University of Washington\"],[560,\"Simon J Bowen\",\"Bowen\",\"\"],[561,\"Aliaksei Miniukovich\",\"Miniukovich\",\"University of Trento\"],[562,\"Antonella De Angeli\",\"Angeli\",\"University of Trento\"],[563,\"Moon-Hwan Lee\",\"Lee\",\"KAIST\"],[564,\"Seijin Cha\",\"Cha\",\"KAIST\"],[565,\"Tek-Jin Nam\",\"Nam\",\"KAIST (Korea Advanced Institute of Science and Technology)\"],[566,\"Yan Xu\",\"Xu\",\"Intel Labs\"],[567,\"Joshua Ratcliff\",\"Ratcliff\",\"Intel Labs\"],[568,\"James Scovell\",\"Scovell\",\"Intel Corporation\"],[569,\"Gheric Speiginer\",\"Speiginer\",\"Georgia Institute of Technology\"],[570,\"Ronald Azuma\",\"Azuma\",\"Intel Labs\"],[571,\"Lane Harrison\",\"Harrison\",\"Tufts University\"],[572,\"Katharina Reinecke\",\"Reinecke\",\"University of Michigan\"],[573,\"Remco Chang\",\"Chang\",\"Tufts University\"],[574,\"Steve Haroz\",\"Haroz\",\"Northwestern University\"],[575,\"Robert Kosara\",\"Kosara\",\"Tableau Software\"],[576,\"Steven Franconeri\",\"Franconeri\",\"Northwestern University\"],[577,\"Chris Harrison\",\"Harrison\",\"\"],[578,\"Baptiste Caramiaux\",\"Caramiaux\",\"Goldsmiths, University of London\"],[579,\"Marco Donnarumma\",\"Donnarumma\",\"Goldsmiths, University of London\"],[580,\"Atau Tanaka\",\"Tanaka\",\"Goldsmiths, University of London\"],[581,\"Myroslav Bachynskyi\",\"Bachynskyi\",\"Max Planck Institute for Informatics\"],[582,\"Gregorio Palmas\",\"Palmas\",\"Max Planck Institute for Informatics\"],[583,\"Antti Oulasvirta\",\"Oulasvirta\",\"Aalto University\"],[584,\"Tino Weinkauf\",\"Weinkauf\",\"Max Planck Institute for Informatics\"],[585,\"Christoph Amma\",\"Amma\",\"Karlsruhe Institute of Technology (KIT)\"],[586,\"Thomas Krings\",\"Krings\",\"Karlsruhe Institute of Technology (KIT)\"],[587,\"Jonas Böer\",\"Böer\",\"Karlsruhe Institute of Technology (KIT)\"],[588,\"Tanja Schultz\",\"Schultz\",\"Karlsruhe Institute of Technology (KIT)\"],[589,\"Pedro Lopes\",\"Lopes\",\"Hasso Plattner Institute\"],[590,\"Alexandra Ion\",\"Ion\",\"Hasso Platter Institute\"],[591,\"Willi Mueller\",\"Mueller\",\"Hasso Platter Institute\"],[592,\"Daniel Hoffmann\",\"Hoffmann\",\"Hasso Plattner Institute\"],[593,\"Patrik Jonell\",\"Jonell\",\"Hasso Plattner Institute\"],[594,\"Patrick Baudisch\",\"Baudisch\",\"Hasso Plattner Institute\"],[595,\"Naomi Yamashita\",\"Yamashita\",\"\"],[596,\"Florian Heller\",\"Heller\",\"RWTH Aachen University\"],[597,\"Jan Borchers\",\"Borchers\",\"RWTH Aachen University\"],[598,\"Jeungmin Oh\",\"Oh\",\"KAIST (Korea Advanced Institute of Science and Technology)\"],[599,\"Woohyeok Choi\",\"Choi\",\"Korea Advanced Institute of Science and Technology\"],[600,\"Joohyun Kim\",\"Kim\",\"KAIST (Korea Advanced Institute of Science and Technology)\"],[601,\"Uichin Lee\",\"Lee\",\"KAIST (Korea Advanced Institute of Science and Technology)\"],[602,\"Brennan Jones\",\"Jones\",\"University of Calgary\"],[603,\"Anna Witcraft\",\"Witcraft\",\"University of Calgary\"],[604,\"Scott Bateman\",\"Bateman\",\"University of Prince Edward Island\"],[605,\"Simon Mayer\",\"Mayer\",\"ETH Zurich\"],[606,\"Andreas Tschofen\",\"Tschofen\",\"ETH Zurich\"],[607,\"Friedemann Mattern\",\"Mattern\",\"ETH Zurich\"],[608,\"Frank R Bentley\",\"Bentley\",\"Yahoo! Labs\"],[609,\"Ying-Yu Chen\",\"Chen\",\"Yahoo Labs\"],[610,\"Christian Holz\",\"Holz\",\"Yahoo Labs\"],[611,\"Pavel A Samsonov\",\"Samsonov\",\"Hasselt University - tUL - iMinds\"],[612,\"Xun Tang\",\"Tang\",\"University of Minnesota\"],[613,\"Werner Kuhn\",\"Kuhn\",\"University of California at Santa Barbara\"],[614,\"Meredith R Morris\",\"Morris\",\"\"],[615,\"Erin L Brady\",\"Brady\",\"University of Rochester\"],[616,\"Jeffrey P Bigham\",\"Bigham\",\"Carnegie Mellon University\"],[617,\"Kristen Dergousoff\",\"Dergousoff\",\"University of Saskatchewan\"],[618,\"Regan Mandryk\",\"Mandryk\",\"University of Saskatchewan\"],[619,\"Patrick C Shih\",\"Shih\",\"The Pennsylvania State University\"],[620,\"Victoria Bellotti\",\"Bellotti\",\"Palo Alto Research Center (PARC)\"],[621,\"Kyungsik Han\",\"Han\",\"The Pennsylvania State University\"],[622,\"John M Carroll\",\"Carroll\",\"The Pennsylvania State University\"],[623,\"Alexander Ambard\",\"Ambard\",\"Palo Alto Research Center\"],[624,\"Daniel Turner\",\"Turner\",\"Palo Alto Research Center\"],[625,\"Christina Gossmann\",\"Gossmann\",\"Palo Alto Research Center\"],[626,\"Kamila Demkova\",\"Demkova\",\"Palo Alto Research Center\"],[627,\"Adrian K Clear\",\"Clear\",\"\"],[628,\"Pascal Lessel\",\"Lessel\",\"DFKI GmbH\"],[629,\"Maximilian Altmeyer\",\"Altmeyer\",\"DFKI GmbH\"],[630,\"Antonio Krüger\",\"Krüger\",\"DFKI GmbH\"],[631,\"Eva Ganglbauer\",\"Ganglbauer\",\"Vienna University of Technology\"],[632,\"Geraldine Fitzpatrick\",\"Fitzpatrick\",\"Vienna University of Technology\"],[633,\"Florian Güldenpfennig\",\"Güldenpfennig\",\"Vienna University of Technology\"],[634,\"William Gaver\",\"Gaver\",\"Goldsmiths, University of London\"],[635,\"Mike Michael\",\"Michael\",\"University of Sydney\"],[636,\"Tobie Kerridge\",\"Kerridge\",\"Goldsmiths, University of London\"],[637,\"Alex Wilkie\",\"Wilkie\",\"Goldsmiths, University of London\"],[638,\"Andy Boucher\",\"Boucher\",\"Goldsmiths, University of London\"],[639,\"Liliana Ovalle\",\"Ovalle\",\"Goldsmiths University of London\"],[640,\"Matthew Plummer Fernandez\",\"Fernandez\",\"Goldsmiths, University of London\"],[641,\"Johanne M Entwistle\",\"Entwistle\",\"Alexandra Institute\"],[642,\"Mia K Rasmussen\",\"Rasmussen\",\"Alexandra Institute\"],[643,\"Nervo Verdezoto\",\"Verdezoto\",\"Aarhus University\"],[644,\"Robert S Brewer\",\"Brewer\",\"Aarhus University\"],[645,\"Mads S Andersen\",\"Andersen\",\"The Open University\"],[646,\"Susan Dumais\",\"Dumais\",\"\"],[647,\"Benedikt Loepp\",\"Loepp\",\"University of Duisburg-Essen\"],[648,\"Katja Herrmanny\",\"Herrmanny\",\"University of Duisburg-Essen\"],[649,\"Juergen Ziegler\",\"Ziegler\",\"University of Duisburg-Essen\"],[650,\"Jaimie Y Park\",\"Park\",\"KAIST\"],[651,\"Neil O'Hare\",\"O'Hare\",\"Yahoo\"],[652,\"Rossano Schifanella\",\"Schifanella\",\"University of Torino\"],[653,\"Alejandro Jaimes\",\"Jaimes\",\"Yahoo\"],[654,\"Chin-Wan Chung\",\"Chung\",\"KAIST\"],[655,\"Yanir Kleiman\",\"Kleiman\",\"Tel Aviv University\"],[656,\"Joel Lanir\",\"Lanir\",\"University of Haifa\"],[657,\"Dov Danon\",\"Danon\",\"Tel Aviv University\"],[658,\"Yasmin Felberbaum\",\"Felberbaum\",\"University of Haifa\"],[659,\"Daniel Cohen-Or\",\"Cohen-Or\",\"Tel Aviv University\"],[660,\"Maximilian Speicher\",\"Speicher\",\"Technische Universität Chemnitz\"],[661,\"Andreas Both\",\"Both\",\"Unister GmbH\"],[662,\"Martin Gaedke\",\"Gaedke\",\"Technische Universität Chemnitz\"],[663,\"Luciano Gamberini\",\"Gamberini\",\"\"],[664,\"Andruid Kerne\",\"Kerne\",\"Texas A&M University\"],[665,\"Andrew Webb\",\"Webb\",\"Texas A&M University\"],[666,\"Steven M Smith\",\"Smith\",\"Texas A&M University\"],[667,\"Rhema Linder\",\"Linder\",\"Texas A&M University\"],[668,\"Nic Lupfer\",\"Lupfer\",\"Texas A&M University\"],[669,\"Yin Qu\",\"Qu\",\"Texas A&M University\"],[670,\"Jonathan Moeller\",\"Moeller\",\"Texas A&M University\"],[671,\"Sashikanth Damaraju\",\"Damaraju\",\"Texas A&M University\"],[672,\"Loutfouz Zaman\",\"Zaman\",\"York University\"],[673,\"Wolfgang Stuerzlinger\",\"Stuerzlinger\",\"Simon Fraser University\"],[674,\"Christian Neugebauer\",\"Neugebauer\",\"University of Applied Sciences Bonn-Rhein-Sieg\"],[675,\"Rob Woodbury\",\"Woodbury\",\"Simon Fraser Univeristy\"],[676,\"Maher Elkhaldi\",\"Elkhaldi\",\"Simon Fraser Univeristy\"],[677,\"Naghmi Shireen\",\"Shireen\",\"Simon Fraser Univeristy\"],[678,\"Michael Terry\",\"Terry\",\"University of Waterloo\"],[679,\"Joy Kim\",\"Kim\",\"Stanford University\"],[680,\"Wilmot Li\",\"Li\",\"Adobe Systems\"],[681,\"Michael S Bernstein\",\"Bernstein\",\"Stanford University\"],[682,\"Daniela Steinsapir\",\"Steinsapir\",\"Adobe Research\"],[683,\"Peter O'Donovan\",\"O'Donovan\",\"University of Toronto\"],[684,\"Aseem Agarwala\",\"Agarwala\",\"Adobe Research\"],[685,\"Sanne Ruelens\",\"Ruelens\",\"iMinds\"],[686,\"Jorick Vissers\",\"Vissers\",\"Social Spaces\"],[687,\"Pieter Duysburgh\",\"Duysburgh\",\"iMinds\"],[688,\"Frisina Chris\",\"Chris\",\"\"],[689,\"Kimiko Ryokai\",\"Ryokai\",\"University of California, Berkeley\"],[690,\"Noriko Misra\",\"Misra\",\"UC Berkeley\"],[691,\"Yoshinori Hara\",\"Hara\",\"Kyoto University\"],[692,\"Daniel Leithinger\",\"Leithinger\",\"\"],[693,\"Sean Follmer\",\"Follmer\",\"MIT Media Lab, Cambridge\"],[694,\"Philipp Schoessler\",\"Schoessler\",\"MIT Media Lab\"],[695,\"Jared Counts\",\"Counts\",\"MIT\"],[696,\"Florent Levillain\",\"Levillain\",\"Université Paris 8\"],[697,\"Sébastien Lefort\",\"Lefort\",\"Université Paris 6\"],[698,\"Elisabetta Zibetti\",\"Zibetti\",\"Université Paris 8\"],[699,\"Francesca Samsel\",\"Samsel\",\"University of Texas at Austin\"],[700,\"Mark Petersen\",\"Petersen\",\"Los Alamos National Lab\"],[701,\"Terece Geld\",\"Geld\",\"University of Texas at Austin\"],[702,\"Greg Abram\",\"Abram\",\"The University of Texas at Austin\"],[703,\"Joanne Wendelberger\",\"Wendelberger\",\"Los Alamos National Lab\"],[704,\"James Ahrens\",\"Ahrens\",\"Los Alamos National lab\"],[705,\"Philippe Palanque\",\"Palanque\",\"University of Toulouse\"],[706,\"Célia Martinie\",\"Martinie\",\"University of Toulouse\"],[707,\"Stephanie Foehrenbach\",\"Foehrenbach\",\"Zuehlke Engineering AG\"],[708,\"Shuli Gilutz\",\"Gilutz\",\"Tel-Aviv University\"],[709,\"Sarah E Garcia\",\"Garcia\",\"UEGroup\"],[710,\"Shuli Gilutz\",\"Gilutz\",\"\"],[711,\"Nesra Yannier\",\"Yannier\",\"Human Computer Interaction Institute\"],[712,\"Ali Israr\",\"Israr\",\"Disney Research\"],[713,\"Jill F Lehman\",\"Lehman\",\"Disney Research\"],[714,\"Roberta L Klatzky\",\"Klatzky\",\"Carnegie Mellon University\"],[715,\"Leyla Norooz\",\"Norooz\",\"University of Maryland\"],[716,\"Matthew Louis Mauriello\",\"Mauriello\",\"Human-Computer Interaction Lab, University of Maryland\"],[717,\"Anita Jorgensen\",\"Jorgensen\",\"University of Maryland\"],[718,\"Brenna McNally\",\"McNally\",\"University of Maryland\"],[719,\"Jon E Froehlich\",\"Froehlich\",\"University of Maryland\"],[720,\"Zhen Bai\",\"Bai\",\"University of Cambridge\"],[721,\"Alan F Blackwell\",\"Blackwell\",\"University of Cambridge\"],[722,\"George Coulouris\",\"Coulouris\",\"University of Cambridge\"],[723,\"Kenneth R Koedinger\",\"Koedinger\",\"Carnegie Mellon University\"],[724,\"Scott E Hudson\",\"Hudson\",\"Carnegie Mellon University\"],[725,\"Henry Duh\",\"Duh\",\"\"],[726,\"Jonathan S Arnowitz\",\"Arnowitz\",\"GE Software\"],[727,\"Yoko Akama\",\"Akama\",\"RMIT University \"],[728,\"Sarah Pink\",\"Pink\",\"RMIT University\"],[729,\"Annie Fergusson\",\"Fergusson\",\"La Trobe University\"],[730,\"Julie R Williamson\",\"Williamson\",\"University of Glasgow\"],[731,\"Daniel Sundén\",\"Sundén\",\"University of Glasgow\"],[732,\"Tae-Jung Yun\",\"Yun\",\"\"],[733,\"Ofra Amir\",\"Amir\",\"Harvard University\"],[734,\"Barbara J Grosz\",\"Grosz\",\"Harvard University\"],[735,\"Krzysztof Z Gajos\",\"Gajos\",\"Harvard University\"],[736,\"Sonja M Swenson\",\"Swenson\",\"Stanford University\"],[737,\"Lee M Sanders\",\"Sanders\",\"Stanford University\"],[738,\"Sun Young Park\",\"Park\",\"University of California, Irvine\"],[739,\"Yunan Chen\",\"Chen\",\"University of California, Irvine\"],[740,\"Scott Rudkin\",\"Rudkin\",\"University of California\"],[741,\"Trevor Perrier\",\"Perrier\",\"University of Washington\"],[742,\"Nicola Dell\",\"Dell\",\"University of Washington\"],[743,\"Brian DeRenzi\",\"DeRenzi\",\"University of Washington\"],[744,\"Richard Anderson\",\"Anderson\",\"University of Washington\"],[745,\"John Kinuthia\",\"Kinuthia\",\"University of Nairobi\"],[746,\"Jennifer Unger\",\"Unger\",\"University of Washington\"],[747,\"Grace John-Stewart\",\"John-Stewart\",\"University of Washington\"],[748,\"Q. Vera Liao\",\"Liao\",\"University of Illinois at Urbana-Champaign\"],[749,\"Wai-Tat Fu\",\"Fu\",\"University of Illinois at Urbana-Champaign\"],[750,\"Sri Shilpa Mamidi\",\"Mamidi\",\"University of Illinois at Urbana-Champaign\"],[751,\"Otmar Hilliges\",\"Hilliges\",\"\"],[752,\"Valkyrie Savage\",\"Savage\",\"Adobe\"],[753,\"Andrew Head\",\"Head\",\"University of California Berkeley\"],[754,\"Björn Hartmann\",\"Hartmann\",\"University of California, Berkeley\"],[755,\"Dan B Goldman\",\"Goldman\",\"Adobe\"],[756,\"Gautham Mysore\",\"Mysore\",\"Adobe Systems\"],[757,\"Rong-Hao Liang\",\"Liang\",\"National Taiwan University\"],[758,\"Chao Shen\",\"Shen\",\"National Taiwan University\"],[759,\"Yu-Chien Chan\",\"Chan\",\"National Taiwan University\"],[760,\"Guan-Ting Chou\",\"Chou\",\"National Taiwan University\"],[761,\"Liwei Chan\",\"Chan\",\"National Taiwan University\"],[762,\"De-Nian Yang\",\"Yang\",\"Academia Sinica\"],[763,\"Mike Y Chen\",\"Chen\",\"National Taiwan University\"],[764,\"Bing-Yu Chen\",\"Chen\",\"National Taiwan University\"],[765,\"Hyosun Kwon\",\"Kwon\",\"The University of Nottingham\"],[766,\"Shashank Jaiswal\",\"Jaiswal\",\"The University of Nottingham\"],[767,\"Peter Bennett\",\"Bennett\",\"University of Bristol\"],[768,\"Boriana Koleva\",\"Koleva\",\"The University of Nottingham\"],[769,\"Holger Schnädelbach\",\"Schnädelbach\",\"The University of Nottingham\"],[770,\"Marynel Vázquez\",\"Vázquez\",\"Carnegie Mellon University\"],[771,\"Eric Brockmeyer\",\"Brockmeyer\",\"Disney Research\"],[772,\"Ruta Desai\",\"Desai\",\"Carnegie Mellon University\"],[773,\"Bongwon Suh\",\"Suh\",\"\"],[774,\"Tanushree Mitra\",\"Mitra\",\"Georgia Institute of Technology\"],[775,\"C.J. Hutto\",\"Hutto\",\"Georgia Institute of Technology\"],[776,\"David A Robb\",\"Robb\",\"Heriot-Watt University\"],[777,\"Stefano Padilla\",\"Padilla\",\"Heriot Watt University\"],[778,\"Britta Kalkreuter\",\"Kalkreuter\",\"Heriot-Watt University\"],[779,\"Mike J Chantler\",\"Chantler\",\"Heriot-Watt University\"],[780,\"Justin Cheng\",\"Cheng\",\"Stanford University\"],[781,\"Walter S Lasecki\",\"Lasecki\",\"University of Rochester\"],[782,\"Jeffrey M Rzeszotarski\",\"Rzeszotarski\",\"Carnegie Mellon University\"],[783,\"Adam Marcus\",\"Marcus\",\"Locu\"],[784,\"Lionel Robert\",\"Robert\",\"University of Michigan\"],[785,\"Daniel M Romero\",\"Romero\",\"University of Michigan\"],[786,\"Andrea Bianchi\",\"Bianchi\",\"\"],[787,\"Alina Hang\",\"Hang\",\"University of Munich (LMU)\"],[788,\"Alexander De Luca\",\"Luca\",\"University of Munich (LMU)\"],[789,\"Heinrich Hussmann\",\"Hussmann\",\"University of Munich (LMU)\"],[790,\"Daniel Buschek\",\"Buschek\",\"University of Munich (LMU)\"],[791,\"Florian Alt\",\"Alt\",\"University of Munich (LMU)\"],[792,\"Emanuel von Zezschwitz\",\"Zezschwitz\",\"University of Munich (LMU)\"],[793,\"Bruno Brunkow\",\"Brunkow\",\"University of Munich (LMU)\"],[794,\"Christian Winkler\",\"Winkler\",\"Ulm University\"],[795,\"Jan Gugenheimer\",\"Gugenheimer\",\"Institute of Media Informatics\"],[796,\"Gabriel Haas\",\"Haas\",\"Ulm University\"],[797,\"Philipp Speidel\",\"Speidel\",\"Ulm University\"],[798,\"David Dobbelstein\",\"Dobbelstein\",\"Ulm University\"],[799,\"Enrico Rukzio\",\"Rukzio\",\"Institute of Media Informatics\"],[800,\"Sameer Patil\",\"Patil\",\"Yahoo Labs\"],[801,\"Roberto Hoyle\",\"Hoyle\",\"Indiana University\"],[802,\"Roman Schlegel\",\"Schlegel\",\"ABB Switzerland Ltd.\"],[803,\"Adam J Lee\",\"Lee\",\"University of Pittsburgh\"],[804,\"David England\",\"England\",\"\"],[805,\"Christian Remy\",\"Remy\",\"University of Zurich\"],[806,\"Silke Gegenbauer\",\"Gegenbauer\",\"CSS Insurance\"],[807,\"François Bérard\",\"Bérard\",\"Grenoble-INP, Univ. Grenoble Alpes\"],[808,\"Amélie Rochet-Capellan\",\"Rochet-Capellan\",\"CNRS, Univ. Grenoble Alpes\"],[809,\"Radu-Daniel Vatavu\",\"Vatavu\",\"University Stefan cel Mare of Suceava\"],[810,\"Jacob O Wobbrock\",\"Wobbrock\",\"University of Washington\"],[811,\"Yunqiu Li\",\"Li\",\"Swansea University\"],[812,\"Patrick Oladimeji\",\"Oladimeji\",\"Swansea University\"],[813,\"Harold Thimbleby\",\"Thimbleby\",\"Swansea University\"],[814,\"Iram W Mirza\",\"Mirza\",\"Google\"],[815,\"Meng  Chee\",\"Chee\",\"Samsung\"],[816,\"Gregory Abowd\",\"Abowd\",\"\"],[817,\"Mark Billinghurst\",\"Billinghurst\",\"University of Canterbury\"],[818,\"Adrian Clark\",\"Clark\",\"University of Canterbury\"],[819,\"Gun Lee\",\"Lee\",\"University of Canterbury\"],[820,\"Woontack Woo\",\"Woo\",\"KAIST\"],[821,\"Thad Starner\",\"Starner\",\"Georgia Institute of Technology\"],[822,\"Shahram Izadi\",\"Izadi\",\"Microsoft Research\"],[823,\"Margaret M Burnett\",\"Burnett\",\"Oregon State University\"],[824,\"Michael J Lee\",\"Lee\",\"University of Washington\"],[825,\"Daniel Ashbrook\",\"Ashbrook\",\"\"],[826,\"Jaeyeon Lee\",\"Lee\",\"Korea Advanced Institute of Science and Technology\"],[827,\"Jaehyun Han\",\"Han\",\"Korea Advanced Institute of Science and Technology\"],[828,\"Geehyuk Lee\",\"Lee\",\"KAIST (Korea Advanced Institute of Science and Technology)\"],[829,\"Jonggi Hong\",\"Hong\",\"KAIST (Korea Advanced Institute of Science and Technology)\"],[830,\"Seongkook Heo\",\"Heo\",\"KAIST (Korea Advanced Institute of Science and Technology)\"],[831,\"Poika Isokoski\",\"Isokoski\",\"University of Tampere\"],[832,\"DoYoung Lee\",\"Lee\",\"Ulsan National Institute of Science and Technology\"],[833,\"MD. Rasel Islam\",\"Islam\",\"Ulsan National Institute of Science and Technology\"],[834,\"Augusto Esteves\",\"Esteves\",\"University of Madeira\"],[835,\"Steven Houben\",\"Houben\",\"University College London\"],[836,\"Nicolai Marquardt\",\"Marquardt\",\"University College London\"],[837,\"Jennifer Pearson\",\"Pearson\",\"Swansea University\"],[838,\"Simon Robinson\",\"Robinson\",\"Swansea University\"],[839,\"Matt Jones\",\"Jones\",\"Swansea University\"],[840,\"Charles Perin\",\"Perin\",\"\"],[841,\"Jeremy Boy\",\"Boy\",\"INRIA\"],[842,\"Jean-Daniel Fekete\",\"Fekete\",\"INRIA\"],[843,\"Francoise Detienne\",\"Detienne\",\"CNRS-Telecom Paristech\"],[844,\"Fereshteh Amini\",\"Amini\",\"University of Manitoba\"],[845,\"Nathalie Henry Riche\",\"Riche\",\"Microsoft Research\"],[846,\"Christophe Hurter\",\"Hurter\",\"IRIT\"],[847,\"Pourang Irani\",\"Irani\",\"University of Manitoba\"],[848,\"Anshul Vikram Pandey\",\"Pandey\",\"New York University\"],[849,\"Katharina Rall\",\"Rall\",\"New York University\"],[850,\"Margaret L Satterthwaite\",\"Satterthwaite\",\"New York University\"],[851,\"Enrico Bertini\",\"Bertini\",\"New York University\"],[852,\"Bon Adriel Aseniero\",\"Aseniero\",\"University of Calgary \"],[853,\"Tiffany Wun\",\"Wun\",\"University of Calgary\"],[854,\"David Ledo\",\"Ledo\",\"University of Calgary\"],[855,\"Guenther Ruhe\",\"Ruhe\",\"University of Calgary\"],[856,\"Luis A. Leiva\",\"Leiva\",\"\"],[857,\"Josephine Kilde\",\"Kilde\",\"University of Colorado Boulder\"],[858,\"Lorenzo Gonzales\",\"Gonzales\",\"Los Alamos National Laboratory\"],[859,\"Anil Shankar\",\"Shankar\",\"Platfora Inc.\"],[860,\"Honray Lin\",\"Lin\",\"Platfora Inc\"],[861,\"Hans-Frederick Brown\",\"Brown\",\"Platfora Inc\"],[862,\"Colson Rice\",\"Rice\",\"Indiana University Bloomington\"],[863,\"Kristen P Blair\",\"Blair\",\"Stanford University\"],[864,\"Jay Pfaffman\",\"Pfaffman\",\"University of South Alabama\"],[865,\"Maria Cutumisu\",\"Cutumisu\",\"Stanford University\"],[866,\"Nicole Hallinen\",\"Hallinen\",\"Stanford University\"],[867,\"Daniel Schwartz\",\"Schwartz\",\"Stanford University\"],[868,\"Sudheendra Hangal\",\"Hangal\",\"Ashoka University\"],[869,\"Vihari Piratla\",\"Piratla\",\"Amuse labs\"],[870,\"Chaiyasit Manovit\",\"Manovit\",\"Ixora Technology\"],[871,\"Peter Chan\",\"Chan\",\"Stanford University\"],[872,\"Monica S Lam\",\"Lam\",\"Stanford University\"],[873,\"Glynn Edwards\",\"Edwards\",\"Stanford University\"],[874,\"Scott R Klemmer\",\"Klemmer\",\"\"],[875,\"James Hollan\",\"Hollan\",\"\"],[876,\"Maria K Wolters\",\"Wolters\",\"\"],[877,\"Peter C Wright\",\"Wright\",\"Newcastle University\"],[878,\"Katie Brittain\",\"Brittain\",\"Newcastle University\"],[879,\"Kathrin M Gerling\",\"Gerling\",\"University of Lincoln\"],[880,\"Regan L Mandryk\",\"Mandryk\",\"University of Saskatchewan\"],[881,\"Conor Linehan\",\"Linehan\",\"University of Lincoln\"],[882,\"Jason Chen Zhao\",\"Zhao\",\"National University of Singapore\"],[883,\"Richard C Davis\",\"Davis\",\"Singapore Management University\"],[884,\"Pin Sym Foong\",\"Foong\",\"National University of Singapore\"],[885,\"Barbara Barbosa Neves\",\"Neves\",\"University of Toronto\"],[886,\"Rachel L Franz\",\"Franz\",\"University of Toronto\"],[887,\" \",\"\",\"\"],[888,\"Ronald Baecker\",\"Baecker\",\"University of Toronto\"],[889,\"Jessica Cauchard\",\"Cauchard\",\"\"],[890,\"Fraser Anderson\",\"Anderson\",\"Autodesk Research\"],[891,\"Daniel Wigdor\",\"Wigdor\",\"University of Toronto\"],[892,\"George Fitzmaurice\",\"Fitzmaurice\",\"Autodesk Research\"],[893,\"Youli Chang\",\"Chang\",\"Seoul National University\"],[894,\"Sehi L'Yi\",\"L'Yi\",\"Seoul National University\"],[895,\"Kyle Koh\",\"Koh\",\"Seoul National University\"],[896,\"Jinwook Seo\",\"Seo\",\"Seoul National University\"],[897,\"Audrey Girouard\",\"Girouard\",\"Carleton University\"],[898,\"Jessica Lo\",\"Lo\",\"Carleton University\"],[899,\"Md Riyadh\",\"Riyadh\",\"Carleton University\"],[900,\"Farshad Daliri\",\"Daliri\",\"Carleton University\"],[901,\"Alexander K Eady\",\"Eady\",\"Carleton University\"],[902,\"Jerome Pasquero\",\"Pasquero\",\"Blackberry Limited\"],[903,\"Matei Negulescu\",\"Negulescu\",\"University of British Columbia\"],[904,\"Joanna McGrenere\",\"McGrenere\",\"University of British Columbia\"],[905,\"Jens Müller\",\"Müller\",\"University\"],[906,\"Roman Rädle\",\"Rädle\",\"University of Konstanz\"],[907,\"Hans-Christian Jetter\",\"Jetter\",\"University College London\"],[908,\"Harald Reiterer\",\"Reiterer\",\"University\"],[909,\"Jaime Teevan\",\"Teevan\",\"\"],[910,\"Min Kyung Lee\",\"Lee\",\"Carnegie Mellon University\"],[911,\"Daniel Kusbit\",\"Kusbit\",\"Carnegie Mellon University\"],[912,\"Evan Metsky\",\"Metsky\",\"Carnegie Mellon University\"],[913,\"Laura Dabbish\",\"Dabbish\",\"Carnegie Mellon University\"],[914,\"Benjamin V Hanrahan\",\"Hanrahan\",\"Xerox Research Center Europe\"],[915,\"Jutta K Willamowski\",\"Willamowski\",\"Xerox Research Center Europe\"],[916,\"Saiganesh Swaminathan\",\"Swaminathan\",\"Xerox Research Centre Europe\"],[917,\"David B Martin\",\"Martin\",\"Xerox Research Center Europe\"],[918,\"Jennifer Marlow\",\"Marlow\",\"Carnegie Mellon University\"],[919,\"Laura A Dabbish\",\"Dabbish\",\"HCII & Heinz College, Carnegie Mellon University, Pittsburgh\"],[920,\"Jodi L Forlizzi\",\"Forlizzi\",\"Carnegie Mellon University\"],[921,\"Niloufar Salehi\",\"Salehi\",\"Stanford University\"],[922,\"Lilly C Irani\",\"Irani\",\"University of California, San Diego\"],[923,\"Ali Alkhatib\",\"Alkhatib\",\"Stanford University\"],[924,\"Eva Ogbe\",\"Ogbe\",\"Stanford University\"],[925,\"Kristy Milland\",\"Milland\",\"Ryerson University\"],[926,\"Clickhappier  \",\"\",\"We Are Dynamo\"],[927,\"Ujwal Gadiraju\",\"Gadiraju\",\"Leibniz Universitat Hannover\"],[928,\"Ricardo Kawase\",\"Kawase\",\"L3S Research Center\"],[929,\"Stefan Dietze\",\"Dietze\",\"L3S Research Center\"],[930,\"Gianluca Demartini\",\"Demartini\",\"University of Sheffield\"],[931,\"Pam Briggs\",\"Briggs\",\"\"],[932,\"Jason W Clark\",\"Clark\",\"George Mason University\"],[933,\"Peter E Snyder\",\"Snyder\",\"University of Illinois at Chicago\"],[934,\"Damon McCoy\",\"McCoy\",\"George Mason University\"],[935,\"Chris Kanich\",\"Kanich\",\"University of Illinois at Chicago\"],[936,\"Robert Templeman\",\"Templeman\",\"Indiana University\"],[937,\"Denise Anthony\",\"Anthony\",\"Dartmouth College\"],[938,\"David Crandall\",\"Crandall\",\"Indiana University Bloomington\"],[939,\"Rebecca S Portnoff\",\"Portnoff\",\"UC Berkeley\"],[940,\"Linda N Lee\",\"Lee\",\"UC Berkeley\"],[941,\"Serge Egelman\",\"Egelman\",\"University of California, Berkeley\"],[942,\"Pratyush Mishra\",\"Mishra\",\"UC Berkeley\"],[943,\"Derek Leung\",\"Leung\",\"UC Berkeley\"],[944,\"David Wagner\",\"Wagner\",\"University of California, Berkeley\"],[945,\"Norman M Su\",\"Su\",\"Indiana University\"],[946,\"Lulu Wang\",\"Wang\",\"Indiana University\"],[947,\"Raghudeep Kannavara\",\"Kannavara\",\"Intel\"],[948,\"Richard Chow\",\"Chow\",\"Intel\"],[949,\"Amy Ogan\",\"Ogan\",\"\"],[950,\"Juho Kim\",\"Kim\",\"Massachusetts Institute of Technology\"],[951,\"Elena L Glassman\",\"Glassman\",\"MIT\"],[952,\"Andres Monroy-Hernandez\",\"Monroy-Hernandez\",\"Microsoft Research\"],[953,\"Erik Andersen\",\"Andersen\",\"Cornell University\"],[954,\"Sumit Gulwani\",\"Gulwani\",\"Microsoft Research\"],[955,\"Zoran Popovic\",\"Popovic\",\"University of Washington\"],[956,\"Cuong Nguyen\",\"Nguyen\",\"Portland State University\"],[957,\"Feng Liu\",\"Liu\",\"Portland State University\"],[958,\"Shiwei Cheng\",\"Cheng\",\"Zhejiang University of Technology\"],[959,\"Zhiqiang Sun\",\"Sun\",\"Zhejiang University of Technology\"],[960,\"Lingyun Sun\",\"Sun\",\"Zhejiang University of Technology\"],[961,\"Kirsten Yee\",\"Yee\",\"Carnegie Mellon University\"],[962,\"Volker Wulf\",\"Wulf\",\"\"],[963,\"Andrew J Ko\",\"Ko\",\"University of Washington\"],[964,\"Jacob Wobbrock\",\"Wobbrock\",\"University of Washington\"],[965,\"David P Randall\",\"Randall\",\"University of Washington\"],[966,\"E.Ilana Diamant\",\"Diamant\",\"University of Washington\"],[967,\"Sarah Barbrow\",\"Barbrow\",\"Wellesley College\"],[968,\"Pernille Bjorn\",\"Bjorn\",\"IT University of Copenhagen\"],[969,\"Morten Esbensen\",\"Esbensen\",\"IT University of Copenhagen\"],[970,\"Rasmus E Jensen\",\"Jensen\",\"IT University of Copenhagen\"],[971,\"Stina Matthiessen\",\"Matthiessen\",\"IT University of Copenhagen\"],[972,\"Gina Venolia\",\"Venolia\",\"\"],[973,\"Jennifer Hyde\",\"Hyde\",\"Carnegie Mellon University\"],[974,\"Elizabeth J Carter\",\"Carter\",\"Carnegie Mellon University\"],[975,\"Sara Kiesler\",\"Kiesler\",\"Carnegie Mellon University\"],[976,\"Jessica K Hodgins\",\"Hodgins\",\"Carnegie Mellon University\"],[977,\"Ikkaku KAWAGUCHI\",\"KAWAGUCHI\",\"University of Tsukuba\"],[978,\"Yusuke SUZUKI\",\"SUZUKI\",\"OKI Electric Industry Co.,Ltd\"],[979,\"Ha Trinh\",\"Trinh\",\"Northeastern University\"],[980,\"Lazlo Ring\",\"Ring\",\"Northeastern University\"],[981,\"Timothy Bickmore\",\"Bickmore\",\"Northeastern University\"],[982,\"Jarmo Laaksolahti\",\"Laaksolahti\",\"Mobile Life @ SICS\"],[983,\"Kristina Höök\",\"Höök\",\"KTH - Royal Institute of Technology\"],[984,\"Sandy J Gould\",\"Gould\",\"University College London\"],[985,\"Duncan P Brumby\",\"Brumby\",\"University College London\"],[986,\"Anna L Cox\",\"Cox\",\"University College London\"],[987,\"Jettie Hoonhout\",\"Hoonhout\",\"Philips Research\"],[988,\"David Lamas\",\"Lamas\",\"Tallinn University\"],[989,\"Effie Law\",\"Law\",\"University of Leicester\"],[990,\"Guy A Boy\",\"Boy\",\"Florida Institute of Technology\"],[991,\"Jeffrey M Bradshaw\",\"Bradshaw\",\"Florida Institute for Human and Machine Cognition\"],[992,\"Soyeon Yi\",\"Yi\",\"International Space University\"],[993,\"David Coyle\",\"Coyle\",\"\"],[994,\"Logan Kendall\",\"Kendall\",\"Microsoft Research\"],[995,\"Dan Morris\",\"Morris\",\"Microsoft Research\"],[996,\"Desney Tan\",\"Tan\",\"Microsoft Research\"],[997,\"Aisling Ann O'Kane\",\"O'Kane\",\"University College London\"],[998,\"Yvonne Rogers\",\"Rogers\",\"University College London\"],[999,\"Ann E Blandford\",\"Blandford\",\"University College London\"],[1000,\"Jeni Paay\",\"Paay\",\"Aalborg University\"],[1001,\"Jesper Kjeldskov\",\"Kjeldskov\",\"Aalborg University\"],[1002,\"Lars Lichon\",\"Lichon\",\"Aalborg University\"],[1003,\"Stephan Rasmussen\",\"Rasmussen\",\"Aalborg University\"],[1004,\"Rob Comber\",\"Comber\",\"Newcastle University\"],[1005,\"Selina Sutton\",\"Sutton\",\"Newcastle University\"],[1006,\"Ed Jenkins\",\"Jenkins\",\"Newcastle University\"],[1007,\"Andy Garbett\",\"Garbett\",\"Newcastle University\"],[1008,\"David Kim\",\"Kim\",\"\"],[1009,\"Madeline Gannon\",\"Gannon\",\"Carnegie Mellon University\"],[1010,\"Huaishu Peng\",\"Peng\",\"Cornell University\"],[1011,\"Jennifer Mankoff\",\"Mankoff\",\"Carnegie Mellon University\"],[1012,\"James McCann\",\"McCann\",\"Disney Research\"],[1013,\"Dustin Beyer\",\"Beyer\",\"Hasso Plattner Institute\"],[1014,\"Serafima Gurevich\",\"Gurevich\",\"Hasso Plattner Institute\"],[1015,\"Stefanie Mueller\",\"Mueller\",\"Hasso Plattner Institute\"],[1016,\"Hsiang-Ting Chen\",\"Chen\",\"Hasso Plattner Institute\"],[1017,\"François V Guimbretière\",\"Guimbretière\",\"Cornell University, Information Science\"],[1018,\"Hao-Hua Chu\",\"Chu\",\"\"],[1019,\"Mads Møller Jensen\",\"Jensen\",\"Aarhus University\"],[1020,\"Majken K Rasmussen\",\"Rasmussen\",\"Aarhus University\"],[1021,\"Kaj \\\" Grønbæk\",\"Grønbæk\",\"Aarhus University\"],[1022,\"Kristina M Knaving\",\"Knaving\",\"University of Gothenburg\"],[1023,\"Paweł W Woźniak\",\"Woźniak\",\"Chalmers University of Technology\"],[1024,\"Staffan L Björk\",\"Björk\",\"University of Gothenburg\"],[1025,\"Matthew Muirhead\",\"Muirhead\",\"RMIT University\"],[1026,\"Felix Kosmalla\",\"Kosmalla\",\"German Research Center for Artificial Intelligence (DFKI)\"],[1027,\"Florian Daiber\",\"Daiber\",\"German Research Center for Artificial Intelligence (DFKI)\"],[1028,\"Rongrong Wang\",\"Wang\",\"\"],[1029,\"Akshita Akshita\",\"Akshita\",\"International Institute of Information Technology\"],[1030,\"Harini Alagarai Sampath\",\"Sampath\",\"International Institute of Information Technology\"],[1031,\"Bipin Indurkhya\",\"Indurkhya\",\"International Institute of Information Technology\"],[1032,\"Eunhwa Lee\",\"Lee\",\"Samsung Electronics Co. Ltd.\"],[1033,\"Yudong Bae\",\"Bae\",\"Samsung Electronics Co. Ltd.\"],[1034,\"Marianna Obrist\",\"Obrist\",\"University of Sussex\"],[1035,\"Elia Gatti\",\"Gatti\",\"University of Birmingham\"],[1036,\"Benjamin Long\",\"Long\",\"Ultrahaptics Limited\"],[1037,\"Thomas Carter\",\"Carter\",\"Ultrahaptics Limited\"],[1038,\"Graham Wilson\",\"Wilson\",\"University of Glasgow\"],[1039,\"Gavin Davidson\",\"Davidson\",\"University of Glasgow\"],[1040,\"Stephen Brewster\",\"Brewster\",\"University of Glasgow\"],[1041,\"Deltcho Valtchanov\",\"Valtchanov\",\"University of Waterloo\"],[1042,\"Mark Hancock\",\"Hancock\",\"University of Waterloo\"],[1043,\"Jennifer Marlow\",\"Marlow\",\"\"],[1044,\"Tawfiq Ammari\",\"Ammari\",\"University of Michigan\"],[1045,\"Priya Kumar\",\"Kumar\",\"University of Michigan\"],[1046,\"Cliff Lampe\",\"Lampe\",\"University of Michigan\"],[1047,\"Sarita Schoenebeck\",\"Schoenebeck\",\"University of Michigan\"],[1048,\"Daniela Petrelli\",\"Petrelli\",\"Sheffield Hallam University \"],[1049,\"Ann Light\",\"Light\",\"Northumbria University\"],[1050,\"Sarah L Mascher\",\"Mascher\",\"University of Iowa\"],[1051,\"David C Wu\",\"Wu\",\"University of Iowa\"],[1052,\"Luiza Pantoja\",\"Pantoja\",\"University of Iowa\"],[1053,\"Theophanis Tsandilas\",\"Tsandilas\",\"\"],[1054,\"Jürgen Steimle\",\"Steimle\",\"Max Planck Institute for Informatics\"],[1055,\"Jonathan Deber\",\"Deber\",\"University of Toronto\"],[1056,\"Ricardo Jota\",\"Jota\",\"University of Toronto\"],[1057,\"Clifton Forlines\",\"Forlines\",\"Tactual Labs\"],[1058,\"Daniel Avrahami\",\"Avrahami\",\"FXPAL\"],[1059,\"Ying-Chao Tung\",\"Tung\",\"National Taiwan University\"],[1060,\"Ta Yang Cheng\",\"Cheng\",\"National Taiwan University\"],[1061,\"Neng-Hao Yu\",\"Yu\",\"National Chengchi University\"],[1062,\"Chiuan Wang\",\"Wang\",\"National Taiwan University\"],[1063,\"Kunihiro Kato\",\"Kato\",\"Meiji University\"],[1064,\"Homei Miyashita\",\"Miyashita\",\"Meiji University\"],[1065,\"Uichin Lee\",\"Lee\",\"\"],[1066,\"Nick Rafter\",\"Rafter\",\"Independent\"],[1067,\"Onkur Sen\",\"Sen\",\"Stanford\"],[1068,\"Gierad Laput\",\"Laput\",\"Carnegie Mellon University\"],[1069,\"Jason Wiese\",\"Wiese\",\"Carnegie Mellon University\"],[1070,\"Robert Xiao\",\"Xiao\",\"Carnegie Mellon University\"],[1071,\"Mitchell Gordon\",\"Gordon\",\"University of Rochester\"],[1072,\"Winnie Leung\",\"Leung\",\"Carnegie Mellon University\"],[1073,\"Ellen Lim\",\"Lim\",\"Carnegie Mellon University\"],[1074,\"Steven P Dow\",\"Dow\",\"Carnegie Mellon University\"],[1075,\"Jahna Otterbacher\",\"Otterbacher\",\"Open University\"],[1076,\"Germaine Irwin\",\"Irwin\",\"\"],[1077,\"Will Simm\",\"Simm\",\"Lancaster University\"],[1078,\"Adrian Friday\",\"Friday\",\"Lancaster University\"],[1079,\"Peter Newman\",\"Newman\",\"Lancaster University\"],[1080,\"Stephen Forshaw\",\"Forshaw\",\"Lancaster University\"],[1081,\"Mike Hazas\",\"Hazas\",\"Lancaster University\"],[1082,\"Alan Dix\",\"Dix\",\"Talis\"],[1083,\"Valerie Sugarman\",\"Sugarman\",\"University of Waterloo\"],[1084,\"Edward Lank\",\"Lank\",\"University of Waterloo\"],[1085,\"Dennis Lund\",\"Lund\",\"Aalborg University\"],[1086,\"Tue Madsen\",\"Madsen\",\"Aalborg University\"],[1087,\"Michael Nielsen\",\"Nielsen\",\"Aalborg University\"],[1088,\"Ray Yun\",\"Yun\",\"Carnegie Mellon University\"],[1089,\"Azizan Aziz\",\"Aziz\",\"Carnegie Mellon University\"],[1090,\"Peter Scupelli\",\"Scupelli\",\"Carnegie Mellon University\"],[1091,\"Bertrand Lasternas\",\"Lasternas\",\"Carnegie Mellon University\"],[1092,\"Chenlu Zhang\",\"Zhang\",\"Carnegie Mellon University\"],[1093,\"Vivian Loftness\",\"Loftness\",\"Carnegie Mellon University\"],[1094,\"Steven M Drucker\",\"Drucker\",\"\"],[1095,\"Michael Nebeling\",\"Nebeling\",\"ETH Zurich\"],[1096,\"Matthias Geel\",\"Geel\",\"ETH Zurich\"],[1097,\"Oleksiy Syrotkin\",\"Syrotkin\",\"ETH Zurich\"],[1098,\"Moira Norrie\",\"Norrie\",\"ETH Zurich\"],[1099,\"Dakuo Wang\",\"Wang\",\"University of California, Irvine\"],[1100,\"Judith S Olson\",\"Olson\",\"University of California, Irvine\"],[1101,\"Jingwen Zhang\",\"Zhang\",\"University of California, Irvine\"],[1102,\"Trung Nguyen\",\"Nguyen\",\"University of California, Irvine\"],[1103,\"Gary M Olson\",\"Olson\",\"University of California, Irvine\"],[1104,\"Johan K Blomkvist\",\"Blomkvist\",\"Linköping University\"],[1105,\"Johan Persson\",\"Persson\",\"IDA\"],[1106,\"Johan Aberg\",\"Aberg\",\"Linköpings universitet\"],[1107,\"Gary W Pritchard\",\"Pritchard\",\"Newcastle University\"],[1108,\"Pam Briggs\",\"Briggs\",\"Northumbria University\"],[1109,\"Giulio Jacucci\",\"Jacucci\",\"\"],[1110,\"James Pierce\",\"Pierce\",\"Carnegie Mellon University\"],[1111,\"Phoebe J Sengers\",\"Sengers\",\"Cornell University\"],[1112,\"Tad Hirsch\",\"Hirsch\",\"University of Washington\"],[1113,\"Tom Jenkins\",\"Jenkins\",\"Georgia Tech\"],[1114,\"William W Gaver\",\"Gaver\",\"Goldsmiths College\"],[1115,\"Carl DiSalvo\",\"DiSalvo\",\"Georgia Institute of Technology\"],[1116,\"Lone Koefoed Hansen\",\"Hansen\",\"Aarhus University\"],[1117,\"Eric Paulos\",\"Paulos\",\"University of California, Berkeley\"],[1118,\"Jae-eul Bae\",\"Bae\",\"KAIST\"],[1119,\"Youn-kyung Lim\",\"Lim\",\"KAIST\"],[1120,\"Jin-bae Bang\",\"Bang\",\"KAKAOLAB\"],[1121,\"Myung-suk Kim\",\"Kim\",\"KAIST\"],[1122,\"Sharon Oviatt\",\"Oviatt\",\"\"],[1123,\"Judith Masthoff\",\"Masthoff\",\"University of Aberdeen\"],[1124,\"Ehud Reiter\",\"Reiter\",\"University of Aberdeen\"],[1125,\"Yvonne Freer\",\"Freer\",\"NHS Lothian\"],[1126,\"Hien Nguyen\",\"Nguyen\",\"University of Aberdeen\"],[1127,\"S. Shyam Sundar\",\"Sundar\",\"The Pennsylvania State University\"],[1128,\"Saraswathi Bellur\",\"Bellur\",\"University of Connecticut\"],[1129,\"Jeeyun Oh\",\"Oh\",\"Robert Morris University\"],[1130,\"Qian Xu\",\"Xu\",\"Elon University\"],[1131,\"Haiyan Jia\",\"Jia\",\"Pennsylvania State University\"],[1132,\"Seok-Hyung Bae\",\"Bae\",\"KAIST\"],[1133,\"Ravin Balakrishnan\",\"Balakrishnan\",\"University of Toronto\"],[1134,\"Tuomo Kujala\",\"Kujala\",\"University of Jyväskylä\"],[1135,\"Michael J Lyons\",\"Lyons\",\"Ritsumeikan University\"],[1136,\"Sidney S Fels\",\"Fels\",\"University of British Columbia\"],[1137,\"Hironobu Takagi\",\"Takagi\",\"\"],[1138,\"Yu Zhong\",\"Zhong\",\"University of Rochester\"],[1139,\"Erin Brady\",\"Brady\",\"University of Rochester\"],[1140,\"Aaron Steinfeld\",\"Steinfeld\",\"Carnegie Mellon University\"],[1141,\"Roy Shilkrot\",\"Shilkrot\",\"Massachusetts Institute of Technology\"],[1142,\"Jochen Huber\",\"Huber\",\"Singapore University of Technology and Design\"],[1143,\"Wong Meng Ee\",\"Ee\",\"National Institute of Education\"],[1144,\"Pattie Maes\",\"Maes\",\"Massachusetts Institute of Technology\"],[1145,\"Suranga C Nanayakkara\",\"Nanayakkara\",\"Singapore University of Technology and Design\"],[1146,\"Stacy M Branham\",\"Branham\",\"University of Maryland Baltimore County\"],[1147,\"Shengdong Zhao\",\"Zhao\",\"\"],[1148,\"Christian Corsten\",\"Corsten\",\"RWTH Aachen University\"],[1149,\"Christian Cherek\",\"Cherek\",\"RWTH Aachen University\"],[1150,\"Thorsten Karrer\",\"Karrer\",\"RWTH Aachen University\"],[1151,\"Young-Woo Park\",\"Park\",\"KAIST\"],[1152,\"Joohee Park\",\"Park\",\"KAIST (Korea Advanced Institute of Science and Technology)\"],[1153,\"Munehiko Sato\",\"Sato\",\"MIT Media Lab\"],[1154,\"Shigeo Yoshida\",\"Yoshida\",\"The University of Tokyo\"],[1155,\"Alex Olwal\",\"Olwal\",\"MIT Media Lab, Cambridge\"],[1156,\"Boxin Shi\",\"Shi\",\"MIT Media Lab\"],[1157,\"Atsushi Hiyama\",\"Hiyama\",\"The University of Tokyo\"],[1158,\"Tomohiro Tanikawa\",\"Tanikawa\",\"The University of Tokyo\"],[1159,\"Michitaka Hirose\",\"Hirose\",\"The University of Tokyo\"],[1160,\"Ramesh Raskar\",\"Raskar\",\"MIT Media Lab\"],[1161,\"Katharina Reinecke\",\"Reinecke\",\"\"],[1162,\"Angelika Strohmayer\",\"Strohmayer\",\"Newcastle University\"],[1163,\"Tawanna R Dillahunt\",\"Dillahunt\",\"University of Michigan\"],[1164,\"Amelia R Malone\",\"Malone\",\"University of Maryland\"],[1165,\"Claudia Müller\",\"Müller\",\"University of Siegen\"],[1166,\"Dominik Hornung\",\"Hornung\",\"University of Siegen\"],[1167,\"Theodor Hamm\",\"Hamm\",\"University of Siegen\"],[1168,\"Volker Wulf\",\"Wulf\",\"University of Siegen\"],[1169,\"Jessica A Pater\",\"Pater\",\"Georgia Institute of Technology\"],[1170,\"Andrew D Miller\",\"Miller\",\"University of Washington\"],[1171,\"Elizabeth D Mynatt\",\"Mynatt\",\"Georgia Institute of Technology\"],[1172,\"Serge Egelman\",\"Egelman\",\"\"],[1173,\"Mahdi Nasrullah Al-Ameen\",\"Al-Ameen\",\"The University of Texas at Arlington\"],[1174,\"Matthew Wright\",\"Wright\",\"The University of Texas at Arlington\"],[1175,\"Shannon Scielzo\",\"Scielzo\",\"The University of Texas at Arlington\"],[1176,\"Sourav K Dandapat\",\"Dandapat\",\"IIT Kharagpur\"],[1177,\"Swadhin Pradhan\",\"Pradhan\",\"University of Texas at Austin\"],[1178,\"Bivas Mitra\",\"Mitra\",\"Indian Institute of Technology\"],[1179,\"Romit Roy Choudhury\",\"Choudhury\",\"University of Illinois at Urbana-Champaign\"],[1180,\"Niloy Ganguly\",\"Ganguly\",\"IIT Kharagpur\"],[1181,\"Hendrik Meutzner\",\"Meutzner\",\"Ruhr University Bochum\"],[1182,\"Santosh Gupta\",\"Gupta\",\"Visvesvaraya National Institute of Technology\"],[1183,\"Dorothea Kolossa\",\"Kolossa\",\"Ruhr University Bochum\"],[1184,\"Philipp Janssen\",\"Janssen\",\"University of Munich (LMU)\"],[1185,\"Youngbae Song\",\"Song\",\"Sungkyunkwan University\"],[1186,\"Geumhwan Cho\",\"Cho\",\"Sungkyunkwan University\"],[1187,\"Seongyeol Oh\",\"Oh\",\"Sungkyunkwan University\"],[1188,\"Hyoungshick Kim\",\"Kim\",\"Sungkyunkwan University\"],[1189,\"Jun Ho Huh\",\"Huh\",\"Honeywell\"],[1190,\"Tom Gross\",\"Gross\",\"\"],[1191,\"Malte F Jung\",\"Jung\",\"Cornell University\"],[1192,\"David Sirkin\",\"Sirkin\",\"Stanford\"],[1193,\"Turgut M Gür\",\"Gür\",\"Stanford University\"],[1194,\"Martin Steinert\",\"Steinert\",\"Norwegian University of Science and Technology\"],[1195,\"Yunfeng Zhang\",\"Zhang\",\"University of Oregon\"],[1196,\"Rachel K Bellamy\",\"Bellamy\",\"IBM T. J. Watson Research Center\"],[1197,\"Wendy A Kellogg\",\"Kellogg\",\"IBM T.J. Watson Research Center\"],[1198,\"Jussi P Jokinen\",\"Jokinen\",\"University of Jyväskylä\"],[1199,\"Johanna M Silvennoinen\",\"Silvennoinen\",\"University of Jyväskylä\"],[1200,\"Piia M Perälä\",\"Perälä\",\"University of Jyväskylä\"],[1201,\"Pertti O Saariluoma\",\"Saariluoma\",\"University of Jyväskylä\"],[1202,\"Florian Mueller\",\"Mueller\",\"\"],[1203,\"Adam M Smith\",\"Smith\",\"University of Washington\"],[1204,\"John Rooksby\",\"Rooksby\",\"University of Glasgow\"],[1205,\"Mattias Rost\",\"Rost\",\"University of Glasgow\"],[1206,\"Alistair Morrison\",\"Morrison\",\"University of Glasgow\"],[1207,\"Matthew Chalmers\",\"Chalmers\",\"University of Glasgow\"],[1208,\"Dimitrios P Darzentas\",\"Darzentas\",\"University of Nottingham\"],[1209,\"Michael A Brown\",\"Brown\",\"The University of Nottingham\"],[1210,\"Martin Flintham\",\"Flintham\",\"University of Nottingham\"],[1211,\"Khaled Bachour\",\"Bachour\",\"University of Nottingham\"],[1212,\"Richard Wetzel\",\"Wetzel\",\"University of Nottingham\"],[1213,\"Trung Dong Huynh\",\"Huynh\",\"University of Southampton\"],[1214,\"Luc Moreau\",\"Moreau\",\"University of Southampton\"],[1215,\"Morgan Ames\",\"Ames\",\"\"],[1216,\"Laura Devendorf\",\"Devendorf\",\"University of California, Berkeley\"],[1217,\"Rachel Jacobs\",\"Jacobs\",\"The University of Nottingham\"],[1218,\"Ewa A Luger\",\"Luger\",\"Microsoft Research\"],[1219,\"Suk Kyoung Choi\",\"Choi\",\"Simon Fraser University\"],[1220,\"Steve DiPaola\",\"DiPaola\",\"Simon Fraser University\"],[1221,\"Sabine Harrer\",\"Harrer\",\"University of Vienna\"],[1222,\"Ben J Kirman\",\"Kirman\",\"University of Lincoln\"],[1223,\"Shaun W Lawson\",\"Lawson\",\"University of Lincoln\"],[1224,\"Marcus Carter\",\"Carter\",\"The University of Melbourne\"],[1225,\"Jan D Smeddinck\",\"Smeddinck\",\"\"],[1226,\"Casper Harteveld\",\"Harteveld\",\"Northeastern University\"],[1227,\"Steven C Sutherland\",\"Sutherland\",\"Northeastern University\"],[1228,\"Ioanna Iacovides\",\"Iacovides\",\"University College London\"],[1229,\"Rodrigo Vicencio-Moreira\",\"Vicencio-Moreira\",\"University of Saskatchewan\"],[1230,\"Daniel Johnson\",\"Johnson\",\"Queensland University of Technology\"],[1231,\"Peta A Wyeth\",\"Wyeth\",\"Queensland University of Technology\"],[1232,\"Gerald Penn\",\"Penn\",\"University of Toronto\"],[1233,\"Hendrik Müller\",\"Müller\",\"Google Australia\"],[1234,\"Aaron Sedley\",\"Sedley\",\"Google, Inc.\"],[1235,\"Shahram Izadi\",\"Izadi\",\"\"],[1236,\"Xianjun  S Zheng\",\"Zheng\",\"Siemens Corporate Research\"],[1237,\"Cedric Foucault\",\"Foucault\",\"Siemens Corporate Research\"],[1238,\"Patrik Matos da Silva \",\"\",\"Siemens Corporate Research\"],[1239,\"Siddharth Dasari\",\"Dasari\",\"Siemens Corporate Research\"],[1240,\"Tao Yang\",\"Yang\",\"Siemens Corporate Research\"],[1241,\"Stuart Goose\",\"Goose\",\"Siemens Technology to Business\"],[1242,\"Philipp Hock\",\"Hock\",\"Ulm University\"],[1243,\"Felix Lauber\",\"Lauber\",\"University of Munich (LMU)\"],[1244,\"Sophia Cook\",\"Cook\",\"University of Munich (LMU)\"],[1245,\"Andreas Butz\",\"Butz\",\"University of Munich (LMU)\"],[1246,\"Mark McGill\",\"McGill\",\"University of Glasgow\"],[1247,\"Daniel Boland\",\"Boland\",\"University of Glasgow\"],[1248,\"Roderick Murray-Smith\",\"Murray-Smith\",\"University of Glasgow\"],[1249,\"Stephen A Brewster\",\"Brewster\",\"University of Glasgow\"],[1250,\"Ilias Apostolopoulos\",\"Apostolopoulos\",\"University of Nevada, Reno\"],[1251,\"Dan Coming\",\"Coming\",\"Google Inc\"],[1252,\"Eelke Folmer\",\"Folmer\",\"University of Nevada, Reno\"],[1253,\"Dominik Schmidt\",\"Schmidt\",\"Hasso Plattner Institute\"],[1254,\"Rob Kovacs\",\"Kovacs\",\"Hasso Plattner Institute\"],[1255,\"Vikram Mehta\",\"Mehta\",\"Hasso Plattner Institute\"],[1256,\"Udayan Umapathi\",\"Umapathi\",\"Hasso Plattner Institute\"],[1257,\"Sven Köhler\",\"Köhler\",\"Hasso Plattner Institute\"],[1258,\"Lung-Pan Cheng\",\"Cheng\",\"Hasso Plattner Institute\"],[1259,\"John Tang\",\"Tang\",\"\"],[1260,\"Keita Higuchi\",\"Higuchi\",\"The University of Tokyo\"],[1261,\"Yinpeng Chen\",\"Chen\",\"Microsoft Corporation\"],[1262,\"Philip A Chou\",\"Chou\",\"Microsoft Corporation\"],[1263,\"Zhengyou Zhang\",\"Zhang\",\"Microsoft Corporation\"],[1264,\"Zicheng Liu\",\"Liu\",\"Microsoft\"],[1265,\"Ignacio Avellino\",\"Avellino\",\"Inria\"],[1266,\"Cédric Fleury\",\"Fleury\",\"Univ Paris-Sud & CNRS\"],[1267,\"Michel Beaudouin-Lafon\",\"Beaudouin-Lafon\",\"Univ Paris-Sud & CNRS\"],[1268,\"Steven J Johnson\",\"Johnson\",\"University of Wisconsin-Madison\"],[1269,\"Irene Rae\",\"Rae\",\"University of Wisconsin, Madison\"],[1270,\"Bilge Mutlu\",\"Mutlu\",\"University of Wisconsin, Madison\"],[1271,\"Leila A Takayama\",\"Takayama\",\"Willow Garage\"],[1272,\"Carolyn Pang\",\"Pang\",\"Simon Fraser University\"],[1273,\"Azadeh Forghani\",\"Forghani\",\"Simon Fraser University\"],[1274,\"Serena Hillman\",\"Hillman\",\"Simon Fraser University\"],[1275,\"Tejinder K Judge\",\"Judge\",\"Google Inc. \"],[1276,\"Michael Massimi\",\"Massimi\",\"Facebook\"],[1277,\"Rodrigo de Oliveira\",\"Oliveira\",\"\"],[1278,\"Victoria Hollis\",\"Hollis\",\"University of California at Santa Cruz\"],[1279,\"Artie Konrad\",\"Konrad\",\"University of California, Santa Cruz\"],[1280,\"Katarzyna Stawarz\",\"Stawarz\",\"University College London\"],[1281,\"Ann Blandford\",\"Blandford\",\"University College London\"],[1282,\"Shaun Lawson\",\"Lawson\",\"University of Lincoln\"],[1283,\"Ben Kirman\",\"Kirman\",\"University of Lincoln\"],[1284,\"Tom Feltwell\",\"Feltwell\",\"University of Lincoln\"],[1285,\"Lisa Hopkins\",\"Hopkins\",\"University of Lincoln\"],[1286,\"Clara Mancini\",\"Mancini\",\"The Open University\"],[1287,\"Rob Harris\",\"Harris\",\"Medical Detection Dogs\"],[1288,\"Brendan Aengenheister\",\"Aengenheister\",\"The Open University\"],[1289,\"Claire Guest\",\"Guest\",\"Medical Detection Dogs\"],[1290,\"Benjamin Bach\",\"Bach\",\"\"],[1291,\"Emanuel Zgraggen\",\"Zgraggen\",\"Brown University\"],[1292,\"Danyel Fisher\",\"Fisher\",\"Microsoft Research\"],[1293,\"Robert DeLine\",\"DeLine\",\"Microsoft Research\"],[1294,\"Chat Wacharamanotham\",\"Wacharamanotham\",\"RWTH Aachen University\"],[1295,\"Krishna Subramanian\",\"Subramanian\",\"RWTH Aachen University\"],[1296,\"Sarah Theres Völkel\",\"Völkel\",\"RWTH Aachen University\"],[1297,\"Romain Vuillemot\",\"Vuillemot\",\"Harvard University\"],[1298,\"Charles Perin\",\"Perin\",\"INRIA Saclay\"],[1299,\"Justin Matejka\",\"Matejka\",\"Autodesk Research\"],[1300,\"Eric D Ragan\",\"Ragan\",\"Oak Ridge National Laboratory\"],[1301,\"John R Goodall\",\"Goodall\",\"Oak Ridge National Laboratory\"],[1302,\"Albert Tung\",\"Tung\",\"Rio Hondo College\"],[1303,\"Thecla Schiphorst\",\"Schiphorst\",\"\"],[1304,\"Yue Pan\",\"Pan\",\"Indiana University Bloomington\"],[1305,\"Erik Stolterman\",\"Stolterman\",\"Indiana University Bloomington\"],[1306,\"Leif Oppermann\",\"Oppermann\",\"Fraunhofer FIT\"],[1307,\"Clemens Putschli\",\"Putschli\",\"Fraunhofer FIT\"],[1308,\"Constantin Brosda\",\"Brosda\",\"Fraunhofer FIT\"],[1309,\"Oleksandr Lobunets\",\"Lobunets\",\"Fraunhofer FIT\"],[1310,\"Fabien Prioville\",\"Prioville\",\"Fabien Prioville Dance Company\"],[1311,\"Christian Greiffenhagen\",\"Greiffenhagen\",\"Loughborough University\"],[1312,\"Matt Adams\",\"Adams\",\"Blast Theory\"],[1313,\"Ju Row Farr\",\"Farr\",\"Blast Theory\"],[1314,\"Nicholas Tandavantij\",\"Tandavantij\",\"Blast Theory\"],[1315,\"Rachel Clarke\",\"Clarke\",\"Newcastle University\"],[1316,\"John McCarthy\",\"McCarthy\",\"University College Cork\"],[1317,\"Kate Anderson\",\"Anderson\",\"Helix Arts\"],[1318,\"Jane Dudman\",\"Dudman\",\"Newcastle University\"],[1319,\"Seung Ah Lee\",\"Lee\",\"Stanford University\"],[1320,\"Engin Bumbacher\",\"Bumbacher\",\"Stanford University\"],[1321,\"Alice M Chung\",\"Chung\",\"Stanford University\"],[1322,\"Nate Cira\",\"Cira\",\"Stanford\"],[1323,\"Byron Walker\",\"Walker\",\"Stanford University\"],[1324,\"Ji Young Park\",\"Park\",\"Stanford University\"],[1325,\"Barry Starr\",\"Starr\",\"Stanford University\"],[1326,\"Paulo Blikstein\",\"Blikstein\",\"Stanford University\"],[1327,\"Ingmar H Riedel-Kruse\",\"Riedel-Kruse\",\"Stanford University\"],[1328,\"Max Wilson\",\"Wilson\",\"\"],[1329,\"Jessalyn Alvina\",\"Alvina\",\"National University of Singapore\"],[1330,\"Thijs Roumen\",\"Roumen\",\"National University of Singapore\"],[1331,\"Maryam Azh\",\"Azh\",\"National University of Singapore\"],[1332,\"Edward J Wang\",\"Wang\",\"University of Washington\"],[1333,\"Max Pfeiffer\",\"Pfeiffer\",\"University of Hannover\"],[1334,\"Tim Dünte\",\"Dünte\",\"University of Hannover\"],[1335,\"Stefan Schneegass\",\"Schneegass\",\"University of Stuttgart\"],[1336,\"Michael Rohs\",\"Rohs\",\"University of Hannover\"],[1337,\"N. Sadat Shami\",\"Shami\",\"\"],[1338,\"Amy X Zhang\",\"Zhang\",\"Massachusetts Institute of Technology\"],[1339,\"Scott Counts\",\"Counts\",\"Microsoft Research\"],[1340,\"Jeremy Birnholtz\",\"Birnholtz\",\"Northwestern University\"],[1341,\"Nicholas A Merola\",\"Merola\",\"Northwestern University\"],[1342,\"Arindam Paul\",\"Paul\",\"Northwestern University\"],[1343,\"Jae Won Kim\",\"Kim\",\"KAIST\"],[1344,\"Dongwoo Kim\",\"Kim\",\"KAIST\"],[1345,\"Brian Keegan\",\"Keegan\",\"Northeastern University\"],[1346,\"Joon Hee Kim\",\"Kim\",\"KAIST\"],[1347,\"Suin Kim\",\"Kim\",\"KAIST\"],[1348,\"Alice Oh\",\"Oh\",\"KAIST (Korea Advanced Institute of Science and Technology)\"],[1349,\"Yelena Mejova\",\"Mejova\",\"Qatar Computing Research Institute\"],[1350,\"Javier Borge-Holthoefer\",\"Borge-Holthoefer\",\"Qatar Computing Research Institute\"],[1351,\"Ingmar Weber\",\"Weber\",\"Qatar Computing Research Institute\"],[1352,\"Yvonne Rogers\",\"Rogers\",\"\"],[1353,\"Anthony Jameson\",\"Jameson\",\"German Research Center for Artificial Intelligence (DFKI)\"],[1354,\"Bettina Berendt\",\"Berendt\",\"KU Leuven\"],[1355,\"Silvia Gabrielli\",\"Gabrielli\",\"Create-Net\"],[1356,\"Federica Cena\",\"Cena\",\"University of Turin\"],[1357,\"Cristina Gena\",\"Gena\",\"University of Turin\"],[1358,\"Fabiana Vernero\",\"Vernero\",\"University of Turin\"],[1359,\"Sunny Consolvo\",\"Consolvo\",\"Google, Inc.\"],[1360,\"Predrag V Klasnja\",\"Klasnja\",\"University of Michigan\"],[1361,\"David W McDonald\",\"McDonald\",\"University of Washington\"],[1362,\"James A Landay\",\"Landay\",\"Stanford University\"],[1363,\"Davide Spano\",\"Spano\",\"\"],[1364,\"Frederic Dehais\",\"Dehais\",\"ISAE\"],[1365,\"Vsevolod Peysakhovich\",\"Peysakhovich\",\"ISAE\"],[1366,\"Sébastien Scannella\",\"Scannella\",\"ISAE\"],[1367,\"Jennifer Fongue\",\"Fongue\",\"ISAE\"],[1368,\"Thibault Gateau\",\"Gateau\",\"ISAE\"],[1369,\"Michael E Young\",\"Young\",\"Kansas State University\"],[1370,\"Julia Schwarz\",\"Schwarz\",\"Carnegie Mellon University\"],[1371,\"Hanchuan Li\",\"Li\",\"University of Washington\"],[1372,\"Can Ye\",\"Ye\",\"Disney Research\"],[1373,\"Alanson P Sample\",\"Sample\",\"Disney Research\"],[1374,\"Eli Blevis\",\"Blevis\",\"School of Informatics & Computing, Indiana University\"],[1375,\"Ilpo K Koskinen\",\"Koskinen\",\"The Hong Polytechnic University\"],[1376,\"KunPyo Lee\",\"Lee\",\"Department of Industrial Design, KAIST\"],[1377,\"Susanne Bødker\",\"Bødker\",\"Aarhus University\"],[1378,\"Lin-Lin Chen\",\"Chen\",\"National Taiwan University of Science and Technology\"],[1379,\"Huaxin Wei\",\"Wei\",\"The Hong Kong Polytechnic University\"],[1380,\"Jared S Bauer\",\"Bauer\",\"University of Washington\"],[1381,\"Mark W Newman\",\"Newman\",\"University of Michigan\"],[1382,\"Amanda M Williams\",\"Williams\",\"Fabule Fabrications, Inc.\"],[1383,\"Silvia Lindtner\",\"Lindtner\",\"University of Michigan\"],[1384,\"ken t anderson\",\"anderson\",\"Intel Corporation\"],[1385,\"Paul Dourish\",\"Dourish\",\"University of California, Irvine\"],[1386,\"Jieun Kim\",\"Kim\",\"Hanyang University\"],[1387,\"Hokyoung Ryu\",\"Ryu\",\"Hanyang University\"],[1388,\"Flore Barcellini\",\"Barcellini\",\"Ergonomics Lab, Research center on work and development, Cnam\"],[1389,\"Jean-marie Burkhardt\",\"Burkhardt\",\"Institut Français des Sciences et Technologies des Transports, de l'Aménagement et des Réseaux\"],[1390,\"Stefanie Mueller\",\"Mueller\",\"\"],[1391,\"Elisa Giaccardi\",\"Giaccardi\",\"Delft University of Technology\"],[1392,\"Elvin Karana\",\"Karana\",\"Delft University of Technology\"],[1393,\"Raf Ramakers\",\"Ramakers\",\"Hasselt University - tUL - iMinds\"],[1394,\"Kashyap Todi\",\"Todi\",\"Hasselt University - tUL - iMinds\"],[1395,\" Thad Starner\",\"Starner\",\"Georgia Institute of Technology\"],[1396,\"John Tang\",\"Tang\",\"Microsoft Research\"],[1397,\"Xiangshi Ren\",\"Ren\",\"Kochi University of Technology\"],[1398,\"Weiyu Zhang\",\"Zhang\",\"National University of Singapore\"],[1399,\"Lu Xiao\",\"Xiao\",\"The University of Western Ontario\"],[1400,\"Anna Przybylska\",\"Przybylska\",\"University of Warsaw\"],[1401,\"Anna De Liddo\",\"Liddo\",\"The Open University\"],[1402,\"Gregorio Convertino\",\"Convertino\",\"Informatica Corporation\"],[1403,\"Todd Davies\",\"Davies\",\"Stanford University\"],[1404,\"Mark Klein\",\"Klein\",\"MIT\"],[1405,\"Kathy K Baxter\",\"Baxter\",\"Google, Inc.\"],[1406,\"Anna Avrekh\",\"Avrekh\",\"Google Inc\"],[1407,\"Bob Evans\",\"Evans\",\"Google, Inc.\"],[1408,\"Marianna Obrist\",\"Obrist\",\"\"],[1409,\"Jakob Tholander\",\"Tholander\",\"Stockholm University\"],[1410,\"Stina Nylander\",\"Nylander\",\"Mobile Life @ SICS\"],[1411,\"Misha Patel\",\"Patel\",\"Foolproof\"],[1412,\"Rohit Ashok Khot\",\"Khot\",\"RMIT University\"],[1413,\"Jeewon Lee\",\"Lee\",\"RMIT University\"],[1414,\"Deepti Aggarwal\",\"Aggarwal\",\"The University of Melbourne\"],[1415,\"Larissa Hjorth\",\"Hjorth\",\"RMIT University\"],[1416,\"Florian ' Mueller\",\"Mueller\",\"RMIT University\"],[1417,\"Ana Tajadura-Jiménez\",\"Tajadura-Jiménez\",\"University College London\"],[1418,\"Maria Basia\",\"Basia\",\"University College London\"],[1419,\"Ophelia Deroy\",\"Deroy\",\"University of London\"],[1420,\"Merle Fairhurst\",\"Fairhurst\",\"University of London\"],[1421,\"Nadia Bianchi-Berthouze\",\"Bianchi-Berthouze\",\"University College London\"],[1422,\"Konstantinos Kazakos\",\"Kazakos\",\"\"],[1423,\"Petr Slovák\",\"Slovák\",\"Vienna University of Technology\"],[1424,\"Ran Gilad-Bachrach\",\"Gilad-Bachrach\",\"Microsoft Research\"],[1425,\"Jeeeun Kim\",\"Kim\",\"University of Colorado\"],[1426,\"Tom Yeh\",\"Yeh\",\"University of Colorado\"],[1427,\"Jan Derboven\",\"Derboven\",\"iMinds - KU Leuven\"],[1428,\"Maarten Van Mechelen\",\"Mechelen\",\"iMinds - KU Leuven\"],[1429,\"Bieke Zaman\",\"Zaman\",\"iMinds - KU Leuven\"],[1430,\"Dirk De Grooff\",\"Grooff\",\"iMinds - KU Leuven\"],[1431,\"Matt Jones\",\"Jones\",\"\"],[1432,\"Carolynne Lord\",\"Lord\",\"Lancaster University\"],[1433,\"Adrian K Clear\",\"Clear\",\"Lancaster University\"],[1434,\"Oliver Bates\",\"Bates\",\"Lancaster University\"],[1435,\"Rosalind Whittam\",\"Whittam\",\"Lancaster University\"],[1436,\"Janine Morley\",\"Morley\",\"Lancaster University\"],[1437,\"Juan Pablo Carrascal\",\"Carrascal\",\"Universitat Pompeu Fabra\"],[1438,\"Karen Church\",\"Church\",\"Yahoo! Labs\"],[1439,\"Rodrigo de Oliveira\",\"Oliveira\",\"Telefonica Research\"],[1440,\"Mauro Cherubini\",\"Cherubini\",\"Telefonica Research\"],[1441,\"John Vines\",\"Vines\",\"\"],[1442,\"Mike Harding\",\"Harding\",\"Lancaster University\"],[1443,\"Bran Knowles\",\"Knowles\",\"Lancaster University\"],[1444,\"Nigel Davies\",\"Davies\",\"Lancaster University\"],[1445,\"Mark Rouncefield\",\"Rouncefield\",\"Lancaster University\"],[1446,\"Eun-Young Ko\",\"Ko\",\"KAIST\"],[1447,\"Jonghyuk Jung\",\"Jung\",\"KAIST\"],[1448,\"Chang Won Lee\",\"Lee\",\"KAIST\"],[1449,\"Nam Wook Kim\",\"Kim\",\"Harvard University\"],[1450,\"Jihee Kim\",\"Kim\",\"KAIST\"],[1451,\"Clara Crivellaro\",\"Crivellaro\",\"Newcastle University\"],[1452,\"Martyn Dade-Robertson\",\"Dade-Robertson\",\"School of Architecture, Planning, and Landscape, University of Newcastle\"],[1453,\"Alex S Taylor\",\"Taylor\",\"Microsoft Research\"],[1454,\"Siân E Lindley\",\"Lindley\",\"Microsoft Research\"],[1455,\"Tim Regan\",\"Regan\",\"Microsoft Research\"],[1456,\"David Sweeney\",\"Sweeney\",\"Microsoft\"],[1457,\"Vasillis Vlachokyriakos\",\"Vlachokyriakos\",\"Newcastle University\"],[1458,\"Lillie Grainger\",\"Grainger\",\"University of Nottingham \"],[1459,\"Jessica Lingel\",\"Lingel\",\"Microsoft Research\"],[1460,\"Alexander De Luca\",\"Luca\",\"\"],[1461,\"Eyal Peer\",\"Peer\",\"Bar-Ilan University\"],[1462,\"Bonnie B Anderson\",\"Anderson\",\"Brigham Young University\"],[1463,\"C. B Kirwan\",\"Kirwan\",\"Brigham Young University\"],[1464,\"David Eargle\",\"Eargle\",\"University of Pittsburgh\"],[1465,\"Jeffrey L Jenkins\",\"Jenkins\",\"Brigham Young University\"],[1466,\"Seth Howard\",\"Howard\",\"Google, Inc.\"],[1467,\"Anthony Vance\",\"Vance\",\"Brigham Young University\"],[1468,\"Adrienne P Felt\",\"Felt\",\"Google\"],[1469,\"Alex Ainslie\",\"Ainslie\",\"Google\"],[1470,\"Robert W Reeder\",\"Reeder\",\"Google, Inc.\"],[1471,\"Somas Thyagaraja\",\"Thyagaraja\",\"Google\"],[1472,\"Alan Bettes\",\"Bettes\",\"Google, Inc.\"],[1473,\"Helen Harris\",\"Harris\",\"Google, Inc.\"],[1474,\"Jeff Grimes\",\"Grimes\",\"University of Pennsylvania\"],[1475,\"Richard Shay\",\"Shay\",\"Carnegie Mellon University\"],[1476,\"Lujo Bauer\",\"Bauer\",\"Carnegie Mellon University\"],[1477,\"Nicolas Christin\",\"Christin\",\"Carnegie Mellon University\"],[1478,\"Lorrie F Cranor\",\"Cranor\",\"Carnegie Mellon University\"],[1479,\"Alain Forget\",\"Forget\",\"Carnegie Mellon University\"],[1480,\"Saranga Komanduri\",\"Komanduri\",\"Carnegie Mellon University\"],[1481,\"Michelle L Mazurek\",\"Mazurek\",\"University of Maryland\"],[1482,\"William Melicher\",\"Melicher\",\"Carnegie Mellon CyLab\"],[1483,\"Sean M Segreti\",\"Segreti\",\"Carnegie Mellon University\"],[1484,\"Blase Ur\",\"Ur\",\"Carnegie Mellon University\"],[1485,\"Enrico Rukzio\",\"Rukzio\",\"\"],[1486,\"Khairi Reda\",\"Reda\",\"Argonne National Laboratory\"],[1487,\"Andrew E Johnson\",\"Johnson\",\"University of Illinois at Chicago\"],[1488,\"Michael E Papka\",\"Papka\",\"Argonne National Laboratory\"],[1489,\"Jason Leigh\",\"Leigh\",\"University of Hawaii at Manoa\"],[1490,\"Lars Lischke\",\"Lischke\",\"University of Stutgart\"],[1491,\"Sven Mayer\",\"Mayer\",\"\"],[1492,\"Katrin Wolf\",\"Wolf\",\"VIS\"],[1493,\"Sylvain Malacria\",\"Malacria\",\"University College London\"],[1494,\"Jonathan Aceituno\",\"Aceituno\",\"Inria Lille\"],[1495,\"Nicolas Roussel\",\"Roussel\",\"Inria\"],[1496,\"Maxime Guillon\",\"Guillon\",\"University Grenoble Alpes\"],[1497,\"François Leitner\",\"Leitner\",\"Aesculap SAS\"],[1498,\"Laurence Nigay\",\"Nigay\",\"University Grenoble Alpes\"],[1499,\"Pengfei Xu\",\"Xu\",\"HKUST\"],[1500,\"Hongbo Fu\",\"Fu\",\"City University of Hong Kong\"],[1501,\"Chiew-Lan Tai\",\"Tai\",\"HKUST\"],[1502,\"Morgan G Ames\",\"Ames\",\"University of California, Irvine\"],[1503,\"Barry Brown\",\"Brown\",\"Mobile Life @ Stockholm University\"],[1504,\"Roel Vertegaal\",\"Vertegaal\",\"Queen's University\"],[1505,\"Jacob Robert\",\"Robert\",\"\"],[1506,\"Susan Dray\",\"Dray\",\"\"],[1507,\"Martin Halvey\",\"Halvey\",\"\"],[1508,\"Alexander Mariakakis\",\"Mariakakis\",\"University of Washington\"],[1509,\"Md Tanvir Islam Aumi\",\"Aumi\",\"University of Washington\"],[1510,\"Jaemin Jo\",\"Jo\",\"Seoul National University\"],[1511,\"Bohyoung Kim\",\"Kim\",\"Seoul National University Bundang Hospital\"],[1512,\"Danielle M Lottridge\",\"Lottridge\",\"Stanford University\"],[1513,\"Christine Rosakranse\",\"Rosakranse\",\"Stanford University\"],[1514,\"Catherine S Oh\",\"Oh\",\"Stanford University\"],[1515,\"Sean J Westwood\",\"Westwood\",\"Stanford University\"],[1516,\"Katherine A Baldoni\",\"Baldoni\",\"Stanford University\"],[1517,\"Abrey S Mann\",\"Mann\",\"Stanford University\"],[1518,\"Clifford I Nass\",\"Nass\",\"Stanford University\"],[1519,\"Jelmer P Borst\",\"Borst\",\"University of Groningen\"],[1520,\"Niels A Taatgen\",\"Taatgen\",\"University of Groningen\"],[1521,\"Hedderik van Rijn\",\"Rijn\",\"University of Groningen\"],[1522,\"Manuela Züger\",\"Züger\",\"University of Zurich\"],[1523,\"Thomas Fritz\",\"Fritz\",\"University of Zurich\"],[1524,\"Will Odom\",\"Odom\",\"\"],[1525,\"Zhiyong Fu\",\"Fu\",\"\"],[1526,\"Jung-Joo Lee\",\"Lee\",\"\"],[1527,\"Jim E Nieters\",\"Nieters\",\"Hewlett Packard\"],[1528,\"Carola F Thompson\",\"Thompson\",\"Splunk, Inc\"],[1529,\"Dr. Thad Starner\",\"Starner\",\"Georgia Institute of Technology, Atlanta, United States\"],[1530,\"Patrick Baudisch\",\"Baudisch\",\"\"],[1531,\"Martin Weigel\",\"Weigel\",\"Max Planck Institute for Informatics\"],[1532,\"Tong Lu\",\"Lu\",\"Carnegie Mellon University\"],[1533,\"Gilles Bailly\",\"Bailly\",\"CNRS LTCI, Télécom-ParisTech\"],[1534,\"Carmel Majidi\",\"Majidi\",\"Carnegie Mellon University\"],[1535,\"Chi-Hao Hsieh\",\"Hsieh\",\"Computer Science\"],[1536,\"Yi-Ling Chen\",\"Chen\",\"National Taiwan University\"],[1537,\"Shuo Yang\",\"Yang\",\"Computer Science\"],[1538,\"Da-Yuan Huang\",\"Huang\",\"National Taiwan University\"],[1539,\"Senaka Buthpitiya\",\"Buthpitiya\",\"Yahoo Inc.\"],[1540,\"Marius Knaust\",\"Knaust\",\"Yahoo Labs\"],[1541,\"Hsin-Liu (Cindy) Kao\",\"Kao\",\"MIT\"],[1542,\"Artem Dementyev\",\"Dementyev\",\"MIT\"],[1543,\"Joseph A Paradiso\",\"Paradiso\",\"Massachusetts Institute of Technology\"],[1544,\"Chris Schmandt\",\"Schmandt\",\"Massachusetts Institute of Technology\"],[1545,\"Koumei Fukahori\",\"Fukahori\",\"Bunkyo-ku\"],[1546,\"Mary P Czerwinski\",\"Czerwinski\",\"\"],[1547,\"Sho Tsugawa\",\"Tsugawa\",\"University of Tsukuba\"],[1548,\"Yusuke Kikuchi\",\"Kikuchi\",\"Kwansei Gakuin University\"],[1549,\"Fumio Kishino\",\"Kishino\",\"Kwansei Gakuin University\"],[1550,\"Kosuke Nakajima\",\"Nakajima\",\"Osaka University\"],[1551,\"Yuichi Itoh\",\"Itoh\",\"Osaka University\"],[1552,\"Hiroyuki Ohsaki\",\"Ohsaki\",\"Kwansei Gakuin University\"],[1553,\"Sofiane Abbar\",\"Abbar\",\"Qatar Computing Research Institute\"],[1554,\"Erin Cherry\",\"Cherry\",\"University of North Carolina at Charlotte\"],[1555,\"Lena Mamykina\",\"Mamykina\",\"Columbia University\"],[1556,\"Drashko Nakikj\",\"Nakikj\",\"Columbia University\"],[1557,\"Noemie Elhadad\",\"Elhadad\",\"Columbia University\"],[1558,\"Bongshin Lee\",\"Lee\",\"\"],[1559,\"Yvonne Jansen\",\"Jansen\",\"University of Copenhagen\"],[1560,\"Pierre Dragicevic\",\"Dragicevic\",\"INRIA\"],[1561,\"Petra Isenberg\",\"Isenberg\",\"Inria\"],[1562,\"Abhijit Karnik\",\"Karnik\",\"Lancaster University\"],[1563,\"Johan Kildal\",\"Kildal\",\"Nokia\"],[1564,\"Simon Stusak\",\"Stusak\",\"University of Munich (LMU)\"],[1565,\"Jeannette Schwarz\",\"Schwarz\",\"University of Munich (LMU)\"],[1566,\"Alvitta Ottley\",\"Ottley\",\"Tufts University\"],[1567,\"Theophanis Tsandilas\",\"Tsandilas\",\"Inria\"],[1568,\"Anastasia Bezerianos\",\"Bezerianos\",\"Univ Paris Sud, CNRS & INRIA\"],[1569,\"Thibaut Jacob\",\"Jacob\",\"Telecom ParisTech\"],[1570,\"David Geerts\",\"Geerts\",\"\"],[1571,\"Ryan Brotman\",\"Brotman\",\"Arizona State University\"],[1572,\"Winslow Burleson\",\"Burleson\",\"New York University\"],[1573,\"Jodi Forlizzi\",\"Forlizzi\",\"Carnegie Mellon University\"],[1574,\"William Heywood\",\"Heywood\",\"Arizona State University\"],[1575,\"Jisoo Lee\",\"Lee\",\"Arizona State University\"],[1576,\"Marshini Chetty\",\"Chetty\",\"University of Maryland\"],[1577,\"Hyojoon Kim\",\"Kim\",\"Georgia Institute of Technology\"],[1578,\"Srikanth Sundaresan\",\"Sundaresan\",\"Berkeley\"],[1579,\"Sam Burnett\",\"Burnett\",\"Georgia Institute of Technology\"],[1580,\"Nick Feamster\",\"Feamster\",\"Princeton University\"],[1581,\"Timothy Neate\",\"Neate\",\"Swansea University\"],[1582,\"Stephen H Fairclough\",\"Fairclough\",\"Liverpool John Moores University, UK\"],[1583,\"Alexander J Karran\",\"Karran\",\"Liverpool John Moores University\"],[1584,\"Kiel Gilleade\",\"Gilleade\",\"Liverpool John Moores University\"],[1585,\"Jianlong Zhou\",\"Zhou\",\"National ICT Australia\"],[1586,\"Jinjun Sun\",\"Sun\",\"National ICT Australia\"],[1587,\"Fang Chen\",\"Chen\",\"National ICT Australia\"],[1588,\"Ronnie Taib\",\"Taib\",\"National ICT Australia\"],[1589,\"Ahmad Khawaji\",\"Khawaji\",\"National ICT Australia \"],[1590,\"Zhidong Li\",\"Li\",\"National ICT Australia\"],[1591,\"Erin T Solovey\",\"Solovey\",\"Drexel University\"],[1592,\"Daniel A Afergan\",\"Afergan\",\"Tufts University\"],[1593,\"Evan M Peck\",\"Peck\",\"Bucknell University\"],[1594,\"Samuel W Hincks\",\"Hincks\",\"Tufts University\"],[1595,\"Robert J Jacob\",\"Jacob\",\"Tufts University\"],[1596,\"Horia A Maior\",\"Maior\",\"University of Nottingham\"],[1597,\"Matthew Pike\",\"Pike\",\"University of Nottingham\"],[1598,\"Sarah Sharples\",\"Sharples\",\"The University of Nottingham\"],[1599,\"Andres Monroy-Hernandez\",\"Monroy-Hernandez\",\"\"],[1600,\"Youyang Hou\",\"Hou\",\"University of Michigan\"],[1601,\"Sunyoung Kim\",\"Kim\",\"Harvard University\"],[1602,\"Lisa Koeman\",\"Koeman\",\"University College London\"],[1603,\"Vaiva Kalnikaitė\",\"Kalnikaitė\",\"Dovetailed\"],[1604,\"Nina Boulus-Rødje\",\"Boulus-Rødje\",\"IT University of Copenhagen\"],[1605,\"Liang Gou\",\"Gou\",\"\"],[1606,\"Kathleen H Pine\",\"Pine\",\"University of California, Irvine\"],[1607,\"Max Liboiron\",\"Liboiron\",\"Memorial University of Newfoundland and Labrador\"],[1608,\"David P Green\",\"Green\",\"Newcastle University\"],[1609,\"Christopher Newell\",\"Newell\",\"Hull University\"],[1610,\"Alia Sheikh\",\"Sheikh\",\"BBC Research & Development\"],[1611,\"Bryan Semaan\",\"Semaan\",\"Syracuse University\"],[1612,\"Heather Faucett\",\"Faucett\",\"University of California Irvine\"],[1613,\"Scott P Robertson\",\"Robertson\",\"University of Hawaii at Manoa\"],[1614,\"Misa Maruyama\",\"Maruyama\",\"University of Hawaii at Manoa\"],[1615,\"Sara Douglas\",\"Douglas\",\"University of Hawaii at Manoa\"],[1616,\"Phil Brooker\",\"Brooker\",\"University of Bath\"],[1617,\"Julie Barnett\",\"Barnett\",\"University of Bath\"],[1618,\"Feng Tian\",\"Tian\",\"\"],[1619,\"Catherine M Baker\",\"Baker\",\"University of Washington\"],[1620,\"Lauren R Milne\",\"Milne\",\"University of Washington\"],[1621,\"Richard E Ladner\",\"Ladner\",\"University of Washington\"],[1622,\"Jeremy Scott\",\"Scott\",\"MIT\"],[1623,\"Rishabh Singh\",\"Singh\",\"MIT\"],[1624,\"Philip J Guo\",\"Guo\",\"University of Rochester\"],[1625,\"Jibin Ou\",\"Ou\",\"ETH\"],[1626,\"Martin Vechev\",\"Vechev\",\"ETH Zurich\"],[1627,\"Otmar Hilliges\",\"Hilliges\",\"ETH Zurich\"],[1628,\"Sorin Lerner\",\"Lerner\",\"UC San Diego\"],[1629,\"Stephen R Foster\",\"Foster\",\"University of California, San Diego\"],[1630,\"William G Griswold\",\"Griswold\",\"University of California, San Diego\"],[1631,\"Benjamin V Hanrahan\",\"Hanrahan\",\"\"],[1632,\"Anke Dittmar\",\"Dittmar\",\"University of Rostock\"],[1633,\"Maximilian Hensch\",\"Hensch\",\"University of Rostock\"],[1634,\"Michael F Clarke\",\"Clarke\",\"Google, Inc.\"],[1635,\"Colin M Gray\",\"Gray\",\"Iowa State University\"],[1636,\"Shad D Gross\",\"Gross\",\"Indiana University Bloomington\"],[1637,\"Peter Lee\",\"Lee\",\"\"],[1638,\"Seth Cooper\",\"Cooper\",\"\"],[1639,\"Morten Fjeld\",\"Fjeld\",\"\"],[1640,\"Adalberto L Simeone\",\"Simeone\",\"University of Portsmouth\"],[1641,\"Eduardo Velloso\",\"Velloso\",\"Lancaster University\"],[1642,\"Ondrej Miksik\",\"Miksik\",\"University of Oxford\"],[1643,\"Vibhav Vineet\",\"Vineet\",\"Stanford University\"],[1644,\"Morten Lidegaard\",\"Lidegaard\",\"University of Oxford\"],[1645,\"Ram Prasaath\",\"Prasaath\",\"University of Oxford\"],[1646,\"Matthias Niessner\",\"Niessner\",\"Stanford University\"],[1647,\"Stuart Golodetz\",\"Golodetz\",\"University of Oxford\"],[1648,\"Stephen L Hicks\",\"Hicks\",\"University of Oxford\"],[1649,\"Patrick Perez\",\"Perez\",\"Technicolor R&I\"],[1650,\"Philip H Torr\",\"Torr\",\"University of Oxford\"],[1651,\"Chun-Yen Hsu\",\"Hsu\",\"National Taiwan University\"],[1652,\"Han-Yu Wang\",\"Wang\",\"HCI lab (R430)\"],[1653,\"Silvia Chyou\",\"Chyou\",\"HCI lab (R430)\"],[1654,\"Jhe-Wei Lin\",\"Lin\",\"National Taiwan University\"],[1655,\"PEI-JUNG WU\",\"WU\",\"Department of Computer Science and Information Engineering\"],[1656,\"Andries Valstar\",\"Valstar\",\"National Taiwan University \"],[1657,\"Peter Mohr\",\"Mohr\",\"Institute for Computer Graphics and Vision\"],[1658,\"Bernhard Kerbl\",\"Kerbl\",\"Institute for Computer Graphics and Vision\"],[1659,\"Michael Donoser\",\"Donoser\",\"Institute for Computer Graphics and Vision\"],[1660,\"Dieter Schmalstieg\",\"Schmalstieg\",\"Graz University of Technology\"],[1661,\"Denis Kalkofen\",\"Kalkofen\",\"Institute for Computer Graphics and Vision\"],[1662,\"Brent Hecht\",\"Hecht\",\"\"],[1663,\"Matthew Oskamp\",\"Oskamp\",\"Queen's University\"],[1664,\"Christophe Bortolaso\",\"Bortolaso\",\"Queen's University\"],[1665,\"Robin Harrap\",\"Harrap\",\"Queen's University\"],[1666,\"T.C. N Graham\",\"Graham\",\"Queen's University\"],[1667,\"Bernhard Jenny\",\"Jenny\",\"Oregon State University\"],[1668,\"Tobias Isenberg\",\"Isenberg\",\"INRIA\"],[1669,\"María-Jesús Lobo\",\"Lobo\",\"INRIA & INRIA Chile\"],[1670,\"Emmanuel Pietriga\",\"Pietriga\",\"INRIA & INRIA Chile\"],[1671,\"Caroline Appert\",\"Appert\",\"CNRS, Univ Paris Sud & INRIA\"],[1672,\"Thore Fechner\",\"Fechner\",\"University of Münster\"],[1673,\"Dennis Wilhelm\",\"Wilhelm\",\"University of Münster\"],[1674,\"Christian Kray\",\"Kray\",\"University of Münster\"],[1675,\"Will Odom\",\"Odom\",\"\"],[1676,\"Rebecca D Watkins\",\"Watkins\",\"Cardiff University\"],[1677,\"Abigail Sellen\",\"Sellen\",\"Microsoft Research Cambridge\"],[1678,\"Jane Gruning\",\"Gruning\",\"The University of Texas at Austin\"],[1679,\"Julia Bullard\",\"Bullard\",\"The University of Texas at Austin\"],[1680,\"Melissa Ocepek\",\"Ocepek\",\"The University of Texas at Austin\"],[1681,\"Doménique van Gennip\",\"Gennip\",\"University of Technology, Sydney\"],[1682,\"Elise van den Hoven\",\"Hoven\",\"University of Technology Sydney\"],[1683,\"Rebecca Gulotta\",\"Gulotta\",\"Carnegie Mellon University\"],[1684,\"Alex Sciuto\",\"Sciuto\",\"Carnegie Mellon University\"],[1685,\"Aisling G Kelliher\",\"Kelliher\",\"Carnegie Mellon University\"],[1686,\"Niels Henze\",\"Henze\",\"\"],[1687,\"Jaime Ruiz\",\"Ruiz\",\"Colorado State University\"],[1688,\"Daniel Vogel\",\"Vogel\",\"University of Waterloo\"],[1689,\"Vittorio Fuccella\",\"Fuccella\",\"University of Salerno\"],[1690,\"Gennaro Costagliola\",\"Costagliola\",\"University of Salerno\"],[1691,\"Hao Lu\",\"Lu\",\"Google\"],[1692,\"Yang Li\",\"Li\",\"Google Research\"],[1693,\"Brian A Smith\",\"Smith\",\"Columbia University\"],[1694,\"Felix Putze\",\"Putze\",\"Karlsruhe Institute of Technology (KIT)\"],[1695,\"Hao-Chuan Wang\",\"Wang\",\"\"],[1696,\"Ge Gao\",\"Gao\",\"NTT Communication Science Labs.\"],[1697,\"Ari M Hautasaari\",\"Hautasaari\",\"NTT Communication Science Labs\"],[1698,\"Susan R Fussell\",\"Fussell\",\"Cornell University\"],[1699,\"Kotaro Hara\",\"Hara\",\"University of Maryland\"],[1700,\"Ben Steichen\",\"Steichen\",\"University of British Columbia\"],[1701,\"Luanne Freund\",\"Freund\",\"University of British Columbia\"],[1702,\"Beryl Plimmer\",\"Plimmer\",\"University of Auckland\"],[1703,\"Liang He\",\"He\",\"Carnegie Mellon University \"],[1704,\"Tariq Zaman\",\"Zaman\",\"\"],[1705,\"Kasun Karunanayaka\",\"Karunanayaka\",\"National University of Singapore\"],[1706,\"Alvin W Yeo\",\"Yeo\",\"Universiti Malaysia Sarawak\"],[1707,\"Garen Jengan\",\"Jengan\",\"Universiti Malaysia Sarawak\"],[1708,\"Rachel Blagojevic\",\"Blagojevic\",\"Massey University\"],[1709,\"Ellen Yi-Luen Do\",\"Do\",\"\"],[1710,\"Maarten Thissen\",\"Thissen\",\"\"],[1711,\"Celine Latulipe\",\"Latulipe\",\"University of North Carolina at Charlotte\"],[1712,\"Darren Edge\",\"Edge\",\"Microsoft Research\"],[1713,\"Natasa Milic-Frayling\",\"Milic-Frayling\",\"Microsoft Research\"],[1714,\"Mohammad Raza\",\"Raza\",\"Microsoft Research \"],[1715,\"Reza Adhitya Saputra\",\"Saputra\",\"University of Waterloo\"],[1716,\"Chao Wang\",\"Wang\",\"Microsoft Research\"],[1717,\"Koji Yatani\",\"Yatani\",\"The University of Tokyo\"],[1718,\"William Jones\",\"Jones\",\"The Information School, University of Washington\"],[1719,\"Robert Capra\",\"Capra\",\"University of North Carolina at Chapel Hill\"],[1720,\"Anne Diekema\",\"Diekema\",\"Utah State University\"],[1721,\"Manuel Pérez-Quiñones\",\"Pérez-Quiñones\",\"Virginia Tech\"],[1722,\"Jesse David Dinneen\",\"Dinneen\",\"McGill University\"],[1723,\"Bradley Hemminger\",\"Hemminger\",\"School of Information and Library Science, University of North Carolina\"],[1724,\"Sandeep Kaur Kuttal\",\"Kuttal\",\"Oregon State University\"],[1725,\"Anita Sarma\",\"Sarma\",\"University of Nebraska, Lincoln\"],[1726,\"Gregg Rothermel\",\"Rothermel\",\"University of Nebraska, Lincoln\"],[1727,\"Joonhwan Lee\",\"Lee\",\"\"],[1728,\"Markel Vigo\",\"Vigo\",\"The University of Manchester\"],[1729,\"Robert Stevens\",\"Stevens\",\"The University of Manchester\"],[1730,\"Yuhao Zhang\",\"Zhang\",\"Stanford University\"],[1731,\"Tania Tudorache\",\"Tudorache\",\"Stanford University\"],[1732,\"Matthew Horridge\",\"Horridge\",\"Stanford University\"],[1733,\"Mark A Musen\",\"Musen\",\"Stanford University\"],[1734,\"Kerry S Chang\",\"Chang\",\"Carnegie Mellon University\"],[1735,\"Brad A Myers\",\"Myers\",\"Carnegie Mellon University\"],[1736,\"Jun Kato\",\"Kato\",\"National Institute of Advanced Industrial Science and Technology\"],[1737,\"Tomoyasu Nakano\",\"Nakano\",\"Information Technology Research Institute, National Institute of Advanced Industrial Science and Technology\"],[1738,\"Masataka Goto\",\"Goto\",\"Information Technology Research Institute, National Institute of Advanced Industrial Science and Technology\"],[1739,\"Mikko Rajanen\",\"Rajanen\",\"University of Oulu\"],[1740,\"Netta Iivari\",\"Iivari\",\"University of Oulu\"],[1741,\"Xiaojuan Ma\",\"Ma\",\"\"],[1742,\"Jonathan Waddington\",\"Waddington\",\"WESC Foundation\"],[1743,\"Kathrin Gerling\",\"Gerling\",\"University of Lincoln\"],[1744,\"Kieran Hicks\",\"Hicks\",\"University of Lincoln\"],[1745,\"Timothy L Hodgson\",\"Hodgson\",\"University of Lincoln\"],[1746,\"David R Flatla\",\"Flatla\",\"University of Dundee\"],[1747,\"Alan R Andrade\",\"Andrade\",\"University of Dundee\"],[1748,\"Ross D Teviotdale\",\"Teviotdale\",\"University of Dundee\"],[1749,\"Dylan L Knowles\",\"Knowles\",\"University of Saskatchewan\"],[1750,\"Craig Stewart\",\"Stewart\",\"University of Dundee\"],[1751,\"Soon Hau Chua\",\"Chua\",\"National University of Singapore\"],[1752,\"Haimo Zhang\",\"Zhang\",\"National University of Singapore\"],[1753,\"Muhammad Hammad\",\"Hammad\",\"National University of Singapore\"],[1754,\"Sahil Goyal\",\"Goyal\",\"National University of Singapore\"],[1755,\"Karan Singh\",\"Singh\",\"University of Toronto\"],[1756,\"Frank R Bentley\",\"Bentley\",\"\"],[1757,\"Wolfgang Beer\",\"Beer\",\"Software Analytics and Evolution\"],[1758,\"Christian Salomon\",\"Salomon\",\"Software Analytics and Evolution\"],[1759,\"Mario Winterer\",\"Winterer\",\"Software Analytics and Evolution\"],[1760,\"Karl Putzhammer\",\"Putzhammer\",\"Acousta Engineering\"],[1761,\"Bernhard Schauer\",\"Schauer\",\"Acousta Engineering\"],[1762,\"Thomas Rechberger\",\"Rechberger\",\"Acousta Engineering\"],[1763,\"HeeJeong Son\",\"Son\",\"Naver Corp\"],[1764,\"Hyunsoo Kim\",\"Kim\",\"Naver Corp\"],[1765,\"Hyojung Kim\",\"Kim\",\"Naver Corp.\"],[1766,\"Avijit Sengupta\",\"Sengupta\",\"Singapore\"],[1767,\"Klarissa T Chang\",\"Chang\",\"National University of SIngapore\"],[1768,\"Maffee Peng-Hui Wan\",\"Wan\",\"National University of Singapore\"],[1769,\"Wen Yong Chua\",\"Chua\",\"National University of Singapore\"],[1770,\"Rasmus Prentow\",\"Prentow\",\"Aalborg University\"],[1771,\"Rasmus Steiniche\",\"Steiniche\",\"Aalborg University\"],[1772,\"Simone D Johansen\",\"Johansen\",\"aalborg University\"],[1773,\"Ivan Aaen\",\"Aaen\",\"Aalborg University\"],[1774,\"Rafael A Calvo\",\"Calvo\",\"The University of Sydney\"],[1775,\"Dorian Peters\",\"Peters\",\"University of Sydney\"],[1776,\"Hwanyong Lee\",\"Lee\",\"Kyungpook National University\"],[1777,\"Victor Erukhimov\",\"Erukhimov\",\"Itsees Inc.\"],[1778,\"Neil Trevett\",\"Trevett\",\"NVIDIA\"],[1779,\"Alon Oh-bach\",\"Oh-bach\",\"Samsung\"],[1780,\"Tom Olson\",\"Olson\",\"ARM\"],[1781,\"Malte F Jung\",\"Jung\",\"\"],[1782,\"Megan Strait\",\"Strait\",\"Tufts University\"],[1783,\"Lara Vujovic\",\"Vujovic\",\"Tufts University\"],[1784,\"Victoria Floerke\",\"Floerke\",\"Tufts University\"],[1785,\"Matthias Scheutz\",\"Scheutz\",\"Tufts University\"],[1786,\"Heather Urry\",\"Urry\",\"Tufts University\"],[1787,\"Sean Andrist\",\"Andrist\",\"University of Wisconsin--Madison\"],[1788,\"Adriana Tapus\",\"Tapus\",\"ENSTA ParisTech\"],[1789,\"Allison Sauppé\",\"Sauppé\",\"University of Wisconsin, Madison\"],[1790,\"Benjamin Walther-Franks\",\"Walther-Franks\",\"University of Bremen\"],[1791,\"Jan D Smeddinck\",\"Smeddinck\",\"University of Bremen\"],[1792,\"Peter Szmidt\",\"Szmidt\",\"University of Bremen\"],[1793,\"Andrei Haidu\",\"Haidu\",\"University of Bremen\"],[1794,\"Michael Beetz\",\"Beetz\",\"University of Bremen\"],[1795,\"Rainer Malaka\",\"Malaka\",\"University of Bremen\"],[1796,\"Jina Huh\",\"Huh\",\"\"],[1797,\"Nicole Crenshaw\",\"Crenshaw\",\"University of California, Irvine\"],[1798,\"Simon Tucker\",\"Tucker\",\"Palo Alto Research Center\"],[1799,\"Les Nelson\",\"Nelson\",\"Palo Alto Research Center (PARC)\"],[1800,\"Honglu Du\",\"Du\",\"Palo Alto Research Center\"],[1801,\"Peter Pirolli\",\"Pirolli\",\"Palo Alto Research Center\"],[1802,\"Chuang-wen You\",\"You\",\"National Taiwan University\"],[1803,\"Kuo-Cheng Wang\",\"Wang\",\"National Taiwan University\"],[1804,\"Ming-Chyi Huang\",\"Huang\",\"Taipei City Hospital Songde Branch\"],[1805,\"Yen-Chang Chen\",\"Chen\",\"National Taiwan University\"],[1806,\"Cheng-Lin Lin\",\"Lin\",\"National Taiwan University\"],[1807,\"Po-Shiun Ho\",\"Ho\",\"National Taiwan University\"],[1808,\"Polly Huang\",\"Huang\",\"National Taiwan University\"],[1809,\"Hao-Hua Chu\",\"Chu\",\"National Taiwan University\"],[1810,\"Mark Blythe\",\"Blythe\",\"Northumbria University\"],[1811,\"Jamie Steane\",\"Steane\",\"Northumbria University \"],[1812,\"Jenny Roe\",\"Roe\",\"University of York\"],[1813,\"Caroline Oliver\",\"Oliver\",\"University of Oxford\"],[1814,\"Amy Gatto\",\"Gatto\",\"Wake Forest School of Medicine\"],[1815,\"Ha T Nguyen\",\"Nguyen\",\"Wake Forest School of Medicine\"],[1816,\"David P Miller\",\"Miller\",\"Wake Forest School of Medicine\"],[1817,\"Sara A Quandt\",\"Quandt\",\"Wake Forest School of Medicine\"],[1818,\"Alain G Bertoni\",\"Bertoni\",\"Wake Forest School of Medicine\"],[1819,\"Alden Smith\",\"Smith\",\"Greene County Healthcare\"],[1820,\"Thomas A Arcury\",\"Arcury\",\"Wake Forest School of Medicine\"],[1821,\"Diego Martinez Plasencia\",\"Plasencia\",\"\"],[1822,\"Jörg Müller\",\"Müller\",\"Aarhus University\"],[1823,\"Dieter Eberle\",\"Eberle\",\"Telekom Innovation Laboratories, TU Berlin\"],[1824,\"Constantin Schmidt\",\"Schmidt\",\"Telekom Innovation Laboratories, TU Berlin\"],[1825,\"Johannes Frohnhofen\",\"Frohnhofen\",\"Hasso Plattner Institute\"],[1826,\"Sven Knebel\",\"Knebel\",\"Hasso Plattner Institute\"],[1827,\"Florian Meinel\",\"Meinel\",\"Hasso Plattner Institute\"],[1828,\"Mariya Perchyk\",\"Perchyk\",\"Hasso Plattner Institute\"],[1829,\"Julian Risch\",\"Risch\",\"Hasso Plattner Institute\"],[1830,\"Jonathan Striebel\",\"Striebel\",\"Hasso Plattner Institute\"],[1831,\"Julia Wachtel\",\"Wachtel\",\"Hasso Plattner Institute\"],[1832,\"Nicholas S Dalton\",\"Dalton\",\"Open University\"],[1833,\"Emily Collins\",\"Collins\",\"University College London\"],[1834,\"Bernd Huber\",\"Huber\",\"Technical University Munich\"],[1835,\"Joong Ho Lee\",\"Lee\",\"Korea Institute of Science and Technology (KIST)\"],[1836,\"Ji-Hyung Park\",\"Park\",\"Korea Institute of Science and Technology (KIST)\"],[1837,\"Toni-Jan Keith Monserrat\",\"Monserrat\",\"\"],[1838,\"Eddie Q Yan\",\"Yan\",\"University of California, Los Angeles\"],[1839,\"Jeff Huang\",\"Huang\",\"Brown University\"],[1840,\"Gifford K Cheung\",\"Cheung\",\"University of Washington\"],[1841,\"Peta Wyeth\",\"Wyeth\",\"Queensland University of Technology\"],[1842,\"Madison Clark\",\"Clark\",\"Queensland University of Technology\"],[1843,\"Christopher Watling\",\"Watling\",\"Queensland University of Technology\"],[1844,\"Sauvik Das\",\"Das\",\"Carnegie Mellon University\"],[1845,\"Alexander E Zook\",\"Zook\",\"Georgia Institute of Technology\"],[1846,\"Mark O Riedl\",\"Riedl\",\"Georgia Institute of Technology\"],[1847,\"Chris Preist\",\"Preist\",\"University of Bristol\"],[1848,\"Robert Jones\",\"Jones\",\"Games Faction Ltd\"],[1849,\"Haewoon Kwak\",\"Kwak\",\"Qatar Computing Research Institute\"],[1850,\"Jeremy Blackburn\",\"Blackburn\",\"Telefonica\"],[1851,\"Seungyeop Han\",\"Han\",\"University of Washington\"],[1852,\"Yang Li\",\"Li\",\"\"],[1853,\"Toby Sharp\",\"Sharp\",\"Microsoft Research\"],[1854,\"Cem Keskin\",\"Keskin\",\"Microsoft Research\"],[1855,\"Duncan Robertson\",\"Robertson\",\"Microsoft Research\"],[1856,\"Jonathan Taylor\",\"Taylor\",\"Microsoft Research\"],[1857,\"Jamie Shotton\",\"Shotton\",\"Microsoft Research\"],[1858,\"David Kim\",\"Kim\",\"Microsoft Research\"],[1859,\"Christoph Rhemann\",\"Rhemann\",\"Microsoft Research\"],[1860,\"Ido Leichter\",\"Leichter\",\"Microsoft Research\"],[1861,\"Alon Vinnikov\",\"Vinnikov\",\"Microsoft Research\"],[1862,\"Yichen Wei\",\"Wei\",\"Microsoft Research\"],[1863,\"Daniel Freedman\",\"Freedman\",\"Microsoft Research\"],[1864,\"Pushmeet Kohli\",\"Kohli\",\"Microsoft Research\"],[1865,\"Eyal Krupka\",\"Krupka\",\"Microsoft Research\"],[1866,\"Andrew Fitzgibbon\",\"Fitzgibbon\",\"Microsoft Research\"],[1867,\"Srinath Sridhar\",\"Sridhar\",\"Max Planck Institute for Informatics\"],[1868,\"Anna M Feit\",\"Feit\",\"Aalto University\"],[1869,\"Christian Theobalt\",\"Theobalt\",\"Max Planck Institute for Informatics\"],[1870,\"Faizan Haque\",\"Haque\",\"University of Waterloo\"],[1871,\"Mathieu Nancel\",\"Nancel\",\"University of Waterloo\"],[1872,\"Jie Song\",\"Song\",\"ETH\"],[1873,\"Fabrizio Pece\",\"Pece\",\"ETHZ\"],[1874,\"Gábor Sörös\",\"Sörös\",\"ETHZ\"],[1875,\"Marion Koelle\",\"Koelle\",\"University of Passau\"],[1876,\"Anusha Withana\",\"Withana\",\"Singapore University of Technology and Design\"],[1877,\"Roshan Peiris\",\"Peiris\",\"Singapore University of Technology and Design\"],[1878,\"Nipuna Samarasekara\",\"Samarasekara\",\"Singapore University of Technology and Design\"],[1879,\"Suranga Nanayakkara\",\"Nanayakkara\",\"Singapore University of Technology and Design\"],[1880,\"Edward Cutrell\",\"Cutrell\",\"\"],[1881,\"George Yerousis\",\"Yerousis\",\"Birzeit University\"],[1882,\"Konstantin Aal\",\"Aal\",\"University of Siegen\"],[1883,\"Thomas von Rekowski\",\"Rekowski\",\"University of Siegen\"],[1884,\"David W Randall\",\"Randall\",\"University of Siegen, Germany\"],[1885,\"Markus Rohde\",\"Rohde\",\"University of Siegen\"],[1886,\"Kagonya Awori\",\"Awori\",\"University of Melbourne\"],[1887,\"Wally Smith\",\"Smith\",\"The University of Melbourne\"],[1888,\"Frank Vetere\",\"Vetere\",\"The University of Melbourne\"],[1889,\"David Engel\",\"Engel\",\"Massachusetts Institute of Technology\"],[1890,\"Anita W Woolley\",\"Woolley\",\"Carnegie Mellon University\"],[1891,\"Ishani Aggarwal\",\"Aggarwal\",\"Tilburg University\"],[1892,\"Christopher F Chabris\",\"Chabris\",\"Union College\"],[1893,\"Masamichi Takahashi\",\"Takahashi\",\"Fuji Xerox Co., Ltd.\"],[1894,\"Keiichi Nemoto\",\"Nemoto\",\"Fuji Xerox Co., Ltd.\"],[1895,\"Carolin Kaiser\",\"Kaiser\",\"University of Erlangen-Nuremberg\"],[1896,\"Young Ji Kim\",\"Kim\",\"Massachusetts Institute of Technology\"],[1897,\"Thomas W Malone\",\"Malone\",\"Massachusetts Institute of Technology\"],[1898,\"Michael J Brzozowski\",\"Brzozowski\",\"Google, Inc.\"],[1899,\"Phil Adams\",\"Adams\",\"Cornell University\"],[1900,\"Antonella De Angeli\",\"Angeli\",\"\"],[1901,\"Bogdan Vasilescu\",\"Vasilescu\",\"Eindhoven University of Technology\"],[1902,\"Daryl Posnett\",\"Posnett\",\"University of California\"],[1903,\"Baishakhi Ray\",\"Ray\",\"University of California\"],[1904,\"Mark G van den Brand\",\"Brand\",\"Eindhoven University of Technology\"],[1905,\"Alexander Serebrenik\",\"Serebrenik\",\"University of Eindhoven\"],[1906,\"Prem Devanbu\",\"Devanbu\",\"UC Davis\"],[1907,\"Vladimir Filkov\",\"Filkov\",\"University of California\"],[1908,\"Preeti Mudliar\",\"Mudliar\",\"Xerox Research Centre, India\"],[1909,\"Nimmi Rangaswamy\",\"Rangaswamy\",\"Xerox Research Centre, India\"],[1910,\"Cynthia Matuszek\",\"Matuszek\",\"University of Maryland, Baltimore County\"],[1911,\"Juho Kim\",\"Kim\",\"\"],[1912,\"Samad Kardan\",\"Kardan\",\"University of British Columbia\"],[1913,\"Cristina Conati\",\"Conati\",\"University of British Columbia\"],[1914,\"Zahid Hossain\",\"Hossain\",\"Stanford University\"],[1915,\"Xiaofan Jin\",\"Jin\",\"Stanford University\"],[1916,\"Engin W Bumbacher\",\"Bumbacher\",\"Stanford University\"],[1917,\"Stephen Koo\",\"Koo\",\"Stanford University\"],[1918,\"Jordan D Shapiro\",\"Shapiro\",\"Stanford University\"],[1919,\"Cynthia Y Truong\",\"Truong\",\"Stanford University\"],[1920,\"Sean Choi\",\"Choi\",\"Stanford University\"],[1921,\"Nathan D Orloff\",\"Orloff\",\"Stanford University\"],[1922,\"John Sadauskas\",\"Sadauskas\",\"Arizona State University\"],[1923,\"Daragh Byrne\",\"Byrne\",\"Carnegie Mellon University\"],[1924,\"Robert K Atkinson\",\"Atkinson\",\"Arizona State University\"],[1925,\"Carrie J Cai\",\"Cai\",\"Massachusetts Institute of Technology\"],[1926,\"James Glass\",\"Glass\",\"Massachusetts Institute of Technology\"],[1927,\"Jinsoo Kim\",\"Kim\",\"KIPFA\"],[1928,\"Sungwon Beck\",\"Beck\",\"\"],[1929,\"Sungeon Kim\",\"Kim\",\"Naver Corporation\"],[1930,\"Kihyun Jung\",\"Jung\",\"SK Planet\"],[1931,\"Silvia Lindtner\",\"Lindtner\",\"\"],[1932,\"Reuben Kirkham\",\"Kirkham\",\"Newcastle University\"],[1933,\"Mark Rice\",\"Rice\",\"Institute for Infocomm Research\"],[1934,\"Hong Huei Tay\",\"Tay\",\"Instiute for Infocomm Research \"],[1935,\"Jamie NG\",\"NG\",\"Institute for Infocomm Research\"],[1936,\"Ranieri Koh\",\"Koh\",\"Institute for Infocomm Research \"],[1937,\"Paul Dunphy\",\"Dunphy\",\"Newcastle University\"],[1938,\"James Nicholson\",\"Nicholson\",\"Newcastle University\"],[1939,\"Nigel Bevan\",\"Bevan\",\"Professional Usability Services\"],[1940,\"Elena L Glassman\",\"Glassman\",\"\"],[1941,\"Catherine Grevet\",\"Grevet\",\"Georgia Institute of Technology\"],[1942,\"Thomas Hillman\",\"Hillman\",\"University of Gothenburg\"],[1943,\"Alexandra Weilenmann\",\"Weilenmann\",\"University of Gothenburg\"],[1944,\"Stacey Kuznetsov\",\"Kuznetsov\",\"Carnegie Mellon University\"],[1945,\"Carrie Doonan\",\"Doonan\",\"Carnegie Mellon Unviversity\"],[1946,\"Nathan Wilson\",\"Wilson\",\"Carnegie Mellon Unviversity\"],[1947,\"Swarna Mohan\",\"Mohan\",\"Carnegie Mellon Unviversity\"],[1948,\"Ramine Tinati\",\"Tinati\",\"University Of Southampton\"],[1949,\"Max Van Kleek\",\"Kleek\",\"University Of Southampton\"],[1950,\"Elena Simperl\",\"Simperl\",\"University of Southampton\"],[1951,\"Markus Luczak-Rösch\",\"Luczak-Rösch\",\"University Of Southampton\"],[1952,\"Robert Simpson\",\"Simpson\",\"University of Oxford\"],[1953,\"Nigel Shadbolt\",\"Shadbolt\",\"University of Southampton\"],[1954,\"Megan French\",\"French\",\"Cornell University\"],[1955,\"Madeline E Smith\",\"Smith\",\"Northwestern University\"],[1956,\"Jeff T Hancock\",\"Hancock\",\"Cornell University\"],[1957,\"Yi-Ping Hung\",\"Hung\",\"\"],[1958,\"Richard Tang\",\"Tang\",\"University of Calgary\"],[1959,\"Xing-Dong Yang\",\"Yang\",\"University of Calgary\"],[1960,\"Joaquim Jorge\",\"Jorge\",\"IST/INESC-ID\"],[1961,\"Daniel Tetteroo\",\"Tetteroo\",\"Eindhoven University of Technology\"],[1962,\"Paul Vreugdenhil\",\"Vreugdenhil\",\"Eindhoven University of Technology\"],[1963,\"Ivor Grisel\",\"Grisel\",\"Eindhoven University of Technology\"],[1964,\"Marc Michielsen\",\"Michielsen\",\"Jesse Hospital\"],[1965,\"Els Kuppens\",\"Kuppens\",\"MS Reva Overpelt\"],[1966,\"Diana Vanmulken\",\"Vanmulken\",\"Adelante Centre of Expertise in Rehabilitation and Audiology\"],[1967,\"Marc Herrlich\",\"Herrlich\",\"University of Bremen\"],[1968,\"Paul Noble\",\"Noble\",\"UCL\"],[1969,\"Katie O'Leary\",\"O'Leary\",\"University of Washington\"],[1970,\"Jordan Eschler\",\"Eschler\",\"University of Washington\"],[1971,\"Lisa M Vizer\",\"Vizer\",\"University of Washington\"],[1972,\"James D Ralston\",\"Ralston\",\"Group Health Research Institute\"],[1973,\"Tom Bartindale\",\"Bartindale\",\"\"],[1974,\"Chang Min Kim\",\"Kim\",\"KAIST\"],[1975,\"Jayson Turner\",\"Turner\",\"Lancaster University\"],[1976,\"Khalil Klouche\",\"Klouche\",\"University of Helsinki\"],[1977,\"Tuukka Ruotsalo\",\"Ruotsalo\",\"Helsinki Institute for Information Technology HIIT, Aalto University\"],[1978,\"Diogo Cabral\",\"Cabral\",\"University of Helsinki\"],[1979,\"Salvatore Andolina\",\"Andolina\",\"University of Helsinki\"],[1980,\"Andrea Bellucci\",\"Bellucci\",\"Universidad Carlos III de Madrid\"],[1981,\"Giulio Jacucci\",\"Jacucci\",\"University of Helsinki\"],[1982,\"Svetlana Yarosh\",\"Yarosh\",\"\"],[1983,\"Karen Renaud\",\"Renaud\",\"University of Glasgow\"],[1984,\"Joseph Maguire\",\"Maguire\",\"University of Glasgow\"],[1985,\"Pamela J Wisniewski\",\"Wisniewski\",\"The Pennsylvania State University\"],[1986,\"Na Wang\",\"Wang\",\"Pennsylvania State University\"],[1987,\"Saijing Zheng\",\"Zheng\",\"Pennsylvania State University\"],[1988,\"Heng Xu\",\"Xu\",\"The Pennsylvania State University\"],[1989,\"Mary Beth Rosson\",\"Rosson\",\"Pennsylvania State University\"],[1990,\"Jin Yea Jang\",\"Jang\",\"The Pennsylvania State University\"],[1991,\"Dongwon Lee\",\"Lee\",\"The Pennsylvania State University\"],[1992,\"Katie Davis\",\"Davis\",\"University of Washington\"],[1993,\"Eve Klein\",\"Klein\",\"Pacific Science Center\"],[1994,\"Cosmin Munteanu\",\"Munteanu\",\"\"],[1995,\"Alessandro Altavilla\",\"Altavilla\",\"Goldsmiths, University of London\"],[1996,\"Scott G Pobiner\",\"Pobiner\",\"Parsons The New School for Design\"],[1997,\"Donald McMillan\",\"McMillan\",\"Mobile Life @ Stockholm University\"],[1998,\"Antoine Loriette\",\"Loriette\",\"Mobile Life @ Stockholm University \"],[1999,\"Maria K Wolters\",\"Wolters\",\"University of Edinburgh\"],[2000,\"Jonathan Kilgour\",\"Kilgour\",\"University of Edinburgh\"],[2001,\"Sarah E MacPherson\",\"MacPherson\",\"University of Edinburgh\"],[2002,\"Myroslava Dzikovska\",\"Dzikovska\",\"University of Edinburgh\"],[2003,\"Johanna D Moore\",\"Moore\",\"University of Edinburgh\"],[2004,\"Hannah Limerick\",\"Limerick\",\"University of Bristol\"],[2005,\"James W Moore\",\"Moore\",\"Goldsmiths, University of London\"],[2006,\"David Coyle\",\"Coyle\",\"University of Bristol\"],[2007,\"Ioannis Politis\",\"Politis\",\"University of Glasgow\"],[2008,\"Frank Pollick\",\"Pollick\",\"University of Glasgow\"],[2009,\"Michael Nebeling\",\"Nebeling\",\"\"],[2010,\"Tero Jokela\",\"Jokela\",\"Nokia Technologies\"],[2011,\"Jarno Ojala\",\"Ojala\",\"Tampere University of Technology\"],[2012,\"Thomas Olsson\",\"Olsson\",\"Tampere University of Technology\"],[2013,\"Mario Schreiner\",\"Schreiner\",\"University of Konstanz\"],[2014,\"Zhihao Lu\",\"Lu\",\"University College London\"],[2015,\"Pei-Yu Chi\",\"Chi\",\"University of California, Berkeley\"],[2016,\"Jens Grubert\",\"Grubert\",\"University of Technology Graz\"],[2017,\"Matthias Heinisch\",\"Heinisch\",\"University of Technology Graz\"],[2018,\"Tawanna R Dillahunt\",\"Dillahunt\",\"\"],[2019,\"Thomas Ludwig\",\"Ludwig\",\"University of Siegen\"],[2020,\"Christian Reuter\",\"Reuter\",\"University of Siegen\"],[2021,\"Tim Siebigteroth\",\"Siebigteroth\",\"University of Siegen\"],[2022,\"Volkmar Pipek\",\"Pipek\",\"University of Siegen\"],[2023,\"Marc-André Kaufhold\",\"Kaufhold\",\"University of Siegen\"],[2024,\"Joel E Fischer\",\"Fischer\",\"The University of Nottingham\"],[2025,\"Steve Reece\",\"Reece\",\"University of Oxford\"],[2026,\"Sarvapali D Ramchurn\",\"Ramchurn\",\"University of Southampton\"],[2027,\"David Jones\",\"Jones\",\"Rescue Global\"],[2028,\"Robert Soden\",\"Soden\",\"University of Colorado Boulder\"],[2029,\"T. Jennings Anderson\",\"Anderson\",\"University of Colorado Boulder\"],[2030,\"Mario Barrenechea\",\"Barrenechea\",\"University of Colorado Boulder\"],[2031,\"Pernille Bjorn\",\"Bjorn\",\"\"],[2032,\"Manuel A Perez-Quinones\",\"Perez-Quinones\",\"Virginia Tech\"],[2033,\"Rowanne Fleck\",\"Fleck\",\"University College London\"],[2034,\"Rosalyn A Robison\",\"Robison\",\"Anglia Ruskin University \"],[2035,\"Marta E Cecchinato\",\"Cecchinato\",\"University College London\"],[2036,\"N. Sadat Shami\",\"Shami\",\"IBM\"],[2037,\"Michael Muller\",\"Muller\",\"IBM T.J. Watson Research\"],[2038,\"Aditya Pal\",\"Pal\",\"IBM Almaden Research Center\"],[2039,\"Mikhil Masli\",\"Masli\",\"IBM\"],[2040,\"Werner Geyer\",\"Geyer\",\"IBM T.J. Watson Research\"],[2041,\"Mark S Ackerman\",\"Ackerman\",\"University of Michigan\"],[2042,\"David R Karger\",\"Karger\",\"Massachusetts Institute of Technology\"],[2043,\"David R Flatla\",\"Flatla\",\"\"],[2044,\"Susan Zhuang\",\"Zhuang\",\"University College London\"],[2045,\"Ghita Jalal\",\"Jalal\",\"Inria/ Universite Paris Sud\"],[2046,\"Nolwenn Maudet\",\"Maudet\",\"INRIA\"],[2047,\"Xiuli Chen\",\"Chen\",\"University of Birmingham\"],[2048,\"Andrew Howes\",\"Howes\",\"University of Birmingham\"],[2049,\"Ashley Lai\",\"Lai\",\"Carnegie Mellon University\"],[2050,\"Tam M Le\",\"Le\",\"Carnegie Mellon University\"],[2051,\"YoungSeok Yoon\",\"Yoon\",\"Carnegie Mellon University\"],[2052,\"Andrew R Faulring\",\"Faulring\",\"Carnegie Mellon University\"],[2053,\"Joel R Brandt\",\"Brandt\",\"Adobe Research\"],[2054,\"Francesca Samsel\",\"Samsel\",\"\"],[2055,\"Kenton P O'Hara\",\"O'Hara\",\"Microsoft Research\"],[2056,\"Gerardo Gonzalez\",\"Gonzalez\",\"King's College, London\"],[2057,\"Robert Corish\",\"Corish\",\"Microsoft Research\"],[2058,\"Antonio Criminisi\",\"Criminisi\",\"Microsoft Research Cambridge\"],[2059,\"Rikin Trivedi\",\"Trivedi\",\"Addenbrookes Hospital\"],[2060,\"Pierre Theodore\",\"Theodore\",\"University of California San Francisco Medical Center\"],[2061,\"Miki Watanabe\",\"Watanabe\",\"Osaka University\"],[2062,\"Kohei Ogawa\",\"Ogawa\",\"Osaka University\"],[2063,\"Hiroshi Ishiguro\",\"Ishiguro\",\"Osaka University\"],[2064,\"Sung Woo Kim\",\"Kim\",\"Kookmin University\"],[2065,\"Eun Hye Park\",\"Park\",\"Kookmin University\"],[2066,\"Yae Eun Lee\",\"Lee\",\"Kookmin University\"],[2067,\"Jong Sung Lee\",\"Lee\",\"Kookmin University\"],[2068,\"Da Hee Lee\",\"Lee\",\"Kookmin University\"],[2069,\"Eun Jin Kim\",\"Kim\",\"Kookmin University\"],[2070,\"Florent Taralle\",\"Taralle\",\"Sagem Defense et Sécurité\"],[2071,\"Alexis Paljic\",\"Paljic\",\"Mines ParisTech\"],[2072,\"Sotiris Manitsaris\",\"Manitsaris\",\"Ecole Nationale Supérieure des Mines de Paris\"],[2073,\"Jordane Grenier\",\"Grenier\",\"Sagem Défense et Sécurité\"],[2074,\"Christophe Guettier\",\"Guettier\",\"Sagem Défense et Sécurité\"]]},\"annotation\":{\"headers\":[\"_id\",\"name\",\"type\",\"description\",\"icon\",\"sequence\"],\"rows\":[[1,\"Best\",\"Award\",\"Best Paper\",\"Best.png\",1],[2,\"Honorable Mention\",\"Award\",\"Honorable Mention\",\"Honorable.png\",2]]},\"event\":{\"headers\":[\"_id\",\"parent_fk\",\"unique_id\",\"type\",\"title\",\"description\",\"short_description\",\"location_fk\",\"display_time\",\"start_time\",\"end_time\",\"person_demonym\",\"event_demonym\"],\"rows\":[[1,-1,\"keynote-1\",\"Keynote\",\"Opening Plenary - Crossing: HCI, Design and Sustainability\",null,null,15,\"Mon 8:30 - 10:00 AM\",1429554600,1429560000,\"Speaker\",null],[2,1,\"key1\",\"Keynote\",\"Crossing: HCI, Design and Sustainability\",\"Two great inventions that opened the era of human-computer interaction design—desktop and mouse—are now disappearing. Computers are becoming smaller and smaller, smarter and smarter. Everyone is now surrounded by many visible and invisible computers, which are all highly connected through the Internet ubiquitously. A new world of artificial intelligence is emerging. When the intelligence of human-being is expanded to his/her surroundings, condensed into a new kind of Intelligent life, the relationship between human-being and the rest of the world has been redefined. How to cross the boundaries and to enable the sustainable interaction between nature (the 1st system), human-beings (the 2nd system), artificial world (the 3rd system), and the cyber world (the 4th system), becomes an interesting proposition and merits new design. But before that, it’s necessary to rethink the anthropocentric view and even design itself. The most attractive feature of design is optimistic. What makes a human being human, lies in that one is not leading a kind of life which merely has needs to be fulfilled, but can also use his/her subjective initiative to control and conduct his/her behavior for a certain common value. Today sustainability is not only a value of ethics, but a value of surviving. How to use and encourage a new kind of HCI design, to generate sustainable behaviors and social changes, further, to redesign the commensalism of the four systems mentioned above will be the main focus of my talk.\",\"Two great inventions that opened the era of human-computer interaction design—desktop and mouse—are now disappearing. Computers are becoming smaller and smaller, smarter and smarter. Everyone is now surrounded by many visible and invisible computers, which are all highly connected through the Internet ubiquitously. A new world of artificial intelligence is emerging. When the intelligence of human-being is expanded to his/her surroundings, condensed into a new kind of Intelligent life, the relati...\",15,\"Mon 8:30 - 10:00 AM\",1429554600,1429560000,\"Speaker\",null],[3,-1,\"break-1\",\"Breaks\",\"Coffee Break\",null,null,15,\"Mon 10:00 - 11:30 AM\",1429560000,1429565400,\"\",\"\"],[4,-1,\"vid-1\",\"Special\",\"Video Preview Session\",null,null,3,\"Mon 10:00 - 11:30 AM\",1429560000,1429565400,\"\",\"\"],[5,-1,\"sgc-ex-1\",\"Special\",\"Student Game Competition Exhibit\",null,null,15,\"Mon 10:00 - 11:30 AM\",1429560000,1429565400,\"\",\"\"],[6,-1,\"s-float-2\",\"Papers\",\"HMDs & Wearables to Overcome Disabilities\",null,null,12,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Chair\",\"Papers\"],[7,6,\"pn388\",\"Paper\",\"Personalized, Wearable Control of a Head-mounted Display for Users with Upper Body Motor Impairments\",\"Head-mounted displays provide relatively hands-free interaction that could improve mobile computing access for users with motor impairments. To investigate this largely unexplored area, we present two user studies. The first, smaller study evaluated the accessibility of Google Glass, a head-mounted display, with 6 participants. Findings revealed potential benefits of a head-mounted display yet demonstrated the need for alternative means of controlling Glass—3 of the 6 participants could not use it at all. We then conducted a second study with 12 participants to evaluate a potential alternative input mechanism that could allow for accessible control of a head-mounted display: switch-based wearable touchpads that can be affixed to the body or wheelchair. The study assessed input performance with three sizes of touchpad, investigated personalization patterns when participants were asked to place the touchpads on their body or wheelchair, and elicited subjective responses. All 12 participants were able to use the touchpads to control the display, and patterns of touchpad placement point to the value of personalization in providing support for each user’s motor abilities.\",\"Following a small study with Google Glass and participants with motor impairments, we propose and evaluate personalized wearable touchpads as a means of accessible input for head-mounted displays.\",12,\"Mon 11:30 - 11:50 AM\",1429565400,1429566600,\"Authors\",null],[8,6,\"pn1898\",\"Paper\",\"Designing Conversation Cues on a Head-Mounted Display to Support Persons with Aphasia\",\"Symbol-based dictionaries of text, images and sound can help individuals with aphasia find the words they need, but are often seen as a last resort because they tend to replace rather than augment the user’s natural speech. Through two design investigations, we explore head-worn displays as a means of providing unobtrusive, always-available, and glanceable vocabulary support. The first study used narrative storyboards as a design probe to explore the potential benefits and challenges of a head-worn approach over traditional augmented alternative communication (AAC) tools. The second study then evaluated a proof-of-concept prototype in both a lab setting with the researcher and in situ with unfamiliar conversation partners at a local market. Findings suggest that a head-worn approach could better allow wearers to maintain focus on the conversation, reduce reliance on the availability of external tools (e.g., paper and pen) or people, and minimize visibility of the support by others. These studies should motivate further investigation of head-worn conversational support. \",\"We contribute a proof-of-concept prototype of head-worn display, vocabulary prompts for persons with aphasia, its evaluation in field and lab settings, and identification of its potential contexts of use.\",12,\"Mon 11:50 - 12:10 PM\",1429566600,1429567800,\"Authors\",null],[9,6,\"pn1373\",\"Paper\",\"Head-Mounted Display Visualizations to Support Sound Awareness for the Deaf and Hard of Hearing\",\"Persons with hearing loss use visual signals such as gestures and lip movement to interpret speech. While hearing aids and cochlear implants can improve sound recognition, they generally do not help the wearer localize sound necessary to leverage these visual cues. In this paper, we design and evaluate visualizations for spatially locating sound on a head-mounted display (HMD). To investigate this design space, we developed eight high-level visual sound feedback dimensions. For each dimension, we created 3-12 example visualizations and evaluated these as a design probe with 24 deaf and hard of hearing participants (Study 1). We then implemented a real-time proof-of-concept HMD prototype and solicited feedback from 4 new participants (Study 2). Study 1 findings reaffirm past work on challenges faced by persons with hearing loss in group conversations, provide support for the general idea of sound awareness visualizations on HMDs, and reveal preferences for specific design options. Although preliminary, Study 2 further contextualizes the design probe and uncovers directions for future work.\",\"Design recommendations for Head-Mounted Display sound awareness systems for the deaf and hard of hearing.\",12,\"Mon 12:10 - 12:30 PM\",1429567800,1429569000,\"Authors\",null],[10,6,\"pn1881\",\"Note\",\"Using Interactive Machine Learning to Support Interface Development Through Workshops with Disabled People\",\"We have applied interactive machine learning (IML) to the creation and customisation of gesturally controlled musical interfaces in six workshops with people with learning and physical disabilities. Our observations and discussions with participants demonstrate the utility of IML as a tool for participatory design of accessible interfaces. This work has also led to a better understanding of challenges in end-user training of learning models, of how people develop personalised interaction strategies with different types of pre-trained interfaces, and of how properties of control spaces and input devices influence people’s customisation strategies and engagement with instruments. This work has also uncovered similarities between the musical goals and practices of disabled people and those of expert musicians. \",\"We identify challenges and benefits of using interactive machine learning for the creation and customization of gesturally-controlled musical interfaces for people with disabilities, based on the outcomes of six workshops.\",12,\"Mon 12:30 - 12:40 PM\",1429569000,1429569600,\"Authors\",null],[11,6,\"pn2582\",\"Note\",\"Tongue-in-Cheek: Using Wireless Signals to Enable Non-Intrusive and Flexible Facial Gestures Detection\",\"Serious brain injuries, spinal injuries, and motor neuron diseases often lead to severe paralysis. Individuals with such disabilities can benefit from interaction techniques that enable them to interact with the devices and thereby the world around them. While a number of systems have proposed tongue-based gesture detection systems, most of these systems require intrusive instrumentation of the user’s body (e.g., tongue piercing, dental retainers, multiple electrodes on chin). In this paper, we propose a wireless, non-intrusive and non-contact facial gesture detection system using X-band Doppler. The system can accurately differentiate between 8 different facial gestures through non-contact sensing, with an average accuracy of 94.3%. \",\"A wireless and non-contact facial gesture detection system using X-band Doppler for users with paralysis. The system can accurately differentiate between 8 different facial gestures through non-contact sensing, with an average accuracy of 94.3%. \",12,\"Mon 12:40 - 12:50 PM\",1429569600,1429570200,\"Authors\",null],[12,-1,\"s130\",\"Papers\",\"Visualizing Data\",null,null,13,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Chair\",\"Papers\"],[13,12,\"pn1552\",\"Paper\",\"MatrixWave: Visual Comparison of Event Sequence Data\",\"Event sequence data analysis is common in many domains, including web and software development, transportation, and medical care. Few have investigated visualization techniques for comparative analysis of multiple event sequence datasets. Grounded in the real-world characteristics of web clickstream data, we explore visualization techniques for comparison of two clickstream datasets collected on different days or from users with different demographics. Through iterative design with web analysts, we designed MatrixWave, a matrix-based representation that allows analysts to get an overview of differences in traffic patterns and interactively explore paths through the website. We use color to encode differences and size to offer context over traffic volume. User feedback on MatrixWave is positive. Our study participants made fewer errors with MatrixWave and preferred it over the more familiar Sankey diagram. \",\"We propose MatrixWave, a novel matrix-based visualization design that allows analysts to interactively explore and compare two related event sequence datasets.\",13,\"Mon 11:30 - 11:50 AM\",1429565400,1429566600,\"Authors\",null],[14,12,\"pn500\",\"Paper\",\"The Effects of Representation and Juxtaposition on Graphical Perception of Matrix Visualization\",\"Analyzing multiple networks at once is a common yet difficult task  in many domains. Using adjacency matrices for this purpose, however,  can be effective because of its superior ability to accommodate dense  networks in a small area.  We evaluate various representations and  juxtaposition designs for visualizing adjacency matrices through a  series of controlled experiments. We investigate the effect of  using square matrices and triangular matrices on the speed and accuracy of  performing graphical-perception tasks. Based on human symmetric  perception, we propose two alternative juxtaposition designs to  the conventional side-by-side juxtaposition, and study how users  perform visual search and comparison tasks regarding different  juxtaposition types. Our results show that the matrix  representations have similar performance, and the matrix juxtaposition types  perform differently. With the design guidelines derived from our  studies, we present a compact visualization termed TileMatrix for  juxtaposing a large number of matrices, and demonstrate its  effectiveness in analyzing multi-faceted, time-varying networks  using real-world data.\",\"We present empirical studies of various representations and juxtaposition designs for adjacency matrices, offer design guidelines implied from our studies, and propose a compact visualization called TileMatrix.\",13,\"Mon 11:50 - 12:10 PM\",1429566600,1429567800,\"Authors\",null],[15,12,\"pn1684\",\"Paper\",\"g-Miner: Interactive Visual Group Mining on Multivariate Graphs\",\"With the rapid growth of rich network data available through various  sources  such  as  social  media  and  digital  archives,there is a growing interest in more powerful network visual analysis tools and methods.  The rich information about the network nodes and links can be represented as multivariate graphs, in which the nodes are accompanied with attributes to represent the properties of individual nodes. An important task often encountered in multivariate network analysis is to uncover link structure with groups, e.g., to understand why a person fits a specific job or certain role in a social group well.The task usually involves complex considerations including specific requirement of node attributes and link structure, and hence a fully automatic solution is typically not satisfactory.In  this  work,  we  identify  the  design  challenges  for  min-ing groups with complex criteria and present an interactive system, “g-Miner,” that enables visual mining of groups on multivariate  graph  data.   We  demonstrate  the  effectiveness of our system through case study and in-depth expert inter-views.   This  work  contributes  to  understanding  the  design of  systems  for  leveraging  users’  knowledge  progressively with algorithmic capacity for tackling massive heterogeneous information.\",\"We present g-Miner, an interactive system for visually mining and refining groups on multivariate graphs. It incorporates efficient data mining algorithms and intuitive visualisation designs to help users form and search desired groups of interests.\",13,\"Mon 12:10 - 12:30 PM\",1429567800,1429569000,\"Authors\",null],[16,12,\"pn1886\",\"Paper\",\"Trajectory Bundling for Animated Transitions\",\"Animated transition has been a popular design choice for smoothly switching between different visualization views or layouts, in which movement trajectories are created as cues for tracking objects during location shifting. Tracking moving objects, however, becomes difficult when their movement paths overlap or the number of tracking targets increases. We propose a novel design to facilitate tracking moving objects in animated transitions. Instead of simply animating an object along a straight line, we create \\\"bundled\\\" movement trajectories for a group of objects that have spatial proximity and share similar moving directions. To study the effect of bundled trajectories, we untangle variations due to different aspects of tracking complexity in a comprehensive controlled user study. The results indicate that using bundled trajectories is particularly effective when tracking more targets (six vs. three targets) or when the object movement involves a high degree of occlusion or deformation. Based on the study, we discuss the advantages and limitations of the new technique, as well as provide design implications.\",\"This paper describes the design and evaluation of a novel trajectory bundling technique for facilitating tracking a group of moving objects in animated transitions.\",13,\"Mon 12:30 - 12:50 PM\",1429569000,1429570200,\"Authors\",null],[17,-1,\"s157\",\"Papers\",\"What do I hear? Communicating with Sound\",null,null,4,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Chair\",\"Papers\"],[18,17,\"pn1275\",\"Note\",\"TabLETS Get Physical: Non-Visual Text Entry on Tablet Devices\",\"Tablet devices can display full-size QWERTY keyboards similar to the physical ones. Yet, the lack of tactile feedback and the inability to rest the fingers on the home keys result in a highly demanding and slow exploration task for blind users. We present SpatialTouch, an input system that leverages previous experience with physical QWERTY keyboards, by supporting two-handed interaction through multitouch exploration and spatial, simultaneous audio feedback. We conducted a user study, with 30 novice touchscreen participants entering text under one of two conditions: (1) SpatialTouch or (2) mainstream accessibility method Explore by Touch. We show that SpatialTouch enables blind users to leverage previous experience as they do a better use of home keys and perform more efficient exploration paths. Results suggest that although SpatialTouch did not result in faster input rates overall, it was indeed able to leverage previous QWERTY experience in contrast to Explore by Touch.\",\"SpatialTouch is a non-visual multitouch QWERTY keyboard for tablet devices that enables blind users to leverage previous experience in physical keyboards. It supports two-handed input through spatial, simultaneous audio feedback.\",4,\"Mon 11:30 - 11:40 AM\",1429565400,1429566000,\"Authors\",null],[19,17,\"pn1355\",\"Note\",\"VocalSketch: Vocally Imitating Audio Concepts\",\"A natural way of communicating an audio concept is to imitate it with one's voice. This creates an approximation of the imagined sound (e.g. a particular owl's hoot), much like how a visual sketch approximates a visual concept (e.g a drawing of the owl). If a machine could understand  vocal imitations, users could communicate with software in this  natural way, enabling new interactions (e.g. programming a music synthesizer by imitating the desired sound with one's voice). In this work, we collect thousands of crowd-sourced vocal imitations of a large set of diverse  sounds, along with data on the crowd's ability to correctly label these vocal imitations. The resulting data set will help the research community understand which audio concepts can be effectively communicated with this approach. We have released the data set so  the community can study the related issues and build systems that leverage  vocal imitation as an interaction modality.\",\"This work describes a new data set that will help researchers understand which audio concepts can be effectively communicated with vocal imitation, a natural method of communicating audio concepts.\",4,\"Mon 11:40 - 11:50 AM\",1429566000,1429566600,\"Authors\",null],[20,17,\"pn1977\",\"Paper\",\"An Evaluation of Multidimensional Controllers for Sound Design Tasks\",\"This paper presents an investigation into musicians’ ability to control sound synthesiser parameters using various inter- faces. The principal aim was to compare separate, 1D parameter controls (touchscreen sliders) to multidimensional con- trollers (an XY touchpad for 2D, the Leap Motion for 3D). Subjects had to match a target sound as quickly and accurately as possible. Results show that after about two hours of practice, the XY pad is 9% faster than two sliders for no accuracy loss, and the Leap is 17% faster than 3 sliders with 9% accuracy loss. The multidimensional controllers improved most with practice. A new perspective on Fitts’ index of difficulty is presented: “Index of Search Space Reduction” (ISSR). ISSR and retrospective accuracy thresholds on the search trajectory are used to obtain straight line plots and throughput values. These plots reveal that the Leap’s speed improvement was mainly due to reaction time, but the XY pad traversed the space faster.\",\"This study reveals multi-dimensional controllers to be faster than separate sliders for a simple sound design task, and introduces a novel way of quantifying throughput in parameter space searches.\",4,\"Mon 11:50 - 12:10 PM\",1429566600,1429567800,\"Authors\",null],[21,17,\"pn1187\",\"Paper\",\"AnnoTone: Record-time Audio Watermarking for Context-aware Video Editing\",\"We present a video annotation system called ``AnnoTone'', which can embed various contextual information describing a scene, such as geographical location. Then the system allows the user to edit the video using this contextual information, enabling one to, for example, overlay with map or graphical annotations. AnnoTone converts annotation data into high-frequency audio signals (which are inaudible to the human ear), and then transmits them from a smartphone speaker placed near a video camera. This scheme makes it possible to add annotations using standard video cameras with no requirements for specific equipment other than a smartphone. We designed the audio watermarking protocol using dual-tone multi-frequency signaling, and developed a general-purpose annotation framework including an annotation generator and extractor. We conducted a series of performance tests to understand the reliability and the quality of the watermarking method. We then created several examples of video-editing applications using annotations to demonstrate the usefulness of Annotone, including an After Effects plug-in.\",\"We present a video annotation system that embeds contextual information into videos as inaudible tones during recording, and a series of example applications that demonstrate the usefulness of this approach.\",4,\"Mon 12:10 - 12:30 PM\",1429567800,1429569000,\"Authors\",null],[22,17,\"pn1966\",\"Paper\",\"Exploring Gesture Sonification to Support Reflective Craft Practice\",\"Much of the knowing employed in skilled craft practice is difficult to communicate solely through written or verbal description. Consequently, the reflection and development of a craft practice in this manner may miss important nuances of practitioners’ skills and experiences. We created digital technologies to sonify (using audio to perceptualize data) a group of craft practitioners' gestures to explore how we can aid their reflection in and on their craft, and consequently develop it. Over a number of workshops, the design of these sonifications were iterated based on how the practitioners responded to them. We found that direct sonification of gesture (sounds generated directly from motion sensor data) helped practitioners understand and reflect upon their own and each other’s practice, encouraged discussion and enabled modification of craft technique.\",\"Much of the knowing employed in craft practice is difficult to communicate solely through written or verbal description. We created digital technologies to sonifiy craft practitioners gestures to aid reflection.\",4,\"Mon 12:30 - 12:50 PM\",1429569000,1429570200,\"Authors\",null],[23,-1,\"s155\",\"Papers\",\"Facebook Newsfeeds & Friendships\",null,null,15,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Chair\",\"Papers\"],[24,23,\"pn2341\",\"Paper\",\"“I always assumed that I wasn’t really that close to [her]”: Reasoning about invisible algorithms in the news feed\",\"Our daily digital life is full of algorithmically selected content such as social media feeds,  recommendations and personalized search results. These algorithms have great power to shape users' experiences, yet users are often unaware of their presence.  Whether it is useful to give users insight into these algorithms' existence or functionality and how such insight might affect their experience are open questions. To address them, we conducted a user study with 40 Facebook users to examine their perceptions of the Facebook News Feed curation algorithm. Surprisingly, more than half of the participants (62.5%) were not aware of the News Feed curation algorithm's existence at all. Initial reactions for these previously unaware participants were surprise and anger. We developed a system, FeedVis, to reveal the difference between the algorithmically curated and an unadulterated News Feed to users, and used it to study how users perceive this difference. Participants were most upset when close friends and family were not shown in their feeds. We also found participants often attributed missing stories to their friends' decisions to exclude them rather than to Facebook News Feed algorithm.  By the end of the study, however, participants were mostly satisfied with the content on their feeds. Following up with participants two to six months after the study, we found that for most, satisfaction levels remained similar before and after becoming aware of the algorithm's presence, however, algorithmic awareness led to more active engagement with Facebook and bolstered overall feelings of control on the site.\",\"In an algorithm awareness study on Facebook News Feed, most users were unaware of the feed curation. We found that with more algorithm knowledge, users engaged more with their feed.\",15,\"Mon 11:30 - 11:50 AM\",1429565400,1429566600,\"Authors\",null],[25,23,\"pn2339\",\"Paper\",\"News Feed: What's in it for Me?\",\"Over a billion people use social networking sites like Facebook to maintain awareness of their friends. Facebook’s News Feed is the primary mechanism by which people are shown updates about their friends’ daily activities on the site in the form of an algorithmically curated list of stories. This paper examines how people browse the News Feed, their perceptions and satisfaction while using it, and the interactions they make with their personal social network. We conducted a qualitative study involving think-aloud semi-structured interviews as the participants casually browsed their own feeds. We observed a wide variation in the use of the News Feed ranging from careful consideration of social conventions, judgment of people, and annoyance and frustration towards certain friends. Our findings suggest that people do not deliberately curate their own News Feed either due to lack of awareness or perceived social repercussions.\",\"What do people find interesting on Facebook? What annoys them? A qualitative examination of News Feed browsing habits reveals that people on Facebook form complicated judgments of themselves and others.\",15,\"Mon 11:50 - 12:10 PM\",1429566600,1429567800,\"Authors\",null],[26,23,\"pn345\",\"Paper\",\"Understanding User Beliefs About Algorithmic Curation in the Facebook News Feed\",\"People are becoming increasingly reliant on online socio-technical systems that employ algorithmic curation to organize, select and present information. We wanted to understand how individuals make sense of the influence of algorithms, and how awareness of algorithmic curation may impact their interaction with these systems. We investigated user understanding of algorithmic curation in Facebook's News Feed, by analyzing open-ended responses to a survey question about whether respondents believe their News Feeds show them every post their Facebook Friends create. Responses included a wide range of beliefs and causal inferences, with different potential consequences for user behavior in the system. Because user behavior is both input for algorithms and constrained by them, these patterns of belief may have tangible consequences for the system as a whole.\",\"We studied user beliefs about whether algorithms affect which posts they see on Facebook. Even when algorithm actions are not explicitly visible, users still adapt their behavior in response.\",15,\"Mon 12:10 - 12:30 PM\",1429567800,1429569000,\"Authors\",null],[27,23,\"pn5110\",\"TOCHI\",\"Modelling what friendship patterns on Facebook reveal about personality and social capital\",\" In this study, we demonstrate how analysis of users’ social network structure—a topic that has remained until recently inconspicuous within Human-Computer Interaction (HCI) research on social systems—can contribute to our understanding of Social Networking Services (SNS) effect on users. Despite a consensus that SNS enhance people’s social capital, prior studies on SNS have provided inconsistent evidence on this process. In a multipronged study, we analyze personality, social capital, and Facebook data from a cohort of participants to model the extent to which one’s SNS reflects aspects of his or personality and affects his bridging social capital. Our empirically validated model shows that empathy and conscientious-ness influence the structural holes in one’s social network, which in turn affects bridging social capital. These findings highlight the importance of network structure as an intermediary between one’s personality and the social benefits one reaps from using SNS. Our work demonstrates how the implicit structural information embedded in users’ social networks can provide key insights into users’ personality and social capital.\",\" In this study, we demonstrate how analysis of users’ social network structure—a topic that has remained until recently inconspicuous within Human-Computer Interaction (HCI) research on social systems—can contribute to our understanding of Social Networking Services (SNS) effect on users. Despite a consensus that SNS enhance people’s social capital, prior studies on SNS have provided inconsistent evidence on this process. In a multipronged study, we analyze personality, social capital, and Faceb...\",15,\"Mon 12:30 - 12:50 PM\",1429569000,1429570200,\"Authors\",null],[28,-1,\"s124\",\"Papers\",\"Activism in Wikipedia & Beyond\",null,null,11,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Chair\",\"Papers\"],[29,28,\"pn1135\",\"Paper\",\"Cross-language Wikipedia Editing of Okinawa, Japan\",\"This article analyzes users who edit Wikipedia articles about Okinawa, Japan, in English and Japanese. It finds these users are among the most active and dedicated users in their primary languages, where they make many large, high-quality edits. However, when these users edit in their non-primary languages, they tend to make edits of a different type that are overall smaller in size and more often restricted to the narrow set of articles that exist in both languages. Design changes to motivate wider contributions from users in their non-primary languages and to encourage multilingual users to transfer more information across language divides are presented.\",\"Users editing Wikipedia in Japanese and English make different types of contributions in their primary and non-primary languages. This affects the spread of information with implications for platform design.\",11,\"Mon 11:30 - 11:50 AM\",1429565400,1429566600,\"Authors\",null],[30,28,\"pn1626\",\"Note\",\"Societal Controversies in Wikipedia Articles\",\"Collaborative content creation inevitably reaches situations where different points of view lead to conflict. We focus on Wikipedia, the free encyclopedia anyone may edit, where disputes about content in controversial articles often reflect larger societal debates. While Wikipedia has a public edit history and discussion section for every article, the substance of these sections is difficult to phantom for Wikipedia users interested in the development of an article and in locating which topics were most controversial. In this paper we present Contropedia, a tool that augments Wikipedia articles and gives insight into the development of controversial topics. Contropedia uses an efficient language agnostic measure based on the edit history that focuses on wiki links to easily identify which topics within a Wikipedia article have been most controversial and when.\",\"Contropedia allows for the fine-grained analysis of disputes within Wikipedia articles by measuring the substantive, disagreeing, edit activity around wiki links.\",11,\"Mon 11:50 - 12:00 PM\",1429566600,1429567200,\"Authors\",null],[31,28,\"pn2108\",\"Note\",\"The Heart Work of Wikipedia: Gendered, Emotional Labor in the World’s Largest Online Encyclopedia\",\"This note explores the issue of women’s participation in Wikipedia through the lens of emotional labor. Using a grounded theory approach, we detail the kinds of tasks women Wikipedians choose to do and explore why they choose the work they do. We also explore the emotional costs of their labor and their strategies for coping. Our analysis of 20 interviews leads us to posit that the gendered and emotional labor required of many women to participate in Wikipedia’s production renders it, problematically, a space of conflicting public and private spheres, motivated by antithetical open and closed values. In addition to other contributions, we believe this insight sheds light on some of the complex dynamics behind Wikipedia’s observed gender gap.\",\"This note uses emotional labor as a lens to examine how Wikipedia’s gender gap relates to feeling rules and participation strategies, while contributing to advancing Hochschild’s theory in mediated situations. \",11,\"Mon 12:00 - 12:10 PM\",1429567200,1429567800,\"Authors\",null],[32,28,\"pn323\",\"Paper\",\"Barriers to the Localness of Volunteered Geographic Information\",\"Localness is an oft-cited benefit of volunteered geographic information (VGI). This study examines whether localness is a constant, universally shared benefit of VGI, or one that varies depending on the context in which it is produced. Focusing on articles about geographic entities (e.g. cities, points of interest) in 79 language editions of Wikipedia, we examine the localness of both the editors working on articles and the sources of the information they cite. We find extensive geographic inequalities in localness, with the degree of localness varying with the socioeconomic status of the local population and the health of the local media. We also point out the key role of language, showing that information in languages not native to a place tends to be produced and sourced by non-locals. We discuss the implications of our work for our understanding of the nature of VGI and user-generated content and highlight a generalizable technical contribution: an algorithm that determines the home country of the original publisher of online content.\",\"Where does Wikipedia's information comes from? Across 79 language editions of Wikipedia, we show that editor and sourcing patterns largely obey rather than overcome traditional socio-economic and language barriers.\",11,\"Mon 12:10 - 12:30 PM\",1429567800,1429569000,\"Authors\",null],[33,28,\"pn2370\",\"Paper\",\"How Activists Are Both Born and Made: An Analysis of Users on Change.org\",\"E-petitioning has become one of the most important and popular forms of online activism. Although e-petition success is driven by user behavior, users have received relatively little study by HCI and social computing researchers. Drawing from theoretical and empirical work in analogous social computing systems, we identify two potentially competing theories about the trajectories of users in e-petition platforms: (1) “power” users in social computing systems are born, not made; and (2) users mature into “power” users. In a quantitative analysis of data from Change.org, one of the largest online e-petition platforms, we test and find support for both theories. A follow-up qualitative analysis shows that not only do users learn from their experience, systems also “learn” from users to make better recommendations. In this sense, we find that although power users are “born,” they are also “made” through both processes of personal growth and improved support from the system.\",\"By examining the born and made hypotheses in a mixed method analysis of Change.org users, our study advances our understanding of user behavior in e-petition systems.\",11,\"Mon 12:30 - 12:50 PM\",1429569000,1429570200,\"Authors\",null],[34,-1,\"s-float-43\",\"Papers\",\"Rethinking Evaluation for Today's HCI\",null,null,5,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Chair\",\"Papers\"],[35,34,\"pn1573\",\"Note\",\"Remote Paper Prototype Testing\",\"To test paper prototypes of mobile applications, we have been experimenting with remote paper prototype testing as an approach and tool for enabling a designer to wizard a paper prototype from afar while a user tests the prototype out of the lab. This paper presents a system for remote paper prototype testing that consists of (1) a video camera placed over a paper prototype, which streams a live audio-visual feed via Google Hangouts to a tester, and (2) Google Glass on the tester, which streams a live audio-visual-data feed to the facilitator and wizard. Results from a pilot study found that remote paper prototype testing helped designers gain valuable insights through use in realistic scenarios.\",\"We develop a method and tool that supports remote wizard-of-oz prototype testing; allows mobile app designers to test paper prototypes in realistic scenarios.\",5,\"Mon 11:30 - 11:40 AM\",1429565400,1429566000,\"Authors\",null],[36,34,\"pn1166\",\"Note\",\"Controlling In-The-Wild Evaluation Studies\",\"In this paper, we investigate the potential of controlled in-the-wild studies as an evaluation methodology that merges the benefits of lab-based and in-the-wild studies. Our exploratory investigation builds upon a comparative, between subject experiment benchmarking different interaction features of a custom public installation that visualized a series of urban datasets. In order to evaluate the usefulness of the in-the-wild versus the controlled in-the-wild methodologies, we compared the resulting findings in terms of participant engagement, insight generation, and social interaction. We propose that a controlled in-the-wild study offers a viable alternative when evaluating more complex interaction methods in public space, hereby potentially reducing the practical efforts of in-the-wild studies to involve participants.\",\"This paper investigates the potential of “controlled in-the-wild studies”, a new evaluation methodology that merges the benefits of lab-based and in-the-wild studies of public displays. \",5,\"Mon 11:40 - 11:50 AM\",1429566000,1429566600,\"Authors\",null],[37,34,\"pn1832\",\"Paper\",\"Evaluation Probes\",\"We introduce evaluation probes for conducting emic, experiential evaluation of urban technologies “in the wild” without direct researcher presence. We commence with a thorough discussion and analysis of the original cultural probes, used by Gaver, Dunne and Pacenti to gain design inspiration, and their subsequent variations. We develop the concept of evaluation probes through careful re-conceptualization and application of the cultural probes in three successive studies conducted in the wild. We recount and reflect on our use of evaluation probes and discuss their merits and limitations in experiential emic evaluation.\",\"This paper contributes a novel probes-based method for conducting emic, experiential evaluation of urban technologies in-the-wild without direct researcher presence.\",5,\"Mon 11:50 - 12:10 PM\",1429566600,1429567800,\"Authors\",null],[38,34,\"pn2386\",\"Paper\",\"Real-World Affinity Diagramming Practices: Bridging the Paper–Digital Gap\",\"Despite the availability of computer-based alternatives both for desktop and touch screen systems, a number of cooperative work processes still commonly rely on simple paper sticky notes. In this paper, we present the first in-depth investigation of the real-world practices of people who use paper-based affinity diagrams and similar clustering processes in their work, in order to identify challenges and requirements for technology support. Findings from retrospective and artifact-based interviews with 13 participants suggest ways in which the rich interactions and material affordances offered by paper are key to the process. Instead of seeking to replicate interactions with paper on a screen, simpler transfer of information between the physical and digital worlds has the potential to address many of the most pressing problems experienced in practice. We describe different types of technology integration and augmentation, with preliminary recommendations for different situations.\",\"Interview study of real-world affinity diagramming practices, aiming at a better understanding of the method and insights on how to bridge paper-based and digital artifacts.\",5,\"Mon 12:10 - 12:30 PM\",1429567800,1429569000,\"Authors\",null],[39,34,\"pn1893\",\"Paper\",\"Situational Ethics: Re-thinking Approaches to Formal Ethics Requirements for Human-Computer Interaction\",\"Most Human-Computer Interaction (HCI) researchers are accustomed to the process of formal ethics review for their evaluation or field trial protocol. Although this process varies by country, the underlying principles are universal. While this process is often a formality, for field research or lab-based studies with vulnerable users, formal ethics requirements can be challenging to navigate – a common occurrence in the social sciences; yet, in many cases, foreign to HCI researchers. Nevertheless, with the increase in new areas of research such as mobile technologies for marginalized populations or assistive technologies, this is a current reality. In this paper we present our experiences and challenges in conducting several studies that evaluate interactive systems in difficult settings, from the perspective of the ethics process. Based on these, we draft recommendations for mitigating the effect of such challenges to the ethical conduct of research. We then issue a call for interaction researchers, together with policy makers, to refine existing ethics guidelines and protocols in order to more accurately capture the particularities of such field-based evaluations, qualitative studies, challenging lab-based evaluations, and ethnographic observations.\",\"An ethics perspective on conducting evaluations and studies in difficult settings, and recommendations and call for a situational approach to ethics that more accurately captures the particularities of HCI fieldwork.\",5,\"Mon 12:30 - 12:50 PM\",1429569000,1429570200,\"Authors\",null],[40,-1,\"s-panel1\",\"Panel\",\"Transfer of HCI Research Innovations\",null,null,1,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"\",\"\"],[41,40,\"pan106\",\"Panel\",\"Technology Transfer of HCI Research Innovations: Challenges and Opportunities\",\"There has been a longstanding concern within HCI that even though we are accumulating great innovations in the field, we rarely see these innovations develop into products. Our panel brings together HCI researchers from academia and industry who have been directly involved in technology transfer of one or more HCI innovations. They will share their experiences around what it takes to transition an HCI innovation from the lab to the market, including issues around time commitment, funding, resources, and business expertise. More importantly, our panelists will discuss and debate the tensions that we (researchers) face in choosing design and evaluation methods that help us make an HCI research contribution versus what actually matters when we go to market. \",\"There has been a longstanding concern within HCI that even though we are accumulating great innovations in the field, we rarely see these innovations develop into products. Our panel brings together HCI researchers from academia and industry who have been directly involved in technology transfer of one or more HCI innovations. They will share their experiences around what it takes to transition an HCI innovation from the lab to the market, including issues around time commitment, funding, resour...\",1,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"\",\"\"],[42,-1,\"s-alt5\",\"alt.chi\",\"Augmentation\",null,null,2,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Authors\",\"Papers\"],[43,42,\"alt140\",\"alt.chi\",\"ChameleonMask: Embodied Physical and Social Telepresence using human surrogates\",\"\",\"...\",2,\"Mon 11:30 - 11:50 AM\",1429565400,1429566600,\"Authors\",\"Papers\"],[44,42,\"alt136\",\"alt.chi\",\"Consider the Moon. Human-Computer Bricolage of Extended Objects\",\"\",\"...\",2,\"Mon 11:50 - 12:10 PM\",1429566600,1429567800,\"Authors\",\"Papers\"],[45,42,\"alt149\",\"alt.chi\",\"The Broken Dream of Pervasive Sentient Ambient Calm Invisible Ubiquitous Computing\",\"\",\"...\",2,\"Mon 12:10 - 12:30 PM\",1429567800,1429569000,\"Authors\",\"Papers\"],[46,42,\"alt153\",\"alt.chi\",\"A Formal Analysis of the ISO 9241-210 Definition of User Experience\",\"\",\"...\",2,\"Mon 12:30 - 12:50 PM\",1429569000,1429570200,\"Authors\",\"Papers\"],[47,-1,\"s-crs108\",\"Course\",\"Designing Websites for Adults 55+\",null,null,6,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Instructor\",null],[48,47,\"crs108\",\"Course\",\"Designing Websites for Adults 55+: Toward Universal Design\",\"This course describes age-related factors that affect ability to use the Web, and presents Web design guidelines that reflect the capabilities, usage patterns, and preferences of older Web users.  The course also explains the value of testing websites on older adults.\",\"The ultimate outcome is that the usability of the Web will be improved for older adults.\",6,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Instructor\",null],[49,-1,\"s-crs128\",\"Course\",\"Cross-Device, Context-dependent UI\",null,null,7,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Instructor\",null],[50,49,\"crs128\",\"Course\",\"Design and Adaptation for Cross-Device, Context-dependent User Interfaces\",\"This tutorial aims to help user interface designers and developers to understand the issues involved in multi-device, context-dependent interactive applications, which can be accessed through wearable, mobile and stationary devices even exploiting different interaction modalities. It will provide a discussion of the possible solutions in terms of concepts, techniques, languages, and tools, with particular attention to Web environments. The tutorial will deal with the various strategies in order to adapt, distribute, and migrate the user interface according to the context of use. \",\"This tutorial aims to help user interface designers and developers to understand the issues involved in multi-device, context-dependent interactive applications, which can be accessed through wearable, mobile and stationary devices \",7,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Instructor\",null],[51,-1,\"s-crs132\",\"Course\",\"Body, Whys & Videotape: Somatic Approaches\",null,null,9,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Instructor\",null],[52,51,\"crs132\",\"Course\",\"Body, Whys & Videotape: Somatic Approaches to Experience in HCI\",\"\",\"...\",9,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Instructor\",null],[53,-1,\"s-float-6\",\"Papers\",\"Non-Rigid Interaction Surfaces\",null,null,3,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Chair\",\"Papers\"],[54,53,\"pn2680\",\"Paper\",\"bioLogic: Natto Cells as Nanoactuators for Shape Changing Interfaces\",\"Based on the natural phenomenon of cells’ hygromorphic transformation, we introduce living Bacillus Subtilis natto cell as a humidity sensitive nanoactuator. In this paper, we unfold the process of exploring and comparing cell types that are proper for HCI use, the development of the composite biofilm, the development of the responsive structures, the control setup for actuating biofilms, and a simulation and fabrication platform. Finally, we provide a variety of application designs, with and without computer control to demonstrate the potential of our bio actuators. Through this paper, we intend to enable the use of natto cells and our platform technologies for HCI researchers, designers and bio-hackers. And more generally, we try to encourage the use and research of biological materials and interdisciplinary research in HCI.\",\"We encourage the use of living natto cells and our platform technologies for the design of shape changing interfaces, and more generally, the use and research of biological materials and interdisciplinary research in HCI.\",3,\"Mon 11:30 - 11:50 AM\",1429565400,1429566600,\"Authors\",null],[55,53,\"pn1217\",\"Note\",\"Control of Non-Solid Diffusers by Electrostatic Charging\",\"The form factors of displays using fog or water surface are limited by our ability to control the non-solid substances used as the diffuser. We propose a charging technique for polar aerosols (e.g., mist or fog) that allows control of the shape and trajectory of such non-solid diffusers using electric fields. We report experiments that allowed us to design a charging mechanism that produces charged fog aerosols with homogeneous electrical mobility. We illustrate our idea by demonstrating how electric fields can be used to control the shape of a fog display and the trajectory of a bubble display.\",\"We present a novel technique to control the shape and position of non-solid diffusers, such as fog and bubble displays. This technique is simple to implement and opens interesting possibilities for new mid air displays. \",3,\"Mon 11:50 - 12:00 PM\",1429566600,1429567200,\"Authors\",null],[56,53,\"pn875\",\"Note\",\"Investigation of Material Properties for Thermal Imaging-Based Interaction\",\"Recent work demonstrated the exciting opportunities that thermal imaging offers for the development of interactive systems. It was shown that a thermal camera can sense when a user touches a surface, performs gestures in the camera's direct field of view and, in addition, performs gestures outside the camera's direct field of view through thermal reflection. In this  paper, we investigate the material properties that should be considered for detecting interaction using thermal imaging considering both in- and outdoor settings. We conducted a study to analyze the recognition performance for different gestures and different surfaces. Using the results, we derive guidelines on material properties of surfaces for detecting on-surface as well as mid-air interaction using a thermal camera. We  discuss the constrains that should be taken into account using thermal imaging as the sensing technology. Finally, we present a material space based on our findings. The space depicts surfaces and the required properties that enable the different interaction techniques.\",\"In this paper we explored important surfaces material properties that should be considered for using thermal imaging as the sensing technology for building interactive surfaces supporting on-surface and mid-air gestures.\",3,\"Mon 12:00 - 12:10 PM\",1429567200,1429567800,\"Authors\",null],[57,53,\"pn2604\",\"Paper\",\"ShapeClip: Towards Rapid Prototyping with Shape-Changing Displays for Designers\",\"This paper presents ShapeClip: a modular tool capable of transforming any computer screen into a z-actuating shape-changing display. This enables designers to produce dynamic physical forms by ‘clipping’ actuators onto screens. ShapeClip displays are portable, scalable, fault-tolerant, and support runtime re-arrangement. Users are not required to have knowledge of electronics or programming, and can develop motion designs with presentation software, image editors, or web-technologies. To evaluate ShapeClip we carried out a full-day workshop with expert designers. Participants were asked to generate shape-changing designs and then construct them using ShapeClip. ShapeClip enabled participants to rapidly and successfully transform their ideas into functional systems.\",\"This paper presents ShapeClip: a modular tool capable of transforming any computer screen into a z-actuating shape-changing display. It contributes: (1) Concept and implementation; (2) A capability demonstration; and (3) Findings from a design workshop.\",3,\"Mon 12:10 - 12:30 PM\",1429567800,1429569000,\"Authors\",null],[58,53,\"pn2122\",\"Paper\",\"FluxPaper: Reinventing Paper with Dynamic Actuation Powered by Magnetic Flux\",\"FluxPaper is a new paper-based medium that enables physical movement and dynamic interaction between a high-power magnetized paper and a programmable magnetic field. FluxPaper has a very thin patterned magnetic layer (0.1 mm) pasted behind the paper. A thin but strong neodymium-based magnet realizes fast, powerful, and precise physical actions while retaining the original characteristics of the paper that is widely used in our daily lives. Owing to an effective magnetic pattern and a computer-controlled magnetic field, FluxPaper can add new interaction modality to ordinary paper. We describe the functions of magnetized paper; challenges through realization; and the interaction scenarios in several applications, such as self-alignment, self-construction, floating on the board, and quickly picking out a target card from a stack.\",\"FluxPaper is a new paper-based medium that enables physical movement and dynamic interaction with a programmable magnetic field to invent a fast, powerful, and precise manipulation as an active paper.\",3,\"Mon 12:30 - 12:50 PM\",1429569000,1429570200,\"Authors\",null],[59,-1,\"s119\",\"Papers\",\"Improving Game Experiences\",null,null,10,\"Mon 11:30 - 12:50 PM\",1429565400,1429570200,\"Chair\",\"Papers\"],[60,59,\"pn282\",\"Paper\",\"The Royal Corgi: Exploring Social Gaze Interaction for Immersive Gameplay\",\"The eyes are a rich channel for non-verbal communication in our daily interactions. We propose social gaze interaction as a game mechanic to enhance user interactions with virtual characters. We develop a game from the ground-up in which characters are designed to be reactive to the player's gaze in social ways, such as getting annoyed when the player seems distracted or changing their dialogue depending on the player's apparent focus of attention. Results from a qualitative user study provide insights about how social gaze interaction is intuitive for users, elicits deep feelings of immersion, and highlight the players' self-consciousness of their own eye movements through their strong reactions to the characters.\",\"We introduce social gaze interaction as game mechanic to enhance players experience and immersion. Players are able to interact with character with their eyes in a social way.\",10,\"Mon 11:30 - 11:50 AM\",1429565400,1429566600,\"Authors\",null],[61,59,\"pn153\",\"Paper\",\"Exploring 3D User Interface Technologies for Improving the Gaming Experience\",\"We present the results of a comprehensive video game study which explores how the gaming experience is effected when several 3D user interface technologies are used simultaneously. We custom designed an air-combat game integrating several 3DUI technologies (stereoscopic 3D, head tracking, and finger-count gestures) and studied the combined effect of these technologies on the gaming experience. Our game design was based on existing design principles for optimizing the usage of these technologies in isolation. Additionally, to enhance depth perception and minimize visual discomfort, the game dynamically optimizes stereoscopic 3D parameters (convergence and separation) based on the user's look direction. We conducted a within subjects experiment where we examined performance data and self-reported data on users perception of the game. Our results indicate that participants performed significantly better when all the 3DUI technologies (stereoscopic 3D, head-tracking and finger-count gestures) were available simultaneously with head tracking as a dominant factor. We explore the individual contribution of each of these technologies to the overall gaming experience and discuss the reasons behind our findings.\",\"We present the results of a comprehensive video game study which explores how the gaming experience is effected when several 3D user interface technologies (stereoscopic 3D, head tracking, and finger-count gestures) are used simultaneously.\",10,\"Mon 11:50 - 12:10 PM\",1429566600,1429567800,\"Authors\",null],[62,59,\"pn1617\",\"Paper\",\"Quantifying and Mitigating the Negative Effects of Local Latencies on Aiming in 3D Shooter Games\",\"Real-time games such as first-person shooters (FPS) are sensitive to even small amounts of lag. The effects of net-work latency have been studied, but less is known about local latency, the lag caused by input devices and displays. While local latency is important to gamers, we do not know how it affects aiming performance and whether we can reduce its negative effects. To explore these issues, we tested local latency in a variety of real-world gaming scenarios and carried out a controlled study focusing on targeting and tracking activities in an FPS game with varying degrees of local latency. In addition, we tested the ability of a lag compensation technique (based on aim assistance) to mitigate the negative effects. Our study found local latencies in the real-world range from 23 to 243 ms which cause significant and substantial degradation in performance (even for latencies as low as 41 ms). The study also showed that our compensation technique worked extremely well, reducing the problems caused by lag in the case of targeting, and removing the problem altogether in the case of tracking. Our work shows that local latency is a real and substantial problem – but games can mitigate the problem with appropriate compensation methods.\",\"Provides empirical evidence about the magnitude of local latency in real-world gaming systems, the effects of local latency on aiming performance, and the effectiveness of lag-compensation techniques.\",10,\"Mon 12:10 - 12:30 PM\",1429567800,1429569000,\"Authors\",null],[63,59,\"pn681\",\"Note\",\"First Person vs. Third Person Perspective in Digital Games: Do Player Preferences Affect Immersion?\",\"Contemporary digital game developers offer a variety of games for the diverse tastes of their customers. Although the gaming experience often depends on one’s preferences, the same may not apply to the level of their immersion. It has been argued whether the player perspective can influence the level of player’s involvement with the game. The aim of this study was to research whether interacting with a game in first person perspective is more immersive than playing in the third person point of view (POV). The set up to test the theory involved participants playing a role-playing game in either mode, naming their preferred perspective, and subjectively evaluating their immersive experience. The results showed that people were more immersed in the game play when viewing the game world through the eyes of the character, regardless of their preferred perspectives.\",\"This paper describes a study, which assessed player immersion in first-person and third-person perspectives in a role-playing game with relation to player preferences in terms of camera viewpoint.\",10,\"Mon 12:30 - 12:40 PM\",1429569000,1429569600,\"Authors\",null],[64,59,\"pn708\",\"Note\",\"VIZMO Game Browser: Accessing Video Games by Visual Style and Mood\",\"Despite the growing interests in video games as consumer products as well as objects of research, current methods for accessing video games are limited. We present Vizmo as a new way of browsing video games based on their visual style and mood. In order to test the usability and usefulness of Vizmo, we asked 19 video game experts to evaluate their interaction with the tool. The results show that experts perceived Vizmo as a novel and aesthetically pleasing game discovery tool which would be most useful for game research on historical and aesthetic aspects. We discuss five key points for improving the design of Vizmo as well as our future plan for the next iteration of this prototype game browser.\",\"We present Vizmo, a novel and aesthetically pleasing game discovery tool that allows users to search or browse video games based on their visual style and mood. \",10,\"Mon 12:40 - 12:50 PM\",1429569600,1429570200,\"Authors\",null],[65,-1,\"break-2\",\"Breaks\",\"Lunch Break (on your own)\",null,null,15,\"Mon 12:50 - 2:30 PM\",1429570200,1429576200,\"\",\"\"],[66,-1,\"s-float-21\",\"Papers\",\"Making & Sharing Assistive Technologies\",null,null,12,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Chair\",\"Papers\"],[67,66,\"pn1118\",\"Paper\",\"Being Seen: Co-Interpreting Parkinson’s Patient’s Movement Ability in Deep Brain Stimulation Programming\",\"The purpose of this study is to address the use of movement assessment sensors for clinical diagnosis and treatment. Eleven patients with Parkinson’s disease who had under-gone deep brain stimulation (DBS) surgery were observed during follow-up appointments for adjustments to the stimulation settings. We examine the ways in which the patients and clinicians assess movement ability together in the clinic and how these assessments relate to the treatment of functional disability through DBS.  We have found that effective assessment of movement and treatment efficacy is a collaborative and interpretive process (co-interpretation) that relies on input from patients, clinicians, and caregivers. From these findings we describe the design directions for movement sensors to support co-interpretation of movement in a clinical context as opposed to simply movement definition.\",\"We show that effective assessment of movement and treatment efficacy is a collaborative and interpretive process (co-interpretation). Describe design directions for movement sensors to support co-interpretation of movement.\",12,\"Mon 2:30 - 2:50 PM\",1429576200,1429577400,\"Authors\",null],[68,66,\"pn1001\",\"Paper\",\"Designing for and with People with Parkinson’s: A Focus on Exergaming\",\"Parkinson’s is a complex and multifaceted condition with a myriad of symptoms, thus, designing for and with this user group requires careful consideration. We reflect upon two studies, employing different design methodologies, relating to the design of rehabilitative exergames in Parkinson’s.  The first explored the concept of designing ‘for’ People with Parkinson’s (PwP) and focused on specifications outlined by clinical stakeholders. The second used a designing ‘with’ approach and modified a pre-established participatory design method for use with  PwP. We call attention to the importance of carrying out design work with PwP and contribute; an empathic understanding of living with Parkinson’s, a set of recommendations for how to design with PwP and a set of wider considerations for developing rehabilitative exergames for PwP. \",\"Describes two case studies focusing on the design of rehabilitative exergames for people with Parkinson’s (PwP). Will benefit future designers wishing to engage PwP and clinicians in the design process. \",12,\"Mon 2:50 - 3:10 PM\",1429577400,1429578600,\"Authors\",null],[69,66,\"pn885\",\"Note\",\"LApp: A Speech Loudness Application for People with Parkinson’s on Google Glass\",\"Reduced vocal volume in Parkinson’s is extremely common and can have significant social and emotional impact. We describe the development and evaluation of LApp—an application for Google Glass to help people with Parkinson’s (PwP) monitor their speech volume and cue themselves to speak louder when necessary. Our findings highlight enthusiasm for using the application both at home as a volume training tool and in public social settings as a situated cueing device. We contribute insights to the literature on how eyewear technologies can provide assistance to people with health conditions and offer insights for the design of future self-monitoring and management applications on Google Glass.\",\"Describes development of a speech volume monitoring and management application for people with Parkinson’s on Google Glass. Will benefit those engaging people with specific needs in designing future Glass applications.\",12,\"Mon 3:10 - 3:20 PM\",1429578600,1429579200,\"Authors\",null],[70,66,\"pn1124\",\"Note\",\"The Virtual Meditative Walk: Virtual Reality Therapy for Chronic Pain Management\",\"Because the nature of chronic pain is complex, pharmacological analgesics are often not enough to achieve an ideal treatment plan. Virtual Reality (VR) technologies have emerged within medical research in recent years for treating acute pain, and proved to be an effective strategy based on pain distraction. This paper describes a VR system designed for chronic pain patients. The system incorporates biofeedback sensors, an immersive virtual environment, and stereoscopic sound titled the “Virtual Meditative Walk” (VMW). It was designed to enable chronic pain patients to learn Mindfulness-based stress reduction (MBSR), a form of meditation. By providing real-time visual and sonic feedback, VMW enables patients to learn how to manage their pain. A proof-of-concept user study was conducted to investigate the effectiveness of the VR system with chronic pain patients in clinical settings. Results show that the VMW was more effective in reducing perceived pain compared to the non-VR control condition.\",\"A proof-of-concept user study was conducted to investigate the effectiveness of a VR system with chronic pain patients. Results show the VMW was more effective in reducing perceived pain than non-VR condition.\",12,\"Mon 3:20 - 3:30 PM\",1429579200,1429579800,\"Authors\",null],[71,66,\"pn2191\",\"Paper\",\"Sharing is Caring: Assistive Technology Designs on Thingiverse\",\"An increasing number of online communities support the open-source sharing of designs that can be built using rapid prototyping to construct physical objects. In this paper, we examine the designs and motivations for assistive technology found on Thingiverse.com, the largest of these communities at the time of this writing. We present results from a survey of all assistive technology that has been posted to Thingiverse since 2008 and a questionnaire distributed to the designers exploring their relationship with assistive technology and the motivation for creating these designs. The majority of these designs are intended to be manufactured on a 3D printer and include assistive devices and modifications for individuals with disabilities, older adults, and medication management. Many of these designs are created by the end-users themselves or on behalf of friends and loved ones. These designers frequently have no formal training or expertise in the creation of assistive technology. This paper discusses trends within this community as well as future opportunities and challenges.\",\"This study examines open-sourced fabrication designs for assistive technology on Thingiverse.com and offers a description of the currently available designs, designer demographics, and strategies for diversifying this population in future.\",12,\"Mon 3:30 - 3:50 PM\",1429579800,1429581000,\"Authors\",null],[72,-1,\"s-float-45\",\"Papers\",\"Music & Art\",null,null,10,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Chair\",\"Papers\"],[73,72,\"pn1942\",\"Paper\",\"Deformable Interfaces for Performing Music\",\"Deformable interfaces offer new possibilities for gestures, some of which have been shown effective in controlled laboratory studies. Little work, however, has attempted to match deformable interfaces to a demanding domain and evaluate them out of the lab. We investigate how musicians use deformable interfaces to perform electronic music. We invited musicians to three workshops, where they explored 10 deformable objects and generated ideas on how to use these objects to perform music. Based on the results from the workshops, we implemented sensors in the five preferred objects and programmed them for controlling sounds. Next, we ran a performance study where six musicians performed music with these objects at their studios. Our results show that (1) musicians systematically map deformations to certain musical parameters, (2) musicians use deformable interfaces especially to filter and modulate sounds, and (3) musicians think that deformable interfaces embody the parameters that they control. We discuss what these results mean to research in deformable interfaces.\",\"This paper makes two contributions to deformable interfaces: 1) design implications for deformable interfaces based on findings from three workshops 2) findings on the use of deformable interfaces out of the lab for music performance.\",10,\"Mon 2:30 - 2:50 PM\",1429576200,1429577400,\"Authors\",null],[74,72,\"pn587\",\"Paper\",\"Sculpting a Mobile Musical Soundtrack\",\"We present an in-the-wild project to design and study a mobile musical soundtrack that enhances the experience of visiting a sculpture park. As with soundtracks for films and games, the goal was to enhance the emotional and narrative aspects of the experience while remaining in the background. We describe a compositional approach in which we first established a broad musical landscape before treating specific exhibits with detailed musical trajectories. Our study reveals how our soundtrack dramatically shaped visitors’ experiences while they remained largely unaware of its operation. We distil seven experiential factors to be addressed by mobile soundtracks alongside ten compositional guidelines.\",\"The work contained in this paper distils seven experiential factors to be addressed by mobile soundtracks alongside ten compositional guidelines to support the creation of mobile soundtracks for walking experiences. \",10,\"Mon 2:50 - 3:10 PM\",1429577400,1429578600,\"Authors\",null],[75,72,\"pn1834\",\"Paper\",\"Walking by Drawing\",\"This paper describes a study of algorithmic living with Trace, a mobile mapping application that generates walking routes based on digital sketches people create and annotate without a map. In addition to creating walking paths, Trace enables people to send the paths to others. We designed Trace to explore the possibility of emphasizing guided wandering over precise, destination-oriented navigation. Studies of sixteen people’s use of Trace over roughly one week reveal how walkers find Trace both delightful and disorienting, highlighting moments of surprise, frustration, and identification with GIS routing algorithms. We conclude by discussing how design interventions offers possibilities for understanding the work of mapping and how it might be done differently in HCI. \",\"This paper describes a study of algorithmic living with Trace, a mobile mapping application that generates walking routes based on digital sketches that people can send to others.\",10,\"Mon 3:10 - 3:30 PM\",1429578600,1429579800,\"Authors\",null],[76,72,\"pn815\",\"Paper\",\"ArtMaps: Interpreting the Spatial Footprints of Artworks\",\"Creating and utilizing simple links between items and locations in map-based systems has become a mainstream component of modern computing. In this paper, we explore support for ‘art mapping’, an activity that requires consideration of more complex interpretations of spatial relationships as users engage with identifying locations of relevance to artworks. Through a user study of the ArtMaps platform, and an exploratory study with professional artists, we identify diverse interpretations of spatial meaning in relation to art. We find that art mapping highlights potential for more active engagement with art through technology, but challenges existing systems for spatial representation. Through connecting our findings with work on designing for interpretation, and on space and place in HCI, we contribute new understanding of creating engagement through the spatial interpretation of art, and define potential characteristics and uses of holistic ‘footprints’ for artworks.\",\"Geotagging is commonplace. We explore how it can be applied to suggesting locations relevant to artworks. The multiplicity of approaches found highlight characteristics and opportunities for spatial ’footprints’ of objects.\",10,\"Mon 3:30 - 3:50 PM\",1429579800,1429581000,\"Authors\",null],[77,-1,\"s100\",\"Papers\",\"Interaction in 3D Space\",null,null,4,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Chair\",\"Papers\"],[78,77,\"pn112\",\"Paper\",\"Physical Loci: Leveraging Spatial, Object and Semantic Memory for Command Selection\",\"Physical Loci, a technique based on an ancient memory technique, allows users to quickly learn a large command set by leveraging spatial, object and verbal/semantic memory to create a cognitive link between individual commands and nearby physical objects in a room (called loci). We first report on an experiment that showed that for learning 25 items Physical Loci outperformed a mid-air Marking Menu baseline. A long-term retention experiment with 48 items then showed that recall was nearly perfect one week later and, surprisingly, independent of whether the command/locus mapping was one’s own choice or somebody else’s. A final study suggested that recall performance is robust to alterations of the learned mapping, whether systematic or random. \",\"Physical Loci is a command selection technique reminiscent of the method of loci that leverages spatial memory, object memory and semantic associations.\",4,\"Mon 2:30 - 2:50 PM\",1429576200,1429577400,\"Authors\",null],[79,77,\"pn1073\",\"Note\",\"LeviPath: Modular Acoustic Levitation for 3D Path Visualisations\",\"LeviPath is a modular system to levitate objects across 3D paths. It consists of two opposed arrays of transducers that create a standing wave capable of suspending objects in mid-air. To control the standing wave, the system employs a novel algorithm based on combining basic patterns of movement. Our approach allows the control of multiple beads simultaneously along different 3D paths. Due to the patterns and the use of only two opposed arrays, the system is modular and can scale its interaction space by joining several LeviPaths. In this paper, we describe the hardware architecture, the basic patterns of movement and how to combine them to produce 3D path visualisations.\",\"LeviPath is a modular system to levitate objects across 3D paths for dynamic physical visualisations. Our approach allows the control of multiple beads simultaneously along different 3D paths.\",4,\"Mon 2:50 - 3:00 PM\",1429577400,1429578000,\"Authors\",null],[80,77,\"pn433\",\"Note\",\"Twist and Learn: Interface Learning in 3DOF Exploration of 3D Scatterplots\",\"The increasing availability of 3D interfaces brings promise of improved user experience in diverse areas. Our study focuses on visual analytics, testing whether 3D interactivity improves performance in a visual data exploration task. Specifically, we compared scene rotation around vertical axis to a full 3D rotation using a  InterSense IS-900 3D controller, in a task involving trivariate trend detection in a 3D scatterplot. We found that, while 3D rotation leads to slower performance, previous exposure to single-axis rotation removes that difference. This shows that an interactive 3D scatterplot can be an effective visual exploration technique for detecting trivariate patterns in the data, and highlights the role of interface learning in design and assessment of novel interfaces.\",\"We test whether 3D interactivity improves performance in a visual analytics task: complex pattern detection in a 3D scatterplot. It does not, but the analysis of interface learning looks promising. \",4,\"Mon 3:00 - 3:10 PM\",1429578000,1429578600,\"Authors\",null],[81,77,\"pn263\",\"Paper\",\"THING: Introducing a Tablet-based Interaction Technique for controlling 3D Hand Models\",\"The hands of virtual characters are highly complex 3D models that can be tedious and time-consuming to animate with current methods. This paper introduces THING, a novel tablet-based approach that leverages multi-touch interaction for a quick and precise control of a 3D hand's pose. The flexion/extension and abduction/adduction of the virtual fingers can be controlled for each finger individually or for several fingers in parallel through sliding motions on the tablet's surface. We designed two variants of THING: (1) MobileTHING, which maps the spatial location and orientation of the tablet to that of the virtual hand, and (2) DesktopTHING, which combines multi-touch controls of fingers with traditional mouse controls for the hand's global position and orientation. We compared the usability of THING against mouse-only controls and a data glove in two controlled experiments. Results show that DesktopTHING was significantly preferred by users while providing performance similar to data gloves. Together, these results could pave the way to the introduction of novel hybrid user interfaces based on tablets and mice in future animation pipelines.\",\"3D hand animation is a difficult process requiring time-consuming methods or expensive hardware. THING allows animators to control 3D hands simply by performing finger gestures over a multi-touch tablet.\",4,\"Mon 3:10 - 3:30 PM\",1429578600,1429579800,\"Authors\",null],[82,77,\"pn623\",\"Paper\",\"The Roly-Poly Mouse: Designing a Rolling Input Device Unifying 2D and 3D Interaction\",\"We present the design and evaluation of the Roly-Poly Mouse (RPM), a rolling input device that combines the advantages of the mouse (position displacement) and of 3D devices (roll and rotation) to unify 2D and 3D interaction. Our first study explores RPM gesture amplitude and stability for different upper shapes (Hemispherical, Convex) and hand postures. 8 roll directions can be performed precisely and their amplitude is larger on Hemispherical RPM. As minor rolls affect translation, we propose a roll correction algorithm to support stable 2D pointing with RPM. We propose the use of compound gestures for 3D pointing and docking, and evaluate them against a commercial 3D device, the SpaceMouse. Our studies reveal that RPM performs 31% faster than the SpaceMouse for 3D pointing and equivalently for 3D rotation. Finally, we present a proof-of-concept integrated RPM prototype along with discussion on the various technical challenges to overcome to build a final integrated version of RPM.\",\"We present the design and evaluation of the Roly-Poly Mouse (RPM), a rolling input device that combines the advantages of the mouse and of 3D devices.\",4,\"Mon 3:30 - 3:50 PM\",1429579800,1429581000,\"Authors\",null],[83,-1,\"s131\",\"Papers\",\"Supporting Change in Developing Countries\",null,null,15,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Chair\",\"Papers\"],[84,83,\"pn400\",\"Paper\",\"Sangeet Swara: A Community-Moderated Voice Forum in Rural India\",\"Interactive voice forums have emerged as a promising platform for people in developing regions to record and share audio messages using low-end mobile phones.  However, one of the barriers to the scalability of voice forums is the process of screening and categorizing content, often done by a dedicated team of moderators.  We present Sangeet Swara, a voice forum for songs and cultural content that relies on the community of callers to curate high-quality posts that are prioritized for playback to others.  An 11-week deployment of Sangeet Swara found broad and impassioned usage, especially among visually impaired users.  We also conducted a follow-up experiment, called Talent Hunt, that sought to reduce reliance on toll-free telephone lines. Together, our deployments span about 53,000 calls from 13,000 callers, who submitted 6,000 posts and 150,000 judgments of other content.  Using a mixed-methods analysis of call logs, audio content, comparison with outside judges, and 204 automated phone surveys, we evaluate the user experience, the strengths and weaknesses of community moderation, financial sustainability, and the implications for future systems.\",\"Describes a vibrant community that emerged on an interactive voice forum in rural India.  Shows that voice forums can be moderated by their own users, just like popular Internet websites.\",15,\"Mon 2:30 - 2:50 PM\",1429576200,1429577400,\"Authors\",null],[85,83,\"pn685\",\"Paper\",\"Mobile Phones for Maternal Health in Rural India\",\"We present our findings from a mixed methods study of mobile phone practices of rural Indian women. We situate our study in the context of Projecting Health, a public health initiative we deployed in Uttar Pradesh (India) to target the dissemination of health information for mothers and newborns. Adopting the lens of feminist reflexivity, we reconsider our design of Projecting Health by factoring in the mobile media consumption and sharing practices of our target audience. We stress the importance of taking a community-oriented approach and show that although there are strict social conventions and patriarchal norms that constrain various practices of these women, they are able to exercise agency and mobilize help within their communities when needed.\",\"This paper provides an interpretive analysis of women's mobile media practices in rural India and how these can be leveraged for more effective dissemination of information for maternal and newborn health. \",15,\"Mon 2:50 - 3:10 PM\",1429577400,1429578600,\"Authors\",null],[86,83,\"pn2476\",\"Paper\",\"Residual Mobilities: Infrastructural Displacement and Post-Colonial Computing in Bangladesh\",\"This paper explores discrepancies between the founding assumptions of mobile and ubiquitous computing in the western world, and the starkly different experiences of mobility and infrastructure to be found in many post-colonial environments. Based on a field study of forced mobility and technology use among populations displaced by the Hatirjheel waterfront development project in Dhaka, Bangladesh, we make two basic arguments. First, we point to the partial nature of assumptions around mobility that frame the imagination of mainstream HCI research, and argue that different and heretofore residual experiences of mobility must also be accounted for in post-colonial and other marginal computing environments. Second, we document four forms of infrastructural experience – dispossession, reconstitution, collaboration, and repair – that characterize real-world engagements with infrastructure in such settings. We conclude with implications for HCI research and design, and reflections on how HCI researchers might better account for such experiences in their work. \",\"We have introduced the concept of residual mobilities to better account for the technology experiences and infrastructural engagements characterizing people undergoing radical experiences of displacement. \",15,\"Mon 3:10 - 3:30 PM\",1429578600,1429579800,\"Authors\",null],[87,83,\"pn2471\",\"Paper\",\"Más Tecnologia, Más Cambio? Investigating an Educational Technology Project in Rural Peru\",\"Providing access to and training in ICTs is seen as key to bridging the digital divide between technology-rich communities and those with poor IT infrastructures. Several projects have focused on providing ICTs for education in developing countries, of which the best known is One Laptop Per Child (OLPC). Although, there has been significant criticism of some of these projects, in particular OLPC, due to its use of a top-down implementation strategy and the limited evidence for its educational benefits, there has been comparatively little analysis of what underlies successful approaches. We aimed to address this deficit by conducting an ethnographic study of community-based projects organised by Blue Sparrow, a small charity that donates refurbished desktop computers to schools in rural Peru, as this organisation has experienced both successes and failures when implementing its educational technology projects. The relative success of Blue Sparrow highlights the benefits of: understanding local contexts; using a bottom up approach; involving stakeholders in setting programme objectives; and empowering communities. We argue that the educational impact of such projects can be improved by: providing teacher training; integrating computers into the wider curriculum; and providing teaching materials and clear objectives for volunteers.\",\"This paper describes an ethnographic study of educational ICT use in a rural Andean community. It provides implications for practitioners seeking to maximise educational ICT success rates in low resource contexts. \",15,\"Mon 3:30 - 3:50 PM\",1429579800,1429581000,\"Authors\",null],[88,-1,\"s116\",\"Papers\",\"Privacy, Security & Interruptions\",null,null,11,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Chair\",\"Papers\"],[89,88,\"pn169\",\"Paper\",\"Playing the Legal Card: Using Ideation Cards to Raise Data Protection Issues within the Design Process\",\"The regulatory climate is in a process of change. Design, having been implicated for some time, is now explicitly linked to law. This paper recognises the heightened role of designers in the regulation of ambient interactive technologies. Taking account of incumbent legal requirements is difficult. Legal rules are convoluted, uncertain, and not geared towards operationalisable heuristics or development guidelines for system designers. Privacy and data protection are a particular moral, social and legal concern for technologies. This paper seeks to understand how to make emerging European data protection regulation more accessible to our community. Our approach develops and tests a series of data protection ideation cards with teams of designers. We find that, whilst wishing to protect users, regulation is viewed as a compliance issue. Subsequently we argue for the use of instruments, such as our cards, as a means to engage designers in leading a human-centered approach to regulation. \",\"This paper recognises the heightened role of designers in regulation of Ubicomp. We develop a series of data protection ideation cards, for HCI, to raise awareness of emergent EU regulations. \",11,\"Mon 2:30 - 2:50 PM\",1429576200,1429577400,\"Authors\",null],[90,88,\"pn1266\",\"Paper\",\"Crowdsourced Exploration of Security Configurations\",\"Smartphone apps today request permission to access a multitude of sensitive resources, which users must accept completely during installation (e.g., on Android) or selectively configure after installation (e.g., on iOS, but also planned for Android). Everyday users, however, do not have the ability to make informed decisions about which permissions are essential for their usage. For enhanced privacy, we seek to leverage crowdsourcing to find minimal sets of permissions that will preserve the usability of the app for diverse users. We advocate an efficient ‘lattice-based’ crowd-management strategy to explore the space of permissions sets. We conducted a user study (N = 26) in which participants explored different permission sets for the popular Instagram app. This study validates our efficient crowd management strategy and shows that usability scores for diverse users can be predicted accurately, enabling suitable recommendations.\",\"This research seeks to leverage crowdsourcing to efficiently find a set of permissions for each user installing an app that strikes an acceptable balance between app usability and user privacy\",11,\"Mon 2:50 - 3:10 PM\",1429577400,1429578600,\"Authors\",null],[91,88,\"pn904\",\"Paper\",\"Open Book: A Socially-inspired Cloaking Technique that Uses Lexical Abstraction to Transform Messages\",\"Both governments and corporations routinely surveil computer-mediated communication (CMC). Technologists often suggest widespread encryption as a defense mechanism, but CMC encryption schemes have historically faced significant usability and adoption problems. Here, we introduce a novel technique called Open Book designed to address these two problems. Inspired by how people deal with eavesdroppers offline, Open Book uses data mining and natural language processing to transform CMC messages into ones that are vaguer than the original. Specifically, we present: 1) a greedy Open Book algorithm that cloaks messages by transforming them to resemble the average Internet message; 2) an open-source, browser-based instantiation of it called Read Me, designed for Gmail; and, 3) a set of experiments showing that intended recipients can decode Open Book messages, but that unintended human- and machine-recipients cannot. Finally, we reflect on some open questions raised by this approach, such as recognizability and future side-channel attacks.\",\"We introduce a new technique called Open Book designed to address encryption's social usability problems. Open Book uses NLP to transform messages into ones that are vaguer than the original.\",11,\"Mon 3:10 - 3:30 PM\",1429578600,1429579800,\"Authors\",null],[92,88,\"pn1501\",\"Paper\",\"Sensors Know When to Interrupt You In the Car: Detecting Driver Interruptibility Through Monitoring of Peripheral Interactions\",\"Interruptions while driving can be quite dangerous, whether these are self-interruptions or external interruptions. They increase driver workload and reduce performance on the primary driving task. Being able to identify when a driver is interruptible is critical for building systems that can mediate these interruptions. In this paper, we collect sensor and human-annotated data from 15 drivers, including vehicle motion, traffic states, physiological responses and driver motion. We demonstrate that this data can be used to build a machine learning classifier that can determine interruptibility every second with a 94% accuracy. We present both population and individual models and discuss the features that contribute to the high performance of this system. Such a classifier can be used to build systems that mediate when drivers use technology to self-interrupt and when drivers are interrupted by technology.\",\"Sensors know when to interrupt you in the car. We show that driver interruptibility can be detected every second with a 94% accuracy through monitoring of peripheral interactions.\",11,\"Mon 3:30 - 3:50 PM\",1429579800,1429581000,\"Authors\",null],[93,-1,\"s-float-41\",\"Papers\",\"Understanding & Evaluating Performance\",null,null,5,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Chair\",\"Papers\"],[94,93,\"pn2048\",\"Paper\",\"ModelTracker: Redesigning Performance Analysis Tools for Machine Learning\",\"Model building in machine learning is an iterative process. The performance analysis and debugging step typically involves a disruptive cognitive switch from model building to error analysis, discouraging an informed approach to model building. We present ModelTracker, an interactive visualization that subsumes information contained in numerous traditional summary statistics and graphs while displaying example-level performance and enabling direct error examination and debugging. Usage analysis from machine learning practitioners building real models with ModelTracker over six months shows ModelTracker is used often and throughout model building. A controlled experiment focusing on ModelTracker’s debugging capabilities shows participants prefer ModelTracker over traditional tools without a loss in model performance.\",\"Presents ModelTracker, an interactive visualization of machine learning models. Field and controlled studies show that ModelTracker encourages more informed model building by enabling frequent and direct data inspection and debugging.\",5,\"Mon 2:30 - 2:50 PM\",1429576200,1429577400,\"Authors\",null],[95,93,\"pn2620\",\"Paper\",\"How Good is 85%? A Survey Tool to Connect Classifier Evaluation to Acceptability of Accuracy\",\"Many HCI and ubiquitous computing systems are characterized by two important properties: their output is uncertain—it has an associated accuracy that researchers attempt to optimize—and this uncertainty is user-facing—it directly affects the quality of the user experience. Novel classifiers are typically evaluated using measures like the F1 score—but given an F-score of (e.g.) 0.85, how do we know whether this performance is good enough? Is this level of uncertainty actually tolerable to users of the intended application—and do people weight precision and recall equally? We set out to develop a survey instrument that can systematically answer such questions. We introduce a new measure, acceptability of accuracy, and show how to predict it based on measures of classifier accuracy. Out tool allows us to systematically select an objective function to optimize during classifier evaluation, but can also offer new insights into how to design feedback for user-facing classification systems (e.g., by combining a seemingly-low-performing classifier with appropriate feedback to make a highly usable system). It also reveals potential issues with the ubiquitous F1-measure as applied to user-facing systems.\",\"We offer new insights into designing better systems with user-facing uncertainty by predicting acceptability of accuracy of novel classifiers and selecting an objective function that reflects users’ perceptions of accuracy.\",5,\"Mon 2:50 - 3:10 PM\",1429577400,1429578600,\"Authors\",null],[96,93,\"pn155\",\"Paper\",\"Examining the Peak-End Effects of Subjective Experience\",\"Psychological research has shown that ‘peak-end’ effects influence people’s retrospective evaluation of hedonic and affective experience. Rather than objectively reviewing the total amount of pleasure or pain during an experience, people’s evaluation is shaped by the most intense moment (the peak) and the final moment (end). We describe an experiment demonstrating that peak-end effects can influence a user’s preference for interaction sequences that are objectively identical in their overall requirements. Participants were asked to choose which of two interactive sequences of five pages they preferred. Both sequences required setting a total of 25 sliders to target values, and differed only in the distribution of the sliders across the five pages – with one sequence intended to induce positive peak-end effects, the other negative. The study found that manipulating only the peak or the end of the series did not significantly change preference, but that a combined manipulation of both peak and end did lead to significant differences in preference, even though all series had the same overall effort.\",\"Demonstrates that peak-end effects, caused by altering the distribution of interaction requirements across pages of information, can influence hedonic assessment of interaction.\",5,\"Mon 3:10 - 3:30 PM\",1429578600,1429579800,\"Authors\",null],[97,93,\"pn1596\",\"Paper\",\"Survival Analysis: Objective assessment of Wait Time in HCI\",\"Waiting for the completion of a system process is an everyday experience. While waiting, system provides feedback to  the user about ongoing process through temporal metaphors (Progress bar, Busy icons, etc.). One of the key performance requirement for temporal metaphors is to retain the user till the process completes. Researchers have evaluated these metaphors through subjective means, and objective assessment has not been well explored. In this paper, we present survival analysis as objective assessment method to evaluate temporal metaphors. Through a field experiment, we demonstrate the application of survival analysis and empirically establish that auditory progress bar (temporal metaphor for audio interfaces) works for callers of a distress helpline. To the best of our knowledge, it is the first study on distress callers. The paper further discusses the applicability of survival analysis for evaluating temporal metaphors and wait time experiments for other applications, tasks, and settings.\",\"Applicability of survival analysis for evaluating temporal metaphors and wait time experiments in the field of HCI\",5,\"Mon 3:30 - 3:50 PM\",1429579800,1429581000,\"Authors\",null],[98,-1,\"s109\",\"Papers\",\"Reflecting Upon Design Reflection\",null,null,1,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Chair\",\"Papers\"],[99,98,\"pn521\",\"Paper\",\"Understanding Long-Term Interactions with a Slow Technology: an Investigation of Experiences with FutureMe\",\"Emerging over a decade ago, slow technology is a design philosophy aimed at supporting experiences of reflection through and on technology in everyday life. Recent research has suggested that slow technologies can open up new forms of interaction with digital content that support self-reflection and re-visitation of the past. However, little work has investigated people’s long-term interactions with systems that embody this design strategy. To investigate, a qualitative study with 31 participants was conducted to understand their long-term experiences with FutureMe—a slow technology that has been in use for over twelve years by more than one million people. Findings reveal that, despite its simplicity, FutureMe produced a range of outcomes—from profound reminiscence to unsettling encounters. Findings are interpreted to present opportunities and implications for future research and practice initiatives.\",\"Presents a study of people’s experiences with FutureMe—a slow messaging technology used for 12 years by over 1 million people. Findings illustrated many outcomes from profound reminiscence to unsettling encounters. \",1,\"Mon 2:30 - 2:50 PM\",1429576200,1429577400,\"Authors\",null],[100,98,\"pn583\",\"Paper\",\"Reflective Informatics: Conceptual Dimensions for Designing Technologies of Reflection\",\"Despite demonstrated interest in designing for reflection, relatively little work provides a detailed explication of what exactly is meant by reflection or how to design around it. This paper fills that gap by reviewing and engaging with conceptual and theoretical models of reflection, organized by the disciplinary and epistemological perspectives each embodies. Synthesizing across this theoretical background, the paper identifies three dimensions of reflection: breakdown, inquiry, and transformation. Together, these dimensions serve as the foundation for reflective informatics, a conceptual approach that helps bring clarity and guidance to the discussion of designing for reflection. The paper distinguishes reflective informatics by demonstrating how it both differs from and complements existing related work. Finally, the paper provides a critically reflexive consideration of its own latent assumptions, especially about the value of reflection, and how they might impact work on designing for reflection.\",\"Reviews literature from multiple epistemological paradigms about human capacity for reflective thought. Synthesizes across this literature to distill three dimensions that can guide designing technologies of reflection.\",1,\"Mon 2:50 - 3:10 PM\",1429577400,1429578600,\"Authors\",null],[101,98,\"pn1048\",\"Paper\",\"Stock Lamp: An Engagement-Versatile Visualization Design\",\"Design methodologies for information visualizations are typically based on the assumption that the users will be fully engaged in the visual exploration of the displayed information. However, recent research suggests that there is an increasing diversity in how users engage with modern visualizations, and that the traditional design theories do not always satisfy the varied users needs. In this paper, we present a new design concept, engagement-versatile design, for visualizations that target users with a variety of engagement styles. Without losing generality, we demonstrate the feasibility of this concept through the designing of a system called Stock Lamp, an engagement-versatile visualization that helps users keep track of the stock market in real-time. This design process includes identifying different modes of engagement, deriving design implications from each engagement-mode, and applying them to the visualization’s design. Our user study shows that Stock Lamp is able to consistently relay market information even when the users are multi-tasking. We believe this study establishes a new concept that promotes a systematic design approach that leverages both theoretical and empirical design methodologies for future visualization development. \",\"A new concept for designing visualizations that target a wide range of audiences with varioud engagement styles is introduced along with a working example of a real-time stock visualization. \",1,\"Mon 3:10 - 3:30 PM\",1429578600,1429579800,\"Authors\",null],[102,98,\"pn1906\",\"Note\",\"Real-Time Representation Versus Response Elicitation in Biosensor Data\",\"Recognized stress management techniques include cultivating mindfulness, breathing exercises, and meditation. While these approaches have been shown to mitigate the negative effects of stress, they can be difficult to learn or consistently apply. To support these techniques, we developed MoodLight, a playful system that uses ambient colored light to provide feedback regarding an individual’s current arousal levels. Like many affective computing systems, MoodLight was designed to help users observe their internal state and learn to relax. However, our findings indicate that prompting or leading feedback can be more effective than real time feedback in helping users relax. This work contributes to affective computing by suggesting alternative approaches to designing biofeedback systems for stress management.\",\"This study of the Moodlight system, which uses ambient light to provide feedback regarding physiological markers of arousal, contributes to affective computing by suggesting alternative approaches to designing biofeedback systems. \",1,\"Mon 3:30 - 3:40 PM\",1429579800,1429580400,\"Authors\",null],[103,-1,\"s-case1\",\"Case Studies\",\"Industrial Innovation\",null,null,2,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Chair\",\"Papers\"],[104,103,\"case115\",\"Case Study\",\"12 Way Mirror –  Reflecting on Window Displays.\",\"Shop windows are the paradigmatic design environment for attracting and holding people’s attention. They also provide a handy mirror in which people can check their appearance. The 12-way mirror project plays with this duality by building and testing an interactive installation that tracks people’s reflections as they look into a shop window. Three versions of the installation are compared, one with static mirrors, one with moving mirrors and one with face-tracking mirrors. These were tested over a 5 day period in the window display of an Eyewear shop on a busy commercial road in East London. Data were collected on how many people looked in the window, for how long and what they did while looking. The results show that while movement attracts people’s attention and stops them, their own reflection is most effective in keeping their interest.\",\"Presents a case study of a public display installation that holds people’s attention and enhances their interaction with a shop window display. \",2,\"Mon 2:30 - 2:50 PM\",1429576200,1429577400,\"Authors\",null],[105,103,\"case133\",\"Case Study\",\"Industry Is Changing, And So Must We\",\"This case study is a call to action for research practitioners and academicians to revamp their skills and curriculum respectively. Failure to evolve will likely marginalize the user research discipline in industry.\",\"This case study is a call to action for research practitioners and academicians to revamp their skills and curriculum respectively.\",2,\"Mon 2:50 - 3:10 PM\",1429577400,1429578600,\"Authors\",null],[106,103,\"case137\",\"Case Study\",\"BodyGuard: A Case Study of Telecare Product Innovation and Development\",\"Telecare is personal and environmental sensors that support people to remain safe and independent in their own home for longer. Telecare plays an important role in addressing the challenges of an ageing population. However, many people do not wear the most common form provided, the community alarm, for reasons that include the way that it looks. In the UK, a contributing factor to this problem is that manufacturers cater to telecare service providers (e.g. local authorities) and as a result, service users are not involved in design processes. This paper describes a redesign of the community alarm by a leading manufacturer, involving participatory design activities with users and the wider public, and design internships. The main innovation of the new community alarm, called BodyGuard, is that it connects with the user’s smartphone to enable it to work outside the home. We report insights and lessons learned during the innovation process, within the context of social care reforms giving people more control and choice over the services that they receive.\",\"Describes the innovation of the telecare community alarm, involving collaboration between academia and industry, participatory design activities with users and the wider public, and design internships.\",2,\"Mon 3:10 - 3:30 PM\",1429578600,1429579800,\"Authors\",null],[107,103,\"case156\",\"Case Study\",\"Volvo Single View of Vehicle: Building a Big Data Service from Scratch in the Automotive Industry\",\"Big data analytics is a major trend affecting business today. Many organizations collect vast amounts of data simply to investigate if its market value can be identified. In this case study, we contribute a practical example of using the big data approach to create innovative services. We describe our work to identify and integrate data sources in order establish what data is available and who may benefit from it. We then show how we worked with users to communicate the vast possibilities created when many data sources are integrated, and participated in building a new big data service. Finally, we share a set of lessons we learned which can guide future big data inquiries. Our work was conducted in the context of the inspection, service, and sale of Volvo trucks, significantly aiding risk management for Volvo Used Trucks EMEA.\",\"We contribute a practical example of using the big data approach to create services in the automotive domain by building a truck price estimation tool.\",2,\"Mon 3:30 - 3:50 PM\",1429579800,1429581000,\"Authors\",null],[108,-1,\"s-crs112\",\"Course\",\"Intro to Human-Computer Interaction 1/2\",null,null,6,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Instructor\",null],[109,108,\"crs112\",\"Course\",\"Introduction to Human-Computer Interaction\",\"The objective of this course is to provide newcomers to Human-Computer Interaction (HCI) with an introduction and overview of the field. In addition to introducing basic concepts, the course will provide enough structure to help understand how the advanced material in the CHI 2015 technical program fits into the overall field.\",\"Newcomers to the field of human-computer interaction will learn basic HCI concepts, processes, methods, and tools, through several real-world examples.\",6,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Instructor\",null],[110,-1,\"s-award3\",\"Special\",\"SIGCHI Social Impact Award\",null,null,3,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"\",\"\"],[111,110,\"award3\",\"Special\",\"SIGCHI Social Impact Award Talk\",\"\",\"...\",3,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"\",\"\"],[112,-1,\"s-crs118\",\"Course\",\"Actionable Inexpensive Games Research 1/2\",null,null,14,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Instructor\",null],[113,112,\"crs118\",\"Course\",\"Actionable Inexpensive Games User Research\",\"This course will allow people to understand the intricacies of rapid games user research methods. For this we will weave together playtesting exercises and help participants turn player feedback into actionable design recommendations. The course is designed from a user experience (UX) perspective and should allow for people unfamiliar with rapid iteration and user testing to playtesting and basic user research skills.\",\"This course is meant to provide new insights for user experience designers and human-computer interaction (HCI) graduate students interested in game evaluation and games user research. \",14,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Instructor\",null],[114,-1,\"s-crs111\",\"Course\",\"Design for Online Video & Television 1/2\",null,null,9,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Instructor\",null],[115,114,\"crs111\",\"Course\",\"Interaction Design for Online Video and Television\",\"This course will teach attendees how to design and evaluate interaction with online video and television. It provides attendees a pragmatic toolset, including techniques and guidelines, which can be directly applied in practice. The different tools will be contextualized based on current developments, giving participants a complete overview of the state of the art and industry.\",\"This course will teach attendees how to design and evaluate interaction with online video and television. It provides a pragmatic toolset, techniques and guidelines, which can be applied in practice.\",9,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Instructor\",null],[116,-1,\"s-sig5\",\"SIG\",\"Interactive Childhood\",null,null,8,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"\",\"\"],[117,116,\"sig109\",\"SIG\",\"CCI SIG: Interactive Childhood - Crossing Cultures and Continents\",\"\",\"...\",8,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"\",\"\"],[118,-1,\"s-crs135\",\"Course\",\"Design for Searching & Finding 1/2\",null,null,7,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Instructor\",null],[119,118,\"crs135\",\"Course\",\"Design for Searching & Finding\",\"Modern user interfaces often contain a search or find components so the user can search for content in the context of the application.  While there are common practices, what actually works best in these situations?  What kinds of search tasks are the users actually trying to accomplish when they do a search?  In this course, we’ll review the search and findability issues that users confront in the course of their tasks, and ways in which information can be found.  We’ll also discuss the ways in which users seek information in social settings.  You will learn several key design principles for creating your own search interfaces, as well as coming to understand what is driving people to search.  \",\"Search and finding is a common user activity. But do you know the relevant factors to design search interfaces?  This course reviews the theory and practices of search interface design.  \",7,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Instructor\",null],[120,-1,\"s108\",\"Papers\",\"Matching & Facilitating Social Interactions\",null,null,13,\"Mon 2:30 - 3:50 PM\",1429576200,1429581000,\"Chair\",\"Papers\"],[121,120,\"pn1541\",\"Paper\",\"Understanding the Role of Community in Online Dating\",\"Online dating sites have become a common means of finding a romantic partner. And yet, these sites differ greatly from many other socially oriented websites: perhaps most notably, the pairwise style of interaction afforded by these sites prevents a robust online community from forming. Users, however, have taken matters into their own hands by creating thriving external forums for discussion of specific dating sites. We report on a multiple methods study of two online dating services, via observation and interviews with users of the forums associated with these sites. Our findings suggest that these forums play an essential role in creating an “outsourced community” for the dating sites, and also reveal practices around how some users “game the system” in online dating, the prevalence of harassment in online dating, and users’ frustrations with current dating sites. We conclude with a number of recommendations for system design.\",\"We explore the relationship between community forums and dyadic online dating systems.\",13,\"Mon 2:30 - 2:50 PM\",1429576200,1429577400,\"Authors\",null],[122,120,\"pn1122\",\"Paper\",\"Making Social Matching Context-Aware - Design Concepts and Open Challenges\",\"Social matching systems recommend people to people. In an ideal world, such systems could be context-aware, in that they would introduce users to each other in situations where they are mutually interested, available and open to meeting (i.e., facilitate a valuable encounter). Unfortunately, today’s systems primarily match individuals based on simple similarity and proximity metrics. This paper explores how contextual information available on today’s mobile phones could be used to identify opportunities for people to make valuable new connections. Three types of context that are relevant for this work are: relational, social and personal. We present insights gained from several iterations of semi-structured interviewing (N=58) exploring these three types of contexts and propose novel context-aware social matching concepts such as: sociability of others as an indicator of opportune social context; activity involvement as an indicator of opportune personal context; and contextual rarity as an indicator of opportune relational context.\",\"This research explores situations in which people are interested in meeting new people and presents novel design concepts for context-aware social matching systems to identify opportunities for valuable encounters.\",13,\"Mon 2:50 - 3:10 PM\",1429577400,1429578600,\"Authors\",null],[123,120,\"pn1509\",\"Paper\",\"The Known Stranger: Supporting Conversations between Strangers with Personalized Topic Suggestions\",\"Striking up a good conversation with new acquaintances is often a difficult problem. In this paper we report on the perceptions of wearable device users who were given real-time personalized topic suggestions during a conversation with a person they just met. Suggestions were generated using a ranking recommendation algorithm, and were delivered via Google Glasses. We conducted a study with 38 pairs of strangers, who received such suggestions while conversing for the first time. Participants found the suggestions to be helpful, but only at the right moments, and for certain types of speakers. Our results contribute to the understanding of how communication interventions influence people’s experience and behaviors, and enhance interpersonal interactions. Our study also presents design implications for applications on wearable devices to facilitate conversations between strangers.\",\"Our results contribute to the understanding of how communication interventions influence people’s experience and behaviors, and enhance interpersonal interactions. Our study also presents design implications for applications on wearable devices to facilitate conversations between strangers.\",13,\"Mon 3:10 - 3:30 PM\",1429578600,1429579800,\"Authors\",null],[124,120,\"pn1023\",\"Paper\",\"Augmenting Social Interactions: Realtime Behavioural Feedback using Social Signal Processing Techniques\",\"Nonverbal and unconscious behaviour is an important component of daily human-human interaction. This is especially true in situations such as public speaking, job interviews or information sensitive conversations, where researchers have shown that an increased awareness of one's behaviour can improve the outcome of the interaction. With wearable technology, such as Google Glass, we now have the opportunity to augment social interactions and provide realtime feedback on one's behaviour in an unobtrusive way. In this paper we present Logue, a system that provides realtime feedback on the presenters' openness, body energy and speech rate during public speaking. The system analyses the user's nonverbal behaviour using social signal processing techniques and gives visual feedback on a head-mounted display. We conducted two user studies with a staged and a real presentation scenario which yielded that Logue's feedback was perceived helpful and had a positive impact on the speaker's performance. \",\"We present a system that provides realtime feedback on the presenters' openness, body energy and speech rate during public speaking using social signal processing techniques and an HMD.\",13,\"Mon 3:30 - 3:50 PM\",1429579800,1429581000,\"Authors\",null],[125,-1,\"break-3\",\"Breaks\",\"Coffee Break\",null,null,15,\"Mon 3:50 - 4:30 PM\",1429581000,1429583400,\"\",\"\"],[126,-1,\"s-alt2\",\"alt.chi\",\"New User Interfaces\",null,null,2,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Authors\",\"Papers\"],[127,126,\"alt151\",\"alt.chi\",\"Emergent Interfaces: Constructive Assembly of Identical Units\",\"\",\"...\",2,\"Mon 4:30 - 4:50 PM\",1429583400,1429584600,\"Authors\",\"Papers\"],[128,126,\"alt129\",\"alt.chi\",\"Your Paper is Dead! Bringing Life to Research Articles with Animated Figures\",\"\",\"...\",2,\"Mon 4:50 - 5:10 PM\",1429584600,1429585800,\"Authors\",\"Papers\"],[129,126,\"alt100\",\"alt.chi\",\"\\\"I Woke Up as a Newspaper\\\": Designing-in Interaction Analytics\",\"\",\"...\",2,\"Mon 5:10 - 5:30 PM\",1429585800,1429587000,\"Authors\",\"Papers\"],[130,126,\"alt154\",\"alt.chi\",\"Not all Days are Equal: Investigating The Meaning In The Digital Calendar\",\"\",\"...\",2,\"Mon 5:30 - 5:50 PM\",1429587000,1429588200,\"Authors\",\"Papers\"],[131,-1,\"s118\",\"Papers\",\"Family Communication\",null,null,10,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Chair\",\"Papers\"],[132,131,\"pn1174\",\"Note\",\"Couples’ Communication Channels: What, When & Why?\",\"An overwhelming variety of communication channels are available to consumers. Here, we present an overview of the aspects that need to be accounted for when intimate partners select a communication channel. We present interviews with 10 cohabiting couples (20 participants) and an 8-day diary study of communication and coordination. Using reported instances of within-couple communication, triggered by relationship-oriented or practical household needs, we identify why particular channels are chosen or sequenced. Extending media richness critiques, we identify additional factors that influence communication choice such as intimate knowledge of the others’ habits, possibilities to add emotional meaning, and couples’ shared needs as an identifiable unit. We also extend the notion of network effects on channel choice, and discuss the ecology of channel, networks, devices and device settings involved between partners. Finally, channel choice is not an all-or-nothing game; multiple channels can, and must, co-exist.\",\"Interview and diary study investigating couples' motivations in within-couple communication channel choice. Focuses on importance of reciprocal communication of affect, and intimate knowledge between partners.\",10,\"Mon 4:30 - 4:40 PM\",1429583400,1429584000,\"Authors\",null],[133,131,\"pn1785\",\"Note\",\"The Messaging Kettle: Prototyping Connection over a Distance between Adult Children and Older Parents\",\"A prototype “messaging kettle” is described. The connected kettle aims to foster communication and engagement with an older friend or relative who lives remotely, during the routine of boiling the kettle. We describe preliminary encounters and findings from demonstrating a working prototype in morning tea gatherings of people in their 50s-late 70s and from introducing it into the homes of two people in their 80s who live on another continent. Key findings are that: The concept of keeping in touch around a “habituated object” such as a kettle was well received; Simple and varied interaction modalities that allow asymmetric forms of communication are needed; Designing for use across different time zones requires attention; And, that even when augmenting a habituated object, the process of introduction, appropriation and habituation still needs significant attention and investigation.\",\"We contribute a  “messaging kettle”. The connected kettle aims to foster communication and engagement with an older friend or relative who lives remotely, during the routine of boiling the kettle. \",10,\"Mon 4:40 - 4:50 PM\",1429584000,1429584600,\"Authors\",null],[134,131,\"pn930\",\"Paper\",\"The Effect of Signal Expense and Dependability on Family Communication in Rural and Northern Canada\",\"Family communication and technology designed to support it is a widely studied topic. However, most research that focuses on family communication in North America tends to assume high degrees of connectivity and Internet access. We present a study of family communication practices in rural and northern areas of Manitoba, Canada where Internet connectivity is intermittent or severely limited in some communities. Our results show the ways in which individuals stay connected with outside relatives can be hampered by communication infrastructure challenges. In particular, these challenges can dictate how, where and how often conversations with loved ones take place. Our results also indicate that these experiences, many of which are negative, can create lasting impressions that may be difficult to alter as infrastructure improves. This suggests opportunities for designing family communication technologies for outdoor locations with better connectivity, scheduling communication during times with better connectivity, and combating social isolation.\",\"New insight into the influence of location on family communication patterns in rural areas of Canada, exposing unique workarounds to connectivity challenges and discussing opportunities for design.\",10,\"Mon 4:50 - 5:10 PM\",1429584600,1429585800,\"Authors\",null],[135,131,\"pn420\",\"Paper\",\"Texting while Parenting: How Adults Use Mobile Phones while Caring for Children at the Playground\",\"Child development research suggests that using phones while caring for children can be problematic, but limited prior work in this space makes defining appropriate use challenging. We conducted the first exploration of whether adults feel pressure to limit phone use in this context and whether they choose to do so. Through mixed methods, we collected data from 466 adult caregivers at playgrounds. We found that phone use was a small part of playground time, yet a notable source of guilt. Adults engaged in systematic and specific phone-use and phone-non-use behaviors in order to prioritize their children above themselves. Our results indicate that caregiver values and self-control together predict behavior and can be used to model phone use in this context. Users’ mixed success with engaging in intentional periods of non-use suggests that a design agenda which prioritizes cycles of engagement, disengagement, and re-engagement may be of value to this group. \",\"This mixed-methods investigation of parents’ phone use while caring for children describes systematic non-use practices in this context. Implications for modeling non-use decisions and designing for both use and non-use.\",10,\"Mon 5:10 - 5:30 PM\",1429585800,1429587000,\"Authors\",null],[136,131,\"pn1583\",\"Paper\",\"Exploring Time-Dependent Concerns about Pregnancy and Childbirth from Search Logs\",\"We study time-dependent patterns of information seeking about pregnancy, birth, and the first several weeks of caring for newborns via analyses of queries drawn from anonymized search engine logs. We show how we can detect and align web search behavior for a population of searchers with the natural clock of gestational physiology via proxies for ground truth based on searchers’ self-report queries (e.g., [I am 30 weeks pregnant and my baby is moving a lot]). Then, we present a methodology for performing additional alignments, that are valuable for learning about the concerns, curiosities, and needs that arise over time with pregnancy and early parenting. Our findings have implications for learning about the temporal dynamics of pregnancy-related interests and concerns, and also for the design of systems that tailor their responses to point estimates of each searcher’s current stage in pregnancy.\",\"In this work, we study time-dependent patterns of information seeking about pregnancy, birth, and the first several weeks of caring for newborns via analyses of anonymized large-scale search engine logs. \",10,\"Mon 5:30 - 5:50 PM\",1429587000,1429588200,\"Authors\",null],[137,-1,\"s153\",\"Papers\",\"How Fast Can you Type on your Phone?\",null,null,4,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Chair\",\"Papers\"],[138,137,\"pn1991\",\"Paper\",\"Effects of Language Modeling and its Personalization on Touchscreen Typing Performance\",\"Modern smartphones correct typing errors and learn user-specific words (such as proper names). Both techniques are useful, yet little has been published about their technical specifics and concrete benefits.  One reason is that typing accuracy is difficult to measure empirically on a large scale. We describe a closed-loop, smart touch keyboard (STK) evaluation system that we have implemented to solve this problem. It includes a principled typing simulator for generating human-like noisy touch input, a simple-yet-effective decoder for reconstructing typed words from such spatial data, a large web-scale background language model (LM), and a method for incorporating LM personalization. Using the Enron email corpus as a personalization test set, we show for the first time at this scale that a combined spatial/language model reduces word error rate from a pre-model baseline of 38.4% down to 5.7%, and that LM personalization can improve this further to 4.6%.\",\"Presents findings of a large-scale touch keyboard typing simulation, showing empirical benefits of integrated language modeling and model personalization.\",4,\"Mon 4:30 - 4:50 PM\",1429583400,1429584600,\"Authors\",null],[139,137,\"pn144\",\"Paper\",\"VelociTap: Investigating Fast Mobile Text Entry using Sentence-Based Decoding of Touchscreen Keyboard Input\",\"We present VelociTap: a state-of-the-art touchscreen keyboard decoder that supports a sentence-based text entry approach. VelociTap enables users to seamlessly choose from three word-delimiter actions: pushing a space key, swiping to the right, or simply omitting the space key and letting the decoder infer spaces automatically. We demonstrate that VelociTap has a significantly lower error rate than Google's  keyboard while retaining the same entry rate. We show that intermediate visual feedback does not significantly affect entry or error rates and we find that using the space key results in the most accurate results.  We also demonstrate that enabling flexible word-delimiter options does not incur an error rate penalty. Finally, we investigate how small we can make the keyboard when using VelociTap. We show that novice users can reach a mean entry rate of 41 wpm on a 40 mm wide smartwatch-sized keyboard at a 3% character error rate.\",\"VelociTap is a state-of-the-art touchscreen keyboard decoder that supports a sentence-based text entry approach. Novices wrote at 41 words-per-minute on a smartwatch-sized keyboard at a 3%  error rate.\",4,\"Mon 4:50 - 5:10 PM\",1429584600,1429585800,\"Authors\",null],[140,137,\"pn1356\",\"Paper\",\"Text Entry on Tiny QWERTY Soft Keyboards\",\"The advent of wearables (e.g., smartwatches, smartglasses, and digital jewelry) anticipates the need for text entry methods on very small devices. We conduct fundamental research on this topic using 3 qwerty-based soft keyboards for 3 different screen sizes, motivated by the extensive training that users have with qwerty keyboards. In addition to ZoomBoard (a soft keyboard for diminutive screens), we propose a callout-based soft keyboard and ZShift, a novel extension of the Shift pointing technique. We conducted a comprehensive user study followed by extensive analyses on performance, usability, and short-term learning. Our results show that different small screen sizes demand different types of assistance. In general, manufacturers can benefit from these findings by selecting an appropriate qwerty soft keyboard for their devices. Ultimately, this work provides designers, researchers, and practitioners with new understanding of qwerty soft keyboard design space and its scalability for tiny touchscreens.\",\"Investigates the scalability of 3 tiny qwerty soft keyboards. Can assist manufacturers in selecting an appropriate qwerty soft keyboard for their devices.\",4,\"Mon 5:10 - 5:30 PM\",1429585800,1429587000,\"Authors\",null],[141,137,\"pn2602\",\"Paper\",\"Performance and User Experience of Touchscreen and Gesture Keyboards in a Lab Setting and in the Wild\",\"We study the performance and user experience of two popular mainstream mobile text entry methods: the Smart Touch Keyboard (STK) and the Smart Gesture Keyboard (SGK). Our first study is a lab-based ten-session text entry experiment. In our second study we use a new text entry evaluation methodology based on the experience sampling method (ESM). In the ESM study, participants installed an Android app on their own mobile phones that periodically sampled their text entry performance and user experience amid their everyday activities for four weeks. The studies show that text can be entered at an average speed of 28 to 39 WPM, depending on the method and the user's experience, with 1.0% to 3.6% character error rates remaining. Error rates of touchscreen input, particularly with SGK, are a major challenge; and reducing out-of-vocabulary errors is particularly important. Both SGK and STK have strengths, weaknesses, and different individual awareness and preferences. Two-thumb touch typing in a focused setting is particularly effective on STK, whereas one-handed SGK typing with the thumb is particularly effective in more mobile situations. When exposed to both, users tend to migrate from STK to SGK. We also conclude that studies in the lab and in the wild can both be informative to reveal different aspects of keyboard experience, but used in conjunction is more reliable in comprehensively assessing input technologies of current and future generations.\",\"An empirical evaluation of touch typing vs. gesture typing on android mobile devices is presented comparing entry rates, error rates, and analyses such as effect of OOV and hand posture.\",4,\"Mon 5:30 - 5:50 PM\",1429587000,1429588200,\"Authors\",null],[142,-1,\"s110\",\"Papers\",\"Crowdsourcing Fans & Friends\",null,null,15,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Chair\",\"Papers\"],[143,142,\"pn1808\",\"Paper\",\"Run Spot Run: Capturing and Tagging Footage of a Race by Crowds of Spectators\",\"There has been a massive growth in the number of people who film and upload amateur footage of events to services such as Facebook and Youtube, or even stream live to services such as LiveStream. We present an exploratory study that investigates the potential of these spectators in creating footage en masse; in this case, during a live trial at a local marathon. We deployed a prototype app, RunSpotRun, as a technology probe to see what kinds of footage spectators would produce. We present an analysis of this footage in terms of its coverage, quality, and contents, and also discuss the implications for a) spectators enjoying the race, and b) extracting the stories of individual runners throughout the race. We conclude with a discussion of the challenges that remain for deploying such technology at a larger scale.\",\"We deployed a prototype app, RunSpotRun, to crowd-source and tag footage of a marathon race. We use this footage to tell stories of individual runners.\",15,\"Mon 4:30 - 4:50 PM\",1429583400,1429584600,\"Authors\",null],[144,142,\"pn1092\",\"Paper\",\"Crowdsourcing Synchronous Spectator Support: (go on, go on, you're the best)n-1\",\"Many studies have shown that crowd-support, such as cheering during sport events, can have a positive impact on athletes’ performance. However, up until recently this support was only possible if the supporters and the athletes were geographically co-located. Can cheering be done remotely and would this be effective? In this paper we investigate the effect and possibilities of live remote cheering on co-located athletes and online supporting crowds that have a weak social tie and no social tie with the athlete. We recruit 140 online spectators and 5 athletes for an ad-hoc 5km road race. Results indicate that crowds socially closer to the athletes are significantly more engaged in the support. The athletes were excited by live remote cheering from friendsourced spectators and cheering from unknown crowdsourced participants indicating that remote friends and outsourced spectators could be an important source of support.\",\"The innovativeness of this work is the crowdsourcing of real-time spectator support through friendsourced and outsourced crowds. Results indicate that remote outsourced spectators could provide effective support.\",15,\"Mon 4:50 - 5:10 PM\",1429584600,1429585800,\"Authors\",null],[145,142,\"pn555\",\"Paper\",\"Bootlegger: Turning Fans into Film Crew\",\"Bootlegger is a system for creating multi-camera films of live music events using mobile devices. Using readily available technology and a synthesis of film-making conventions, the system coordinates music fans at live shows into an improvised film crew, suggesting shots, collating footage and generating rich metadata in real time. Bootlegger is part of a research project exploring adapting professional media workflows to amateur contexts in order to lower the bar to entry for media production. By enabling concert-goers to contribute to high-quality concert films, the system leverages mobile phone ‘bootlegging’ practices to support emerging musicians.\",\"Bootlegger is a system for creating high-quality multi-camera films of live music events. Bootlegger coordinates music fans into flexible camera crews using mobile devices.\",15,\"Mon 5:10 - 5:30 PM\",1429585800,1429587000,\"Authors\",null],[146,142,\"pn1453\",\"Paper\",\"In-group Questions and Out-group Answers: Crowdsourcing Daily Living Advice for Individuals with Autism\",\"Difficulty in navigating daily life can lead to frustration and decrease independence for people with autism. While they turn to online autism communities for information and advice for coping with everyday challenges, these communities may present only a limited perspective because of their in-group nature. Obtaining support from out-group sources beyond the in-group community may prove valuable in dealing with challenging situations such as public anxiety and workplace conflicts. In this paper, we explore the value of supplementary out-group support from crowdsourced responders added to in-group support from a community of members. We find that out-group sources provide relatively rapid, concise responses with direct and structured information, socially appropriate coping strategies without compromising emotional value. Using an autism community as a motivating example, we conclude by providing design implications for combining in-group and out-group resources that may enhance the question-and-answer experience. \",\"We propose and evaluate a crowdsourcing approach for augmenting an existing online community to better support people with autism by offering rapid, concise, and socially appropriate coping strategies without compromising emotional support.\",15,\"Mon 5:30 - 5:50 PM\",1429587000,1429588200,\"Authors\",null],[147,-1,\"s146\",\"Papers\",\"Managing Personal Privacy\",null,null,11,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Chair\",\"Papers\"],[148,147,\"pn466\",\"Paper\",\"Your Location has been Shared 5,398 Times! A Field Study on Mobile App Privacy Nudging\",\"Smartphone users are often unaware of the data collected by apps running on their devices. We report on a study that evaluates the benefits of giving users an app permission manager and sending them nudges intended to raise their awareness of the data collected by their apps. Our study provides both qualitative and quantitative evidence that these approaches are complementary and can each play a significant role in empowering users to more effectively control their privacy. For instance, even after a week with access to the permission manager, participants benefited from nudges showing them how often some of their sensitive data was being accessed by apps, with 95% of participants reassessing their permissions, and 58% of them further restricting some of their permissions. We discuss how participants interacted both with the permission manager and the privacy nudges, analyze the effectiveness of both solutions, and derive some recommendations.\",\"We evaluated in situ the benefits of giving mobile users an app permission manager and complementing it with nudges to raise users’ awareness of the data collected by their apps.\",11,\"Mon 4:30 - 4:50 PM\",1429583400,1429584600,\"Authors\",null],[149,147,\"pn763\",\"Paper\",\"Can an Algorithm Know the “Real You”?: Understanding People’s Reactions to Hyper-personal Analytics Systems\",\"Recent research has developed analytics that threaten online self-presentation and privacy by automatically generating profiles of individuals’ most personal traits—their personality, values, motivations, and so on. But we know little about people's reactions to personal traits profiles of themselves, or what influences their decisions to share such profiles. We present an early qualitative study of people’s reactions to a working hyper-personal analytics system. The system lets them see their personality and values profile derived from their own social media text. Our results reveal a paradox. Participants found their personal traits profiles creepily accurate and did not like sharing them in many situations. However, they felt pressured by the social risks of not sharing and showed signs of learned helplessness, leading them to share despite their misgivings. Further, they felt unqualified to significantly modify their profile contents due to a surprising trust in the “expert” algorithm. We explore design implications for hyper-personal analytics systems that consider the needs and preferences of the people being profiled, suggesting ways to enhance the control they feel and the benefits they reap.\",\"Qualitative study of user reactions to a working system inferring personality from social media text. Presents design recommendations based on system features that promote user buy-in, sharing, comfort, and privacy.\",11,\"Mon 4:50 - 5:10 PM\",1429584600,1429585800,\"Authors\",null],[150,147,\"pn1480\",\"Paper\",\"Privacy Tipping Points in Smartphones Privacy Preferences\",\"The aim of this research was to understand what affects people's privacy preferences in smartphone apps. We ran a four-week study in the wild with 34 participants. Participants were asked to answer questions, which were used to gather their personal context and to measure their privacy preferences by varying app name and purpose of data collection. Our results show that participants shared the most when no information about data access or purpose was given, and shared the least when both of these details were specified. When just one of either purpose or the requesting app was shown, participants shared less when just the purpose was specified than when just the app name was given. We found that the purpose for data access was the predominant factor affecting users' choices. In our study the purpose condition vary from being not specified, to vague to be very specific. Participants were more willing to disclose data when no purpose was specified. When a vague purpose was shown, participants became more privacy-aware and were less willing to disclose their information. When specific purposes were shown participants were more willing to disclose when the purpose for requesting the information appeared to be beneficial to them, and shared the least when the purpose for data access was solely beneficial to developers.\",\"We studied what affects 34 participants’ privacy preferences in Android-apps. When no information about data-access or purpose was given participants shared the most, while when both of these details were specified they shared the least. \",11,\"Mon 5:10 - 5:30 PM\",1429585800,1429587000,\"Authors\",null],[151,147,\"pn895\",\"Paper\",\"VeilMe: An Interactive Visualization Tool for Privacy Configuration of Using Personality Traits\",\"With the recent advances in using data analytics to automatically infer one's personality traits from their social media data, users are facing a growing tension between the use of the technology to aid self development in workplace and the privacy concerns of such use. Given the richness of personality data that can be derived today and the varied sensitivity of revealing such data, it is a non-trivial task for users to configure their privacy settings for sharing and protecting their derived personality data. Here we present the design, development, and evaluation of an interactive visualization tool, VeilMe, which helps users configure the privacy settings for the use of their personality portraits derived from social media. Unlike other privacy configuration tools, our tool offers two distinct advantages. First, it presents a novel and intuitive visual interface that aids users in understanding and exploring their own personality traits derived from their social media data, and configuring their privacy preferences. Second, our tool helps users to jump start their privacy settings by suggesting initial sharing strategies based on a set of factors, including the users' personality and target audience. We have evaluated the use of our tool with 124 participants in an enterprise context. Our results show that VeilMe effectively supports various user privacy configuration tasks, and also suggest several design implications, including the approaches to personalized privacy configurations.\",\"A novel yet intuitive visual interface that helps users to explore and configure the privacy policies of their personality traits for different social groups, with multiple preset strategies evaluated.\",11,\"Mon 5:30 - 5:50 PM\",1429587000,1429588200,\"Authors\",null],[152,-1,\"s-float-30\",\"Papers\",\"Understand & Enhancing Learning\",null,null,5,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Chair\",\"Papers\"],[153,152,\"pn1147\",\"Paper\",\"Using Time-Anchored Peer Comments to Enhance Social Interaction in Online Educational Videos\",\"Online learning is increasingly prevalent as an option for self-learning and as a resource for instructional design. Prerecorded video is currently the main medium of online education content delivery and instruction; this affords asynchronicity and flexibility, and enables the dissemination of lecture content in a distributed and scalable manner. However, the same properties may impede learners' engagement due to the lack of social interaction and peer support. In this paper, we propose a time-anchored commenting interface to allow online learners who watch the same video clips to exchange comments on them. Comments left by previous learners at specific time points of a video are displayed to new learners when they watch the same video and reach those time points. We investigated how the display of time-anchored comments (dynamic or static) and type of comments (content-related or social-oriented) influenced users' perceived engagement, perceived social interactivity, and learning outcomes. Our results show that dynamically displaying time-anchored comments can indeed enhance learners' perceived social interactivity.  Moreover, the content of comments would further affect learners' intention of commenting.  Based on our findings, we make various recommendations for the improvement of social interaction and learning experience in online education.\",\"A time-anchored commenting design is proposed for online learning videos. Based on our experiment findings, we make various recommendations for improving social interaction and learning experience in online education.\",5,\"Mon 4:30 - 4:50 PM\",1429583400,1429584600,\"Authors\",null],[154,152,\"pn933\",\"Paper\",\"Designing a Physical Aid to Support Active Reading on Tablets\",\"Tablet computers and portable eReaders are gradually becoming the preferred platform for the consumption of textual materials. However, although these technologies are powerful, it is widely acknowledged that print documents better support the advanced active reading tasks necessary to gain a deep understanding of a text. While prior work to address this issue has aimed improve digital eReaders by either leveraging familiar physical affordances or by extending paper’s capabilities with digital tools, in this paper we propose a juncture of these two approaches. We first present a formative study that captures the needs and requirements of users during active reading tasks with tablets. We instantiate the findings in the design of a simple physical aid to support active reading: a smart bookmark. We then define an interaction space for this device, describe a set of interfaces designed to facilitate active reading and close with a user study that assesses the potential of the bookmark device and interaction techniques.\",\"This paper contributes a design-led study of active reading practices that culminates in the development of the eTab - a tangible reading aid for tablet computers.\",5,\"Mon 4:50 - 5:10 PM\",1429584600,1429585800,\"Authors\",null],[155,152,\"pn5119\",\"TOCHI\",\"Motivation as a Lens to Understand Online Learners: Towards Data-Driven Design with the OLEI Scale\",\"Open online learning environments attract an audience with diverse motivations who interact with structured courses in a number of ways. To systematically describe the motivations of these learners, we developed the Online Learning Enrollment Intentions (OLEI) scale, a 13-item questionnaire derived from open-ended responses to capture learners' authentic perspectives. Though motivations varied across courses, we found each motivation to predict key behavioral outcomes for learners (N=71,475 across 14 courses). From learners’ motivational and behavioral patterns, we infer a variety of needs they seek to gratify by engaging with the courses, such as meeting new people and learning English. To meet these needs, we propose multiple design directions, including virtual social spaces outside any particular course, improved support for local groups of learners, and modularization to promote accessibility and organization of course content. Motivations thus provide a lens for understanding online learners and designing online courses to better support their needs.\",\"Open online learning environments attract an audience with diverse motivations who interact with structured courses in a number of ways. To systematically describe the motivations of these learners, we developed the Online Learning Enrollment Intentions (OLEI) scale, a 13-item questionnaire derived from open-ended responses to capture learners' authentic perspectives. Though motivations varied across courses, we found each motivation to predict key behavioral outcomes for learners (N=71,475 acro...\",5,\"Mon 5:10 - 5:30 PM\",1429585800,1429587000,\"Authors\",null],[156,152,\"pn5128\",\"TOCHI\",\"Large-Scale Educational Campaigns\",\"Educational technology requires a delivery mechanism in order to scale. One method which has not yet seen widespread use is the educational campaign: large-scale, short-term events focused on a specific educational topic, such as the Hour of Code campaign. These are designed to generate media coverage and lend themselves nicely to collaborative or competitive goals, thus potentially leveraging social effects and community excitement to increase engagement and reach students who would otherwise not participate. In this paper, we present a case study of three such campaigns we ran to encourage students to play an algebra game, DragonBox Adaptive: the Washington, Norway, and Minnesota Algebra Challenges. We provide several design recommendations for future campaigns based on our experience, including the effects of different incentive schemes, the insertion of “tests” to fastforward students to levels of appropriate difficulty, and the strengths and weaknesses of campaigns as a method of collecting experimental data.\",\"Educational technology requires a delivery mechanism in order to scale. One method which has not yet seen widespread use is the educational campaign: large-scale, short-term events focused on a specific educational topic, such as the Hour of Code campaign. These are designed to generate media coverage and lend themselves nicely to collaborative or competitive goals, thus potentially leveraging social effects and community excitement to increase engagement and reach students who would otherwise n...\",5,\"Mon 5:30 - 5:50 PM\",1429587000,1429588200,\"Authors\",null],[157,-1,\"s-float-29\",\"Papers\",\"The Value of Things\",null,null,1,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Chair\",\"Papers\"],[158,157,\"pn5113\",\"TOCHI\",\"The Challenges of Using Biodata in Promotional Filmmaking\",\"We present a study of how filmmakers collected and visualised physiological data—‘biodata’—to construct a series of short promotional films depicting people undergoing ‘thrilling’ experiences. Drawing on ethnographic studies of two major advertising campaigns, we highlight key concerns for integrating sensors and sensor data into film production. Our findings address the perceived benefits of using biodata within narratives; the nature of different on-screen representations of biodata; and the challenges presented when integrating biodata into production processes. Drawing on this, we reconsider the nature of information visualisation in the filmmaking context. Further implications from our case studies provide recommendations for HCI collaborations with filmmaking and broadcast industries, focussing both on the practical matters of fitting sensor technologies into and handling data within production workflows, as well as discussing the broader implications for managing the veracity of that data within professional media production.\",\"We present a study of how filmmakers collected and visualised physiological data—‘biodata’—to construct a series of short promotional films depicting people undergoing ‘thrilling’ experiences. Drawing on ethnographic studies of two major advertising campaigns, we highlight key concerns for integrating sensors and sensor data into film production. Our findings address the perceived benefits of using biodata within narratives; the nature of different on-screen representations of biodata; and the c...\",1,\"Mon 4:30 - 4:50 PM\",1429583400,1429584600,\"Authors\",null],[159,157,\"pn1376\",\"Paper\",\"On Vintage Values: The Experience of Secondhand Fashion Reacquisition\",\"Secondhand fashion is a rapidly growing, lucrative market with both off- and online outlets. Studies of secondhand consumption have focused primarily on people’s motivations for secondhand shopping, highlighting sustainability and/or thrift. We extend this work by looking at the motivations and practices of secondhand shoppers who are driven instead by style, playfulness and treasure-hunting. We present findings from ethnographic observation and interviews with 13 secondhand shoppers. Three secondhand shopping orientations emerged. Perfection Seeking involves seeking items that fit with an individual look or personal brand. These items are seen as unique, and demonstrate an alternative to mainstream fashion and consumption. Casual curiosity is less focused, more engaged in browsing, and driven by both secondhand objects and the secondhand experience itself. Digging involves the focused pursuit of hidden “gems” or treasures, following the belief that unusual items are waiting to be found. We offer ideas for designing secondhand shopping experiences to support the needs for storytelling, experiential pleasure, and negotiation around durable value. \",\"Through ethnographic methods we study recirculation, a cyclical process of acquiring, using, and disposing of goods. Focusing on experiences, we identify three acquisition orientations: perfection seeking, casual curiosity, and digging.\",1,\"Mon 4:50 - 5:10 PM\",1429584600,1429585800,\"Authors\",null],[160,157,\"pn148\",\"Paper\",\"Your Money’s No Good Here: The Elimination of Cash Payment on London Buses\",\"As digital payments become increasingly important features of economic exchange, traditional forms of payment such as cash are becoming phased out in certain settings. We study one such context—the elimination of cash payment on London buses in July 2014. We conducted ethnographic fieldwork, interviews with drivers and collected online and social media comments before, during and shortly after the introduction of cashless fares. We explore how drivers and passengers were fearful of the change due in part to a lack of information and communication, the anticipation of negative effects on vulnerable passengers and a compromise in freedom, flexibility and surveillance. We highlight the ways cashless payments can alter the social function of money, create new forms of work for drivers and passengers, and if not carefully introduced can cause emotional stress and fears of state surveillance and control.\",\"Examines the removal of cash payments on London’s buses in favour of contactless methods of payment, and the impact this has on drivers, passengers and the social functions of money.\",1,\"Mon 5:10 - 5:30 PM\",1429585800,1429587000,\"Authors\",null],[161,157,\"pn1498\",\"Note\",\"Informing and Improving Retirement Saving Performance using Behavioral Economics Theory-driven User Interfaces\",\"Can human-computer interaction help people make informed and effective decisions about their retirement savings? We applied the behavioral economic theories of endowment effect and loss aversion to the design of novel retirement saving user interfaces. To examine effectiveness, we conducted an experiment in which 487 participants were exposed to one of three experimental user interface designs of a retirement saving simulator, representing endowment effect, loss aversion and control. Users made 34 yearly asset allocation decisions. We found that designs informed by the endowment effect and loss aversion theories and which communicated to savers the long-term implications of their asset allocation choices, led users to adjust their behavior, make larger and more frequent asset allocation changes, and achieve their saving goals more effectively.\",\"We exposed participants to user interface designs of a retirement saving simulator, representing endowment effect, loss aversion and control. Designs informed by endowment effect and loss aversion were more effective.\",1,\"Mon 5:30 - 5:40 PM\",1429587000,1429587600,\"Authors\",null],[162,-1,\"s-float-48\",\"Papers\",\"Collaborative Tables, Walls & Rooms\",null,null,13,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Chair\",\"Papers\"],[163,162,\"pn564\",\"Paper\",\"Fluid Grouping: Quantifying Group Engagement around Interactive Tabletop Exhibits in the Wild\",\"Interactive surfaces are increasingly common in museums and other informal learning environments where they are seen as a medium for promoting social engagement. However, despite their increasing prevalence, we know very little about factors that contribute to collaboration and learning around interactive surfaces. In this paper we present analyses of visitor engagement around several multi-touch tabletop science exhibits. Observations of 629 visitors were collected through two widely used techniques: video study and shadowing. We make four contributions: 1) we present an algorithm for identifying groups within a dynamic flow of visitors through an exhibit hall; 2) we present measures of group-level engagement along with methods for statistically analyzing these measures; 3) we assess the effect of observational techniques on visitors’ engagement, demonstrating that consented video studies do not necessarily reflect visitor behavior in more naturalistic circumstances; and 4) we present an analysis showing that groups of two, groups with both children and adults, and groups that take turns spend longer at the exhibits and engage more with scientific concepts.\",\"Proposed a novel Group Identification Algorithm in a dynamic visitor flow and engagement metrics for statistical analysis in interactive informal learning environments. Demonstrated effects of two typical study methodologies.\",13,\"Mon 4:30 - 4:50 PM\",1429583400,1429584600,\"Authors\",null],[164,162,\"pn5134\",\"TOCHI\",\"Up Close and Personal: Collaborative Work on a High-Resolution Multitouch Wall Display\",\"Multitouch wall-sized displays afford new forms of collaboration: They can be used up close by several users simultaneously, offer high resolution, and provide sufficient space for intertwining individual and joint work. The difference to displays without these capabilities is not well understood. To better understand the collaboration of groups around high-resolution multitouch wall displays, we conducted an exploratory study. Pairs collaborated on a problem-solving task using a 2.8m × 1.2m multitouch display with 24.8 megapixels. The study examines how participants collaborate; navigate relative to the display and to each other; and interact with and share the display. Participants physically navigated among different parts of the display, switched fluidly between parallel and joint work, and shared the display evenly. The results contrast earlier research that suggests difficulties in sharing and collaborating around wall displays. The study suggests that multitouch wall displays can support different collaboration styles and fluid transitions in group work.\",\"Multitouch wall-sized displays afford new forms of collaboration: They can be used up close by several users simultaneously, offer high resolution, and provide sufficient space for intertwining individual and joint work. The difference to displays without these capabilities is not well understood. To better understand the collaboration of groups around high-resolution multitouch wall displays, we conducted an exploratory study. Pairs collaborated on a problem-solving task using a 2.8m × 1.2m mul...\",13,\"Mon 4:50 - 5:10 PM\",1429584600,1429585800,\"Authors\",null],[165,162,\"pn851\",\"Paper\",\"Flexible Ecologies And Incongruent Locations\",\"In this paper we report on some experiments with a high fidelity media space, t-Room, an immersive system that presents full scale, real-time images of co-participants. The system has been enhanced to provide more flexibility in the ways participants could organise themselves and the materials they are working on. Drawing on some quasi-naturalistic experiments, where the participants were required to undertake a range of complex tasks, we consider the formations they adopt and the issues and problems that arise when they attempt to establish and preserve a common focus and alignment. We conclude by briefly discussing the consequences for developing advanced spaces to support collaborative work and understanding complex video-mediated interaction. \",\"This study contributes to the studies of systems to support real-time collaborative activities by presenting some form of embodiment. It develops the analysis of fractured ecologies and fragmented interaction.\",13,\"Mon 5:10 - 5:30 PM\",1429585800,1429587000,\"Authors\",null],[166,162,\"pn2005\",\"Paper\",\"Mapping out Work in a Mixed Reality Project Room\",\"We present results from a study examining how the physical layout of a project room and task affect the cognitive maps acquired of a connected virtual environment during mixed-presence collaboration. Results indicate that a combination of physical layout and task impacts cognitive maps of the virtual space. Participants did not form a strong model of how different physical work regions were situated relative to each other in the virtual world when the tasks performed in each region differed. Egocentric perspectives of multiple displays enforced by different furniture arrangements encouraged cognitive maps of the virtual world that reflected these perspectives, when the displays were used for the same task. These influences competed or coincided with document-based, audiovisual and interface cues, influencing collaboration. We consider the implications of our findings on WYSIWIS mappings between real and virtual for mixed-presence collaboration. \",\"Mixed reality allows mixed presence collaboration that is tightly integrated with physical workspaces. Our study examines when and how linked physical and virtual environments should spatially correspond. \",13,\"Mon 5:30 - 5:50 PM\",1429587000,1429588200,\"Authors\",null],[167,-1,\"s-crs112-1\",\"Course\",\"Intro to Human-Computer Interaction 2/2\",null,null,6,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Instructor\",null],[168,167,\"crs112\",\"Course\",\"Introduction to Human-Computer Interaction\",\"The objective of this course is to provide newcomers to Human-Computer Interaction (HCI) with an introduction and overview of the field. In addition to introducing basic concepts, the course will provide enough structure to help understand how the advanced material in the CHI 2015 technical program fits into the overall field.\",\"Newcomers to the field of human-computer interaction will learn basic HCI concepts, processes, methods, and tools, through several real-world examples.\",6,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Instructor\",null],[169,-1,\"s-crs135-1\",\"Course\",\"Design for Searching & Finding 2/2\",null,null,7,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Instructor\",null],[170,169,\"crs135\",\"Course\",\"Design for Searching & Finding\",\"Modern user interfaces often contain a search or find components so the user can search for content in the context of the application.  While there are common practices, what actually works best in these situations?  What kinds of search tasks are the users actually trying to accomplish when they do a search?  In this course, we’ll review the search and findability issues that users confront in the course of their tasks, and ways in which information can be found.  We’ll also discuss the ways in which users seek information in social settings.  You will learn several key design principles for creating your own search interfaces, as well as coming to understand what is driving people to search.  \",\"Search and finding is a common user activity. But do you know the relevant factors to design search interfaces?  This course reviews the theory and practices of search interface design.  \",7,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Instructor\",null],[171,-1,\"s-crs118-1\",\"Course\",\"Actionable Inexpensive Games Research 2/2\",null,null,14,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Instructor\",null],[172,171,\"crs118\",\"Course\",\"Actionable Inexpensive Games User Research\",\"This course will allow people to understand the intricacies of rapid games user research methods. For this we will weave together playtesting exercises and help participants turn player feedback into actionable design recommendations. The course is designed from a user experience (UX) perspective and should allow for people unfamiliar with rapid iteration and user testing to playtesting and basic user research skills.\",\"This course is meant to provide new insights for user experience designers and human-computer interaction (HCI) graduate students interested in game evaluation and games user research. \",14,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Instructor\",null],[173,-1,\"s-crs111-1\",\"Course\",\"Design for Online Video & Television 2/2\",null,null,9,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Instructor\",null],[174,173,\"crs111\",\"Course\",\"Interaction Design for Online Video and Television\",\"This course will teach attendees how to design and evaluate interaction with online video and television. It provides attendees a pragmatic toolset, including techniques and guidelines, which can be directly applied in practice. The different tools will be contextualized based on current developments, giving participants a complete overview of the state of the art and industry.\",\"This course will teach attendees how to design and evaluate interaction with online video and television. It provides a pragmatic toolset, techniques and guidelines, which can be applied in practice.\",9,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Instructor\",null],[175,-1,\"s134\",\"Papers\",\"Makers & Hackers\",null,null,3,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Chair\",\"Papers\"],[176,175,\"pn2318\",\"Paper\",\"Tutorial Authorship and Hybrid Designers: The Joy (and Frustration) of DIY Tutorials\",\"Tutorials are critical to the success and vitality of DIY practices. In this paper, we elevate the importance of tutorial authorship as one way to maintain and improve the quality of tutorials in DIY. We discuss the role interaction designers can play as hybrid designers, mediating between author and audience to contribute to the improvement of practices of tutorial authorship in DIY. We examine the quality of tutorials through the building and analysis of ten DIY projects and tutorials. We analyze key issues across three categories: 1) competences, components and tools, 2) sequencing, 3) and communication. We offer findings that are both practical guidelines for detailed improvements of tutorials and structural themes for improving tutorial authorship including the themes of accurate information, competences and tools, and tutorial format. In conclusion, we discuss the potential for interaction designers to simultaneously mediate and shape tutorials and tools in a form of hybrid design. \",\"We elevate the importance of tutorial authorship and explore the role of interaction designers as hybrid designers, mediating between authors and audience to improve the practices of DIY tutorial authorship.\",3,\"Mon 4:30 - 4:50 PM\",1429583400,1429584600,\"Authors\",null],[177,175,\"pn1210\",\"Paper\",\"Hybrid Practice in the Kalahari: Design Collaboration through Digital Tools and Hunter-Gatherer Craft\",\"People have been making things for a long time, yet digital making has developed mostly within an industrial context. We question how non-digital craft cultures can inform the design of digital tools. Furthermore, what methods can help us understand these cultures in ways that are relevant to digital practice? As makers ourselves, we see potential for collaborative making to mitigate barriers in communication and provide insight into non-digital practices and values. To evaluate this approach, we visited a hunter-gatherer community that preserves an ancient craft, bringing with us digital design and fabrication tools. Working together, we merged digital tools with ostrich eggshell jewelry craft. We use this experience to draw conclusions about making as a form of communication, the importance of supporting appropriation and immediacy in collaborations, the challenge of combining abstract design tools with concrete approaches, and the value of incorporating design and making into communal life.\",\"Through collaborative making in the Kalahari, we combine digital design and fabrication with traditional craft to gain insight into how non-digital craft cultures can inform the design of digital tools. \",3,\"Mon 4:50 - 5:10 PM\",1429584600,1429585800,\"Authors\",null],[178,175,\"pn2165\",\"Paper\",\"The Proper Care and Feeding of Hackerspaces:  Care Ethics and Cultures of Making\",\"Communities of making have been at the center of attention in popular, business, political, and academic research circles in recent years. In HCI, they seem to carry the promise of new forms of computer use, education, innovation, and even ways of life. In the West in particular, the maker manifestos of these communities have shown strong elements of a neoliberal ethos, one that prizes self-determination, tech-savvy, independence, freedom from government, suspicion of authority, and so forth. Yet such communities, to function as communities, also require values of collaboration, cooperation, interpersonal support—in a word, care. In this ethnographic study, we studied and participated as members of a hackerspace for 19 months, focusing in particular not on their technical achievements, innovations, or for glimmers of a more sustainable future, but rather to make visible and to analyze the community maintenance labor that helps the hackerspace support the practices that its members, society, and HCI research are so interested in. We found that the maker ethic entails a complex negotiation of both a neoliberal libertarian ethos and a care ethos.\",\"In this ethnography of a hackerspace, we study the labor of building and maintaining community, which entails a complex negotiation of both a neoliberal libertarian ethos and a care ethos.  \",3,\"Mon 5:10 - 5:30 PM\",1429585800,1429587000,\"Authors\",null],[179,175,\"pn353\",\"Paper\",\"Patterns of Physical Design Remixing in Online Maker Communities\",\"Makers participate in remixing culture by drawing inspiration from, combining, and adapting designs for physical objects. To examine how makers remix each others’ designs on a community scale, we analyzed metadata from over 175,000 digital designs from Thingiverse, the largest online design community for digital fabrication. Remixed designs on Thingiverse are predominantly generated designs from Customizer– a built-in web app for adjusting parametric designs. However, we find that these designs do not elicit subsequent user activity and the authors who generate them tend not to contribute additional content to Thingiverse. Outside of Customizer, influential sources of remixing include complex assemblies and design primitives, as well as non-physical resources posing as physical designs. Building on our findings, we discuss ways in which online maker communities could become more than just design repositories and better support collaborative remixing.\",\"Makers participate in remixing culture by drawing inspiration from, combining, and adapting designs for physical objects. To examine how makers remix each others’ designs on a community scale, we analyzed metadata from over 175,000 digital designs from Thingiverse, the largest online design community for digital fabrication.\",3,\"Mon 5:30 - 5:50 PM\",1429587000,1429588200,\"Authors\",null],[180,-1,\"s-float-23\",\"Papers\",\"Health Sensors & Monitoring\",null,null,12,\"Mon 4:30 - 5:50 PM\",1429583400,1429588200,\"Chair\",\"Papers\"],[181,180,\"pn408\",\"Paper\",\"No News is Good News: Remote Monitoring of Implantable Cardioverter-Defibrillator Patients\",\"Implantable cardioverter-defibrillator (ICD) patients have increased safety when connected to remote monitoring as ICD problems and issues are instantly discovered compared to patients without a monitor. While remote monitoring is intrusive in the domestic environment, little HCI research has investigated how people live and interact with such monitoring technologies. We conducted a study with 19 ICD patients and their spouses using diaries and interviews. Our findings illustrate that our participants were satisfied with the monitoring despite the fact that they had almost no knowledge of the data collected and they lacked feedback from the monitor on transmission and operation. Based on our findings, we describe a safety paradox for remote monitoring as participants experienced less safety while being safer, and identify privacy and surveillance concerns in the unequal monitoring of ICD patients.\",\"This paper contributes to our knowledge on remote monitoring technologies and illustrates a safety paradox where implantable cardioverter-defibrillator patients experience increased anxiety while being remotely monitored.\",12,\"Mon 4:30 - 4:50 PM\",1429583400,1429584600,\"Authors\",null],[182,180,\"pn422\",\"Paper\",\"Smart Homes that Monitor Breathing and Heart Rate\",\"The evolution of ubiquitous sensing technologies has led to intelligent environments that can monitor and react to our daily activities, such as adapting our heating and cooling systems, responding to our gestures, and monitoring our elderly.  In this paper, we ask whether it is possible for smart environments to monitor our vital signs remotely, without instrumenting our bodies.  We introduce Vital-Radio, a wireless sensing technology that monitors breathing and heart rate without body contact. Vital-Radio exploits the fact that wireless signals are affected by motion in the environment, including chest movements due to inhaling and exhaling and skin vibrations due to heartbeats. We describe the operation of Vital-Radio and demonstrate through a user study that it can track users' breathing and heart rates with a median accuracy of 99%, even when users are 8~meters away from the device, or in a different room. Furthermore, it can monitor the vital signs of multiple people simultaneously.  We envision that Vital-Radio can enable smart homes that monitor people's vital signs without body instrumentation, and actively contribute to their inhabitants' well-being.\",\"Vital-Radio is a wireless sensing technology that monitors breathing and heart rate without body contact. It tracks users’ vitals with 99% accuracy, even when they are behind a wall. \",12,\"Mon 4:50 - 5:10 PM\",1429584600,1429585800,\"Authors\",null],[183,180,\"pn1990\",\"Paper\",\"Balancing Accuracy and Fun: Designing Camera Based Mobile Games for Implicit Heart Rate Monitoring\",\"Heart rate monitoring is widely used in clinical care, fitness training, and stress management. However, tracking individuals' heart rates faces two major challenges, namely equipment availability and user motivation. In this paper, we present a novel technique, LivePulse Games (LPG), to measure users' heart rates in real time by having them play games on unmodified mobile phones. With LPG, the heart rate is calculated by detecting changes in transparency of users' fingertips via the built-in camera of a mobile device. More importantly, LPG integrate users' camera lens covering actions as an essential control mechanism in game play, and detect heart rates implicitly from intermittent lens covering actions. We explore the design space and trade-offs of LPG through three rounds of iterative design. In a 12-subject user study, we found that LPG are fun to play and can measure heart rates accurately. We also report the insights for balancing measurement speed, accuracy, and entertainment value in LPG. \",\"LivePulse Games (LPG) is a novel technique to measure users' heart rates in real time by having them play serious games on unmodified mobile phones.\",12,\"Mon 5:10 - 5:30 PM\",1429585800,1429587000,\"Authors\",null],[184,180,\"pn1424\",\"Paper\",\"Measuring Photoplethysmogram-Based Stress-Induced Vascular Response Index to Assess Cognitive Load and Stress\",\"Quantitative assessment for cognitive load and mental stress is very important in optimizing human-computer system designs to improve performance and efficiency. Traditional physiological measures, such as heart rate variation (HRV), blood pressure and electrodermal activity (EDA), are widely used but still have limitations in sensitivity, reliability and usability. In this study, we propose a novel photoplethysmogram-based stress induced vascular index (sVRI) to measure cognitive load and stress. We also provide the basic methodology and detailed algorithm framework. We employed a classic experiment with three levels of task difficulty and three stages of testing period to verify the new measure. Compared with the blood pressure, heart rate and HRV components recorded simultaneously, the sVRI reached the same level of significance on the effect of task difficulty/period as the most significant other measure. Our findings showed sVRI’s potential as a sensitive, reliable and usable parameter.\",\"We provide a new method of assessing cognitive load and mental stress using PPG-based stress induced vascular index (sVRI). It is sensitive, reliable, real-time, low-cost, noninvasive and hopefully wearable\",12,\"Mon 5:30 - 5:50 PM\",1429587000,1429588200,\"Authors\",null],[185,-1,\"special-1\",\"Special\",\"Opening Reception & Exhibit Hall Grand Opening\",null,null,15,\"Mon 6:00 - 7:30 PM\",1429588800,1429594200,\"\",\"\"],[186,-1,\"keynote-2\",\"Keynote\",\"Plenary Session - UX Design in the IoT Era\",null,null,15,\"Tue 8:30 - 9:20 AM\",1429641000,1429644000,\"Speaker\",null],[187,186,\"key2\",\"Keynote\",\"UX Design in the IoT Era\",\"The current advancement of IoT technology has accelerated the era of hyper-connectivity in our lives. This has vastly driven convergence among different fields along with the expansion of our thoughts and behaviors. However, to provide meaningful experiences, these relational expansions and unprecedented possibilities opened up by IoT need to be founded on core human values. Furthermore, harmonious integration between technology and design is also essential. Today, I would like to talk about what must be done in order to foster the IoT as a human-centered innovation and how UX design can realize the well balanced and harmonious IoT environment.\",\"The current advancement of IoT technology has accelerated the era of hyper-connectivity in our lives. This has vastly driven convergence among different fields along with the expansion of our thoughts and behaviors. However, to provide meaningful experiences, these relational expansions and unprecedented possibilities opened up by IoT need to be founded on core human values. Furthermore, harmonious integration between technology and design is also essential. Today, I would like to talk about wha...\",15,\"Tue 8:30 - 9:20 AM\",1429641000,1429644000,\"Speaker\",null],[188,-1,\"s-float-22\",\"Papers\",\"The Value of the Village in Caregiving\",null,null,12,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Chair\",\"Papers\"],[189,188,\"pn2185\",\"Paper\",\"Effects of Public Commitments and Accountability in a Technology-Supported Physical Activity Intervention\",\"Walking and other forms of physical activity have many health benefits, but people often fail to follow through on their own goals of being more active. To address gaps in current understanding of how to design technology-supported physical activity interventions, we conducted a randomized field experiment of a commitment device: making public announcements. In a control condition, weekly commitments were kept private. In two treatment conditions, they were announced on Facebook and by email. In one of the two, the announcements also included results: whether the previous week’s commitment was kept.  We find that, with or without public results, these posts can elicit supportive replies from the poster’s social networks. People in both public announcements conditions were less likely to make commitments. We conclude that the prospect of public accountability may suppress the making of commitments in a way that counteracts the benefits of that accountability. Designers will need to address this limitation in order to make effective use of public accountability as a commitment device.\",\"We conducted a randomized field experiment evaluating the effects of public commitments to walking. We compare commitments shared on a social network site and by email to commitments made privately.\",12,\"Tue 9:30 - 9:50 AM\",1429644600,1429645800,\"Authors\",null],[190,188,\"pn1945\",\"Paper\",\"Rare World: Towards Technology for Rare Diseases\",\"Researchers have created innovative technological solutions to support people with common chronic illnesses. In this study, we investigate design opportunities for people with rare diseases who are not well studied or have smaller populations to work with, because although an individual’s disease may be rare, the number of people living with a rare disease is substantial. We conducted an interview study with 19 individuals with rare diseases from around the world to understand common problems and experiences that could be supported through design. We found that communicating with friends, family, and providers about her disease were challenges for participants. Additionally, participants thought of their disease as being a large part of who they were. We discuss these findings in the context of prior work on common chronic illnesses, addressing the potential relevance of existing technological interventions for people with rare diseases.\",\"We investigate design opportunities for people with rare diseases, providing a discussion of differences between rare diseases and common diseases, and exploring how technologies could address some of these opportunities.\",12,\"Tue 9:50 - 10:10 AM\",1429645800,1429647000,\"Authors\",null],[191,188,\"pn5108\",\"TOCHI\",\"Health Vlogs as Social Support for Chronic Illness Management\",\"Studies have shown positive impact of video blogs (vlogs) on patient education. However, we know little on how patient-initiated vlogs shape the relationships among vloggers and viewers. We qualitatively analyzed 72 vlogs on YouTube by users diagnosed with HIV, diabetes, or cancer and 1,274 comments posted to the vlogs to understand viewers’ perspectives on the vlogs. We found that the unique video medium allowed intense and enriched personal and contextual disclosure to the viewers, leading to strong community-building activities and social support among vloggers and commenters, both informationally and emotionally. Furthermore, the unique communication structure of the vlogs allowed ad hoc small groups to form, which showed different group behavior than typical text-based social media, such as online communities. We provide implications to the health care industry and the human-computer interaction community on how future technologies for health vlogs could be designed to further support chronic illness management.\",\"Studies have shown positive impact of video blogs (vlogs) on patient education. However, we know little on how patient-initiated vlogs shape the relationships among vloggers and viewers. We qualitatively analyzed 72 vlogs on YouTube by users diagnosed with HIV, diabetes, or cancer and 1,274 comments posted to the vlogs to understand viewers’ perspectives on the vlogs. We found that the unique video medium allowed intense and enriched personal and contextual disclosure to the viewers, leading to ...\",12,\"Tue 10:10 - 10:30 AM\",1429647000,1429648200,\"Authors\",null],[192,188,\"pn2419\",\"Note\",\"Looking for Respite and Support: Technological Opportunities for Spousal Caregivers\",\"Our research aims at informing the design of technological solutions to alleviate the stress resulting from the involvement of spouses of Alzheimer’s disease patients as caregivers. For so doing, we have observed and analyzed the different offline solutions that are offered by a healthcare network in the Aube region (North-East of France). We discuss the key factors that we have identified for building an effective support network and identify five perspectives for the development of an online social support platform to lower the burden of spousal caregivers.\",\"Our study aims at identifying the sources of respite and support currently found by spousal caregivers of Alzheimer's disease patients in their daily life for the design of innovative solutions.\",12,\"Tue 10:30 - 10:40 AM\",1429648200,1429648800,\"Authors\",null],[193,188,\"pn248\",\"Note\",\"Barriers and Negative Nudges: Exploring Challenges in Food Journaling\",\"Although food journaling is understood to be both important and difficult, little work has empirically documented the specific challenges people experience with food journals. We identify key challenges in a qualitative study combining a survey of 141 current and lapsed food journalers with analysis of 5,526 posts in community forums for three mobile food journals. Analyzing themes in this data, we find and discuss barriers to reliable food entry, negative nudges caused by current techniques, and challenges with social features. Our results motivate research exploring a wider range of approaches to food journal design and technology.\",\"We contribute a qualitative analysis of a survey of 141 current and lapsed food journalers with an analysis of 5,526 posts in community forums to empirically document specific challenges people encounter in food journaling.\",12,\"Tue 10:40 - 10:50 AM\",1429648800,1429649400,\"Authors\",null],[194,-1,\"s132\",\"Papers\",\"I Like What I See - Interface Aesthetics\",null,null,13,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Chair\",\"Papers\"],[195,194,\"pn2480\",\"Paper\",\"Computation of Interface Aesthetics\",\"People prefer attractive interfaces. Designers strive to outmatch competitors, and create apps and websites that stand out. However, significant expenses on design are unaffordable to small companies; instead, they could adopt automatic tools of interface aesthetics evaluation, a cheaper strategy to good design. This paper describes an important step towards such a tool; it presents eight automatic metrics of graphical user interface (GUI) aesthetics. We tested the metrics in two exploratory studies – on desktop webpages (N = 62) and on iPhone apps (N = 53) – and found them to function on both GUI types and for both immediate (150ms exposure) and deliberate (4s exposure) aesthetics impressions. Our best-fit regression models explained up to 49% of variance in webpage aesthetics and up to 32% (if app genre is considered) of variance in iPhone app aesthetics. These results confirm past results and suggest the metrics are valid and reliable enough to be widely discussed, and possibly, to be embedded in our prospective GUI evaluation tool, tLight.\",\"GUI-type independent, automatic methods of predicting appreciation of GUI visual appeal, featuring 8 screenshot-based metrics.\",13,\"Tue 9:30 - 9:50 AM\",1429644600,1429645800,\"Authors\",null],[196,194,\"pn481\",\"Paper\",\"Patina Engraver: Visualizing Activity Logs as Patina in Fashionable Trackers\",\"Despite technological improvements in commercial activity trackers, little attention has been given to their emotional, social, or fashion-related qualities, such as their visual aesthetics and their relationship to self-expression and social connection. As an alternative integrated approach incorporating HCI, fashion, and product design, our project made use of the characteristics of patina to improve activity trackers as fashionable wearables. We developed the Patina Engraving System, which engraves patina-like patterns on an activity tracker according to a user’s activity logs. Using a piercing technique, the patina of activity logs has been made abstract, visually rich, gradually emerging, and historically accumulated. During the field trial, we found that the patina motivated the participants to increase exercises for engraving aesthetic patinas. A tracker with patina triggered spontaneous social interactions in face-to-face situations. The participants also cherished the trackers that held their own history. Based on the field trial, we discuss design implications for utilizing patina in designing future fashionable technologies.\",\"This paper details an activity log visualization technique by applying the concept of patina. We expect this research to inspire designs for diverse fashionable tracking devices.\",13,\"Tue 9:50 - 10:10 AM\",1429645800,1429647000,\"Authors\",null],[197,194,\"pn1550\",\"Note\",\"Real-time Guidance Camera Interface to Enhance Photo Aesthetic Quality\",\"This paper explores whether it is effective to use real-time on-screen guidance to help users take better photos with mobile devices. Using a three-camera array, we developed a photo-taking interface that provides real-time feedback on how to position the subject-of-interest according to a photography composition rule: rule-of-thirds. We conduct a user study to compare the aesthetic quality of photos taken with our real-time guidance interface against a static gridline interface common to existing digital cameras. Expert photographers and Mechanical Turk workers rate the aesthetic quality of these pairs of photos. Results indicate the photos taken with our real-time guidance interface have significantly higher aesthetics scores. This study shows the potential in using camera array, computational photography, and real-time guidance interface to help non-expert users take better photos.\",\"This work designs and evaluates a real-time guidance camera interface for photo composition. The user study shows that real-time guidance has a significant positive effect on photo aesthetic quality.\",13,\"Tue 10:10 - 10:20 AM\",1429647000,1429647600,\"Authors\",null],[198,194,\"pn2305\",\"Note\",\"Infographic Aesthetics: Designing for the First Impression\",\"Information graphics, or infographics, combine elements of data visualization with design and have become an increasingly popular means for disseminating data. While several studies have suggested that aesthetics in visualization and infographics relate to desirable outcomes like engagement and memorability, it remains unknown how quickly aesthetic impressions are formed, and what it is that makes an infographic appealing. We address these questions by analyzing 1,278 participants' ratings on appeal after seeing infographics for 500ms. Our results establish that: 1) people form a reliable first impression of the appeal of an infographic based on a mere exposure effect, 2) this first impression is largely based on colorfulness and visual complexity, and 3) age, gender, and education level influence the preferred level of colorfulness and complexity. More generally, these findings suggest that outcomes such as engagement and memorability might be determined much earlier than previously thought.\",\"People form a reliable opinion of an infographics’ appeal within the first 500ms of seeing it.\",13,\"Tue 10:20 - 10:30 AM\",1429647600,1429648200,\"Authors\",null],[199,194,\"pn768\",\"Paper\",\"ISOTYPE Visualization – Working Memory, Performance, and Engagement with Pictographs\",\"Although the infographic and design communities have used simple pictographic representations for decades, it is still unclear whether they can make visualizations more effective. Using simple charts, we tested how pictographic representations impact (1) memory for information just viewed, as well as under the load of additional information, (2) speed of finding information, and (3) engagement and preference in seeking out these visualizations. We find that superfluous images can distract. But we find no user costs – and some intriguing benefits – when pictographs are used to represent the data.\",\"A series of experiments examining how and why using pictographs can impact the utility of charts\",13,\"Tue 10:30 - 10:50 AM\",1429648200,1429649400,\"Authors\",null],[200,-1,\"s141\",\"Papers\",\"Muscle-Computer Interfaces\",null,null,3,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Chair\",\"Papers\"],[201,200,\"pn5121\",\"TOCHI\",\"Understanding Gesture Expressivity through Muscle Sensing\",\"Expressivity is a visceral capacity of the human body. To understand what makes a gesture expressive, we need to consider not only its spatial placement and orientation, but also its dynamics and the mechanisms enacting them. We start by defining gesture and gesture expressivity, and then present fundamental aspects of muscle activity and ways to capture information through electromyography (EMG) and mechanomyography (MMG). We present pilot studies that inspect the ability of users to control spatial and temporal variations of 2D shapes and that use muscle sensing to assess expressive information in gesture execution beyond space and time. This leads us to the design of a study that explores the notion of gesture power in terms of control and sensing. Results give insights to interaction designers to go beyond simplistic gestural interaction, towards the design of interactions that draw upon nuances of expressive gesture.\",\"Expressivity is a visceral capacity of the human body. To understand what makes a gesture expressive, we need to consider not only its spatial placement and orientation, but also its dynamics and the mechanisms enacting them. We start by defining gesture and gesture expressivity, and then present fundamental aspects of muscle activity and ways to capture information through electromyography (EMG) and mechanomyography (MMG). We present pilot studies that inspect the ability of users to control sp...\",3,\"Tue 9:30 - 9:50 AM\",1429644600,1429645800,\"Authors\",null],[202,200,\"pn5115\",\"TOCHI\",\"Informing the Design of Novel Input Methods with Muscle Coactivation Clustering\",\"This paper presents a novel summarization of biomechanical and performance data for user interface designers. Previously, there was no simple way for designers to predict how the location, direction, velocity, precision, or amplitude of users' movement affects performance and fatigue. We cluster muscle coactivation data from a 3D pointing task covering the whole reachable space of the arm. We identify eleven clusters of pointing movements with distinct muscular, spatio-temporal and performance properties. We discuss their use as heuristics when designing for 3D pointing.\",\"This paper presents a novel summarization of biomechanical and performance data for user interface designers. Previously, there was no simple way for designers to predict how the location, direction, velocity, precision, or amplitude of users' movement affects performance and fatigue. We cluster muscle coactivation data from a 3D pointing task covering the whole reachable space of the arm. We identify eleven clusters of pointing movements with distinct muscular, spatio-temporal and performance p...\",3,\"Tue 9:50 - 10:10 AM\",1429645800,1429647000,\"Authors\",null],[203,200,\"pn1980\",\"Paper\",\"Advancing Muscle-Computer Interfaces with High-Density Electromyography\",\"In this paper we present our results on using electromyographic (EMG) sensor arrays for finger gesture recognition. Sensing muscle activity allows to capture finger motion without placing sensors directly at the hand or fingers and thus may be used to build unobtrusive body-worn interfaces. We use an electrode array with 192 electrodes to record a high-density EMG of the upper forearm muscles.  We present in detail a baseline system for gesture recognition on our dataset, using a naive Bayes classifier to discriminate the 27 gestures. We recorded 25 sessions from 5 subjects. We report an average accuracy of 90% for the within-session scenario, showing the feasibility of the EMG approach to discriminate a large number of subtle gestures.  We analyze the effect of the number of used electrodes on the recognition performance and show the benefit of using high numbers of electrodes. Cross-session recognition typically suffers from electrode position changes from session to session. We present two methods to estimate the electrode shift between sessions based on a small amount of calibration data and compare it to a baseline system with no shift compensation. The presented methods raise the accuracy from 59% baseline accuracy to 75% accuracy after shift compensation. The dataset is publicly available.\",\"We explore the use of high-density EMG for finger gesture recognition and introduce methods to compensate electrode shift between sessions.\",3,\"Tue 10:10 - 10:30 AM\",1429647000,1429648200,\"Authors\",null],[204,200,\"pn1766\",\"Paper\",\"Proprioceptive Interaction\",\"We propose a new way of eyes-free interaction for wearables. It is based on the user’s proprioceptive sense, i.e., rather than seeing, hearing, or feeling an outside stimulus, users feel the pose of their own body. We have implemented a wearable device called Pose-IO that offers input and output based on proprioception. Users communicate with Pose-IO through the pose of their wrists. Users enter information by performing an input gesture by flexing their wrist, which the device senses using a 3-axis accelerometer. Users receive output from Pose-IO by find-ing their wrist posed in an output gesture, which Pose-IO actuates using electrical muscle stimulation. This mechanism allows users to interact with Pose-IO without visual or auditory senses, but through the proprioceptive sense alone. We developed three simple applications that demonstrate symmetric proprioceptive interaction, where input and output occur through the same limb, as well as asymmetric interaction, where input and output occur through different limbs. In a first user study, participants using a symmetric proprioceptive interface re-entered poses received from Pose-IO with an average accuracy of 5.8° despite the minimal bandwidth offered by the device. In a second, exploratory study, we investigated participants’ emotional response to asymmetric proprioceptive interaction and the concept of the user’s body serving as interface. Participants reported to enjoy the experience (4.6 out of 5). \",\"Proprioceptive interaction allows for eyes-free interaction based on proprioception alone. We devised a bracelet which allows to input and output to happen exclusively through the user's muscles.\",3,\"Tue 10:30 - 10:50 AM\",1429648200,1429649400,\"Authors\",null],[205,-1,\"s148\",\"Papers\",\"Phones for more than Just Talking & Text\",null,null,4,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Chair\",\"Papers\"],[206,205,\"pn265\",\"Note\",\"AudioScope: Smartphones as Directional Microphones in Mobile Audio Augmented Reality Systems\",\"Mobile audio augmented reality systems (MAARS) provide a new and engaging modality to present information or to create playful experiences. Using special filters, spatial audio rendering creates the impression that the sound of a virtual source emanates from a certain position in the physical space. So far, most of the implementations of such systems rely on head tracking to create a realistic effect, which requires additional hardware. Recent results indicate that the built-in sensors of a smartphone can be used as source for orientation measurement, reducing deployment to a simple app download. AudioScope presents an alternative interaction technique to create such an experience, using the metaphor of pointing a directional microphone at the environment. In an experiment with 20 users, we compared the time to locate a proximate audio source and the perceived presence in the virtual environment. Results show that there is no significant difference between head-orientation measurement and AudioScope regarding accuracy and perceived presence. This means that MAARS, such as audio guides for museums, do not require special hardware but can run on the visitor's smartphones with standard headphones.\",\"Mobile audio augmented reality often relies on head tracking, which requires additional hardware. We evaluated the metaphor of a directional microphone to explore virtual audio spaces, using the built-in sensors of a modern smartphone.\",4,\"Tue 9:30 - 9:40 AM\",1429644600,1429645200,\"Authors\",null],[207,205,\"pn1647\",\"Note\",\"ScanShot: Detecting Document Capture Moments and Correcting Device Orientation\",\"Document capturing with smartphone cameras is performed increasingly often in our daily lives. However, our user study results (n=10) showed that more than 80% of landscape tasks had incorrect orientations. To solve this problem, we systematically analyzed user behavior of document capturing and proposed a novel solution called ScanShot that detects document capturing moments to help users correct the orientation errors. ScanShot tracks the gravity direction to capture document capturing moments, analyzes logged gyroscope data to automatically update orientation changes, and provides visual feedback of the inferred orientation for manual correction. Our user study results (n=20) confirmed that capturing moments can be recognized with accuracy of 97.5%, our update mechanism can reduce the orientation errors by 59 percentage points.\",\"We proposed a novel solution called ScanShot for correcting orientation errors that commonly occur when taking pictures of documents with a smartphone camera.\",4,\"Tue 9:40 - 9:50 AM\",1429645200,1429645800,\"Authors\",null],[208,205,\"pn1129\",\"Paper\",\"Mechanics of Camera Work in Mobile Video Collaboration\",\"Mobile video conferencing, where one or more participants are moving about in the real world, enables entirely new interaction scenarios (e.g., asking for help to construct or repair an object, or showing a physical location). While we have a good understanding of the challenges of video conferencing in office or home environments, we do not fully understand the mechanics of camera work—how people use mobile devices to communicate with one another—during mobile video calls. To provide an understanding of what people do in mobile video collaboration, we conducted an observational study where pairs of participants completed tasks using a mobile video conferencing system. Our analysis suggests that people use the camera view deliberately to support their interactions—for example, to convey a message or to ask questions—but the limited field of view, and the lack of camera control can make it a frustrating experience.\",\"Develops and articulates a set of mechanics describing how people use mobile devices to communicate with one another during mobile video calls. Mechanics are based on an observational study.\",4,\"Tue 9:50 - 10:10 AM\",1429645800,1429647000,\"Authors\",null],[209,205,\"pn5118\",\"TOCHI\",\"User Interfaces for Smart Things - A Generative Approach with Semantic Interaction Descriptions\",\"With ever more devices being connected to the Internet and everyday objects becoming “smart” due to embedded processors and communication capabilities, the provisioning of intuitive user interfaces to control smart things is quickly gaining importance. To address this issue, we present a model-based interface description scheme that enables automatic, modality-independent user interface generation. User interface description languages based on our approach carry enough information to suggest appropriate and intuitive interfaces. Still, they are simple enough to enable developers to describe the interaction semantics of a smart thing using very little, easily producible markup. This is enabled by describing the atomic interactive components of a device rather than the device as a whole, and capturing the high-level semantics of an interaction. As a concrete language based on this approach, we propose a taxonomy of abstract sensing and actuation primitives and present a smartphone application that can act as a ubiquitous device controller. An evaluation of our approach in a laboratory setup, home environments, and a lecture hall automation system as well as the results of a user study highlight the accessibility of the proposed description scheme for application developers, its suitability for controlling smart devices, and its generality with respect to describing heterogeneous smart things.\",\"With ever more devices being connected to the Internet and everyday objects becoming “smart” due to embedded processors and communication capabilities, the provisioning of intuitive user interfaces to control smart things is quickly gaining importance. To address this issue, we present a model-based interface description scheme that enables automatic, modality-independent user interface generation. User interface description languages based on our approach carry enough information to suggest app...\",4,\"Tue 10:10 - 10:30 AM\",1429647000,1429648200,\"Authors\",null],[210,205,\"pn462\",\"Note\",\"Reducing the Stress of Coordination: Sharing Travel Time Information Between Contacts on Mobile Phones\",\"We explore the everyday use of a new abstraction for mo-bile location-sharing. By sharing the travel time between contacts calculated for walking, transit, and driving, we have enabled users to more easily coordinate meeting up and planning family obligations. Specifically, our participants reported that the information helped to lower the stress of these activities and provided reassurance of the arrival times of their close friends and family. In this paper, we describe our system, motivate its design, and explore results from a 20-user, 21-day field trial showing the use-fulness of the abstraction as well as attitudes towards privacy when sharing travel times with close friends or family. \",\"We demonstrate how sharing time-away information (instead of absolute location) helps decrease the stress of meeting up while helping to preserve privacy.\",4,\"Tue 10:30 - 10:40 AM\",1429648200,1429648800,\"Authors\",null],[211,205,\"pn732\",\"Note\",\"You Can’t Smoke Here: Towards Support for Space Usage Rules in Location-aware Technologies\",\"Recent work has identified the lack of space usage rule (SUR) data – e.g. “no smoking”, “no campfires” – as an important limitation of online/mobile maps that presents risks to user safety and the environment. In order to address this limitation, a large-scale means of mapping SURs must be developed. In this paper, we introduce and motivate the problem of mapping space usage rules and take the first steps towards identifying solutions. We show how computer vision can be employed to identify SUR indicators in the environment (e.g. “No Smoking” signs) with reasonable accuracy and describe techniques that can assign each rule to the appropriate geographic feature. \",\"This note introduces the problem of mapping space usage rules (SURs) like “no smoking” and “no fishing”. We discuss a computer vision-based SUR mapping approach and highlight novel SUR-based applications.\",4,\"Tue 10:40 - 10:50 AM\",1429648800,1429649400,\"Authors\",null],[212,-1,\"s-float-14\",\"Papers\",\"Motivation & Participation\",null,null,15,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Chair\",\"Papers\"],[213,212,\"pn1059\",\"Paper\",\"Gauging Receptiveness to Social Microvolunteering\",\"Crowd-powered systems that help people are difficult to scale and sustain because human labor is expensive and worker pools are difficult to grow. To address this problem we introduce the idea of social microvolunteering, a type of intermediated friendsourcing in which a person can provide access to their friends as potential workers for microtasks supporting causes that they care about. We explore this idea by creating Visual Answers, an exemplar social microvolunteering application for Facebook that posts visual questions from people who are blind. We present results of a survey of 350 participants on the concept of social microvolunteering, and a deployment of the Visual Answers application with 91 participants, which collected 618 high-quality answers to questions asked over 12 days, illustrating the feasibility of the approach.\",\"This paper introduces and explores social microvolunteering, which combines the speed and anonymity of crowdsourcing with the reliability and free answers from friendsourcing for altruistic tasks.\",15,\"Tue 9:30 - 9:50 AM\",1429644600,1429645800,\"Authors\",null],[214,212,\"pn906\",\"Paper\",\"Mobile Gamification for Crowdsourcing Data Collection: Leveraging the Freemium Model\",\"Classic ways of gathering data on human behaviour are time-consuming, costly and are subject to limited participant pools. Crowdsourcing offers a reduction in operating costs and access to a diverse and large participant pool; however issues arise concerning low worker pay and questions about data quality. Gamification provides a motivation to participate, but also requires the development of specialized, research-question specific games that can be costly to produce. Our solution combines gamification and crowdsourcing in a smartphone-based system that emulates the popular Freemium model of play to motivate voluntary participation through in-game rewards, using a robust framework to study multiple unrelated research questions within the same system. We deployed our game on the Android store and compared it to a gamified laboratory version and a non-gamified laboratory version, and found that players who used the in-game rewards were motivated to do experimental tasks. There was no difference between the systems for performance on a motor task; however, performance on the cognitive task was worse for the crowdsourced game. We discuss options for improving performance on tasks requiring attention. \",\"We combine gamification and crowdsourcing in a smartphone-based system that emulates the popular Freemium model of play to motivate voluntary participation in experimental tasks through in-game rewards.\",15,\"Tue 9:50 - 10:10 AM\",1429645800,1429647000,\"Authors\",null],[215,212,\"pn2375\",\"Paper\",\"Unequal Time for Unequal Value: Implications of Differing Motivations for Participation in Timebanking\",\"Timebanking is a service-based community currency, built on the principle that everyone’s time is valued equally. It has potential for community building and reenergizing neighborhoods, but it faces several adoption challenges. We report on the largest investigation of timebanking practices to date by analyzing a combination of service exchange records from the three largest hOurworld timebanks with over 3,500 members with 33,000 completed service exchanges, and a survey of 446 members of over 120 hOurworld timebanks. Our findings suggest that the ideal of ‘equal time, equal value’ that is at the foundation of timebanking is a source of tension between members with instrumental versus idealistic and altruistic motivations. We suggest that future peer-to-peer systems must incorporate different rewards and incentives in order to accommodate users with different motivations. \",\"P2P services are exploding but little has been reported on what motivates participation. We present a close examination of an established community currency practice to explore new design opportunities.\",15,\"Tue 10:10 - 10:30 AM\",1429647000,1429648200,\"Authors\",null],[216,212,\"pn747\",\"Paper\",\"A Muddle of Models of Motivation For Using Peer-to-Peer Economy Systems\",\"This paper reports on a study of motivations for the use of peer-to-peer or sharing economy services. We interviewed both users and providers of these systems to obtain different perspectives and to determine if providers are matching their system designs to the most important drivers of use. We found that the motivational models implicit in providers’ explanations of their systems’ designs do not match well with what really seems to motivate users. Providers place great emphasis on idealistic motivations such as creating a better community and increasing sustainability. Users, on the other hand are looking for services that provide what they need whilst increasing value and convenience. We discuss the divergent models of providers and users and offer design implications for peer system providers.\",\"A detailed study from 68 interviews of what motivates people to participate in peer-to-peer or sharing economy services and what motivations service system providers believe drive usage and design their systems to foster.\",15,\"Tue 10:30 - 10:50 AM\",1429648200,1429649400,\"Authors\",null],[217,-1,\"s-float-12\",\"Papers\",\"Sustainability & Recycling\",null,null,11,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Chair\",\"Papers\"],[218,217,\"pn982\",\"Paper\",\"Analysis of Recycling Capabilities of Individuals and Crowds to Encourage and Educate People to Separate Their Garbage Playfully\",\"Sorting garbage is a relevant topic in many countries as it contributes to environmental protection. Empirical evidence suggests that not all people separate waste, potentially because they do not know how to do it correctly or are simply not motivated enough. We present the results of an online study (N=184) investigating people's capabilities for classifying waste, their capabilities to improve in this task over time and their current garbage separation behavior. The study confirms that the Wisdom of Crowds is applicable in this context as the crowd produces only half as many errors as the individual and feedback helps participants to improve. Based on this, we introduce the idea of a crowd classifying waste in a game, with their classification result then being used as feedback on gamified public trash cans to educate both the crowd playing the game and people using the trash can playfully.\",\"Based on results of a gamified online questionnaire, we use a public trash can using Gamification and a mobile game to engage people to classify waste and to motivate recycling.\",11,\"Tue 9:30 - 9:50 AM\",1429644600,1429645800,\"Authors\",null],[219,217,\"pn833\",\"Paper\",\"Why and what did we throw out? Probing on Reflection through the Food Waste Diary\",\"Issues of consumer food waste in industrialised countries are becoming an increasing concern and this is paralleled by a growing interest in HCI to support more sustainable consumption practices. In this paper we report on a mobile food waste diary application that was made available on app stores, with the aim of enabling motivated people to reflect on their moments of food waste and to explore rationales. Through analysis of the entries submitted by users of the diary application, we identify instances of reflection located on different levels. The intention of supporting reflection was visible in instances of submitted diary entries where deeper in- sights about the relationships between food waste, previous experiences, habits, knowledge, occurrences and intentions to change were offered.\",\"We report on a mobile food waste diary application that was made available on app stores, with the aim of enabling motivated people to reflect on their moments of food waste and to explore rationales.\",11,\"Tue 9:50 - 10:10 AM\",1429645800,1429647000,\"Authors\",null],[220,217,\"pn2310\",\"Paper\",\"Energy Babble: Mixing Environmentally-Oriented Internet Content to Engage Community Groups\",\"The Energy Babble is a kind of automated talk-radio that is obsessed with energy and the environment. We developed it with, and deployed it to, a number of existing ‘energy communities’ in the UK. The system gathers content from a variety of online sources, including Twitter™ feeds from the communities, from governmental departments, and from the National Grid, and chats about it continually using a number of synthesised voices interspersed with a variety of jingles and sound effects.  Designed to playfully reflect and comment on the existing state of discourse and reports of practice in the UK, the Babble can be considered both as a product and as a research tool, in which role it worked to highlight issues, understandings, practices and difficulties in the communities with whom we worked.  \",\"The Energy Babble is like an automated talk radio for communities concerned with sustainable energy. It raises new possibilities and issues concerning information, communication and policy for Environmental HCI.\",11,\"Tue 10:10 - 10:30 AM\",1429647000,1429648200,\"Authors\",null],[221,217,\"pn569\",\"Paper\",\"Beyond the Individual: The Contextual Wheel of Practice as a Research Framework for Sustainable HCI\",\"Addressing human impact on the environment by focusing on shared everyday practices, rather than just individual behavior is an approach that shows promise. However, it can be challenging to put this approach into concrete use, especially in teams unfamiliar with the practice orientation. To support the practice approach, we introduce the Contextual Wheel of Practice (COWOP), a framework that can: 1) help researchers and designers to better understand practices, 2) design effective interventions, and 3) facilitate collaboration between team members from different disciplines, who may not be familiar with the practice orientation. We describe how COWOP was developed, and our experiences using COWOP in three different cases. We then position COWOP as part of the “turn to practice” in HCI, and discuss how it can be useful to HCI researchers and be applied in domains beyond sustainability, such as healthcare and privacy.\",\"The Contextual Wheel of Practice is a practice-theoretical framework for analysis, design, and evaluation within sustainable HCI, that is also useful for introducing others to the practice orientation.\",11,\"Tue 10:30 - 10:50 AM\",1429648200,1429649400,\"Authors\",null],[222,-1,\"s151\",\"Papers\",\"Search & Recommendations\",null,null,5,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Chair\",\"Papers\"],[223,222,\"pn1958\",\"Paper\",\"Blended Recommending: Integrating Interactive Information Filtering and Algorithmic Recommender Techniques\",\"We present a novel approach that integrates algorithmic recommender techniques with interactive faceted filtering methods. We refer to this approach as blended recommending. It allows users to interact with a set of filter facets representing criteria that can serve as input for different recommendation methods including both collaborative and content-based filtering. Users can select filter criteria from these facets and weight them to express their preferences and to exert control over the hybrid recommendation process. In contrast to hard Boolean filtering, the method aggregates the weighted criteria and calculates a ranked list of recommendations that is visualized and immediately updated when users change the filter settings. Based on this approach, we implemented an interactive movie recommender, MyMovieMixer. In a user study, we compared the system with a conventional faceted filtering system that served as a baseline to obtain insights into user interaction behavior and to assess recommendation quality for our system. The results indicate, among other findings, a higher level of perceived user control, more detailed preference settings, and better suitability when the search goal is vague.\",\"Blended recommending is a novel approach integrating faceted filtering with recommender methods. By selecting and weighting filter criteria users can express their preferences and control a hybrid recommendation process.\",5,\"Tue 9:30 - 9:50 AM\",1429644600,1429645800,\"Authors\",null],[224,222,\"pn2207\",\"Paper\",\"A Large-Scale Study of User Image Search Behavior on the Web\",\"In this study, we analyze user image search behavior from a large-scale Yahoo! Image Search query log, based on the hypothesis that behavior is dependent on query type. We categorize queries using two orthogonal taxonomies (subject-based and facet-based) and identify important query types at the intersection of these taxonomies. We study user search behavior on a large-scale set of search sessions for each query type, examining characteristics of sessions, query reformulation patterns, click patterns, and page view patterns. We identify important behavioral differences across query types, in particular showing that some query types are more exploratory, while others correspond to focused search. We also supplement our study with a survey to link the behavioral differences to users' intent. Our findings shed light on the importance of considering query categories to better understand user behavior on image search platforms.\",\"We identify the popular types of image search queries and study the behavioral differences with respect to query type, based on a large-scale, up-to-date web image search log.\",5,\"Tue 9:50 - 10:10 AM\",1429645800,1429647000,\"Authors\",null],[225,222,\"pn532\",\"Paper\",\"DynamicMaps: Similarity-based Browsing through a Massive Set of Images\",\"We present a novel system for browsing through a very large set of images according to similarity. The images are dynamically placed on a 2D canvas next to their nearest neighbors in a high-dimensional feature space. The layout and choice of images is generated on-the-fly during user interaction, reflecting the user's navigation tendencies and interests. This intuitive solution for image browsing provides a continuous experience of navigating through an infinite 2D grid arranged by similarity. In contrast to common multidimensional embedding methods, our solution does not entail an upfront creation of a full global map. Image map generation is dynamic, fast and scalable, independent of the number of images in the dataset, and seamlessly supports online updates to the dataset. Thus, the technique is a viable solution for massive and constantly varying datasets consisting of millions of images. Evaluation of our approach shows that when using DynamicMaps, users viewed many more images per minute compared to a standard relevance feedback interface, suggesting that it supports more fluid and natural interaction that enables easier and faster movement in the image space. Most users preferred DynamicMaps, indicating it is more exploratory, better supports serendipitous browsing and more fun to use\",\"DynamicMaps provides an intuitive solution for image browsing through very large datasets by allowing the user to continuously navigate through an infinite 2D grid arranged according to similarity.\",5,\"Tue 10:10 - 10:30 AM\",1429647000,1429648200,\"Authors\",null],[226,222,\"pn2447\",\"Paper\",\"S.O.S.: Does Your Search Engine Results Page (SERP) Need Help?\",\"Over the past 20 years, search engines have become emph{the} entry point of the WWW. Due to evolving needs for different and new kinds of information, the interfaces of search engine results pages (SERPs) change over time. Thus, their usability must be continuously evaluated to ensure user satisfaction and competitive edge. As no complete solution exists, we present emph{S.O.S.:}the emph{SERP Optimization Suite}. Our approach comprises (a) emph{WaPPU}, which is a near real-time tool for evaluating web interfaces based on usability scores, and (b) a emph{catalog of best practices} that maps bad scores to potential causes and corresponding adjustments for optimization. During a case study in which we assessed and optimized a real-world SERP, S.O.S.has proven its feasibility and effectiveness by significantly improving the SERP's usability.\",\"S.O.S. enables split testing of search engine results pages based on usability scores for, e.g. readability. Potential optimizations to the page are automatically suggested for suboptimal scores.\",5,\"Tue 10:30 - 10:50 AM\",1429648200,1429649400,\"Authors\",null],[227,-1,\"s-float-40\",\"Papers\",\"Supporting Creativity through UX Design\",null,null,1,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Chair\",\"Papers\"],[228,227,\"pn5104\",\"TOCHI\",\"Using Metrics of Curation to Evaluate Information-Based Ideation\",\"We introduce information-based ideation (IBI), a paradigm for investigating performance of open-ended tasks and activities in which users develop new ideas. IBI tasks span imagining, planning and reflecting on a weekend, vacation, outfit, makeover, paper, internship, thesis, design, campaign,  crisis response, career, or invention.  Through engagement in IBI tasks, people create curation products. Curation of digital media incorporates conceptualization, finding and choosing information objects, annotation, and synthesis. To formulate a quantitative methodology for evaluating IBI support tools, we build on prior creative cognition research in engineering design to derive a battery of ideation metrics of curation.  IBI support environments are characterized by the medium they afford for representing curation. An in-depth case study investigates information composition, an art-based medium for representing a curation as a visual semantic connected whole. To evaluate support for creativity, we apply ideation metrics of curation to analyze results from experiments with 44 and 49 participants.  Evaluating creativity support environments is challenging. Some approaches address people’s experiences of creativity. The present method measures creativity, across conditions, in the products that people make.  This research introduces information-based ideation (IBI), a paradigm for investigating open-ended tasks and activities in which users develop new ideas. IBI tasks span imagining, planning, and reflecting on a weekend, vacation, outfit, makeover, paper, internship, thesis, design, campaign, crisis response, career, or invention. What products do people create through engagement in IBI? Curation of digital media incorporates conceptualization, finding and choosing information objects, annotation, and synthesis. Through engagement in IBI tasks, people create curation products. This article formulates a quantitative methodology for evaluating IBI support tools, building on prior creative cognition research in engineering design to derive a battery of ideation metrics of curation. Elemental ideation metrics evaluate creativity within curated found objects. Holistic ideation metrics evaluate how a curation puts elements together.  IBI support environments are characterized by their underlying medium of curation. Curation media include lists, such as listicles, and grids, such as the boards of Pinterest.  An in-depth case study investigates information composition, an art-based medium representing a curation as a freeform visual semantic connected whole. We raise two creative cognition challenges for IBI. One challenge is overcoming fixation—for instance, when a person gets stuck in a counterproductive mental set. The other challenge is to bridge information visualization’s synthesis gap, by providing support for connecting findings. To address the challenges, we develop mixed-initiative information composition (MI2C), integrating human curation of information composition with automated agents of information retrieval and visualization.  We hypothesize that MI2C generates provocative stimuli that help users overcome fixation to become more creative on IBI tasks. We hypothesize that MI2C’s integration of curation and visualization bridges the synthesis gap to help users become more creative. To investigate these hypotheses, we apply ideation metrics of curation to interpret results from experiments with 44 and 49 participants.\",\"We introduce information-based ideation (IBI), a paradigm for investigating performance of open-ended tasks and activities in which users develop new ideas. IBI tasks span imagining, planning and reflecting on a weekend, vacation, outfit, makeover, paper, internship, thesis, design, campaign,  crisis response, career, or invention.  Through engagement in IBI tasks, people create curation products. Curation of digital media incorporates conceptualization, finding and choosing information objects,...\",1,\"Tue 9:30 - 9:50 AM\",1429644600,1429645800,\"Authors\",null],[229,227,\"pn1419\",\"Paper\",\"GEM-NI: A System for Creating and Managing Alternatives In Generative Design\",\"We present GEM-NI – a graph-based generative-design tool that supports parallel exploration of alternative designs. Producing alternatives is a key feature of creative work, yet it is not strongly supported in most extant tools. GEM-NI enables various forms of exploration with alternatives such as parallel editing, recalling history, branching, merging, comparing, and Cartesian products of and for alternatives. Further, GEM-NI provides a modal graphical user interface and a design gallery, which both allow designers to control and manage their design exploration. We conducted an exploratory user study followed by in-depth one-on-one interviews with moderately and highly skills participants and obtained positive feedback for the system features, showing that GEM-NI supports creative design work well.\",\"To facilitate design space exploration we present a system for managing alternatives in design with parallel editing, merging, resurrection with lineage preservation, and design galleries with products of generative networks.\",1,\"Tue 9:50 - 10:10 AM\",1429645800,1429647000,\"Authors\",null],[230,227,\"pn2022\",\"Paper\",\"Motif: Supporting Novice Creativity through Expert Patterns\",\"Creating personal narratives helps people build meaning around their experiences. However, novices lack the knowledge and experience to create stories with strong narrative structure. Current storytelling tools often structure novice work through templates, enforcing a linear creative process that asks novices for materials they may not have. In this paper, we propose scaffolding creative work using storytelling patterns extracted from stories created by experts. Patterns are modular sets of related camera shots that expert videographers commonly use to achieve a specific narrative function. After identifying a set of patterns from high-quality storytelling videos, we created Motif, a mobile video storytelling application that allows users to construct video stories by combining these patterns. By making existing solutions used by experts available to novices, we encourage capturing shots with story structure and narrative goals in mind. In a controlled study where we asked participants to create travel video stories, videos created with patterns conveyed stronger narrative structure and were considered higher quality by expert evaluators than videos created without patterns.\",\"We can scaffold novice creativity using storytelling patterns extracted from expert stories. Through Motif, a mobile video storytelling application, we allow users to construct video stories by combining these patterns. \",1,\"Tue 10:10 - 10:30 AM\",1429647000,1429648200,\"Authors\",null],[231,227,\"pn234\",\"Note\",\"DesignScape: Design with Interactive Layout Suggestions\",\"Creating graphic designs can be challenging for novice users.  This paper presents DesignScape, a system which aids the design process by making interactive layout suggestions, i.e., changes in the position, scale, and alignment of elements. The system uses two distinct but complementary types of suggestions: refinement suggestions, which improve the current layout, and brainstorming suggestions, which change the style. We  investigate two interfaces for interacting with suggestions. First, we develop a suggestive interface, where suggestions are previewed and can be accepted. Second, we develop an adaptive interface where elements  move automatically to improve the layout. We compare both interfaces with a baseline without suggestions, and show that for novice designers, both interfaces produce significantly better layouts, as evaluated by other novices.\",\"This paper presents DesignScape, a system which aids the design process by making interactive layout suggestions for both improving the current design and exploring style variation.\",1,\"Tue 10:30 - 10:40 AM\",1429648200,1429648800,\"Authors\",null],[232,227,\"pn302\",\"Note\",\"Using Game Principles in UX Research:  A Board Game for Eliciting Future User Needs\",\"This paper presents a board game approach as a UX research technique to assess potential user experiences regarding a future product. It discusses how the use of a board game may provide a) a safe research environment in which participants feel comfortable to share their thoughts and experiences in a group setting, and b) a tool to facilitate users to think about their needs regarding a future product. The use of the board game approach is illustrated by a case study in the context of developing a new train information system. The design of the board game that was used is described in detail, as well as how the game was used to elicit potential future experiences. A survey amongst the participants showed that the board game was appreciated as a surprising, pleasant and ‘safe’ research method. \",\"This paper presents a board game approach as a UX research technique to assess potential user experiences regarding a future product. \",1,\"Tue 10:40 - 10:50 AM\",1429648800,1429649400,\"Authors\",null],[233,-1,\"s-case2\",\"Case Studies\",\"Art & Life\",null,null,2,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Chair\",\"Papers\"],[234,233,\"case120\",\"Case Study\",\"Artistic Distance: Body Movements as Launching Points For Art Inquiry\",\"How does the body matter in art observations? Do physical distances, movements, and perspectives influence the way one appreciates art? Do experts and novices use their body differently in engaging with art objects? We present results of our studies with 22 art experts and novices in two types of art, “Ikebana” (Japanese traditional flower arrangement) and abstract paintings. In both types of art, we observed that experts engaged with the art from multiple perspectives while exhibiting minimal movements around the art. Novices, in contrast, either hovered around the art looking for clues of interpretations or did not move at all due to lack of interest. We discuss implications for design of embodied systems that can support users with various levels of expertise. \",\"We present studies with 22 art experts and novices in “Ikebana” and abstract paintings. We discuss design of embodied systems that support users with various levels of expertise.\",2,\"Tue 9:30 - 9:50 AM\",1429644600,1429645800,\"Authors\",null],[235,233,\"case147\",\"Case Study\",\"TRANSFORM: Embodiment of “Radical Atoms” at Milano Design Week\",\"RANSFORM fuses technology and design to celebrate the transformation from a piece of static furniture to a dynamic machine driven by streams of data and energy. TRANSFORM aims to inspire viewers with unexpected transformations, as well as the aesthetics of a complex machine in motion. This paper describes the concept, engine, product, and motion design of TRANSFORM, which was first exhibited at LEXUS DESIGN AMAZING 2014 MILAN in April 2014.\",\"This paper describes the concept, engine, product, and motion design of TRANSFORM, which was first exhibited at LEXUS DESIGN AMAZING 2014 MILAN in April 2014.\",2,\"Tue 9:50 - 10:10 AM\",1429645800,1429647000,\"Authors\",null],[236,233,\"case163\",\"Case Study\",\"Moving on its Own: How do Audience Interacts with an Autonomous Moving Artwork\",\"In contemporary art, a new type of artworks use motion as a material from which to create the illusion of life. These autonomous robotic artworks have a behavioral specificity; they tend to be perceived as living, and by some account intentional entities. To account for this behavioral specifity and how it affects the audience experience, we propose a data-driven approach to reveal specific visit patterns. Through a cluster analysis performed on visitors’ path inside an installation involving autonomous objects, we highlight four different attitudes characterized by patterns of approach or withdrawal, passive observation and exploration. \",\"Autonomous robotic artworks tend to be perceived as living and intentional entities. We explore the way visitors interact with an artistic installation involving this original form of robots.\",2,\"Tue 10:10 - 10:30 AM\",1429647000,1429648200,\"Authors\",null],[237,233,\"case183\",\"Case Study\",\"Colormaps that Improve Perception of High-Resolution Ocean Data\",\"Scientists from the Climate, Ocean and Sea Ice Modeling Team (COSIM) at the Los Alamos National Laboratory (LANL) are interested in gaining a deeper understanding of three primary ocean currents: the Gulf Stream, the Kuroshio Current, and the Agulhas Current & Retroflection. To address these needs, visual artist Francesca Samsel teamed up with experts from the areas of computer science, climate science, statistics, and perceptual science.  By engaging an artist specializing in color, we created colormaps that provide the ability to see greater detail in these high-resolution datasets.  The new colormaps applied to the POP dataset enabled scientists to see areas of interest unclear using standard colormaps.  Improvements in the perceptual range of color allowed scientists to highlight structures within specific ocean currents. Work with the COSIM team members drove development of nested colormaps which provide further detail to the scientists.\",\"We have built and tested colormaps enabling scientists to see greater detail within their data.\",2,\"Tue 10:30 - 10:50 AM\",1429648200,1429649400,\"Authors\",null],[238,-1,\"s-crs122\",\"Course\",\"Designing & Assessing Task Models 1/2\",null,null,6,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Instructor\",null],[239,238,\"crs122\",\"Course\",\"Designing and Assessing Interactive Systems Using Task Models\",\"This two-part course takes a practical approach to introduce the principles, methods and tools in task modelling. Part 1: A non-technical introduction demonstrates that task models support successful design of interactive systems. Part 2: A more technical interactive hands-on exercise of how to \\\"do it right\\\", such as: How to go from task analysis to task models? How to assess (through analysis and simulation) that a task model is correct? How to identify complexity of user tasks … \",\"This course takes a practical approach to the principles, methods and tools in task modelling. Part 1 is introductory while Part 2 is interactive hands-on exercises about how to \\\"do-it-right\\\"\",6,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Instructor\",null],[240,-1,\"s-crs100\",\"Course\",\"Learn to Sketch (Even if You Can’t Draw) 1/2\",null,null,7,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Instructor\",null],[241,240,\"crs100\",\"Course\",\"Learn to Sketch (Even if You Can’t Draw): Hands-on Sketching Course\",\"Sketching as a technique to quickly draw something on a piece of paper can be used to explore and communicate ideas. Practitioners can make use of their ability to draw sketches from an early phase of a project on. It can be valuable not only for the exploration of ideas but also for gathering feedback from stakeholders and to foster a common understanding of requirements and concepts. This course introduces basic sketching techniques and a visual language which participants can immediately apply. It is a hands-on course which allows participants to do a lot of sketching during the session.\",\"Sketching as a technique to quickly draw ideas is used to explore and communicate ideas. This course introduces basic sketching techniques and a visual language, which participants can immediately apply.\",7,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Instructor\",null],[242,-1,\"s-crs129\",\"Course\",\"Methods for Child Computer Interaction 1/2\",null,null,14,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Instructor\",null],[243,242,\"crs129\",\"Course\",\"Research Methods for Child Computer Interaction\",\"In this course participants will learn about theory and practice of conducting research in children’s HCI. The course is divided into two sessions: basic principles and theory, and best practices. The instructors have multiple years of experience designing, conducting, and analyzing children-computer interaction (CCI) studies, in the UK, USA, and Israel.\",\"This course introduces participants to ethical and appropriate research with children.  A case study is used to show research methods. The course suits those working with children in HCI.\",14,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Instructor\",null],[244,-1,\"s-crs106\",\"Course\",\"Practical UX Research Methodologies 1/2\",null,null,9,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Instructor\",null],[245,244,\"crs106\",\"Course\",\"Practical UX Research Methodologies\",\"Half-Day course on the practical research methods used to understand the changing technology climate.  Experts from UEGroup, a Silicon Valley research and design company, will lead an interactive discussion and give practical suggestions for developing methodologies including: Ethnography, Out of Box Experiences, and Usability Testing. \",\"Walk away from the course with a more complete understanding of the different methodologies and begin to understand when to incorporate each approach to their unique applications.  \",9,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Instructor\",null],[246,-1,\"s133\",\"Papers\",\"Kids Haptic, Wearable, Tangible Learning\",null,null,10,\"Tue 9:30 - 10:50 AM\",1429644600,1429649400,\"Chair\",\"Papers\"],[247,246,\"pn1390\",\"Paper\",\"FeelSleeve: Haptic Feedback to Enhance Early Reading\",\"Engaging children with traditional approaches in education, especially reading, grows ever more difficult in the face of their attachment to tablets and computer games. We explore the possibility of making the story reading experience more interesting and memorable for children using haptic augmentation. In this paper, we present FeelSleeve, an interface that allows children to feel story events in their hands while they are reading on a mobile device. FeelSleeve uses transducers and audio output from the tablet within a gloved attachment to create vibratory effects that are meaningfully related to story content. We describe a study investigating whether embedding such haptic feedback into stories enhances reading for six to nine year olds. Our results indicate that story events accompanied by haptic feedback are better comprehended and appear to be more salient in memory. These results provide evidence that haptic effects have the potential to improve children’s reading experience and make it more memorable.\",\"We present FeelSleeve, an interface allowing children to feel story events while reading on a mobile device. Our studies show that haptic effects have potential to improve children’s reading comprehension. \",10,\"Tue 9:30 - 9:50 AM\",1429644600,1429645800,\"Authors\",null],[248,246,\"pn919\",\"Paper\",\"BodyVis: A New Approach to Body Learning Through Wearable Sensing and Visualization\",\"Internal organs are hidden and untouchable, making it difficult for children to learn their size, position, and function. Traditionally, human anatomy (body form) and physiology (body function) are taught using techniques ranging from worksheets to three-dimensional models. We present a new approach called BodyVis, an e-textile shirt that combines biometric sensing and wearable visualizations to reveal otherwise invisible body parts and functions. We describe our 15-month iterative design process including lessons learned through the development of three prototypes using participatory design and two evaluations of the final prototype: a design probe interview with seven elementary school teachers and three single-session deployments in after-school programs. Our findings have implications for the growing area of wearables and tangibles for learning.\",\"We introduce a new approach and system called BodyVis for children's body learning, which combines wearable biometric sensors and on-body visualization to provide new insights into anatomy and physiology.\",10,\"Tue 9:50 - 10:10 AM\",1429645800,1429647000,\"Authors\",null],[249,246,\"pn654\",\"Paper\",\"Exploring Expressive Augmented Reality: The FingAR Puppet System for Social Pretend Play\",\"We present \\\"FingAR Puppet\\\", an Augmented Reality (AR) system enhancing social pretend play by young children. Unlike goal-oriented AR systems that augment reality with informative instructions, FingAR Puppet helps children associate expressive interpretations with immediate reality. Empirical results show that FingAR Puppet promotes reasoning about emotional states, communication and divergent thinking during social pretend play for children 4-6 years old. We suggest that this study opens an interesting space for future AR systems to support complex cognitive and social development in early childhood. We also identify broader implications from using theories of cognitive development to guide the design of tangible and augmented interactions.\",\"We present FingAR Puppet, an Augmented Reality system enhancing social pretend play, to suggest the potential of Augmented Reality in supporting complex cognitive and social development in early childhood.\",10,\"Tue 10:10 - 10:30 AM\",1429647000,1429648200,\"Authors\",null],[250,246,\"pn1391\",\"Paper\",\"Learning from Mixed-Reality Games:  Is Shaking a Tablet as Effective as Physical Observation?\",\"The possibility of leveraging technology to support children’s learning in the real world is both appealing and technically challenging. We have been exploring factors in tangible games that may contribute to both learning and enjoyment with an eye toward technological feasibility and scalability. Previous research found that young children learned early physics principles better when interactively predicting and observing experimental comparisons on a physical earthquake table than when seeing a video of the same. Immersing children in the real world with computer vision-based feedback appears to evoke embodied cognition that enhances learning. In the current experiment, we replicated this intriguing result of the mere difference between observing the real world versus a flat-screen. Further, we explored whether a simple and scalable addition of physical control (such as shaking a tablet) would yield an increase in learning and enjoyment. Our 2x2 experiment found no evidence that adding simple forms of hands-on control enhances learning, while demonstrating a large impact of physical observation. A general implication for educational game design is that affording physical observation in the real world accompanied by interactive feedback may be more important than affording simple hands-on control on a tablet.\",\"Our study demonstrates that real-world physical observation accompanied by real-time interactive feedback in a mixed-reality game is more impactful for learning and enjoyment than having physical control on a tablet.\",10,\"Tue 10:30 - 10:50 AM\",1429648200,1429649400,\"Authors\",null],[251,-1,\"break-4\",\"Breaks\",\"Coffee Break\",null,null,15,\"Tue 10:50 - 11:30 AM\",1429649400,1429651800,\"\",\"\"],[252,-1,\"int-1\",\"Interactivity\",\"Interactivity Demos Exhibit\",null,null,15,\"Tue 10:50 - 11:30 AM\",1429649400,1429651800,\"\",\"\"],[253,-1,\"wip-1\",\"WIPs\",\"Work in Progress Exhibit\",null,null,15,\"Tue 10:50 - 11:30 AM\",1429649400,1429651800,\"\",\"\"],[254,-1,\"s-alt3\",\"alt.chi\",\"HCI Methodology\",null,null,2,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Authors\",\"Papers\"],[255,254,\"alt138\",\"alt.chi\",\"HCI as an Inter-Discipline\",\"\",\"...\",2,\"Tue 11:30 - 11:50 AM\",1429651800,1429653000,\"Authors\",\"Papers\"],[256,254,\"alt133\",\"alt.chi\",\"The User Experience Designer’s Charlatan Test: a First Step towards UX Sanity Checking\",\"\",\"...\",2,\"Tue 11:50 - 12:10 PM\",1429653000,1429654200,\"Authors\",\"Papers\"],[257,254,\"alt122\",\"alt.chi\",\"Design + Ethnography + Futures: surrendering in uncertainty\",\"\",\"...\",2,\"Tue 12:10 - 12:30 PM\",1429654200,1429655400,\"Authors\",\"Papers\"],[258,254,\"alt127\",\"alt.chi\",\"Deep Cover HCI: Value, Ethics, and Practice\",\"\",\"...\",2,\"Tue 12:30 - 12:50 PM\",1429655400,1429656600,\"Authors\",\"Papers\"],[259,-1,\"s-float-25\",\"Papers\",\"Healthcare Bias, Engagement & Adaptation\",null,null,12,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Chair\",\"Papers\"],[260,259,\"pn1045\",\"Paper\",\"From Care Plans to Care Coordination: Opportunities for Computer Support of Teamwork in Complex Healthcare\",\"Children with complex health conditions require care from a large, diverse team of caregivers that includes multiple types of medical professionals, parents and community support organizations. Coordination of their outpatient care, essential for good outcomes, presents major challenges. Extensive healthcare research has shown that the use of integrated, team-based care plans improves care coordination, but such plans are rarely deployed in practice. This paper reports on a study of care teams treating children with complex conditions at a major university tertiary care center. This study investigated barriers to plan implementation and resultant care coordination problems. It revealed the complex nature of teamwork in complex care, which poses challenges to team coordination that extend beyond those identified in prior work and handled by existing coordination systems.  The paper builds on a computational teamwork theory to identify opportunities for technology to support increased plan-based complex-care coordination and to propose design approaches for systems that enable and enhance such coordination. \",\"This paper investigates care coordination for patients with complex conditions, identifies opportunities for technology to enhance it and proposes design principles for such technology based on a computational teamwork theory.\",12,\"Tue 11:30 - 11:50 AM\",1429651800,1429653000,\"Authors\",null],[261,259,\"pn5109\",\"TOCHI\",\"Technological and Organizational Adaptation of EMR Implementation in an Emergency Department\",\"Implementation of large health information technology (HIT) systems is critical to healthcare organizations and has seen heavy investment. However, research has not fully explored the adaptation of HIT systems, particularly the tensions between individual flexibility and organizational needs in the adaptation process. This study analyzes how Emergency Department (ED) clinicians adapted to a new hospital-wide Electronic Medical Records (EMR) system. We present four adaptation cases revealing two interrelated types of adaptations – technical and organizational – as responses to the new system in use. First, individual clinicians respond to the immediate alteration in workflows caused by the EMR, while the organizational adaptations later mitigate the changes in healthcare quality control resulting from the clinicians’ initial adaptation. Our analysis reflects the critical nature and value of both adaptation types, with an emphasis on the triggers and process of organizational adaptation, for the successful implementation of a socio-technical-political system in a healthcare organization.\",\"Implementation of large health information technology (HIT) systems is critical to healthcare organizations and has seen heavy investment. However, research has not fully explored the adaptation of HIT systems, particularly the tensions between individual flexibility and organizational needs in the adaptation process. This study analyzes how Emergency Department (ED) clinicians adapted to a new hospital-wide Electronic Medical Records (EMR) system. We present four adaptation cases revealing two ...\",12,\"Tue 11:50 - 12:10 PM\",1429653000,1429654200,\"Authors\",null],[262,259,\"pn103\",\"Paper\",\"Engaging Pregnant Women in Kenya with a Hybrid Computer-Human SMS Communication System\",\"A growing body of HCI4D research studies the use of SMS communication to deliver health and information services to underserved populations. This paper contributes a novel dimension to this field of study by examining if a hybrid computer-human SMS system can engage pregnant women in Kenya in health-related communication. Our approach leverages the different strengths of both the computer and the human. The computer automates the bulk-sending of personalized messages to patients, allowing the human to read patients' replies and respond to those in need of attention. Findings from a 12-month deployment with 100 women show that our approach is capable of engaging the majority of participants in health-related conversations. We show that receiving messages from the system triggers participant communication and the amount of communication increases as participants approach their expected due date. In addition, analysis of participants' messages shows that they often contain sensitive health information conveyed through a complex mixture of languages and 'txting' abbreviations, all of which highlight the benefits of including a human in the workflow. Our findings are relevant for HCI researchers and practitioners interested in understanding or engaging underserved populations. \",\"We present a hybrid computer-human SMS system that encourages people in low-resource settings to engage in health-related communication and describe a 12-month system deployment with 100 pregnant women in Kenya.\",12,\"Tue 12:10 - 12:30 PM\",1429654200,1429655400,\"Authors\",null],[263,259,\"pn2470\",\"Paper\",\"It Is All About Perspective: An Exploration of Mitigating Selective Exposure with Aspect Indicators\",\"Selective exposure, the preferential seeking of confirmatory information, can potentially exacerbate fragmentation of online opinions and lead to biased decisions. We tested whether features that allowed users to better distinguish information about different issue aspects would encourage them to take different perspectives, thereby moderating the negative influence of pre-existing beliefs on information seeking. Using an information aggregator that provided drug related comments, we conducted an experiment to study the impact of aspect indicators (indicating whether the comment was about effectiveness or side effects) on moderating selective exposure. We found that, when participants were asked to decide between medications for high-risk diseases, and had preexisting biased beliefs in their effectiveness (one medication was less effective than the other), without aspect indicators they exhibited selective exposure to both types of comments (effectiveness and side effects) and were biased to choose the medication in confirmation of their pre-existing beliefs. With aspect indicators, we found reduced selective exposure to information about side effects of the medications, and as a result their overall decision bias was mitigated. However, the effect of aspect indicators in reducing selective exposure was moderated by the decision contexts, including the perceived risk of the diseases and whether the aspect was perceived to be critical to the decision. \",\"With an information aggregator presenting diverse opinions on medications, we conducted an experiment to test the idea of mitigating selective exposure by distinguishing focused issue aspects of information.\",12,\"Tue 12:30 - 12:50 PM\",1429655400,1429656600,\"Authors\",null],[264,-1,\"s161\",\"Papers\",\"Tangible Interactions\",null,null,4,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Chair\",\"Papers\"],[265,264,\"pn1888\",\"Paper\",\"TUIkit: Evaluating Physical and Functional Experiences of Tangible User Interface Prototypes\",\"This paper describes TUIkit, a new method for evaluating both physical and functional experiences of users with early TUI prototypes. By means of a study to evaluate interactive dice prototypes, TUIkit’s appropriateness for tracing the effect of different physical attributes (e.g. shape, size, weight, material, texture) on the functional and thus overall user experience was investigated. The results show that separating physical and functional experiences first and joining these afterwards, enhanced the evaluation of TUI prototypes. By applying this approach, participants became more aware of how they physically experienced the prototypes, rather than focusing solely on the functional value of the prototypes. This awareness supports earlier studies that suggest that TUIs consist of more than just interaction, and that form and materiality has a strong impact on their user experience. Finally, we suggest some future adjustments of the TUIkit method.\",\"In this paper we present TUIkit, a new method for evaluating both physical and functional experiences of users with early TUI prototypes.\",4,\"Tue 11:30 - 11:50 AM\",1429651800,1429653000,\"Authors\",null],[266,264,\"pn453\",\"Note\",\"Lamello: Passive Acoustic Sensing for Tangible Input Components\",\"We describe Lamello, an approach for creating tangible input components that recognize user interaction via passive acoustic sensing. Lamello employs comb-like structures with varying-length tines at interaction points (e.g., along slider paths). Moving a component generates tine strikes; a real-time audio processing pipeline analyzes the resultant sounds and emits high-level interaction events. Our main contributions are in the co-design of the tine structures, information encoding schemes, and audio analysis. We demonstrate 3D printed Lamello-powered buttons, sliders, and dials. \",\"Lamello is an approach for fabricating devices that make sounds when used, along with a training-free audio processing pipeline to interpret user interactions.\",4,\"Tue 11:50 - 12:00 PM\",1429653000,1429653600,\"Authors\",null],[267,264,\"pn1620\",\"Note\",\"WonderLens: Optical Lenses and Mirrors for Tangible Interactions on Printed Paper\",\"This work presents WonderLens, a system of optical lenses and mirrors for enabling tangible interactions on printed paper. When users perform spatial operations on the optical components, they deform the visual content that is printed on paper, and thereby provide dynamic visual feedback on user interactions without any display devices. The magnetic unit that is embedded in each lens and mirror allows the unit to be identified and tracked using an analog Hall-sensor grid that is placed behind the paper, so the system provides additional auditory and visual feedback through different levels of embodiment, further enhancing the interactivity with the printed content on the physical paper. \",\"WonderLens is a system of optical lenses and mirrors for enabling tangible interactions on printed paper. The lenses and mirrors provide dynamic visual feedback on user interactions without any display devices.\",4,\"Tue 12:00 - 12:10 PM\",1429653600,1429654200,\"Authors\",null],[268,264,\"pn451\",\"Paper\",\"FugaciousFilm: Exploring Attentive Interaction with Ephemeral Material\",\"This paper introduces FugaciousFilm, a soap film based touch display, as a platform for Attentive Interaction that encourages the user to be highly focused throughout the use of the interface. Previous work on ephemeral user interfaces has primarily focused on the development of ambient and peripheral displays. In contrast, FugaciousFilm is an ephemeral display that aims to promote highly attentive interaction. We present the iterative process of developing this interface, spanning technical explorations, prototyping and a user study. We report lessons learnt when designing the interface; ranging from the soap film mixture to the impact of frames and apertures. We then describe developing the touch, push, pull and pop interactions. Our user study shows how FugaciousFilm led to focused and attentive interactions during a tournament of enhanced Tic-Tac-Toe. We then finish by discussing how the principles of vulnerability and delicacy can motivate the design of attentive ephemeral interfaces.  \",\"This paper articulates the broader principles of vulnerability and fragility that explain how ephemeral interfaces can promote attentive interaction.\",4,\"Tue 12:10 - 12:30 PM\",1429654200,1429655400,\"Authors\",null],[269,264,\"pn2464\",\"Paper\",\"3D Printing Pneumatic Device Controls with Variable Activation Force Capabilities\",\"We explore 3D printing physical controls whose tactile response can be manipulated programmatically through pneumatic actuation. In particular, by manipulating the internal air pressure of various pneumatic elements, we can create mechanisms that require different levels of actuation force and can also change their shape. We introduce and discuss a series of example 3D printed pneumatic controls, which demonstrate the feasibility of our approach. This includes conventional controls, such as buttons, knobs and sliders, but also extends to domains such as toys and deformable interfaces. We describe the challenges that we faced and the methods that we used to overcome some of the limitations of current 3D printing technology. We conclude with example applications and thoughts on future avenues of research.\",\"We augment standard input controls with pneumatics to afford variable-activation force capabilities and haptic feedback, and provide methods for rapidly fabricating these input-output controls through multi-material 3D printing.\",4,\"Tue 12:30 - 12:50 PM\",1429655400,1429656600,\"Authors\",null],[270,-1,\"s135\",\"Papers\",\"Evaluating Crowdsourcing\",null,null,15,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Chair\",\"Papers\"],[271,270,\"pn2336\",\"Paper\",\"Comparing Person- and Process-centric Strategies for  Obtaining Quality Data on Amazon Mechanical Turk\",\"In the past half-decade, Amazon Mechanical Turk has radically changed the way many scholars do research. The availability of a massive, distributed, anonymous crowd of individuals willing to perform general human-intelligence micro-tasks for micro-payments is a valuable resource for researchers and practitioners. This paper addresses the challenges of obtaining quality annotations for subjective judgment oriented tasks of varying difficulty. We design and conduct a large, controlled experiment (N=68,000) to measure the efficacy of selected strategies for obtaining high quality data annotations from non-experts. Our results point to the advantages of person-oriented strategies over process-oriented strategies. Specifically, we find that screening workers for requisite cognitive aptitudes and providing training in qualitative coding techniques is quite effective, significantly outperforming control and baseline conditions. Interestingly, such strategies can improve coder annotation accuracy above and beyond common benchmark strategies such as Bayesian Truth Serum (BTS).\",\"We present two large field experiments testing person- and process-centric interventions aimed at improving results quality for subjective judgment data annotations on Amazon Mechanical Turk.\",15,\"Tue 11:30 - 11:50 AM\",1429651800,1429653000,\"Authors\",null],[272,270,\"pn1840\",\"Paper\",\"Crowdsourced Feedback With Imagery Rather Than Text: Would Designers Use It?\",\"Cognitive styles theories suggest that we divide into visual and verbal thinkers. In this paper we describe a method designed to encourage visual communication between designers and their audiences. This new visual feedback method is based on enabling fast intuitive selections by the crowd from image banks when responding to an idea. Visual summarization reduces the massed image choices to a small number of representative images. These summaries are then consumed at a glance by designers receiving the feedback leading to thoughtful reflection on their designs. We report an evaluation using two types of imagery for feedback. Twelve designers took part, receiving visual feedback in response to their designs. In semi-structured interviews they described their interpretation of the feedback, how it inspired them to change their designs and contrasted it with text feedback. Eleven of the twelve designers revealed that they would be enthusiastic users of a service providing this new mode of feedback. \",\"We describe a new method of image-based feedback letting designers access crowds’ perceptual and emotional reactions to designs. We report an evaluation: designers viewed visual feedback contrasting it with text.\",15,\"Tue 11:50 - 12:10 PM\",1429653000,1429654200,\"Authors\",null],[273,270,\"pn206\",\"Paper\",\"Measuring Crowdsourcing Effort with Error-Time Curves\",\"Crowdsourcing systems lack effective measures of the effort required to complete each task.  Without knowing how much time workers need to execute a task well, requesters struggle to accurately structure and price their work. Objective measures of effort could better help workers identify tasks that are worth their time. We propose a data-driven effort metric, ETA (error-time area), that can be used to determine a task's fair price. It empirically models the relationship between time and error rate by manipulating the time that workers have to complete a task. ETA reports the area under the error-time curve as a continuous metric of worker effort. The curve's 10th percentile is also interpretable as the minimum time most workers require to complete the task without error, which can be used to price the task. We validate the ETA metric on ten common crowdsourcing tasks, including tagging, transcription, and search, and find that ETA closely tracks how workers would rank these tasks by effort. We also demonstrate how ETA allows requesters to rapidly iterate on task designs and measure whether the changes improve worker efficiency. Our findings can facilitate the process of designing, pricing, and allocating crowdsourcing tasks.\",\"Crowdsourcing systems lack effective measures of the effort required to complete each task. We show how ETA (error-time area), a data-driven effort metric, can be used to determine a task's fair price.\",15,\"Tue 12:10 - 12:30 PM\",1429654200,1429655400,\"Authors\",null],[274,270,\"pn2588\",\"Note\",\"The Effects of Sequence and Delay on Crowd Work\",\"A common approach in crowdsourcing is to break large tasks into small microtasks so that they can be parallelized across many crowd workers and so that redundant work can be more easily compared for quality control. In practice, this can result in the microtasks being presented out of their natural order and often introduces delays between individual microtasks. In this paper, we demonstrate in a study of 338 crowd workers that non-sequential microtasks and the introduction of delays significantly decreases worker performance. We show that interruptions where a large delay occurs between two related tasks can cause up to a 102% slowdown in completion time, and interruptions where workers are asked to perform different tasks in sequence can slow down completion time by 57%. We conclude with a set of design guidelines to improve both worker performance and realized pay, and instructions for implementing these changes in existing interfaces for crowd work.\",\"In this paper, we demonstrate in a study of 338 crowd workers that non-sequential microtasks and the introduction of delays significantly decreases worker performance.\",15,\"Tue 12:30 - 12:40 PM\",1429655400,1429656000,\"Authors\",null],[275,270,\"pn1837\",\"Note\",\"Crowd Size, Diversity and Performance\",\"Crowds are increasingly being adopted to solve complex problems. Size and diversity are two key characteristics of crowds; however their relationship to performance is often paradoxical. To better understand the effects of crowd size and diversity on crowd performance we conducted a study on the quality of 4,317 articles in the WikiProject Film community. The results of our study suggest that crowd size leads to better performance when crowds are more diverse. However, there is a break-even point -- smaller, less diverse crowds can outperform more diverse crowds of similar size. Our results offer new insights into the effects of size and diversity on the performance of crowds. \",\"This study examines the effects of size and diversity on the performance of Wikipedia crowds. Results quantitatively demonstrated that the relationship between crowd size and performance depended on crowd diversity. \",15,\"Tue 12:40 - 12:50 PM\",1429656000,1429656600,\"Authors\",null],[276,-1,\"s-float-33\",\"Papers\",\"Smart Smartphone Authentication\",null,null,11,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Chair\",\"Papers\"],[277,276,\"pn136\",\"Paper\",\"I Know What You Did Last Week! Do You? Dynamic Security Questions for Fallback Authentication on Smartphones\",\"In this paper, we present the design and evaluation of dynamic security questions for fallback authentication. In case users lose access to their device, the system asks questions about their usage behavior (e.g. calls, text messages or app usage). We performed two consecutive user studies with real users and real adversaries to identify questions that work well in the sense that they are easy to answer for the genuine user, but hard to guess for an adversary. The results show that app installations and communication are the most promising categories of questions. Using three questions from the evaluated categories was sufficient to get an accuracy of 95.5% - 100%.\",\"Reports the results of two consecutive user studies on the design of dynamic security questions on smartphones and discusses their usability, security and privacy implications.  \",11,\"Tue 11:30 - 11:50 AM\",1429651800,1429653000,\"Authors\",null],[278,276,\"pn657\",\"Paper\",\"Improving Accuracy, Applicability and Usability of Keystroke Biometrics on Mobile Touchscreen Devices\",\"Authentication methods can be improved by considering implicit, individual behavioural cues. In particular, verifying users based on typing behaviour has been widely studied with physical keyboards. On mobile touchscreens, the same concepts have been applied with little adaptations so far. This paper presents the first reported study on mobile keystroke biometrics which compares touch-specific features between three different hand postures and evaluation schemes. Based on 20.160 password entries from a study with 28 participants over two weeks, we show that including spatial touch features reduces implicit authentication equal error rates (EER) by 26.4 - 36.8% relative to the previously used temporal features. We also show that authentication works better for some hand postures than others. To improve applicability and usability, we further quantify the influence of common evaluation assumptions: known attacker data, training and testing on data from a single typing session, and fixed hand postures. We show that these practices can lead to overly optimistic evaluations. In consequence, we describe evaluation recommendations, a probabilistic framework to handle unknown hand postures, and ideas for further improvements.\",\"Presents an analysis of touch-specific typing features, such as offsets between key centres and touch locations, to improve mobile keystroke biometrics.\",11,\"Tue 11:50 - 12:10 PM\",1429653000,1429654200,\"Authors\",null],[279,276,\"pn480\",\"Note\",\"SwiPIN - Fast and Secure PIN-Entry on Smartphones\",\"In this paper, we present SwiPIN, a novel authentication system that allows input of traditional PINs using simple touch gestures like up or down and makes it secure against human observers. We present two user studies which evaluated different designs of SwiPIN and compared it against traditional PIN. The results show that SwiPIN performs adequately fast (3.7 s) to serve as an alternative input method for risky situations. Furthermore, SwiPIN is easy to use, significantly more secure against shoulder surfing attacks and switching between PIN and SwiPIN feels natural.\",\"We present SwiPIN, a novel authentication system that allows input of traditional PINs using simple touch gestures like up or down which makes it secure against human observers. \",11,\"Tue 12:10 - 12:20 PM\",1429654200,1429654800,\"Authors\",null],[280,276,\"pn1031\",\"Note\",\"Glass Unlock: Enhancing Security of Smartphone Unlocking through Leveraging a Private Near-eye Display\",\"This paper presents Glass Unlock, a novel concept using smart glasses for smartphone unlocking, which is theoretically secure against smudge attacks, shoulder-surfing, and camera attacks. By introducing an additional temporary secret like the layout of digits that is only shown on the private near-eye display, attackers cannot make sense of the observed input on the almost empty phone screen. We report a user study with three alternative input methods and compare them to current state-of-the-art systems. Our findings show that Glass Unlock only moderately increases authentication times and that users favor the input method yielding the slowest input times as it avoids focus switches between displays.\",\"A technique using smart glasses for smartphone unlocking leading to drastically improved authentication security. Evaluated in a user study with different I/O configurations and against the state of art.\",11,\"Tue 12:20 - 12:30 PM\",1429654800,1429655400,\"Authors\",null],[281,276,\"pn167\",\"Note\",\"I Feel Like I'm Taking Selfies All Day! Towards Understanding Biometric Authentication on Smartphones\",\"We present the results of an MTurk survey (n=383) on the reasons for using and not using biometric authentication systems on smartphones. We focused on Apple's Touch ID as well as Android's Face Unlock as they are the most prevalent systems on the market. For both systems, we categorized the participants as a) current users, b) former users that deactivated it at some point and c) nonusers. The results show that usability is one of the main factors that influences the decision on whether or not to use biometric verification on the smartphone. To our surprise and as opposed to previous research on biometric authentication, privacy and trust issues were not among the most important decision factors.\",\"Reports the findings of a study about reasons for (not) using biometric authentication on smartphones. The results indicate that usability is among the main factors in the decision process.\",11,\"Tue 12:30 - 12:40 PM\",1429655400,1429656000,\"Authors\",null],[282,276,\"pn298\",\"Note\",\"Interrupt Now or Inform Later?: Comparing Immediate and Delayed Privacy Feedback\",\"Feedback about privacy-affecting system operations is important for informed end-user privacy management. While feedback is most relevant if provided immediately, such delivery interrupts the user and risks disrupting ongoing tasks. The timing, volume, and nature of feedback is therefore critical for avoiding inopportune interruption. We varied the timing and actionability of feedback regarding accesses to a user's physical location. We found that the sense of privacy violation was heightened when feedback was immediate, but not actionable. While immediate and actionable feedback may sometimes be necessary, our findings suggest that moderately delayed feedback is often acceptable. A moderate delay may serve as a compromise to minimize interruption and avoid overly alarming reaction to immediate feedback. However, immediate and actionable feedback could still be beneficial when privacy sensitivity is high or ambiguous.\",\"We varied the timing and actionability of privacy feedback regarding location accesses. Our findings suggest that a moderate delay may effectively minimize interruptions and avoid alarming reaction to immediate feedback.\",11,\"Tue 12:40 - 12:50 PM\",1429656000,1429656600,\"Authors\",null],[283,-1,\"s-float-42\",\"Papers\",\"New Evaluation Approaches\",null,null,5,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Chair\",\"Papers\"],[284,283,\"pn2425\",\"Paper\",\"Bridging the Theory-Practice Gap: Lessons and Challenges of Applying the Attachment Framework for Sustainable HCI Design\",\"Despite significant progress in sustainable HCI towards theoretical frameworks to guide design, there is a gap between theory and practice, so that the impact of such frameworks is limited. As an initial exploration in bridging the theory-practice gap, we conducted a study using one well-established design framework, the Attachment Framework, to evaluate its applicability in use. We conducted a comparative study with 14 designers to explore the effect of the Attachment Framework on design, and evaluated their designs with 10 design experts using a set of six design criteria.  Our results indicated a positive effect on the criterion of novelty, with mixed effects on attachment, presentation, aesthetics, usefulness, and feasibility. We contribute a set of challenges in the application of design frameworks to practice and offer a critical reflection on how researchers can more effectively communicate sustainable HCI design frameworks to practitioners.\",\"Lessons learned from our comparative study of the Attachment Framework and challenges for bridging the theory-practice gap in Sustainable HCI.\",5,\"Tue 11:30 - 11:50 AM\",1429651800,1429653000,\"Authors\",null],[285,283,\"pn1188\",\"Paper\",\"The Transfer of Learning as HCI Similarity: Towards an Objective Assessment of the Sensory-Motor Basis of Naturalness\",\"Human-computer interaction should be natural. However, the notion of natural is questioned due to a lack of theoretical background and methods to objectively measure the naturalness of a HCI. A frequently cited aspect of natural HCIs is their ability to benefit from knowledge and skills that users develop in their interaction with the real (non-digital) world. Among these skills, sensory-motor abilities are essential to operate many HCIs. This suggests that the transfer of these abilities between physical and digital interactions could be used as an experimental tool to assess the sensory-motor similarity between interactions, and could be considered as an objective measurement of the sensory-motor grounding of naturalness. In this framework, we introduce a new experimental paradigm inspired by motor learning research to assess sensory-motor similarity, as revealed by the transfer of learning. We tested this paradigm in an empirical study to question the naturalness of three HCIs: direct-touch, mouse pointing and absolute indirect-touch. The study revealed how skill learning transfers from these three digital interactions towards an equivalent physical interaction. We observed strong transfer of skill between direct-touch and physical interaction, but no transfer from the other two interactions. This work provides a first objective assessment of the sensory-motor basis of direct-touch naturalness, and a new empirical path to question HCI similarity and naturalness. \",\"We propose a novel paradigm to assess the sensory-motor similarity between HCIs based on transfer of learning, and provide a first indication of the naturalness of various HCIs.\",5,\"Tue 11:50 - 12:10 PM\",1429653000,1429654200,\"Authors\",null],[286,283,\"pn528\",\"Paper\",\"Formalizing Agreement Analysis for Elicitation Studies: New Measures, Significance Test, and Toolkit\",\"We address in this work the process of agreement rate analysis for characterizing the level of consensus between participants' proposals elicited during guessability studies. Two new measures, i.e., disagreement rate for referents and coagreement rate between referents, are proposed to accompany the widely-used agreement rate formula of Wobbrock et al. [37] when reporting participants' consensus for symbolic input. A statistical significance test for comparing the agreement rates of k>=2 referents is presented in analogy with Cochran's success/failure Q test [5], for which we express the test statistic in terms of agreement and coagreement rates. We deliver a toolkit to assist practitioners to compute agreement, disagreement, and coagreement rates, and run statistical tests for agreement rates at p=.05, .01, and .001 levels of significance. We validate our theoretical development of agreement rate analysis in relation with several previously published elicitation studies. For example, when we present the probability distribution function of the agreement rate measure, we also use it (1) to explain the magnitude of agreement rates previously reported in the literature, and (2) to propose qualitative interpretations for agreement rates, in analogy with Cohen's guidelines for effect sizes [6]. We also re-examine previously published elicitation data from the perspective of the agreement rate test statistic, and highlight new findings on the effect of referents over agreement rates, unattainable prior to this work. We hope that our contributions will advance the current knowledge in agreement rate analysis, providing researchers and practitioners with new techniques and tools to help them understand user-elicited data at deeper levels of detail and sophistication.\",\"We introduce a corrected formula for computing agreement rates, new measures for analyzing users' consensus during elicitation studies (disagreement and coagreement), a statistical test for agreement rates, and a toolkit.\",5,\"Tue 12:10 - 12:30 PM\",1429654200,1429655400,\"Authors\",null],[287,283,\"pn1887\",\"Paper\",\"Exploring the Effect of Pre-operational Priming Intervention on Number Entry Errors\",\"Managing and reducing error in number entry tasks is important, especially in safety critical contexts. Understanding factors that can affect number entry accuracy could help the design of more dependable systems. We present three interventions for number entry tasks, inspired by known priming effects (where exposure to prior stimuli can impact task performance). The interventions were questions for the operator to answer before entering each number. Questions related to the value/size of the number, its structure, and the context of the number entry task respectively. Results of a within-subject study show that although there was no significant difference amongst performance across interventions, all three interventions helped to improve the accuracy of number entry by reducing entry errors (by up to 40.8%) and unnoticed errors (by up to 60.7%). These are impressive gains and suggest the importance of more work in this area.\",\"This paper makes a contribution to preventing human errors, specifically reducing number entry errors in safety critical fields, while using healthcare as a motivating context.\",5,\"Tue 12:30 - 12:50 PM\",1429655400,1429656600,\"Authors\",null],[288,-1,\"s-panel2\",\"Panel\",\"You've Been Acquired!\",null,null,1,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"\",\"\"],[289,288,\"pan108\",\"Panel\",\"You've Been Acquired!\",\"Today’s mergers and acquisitions (M&As) are increasingly focused on the user experience and design expertise they bring to the acquiring entity. This panel will share vignettes based on personal M&A experiences that provide suggestions and recommendations for user experience teams on both the acquiring and acquired side of the table. The areas of focus for the discussions will be team, culture and design assimilation and how M&As can impact designers’ work and personal growth as individuals cross over into new organizations. \",\"Today’s mergers and acquisitions (M&As) are increasingly focused on the user experience and design expertise they bring to the acquiring entity. This panel will share vignettes based on personal M&A experiences that provide suggestions and recommendations for user experience teams on both the acquiring and acquired side of the table. The areas of focus for the discussions will be team, culture and design assimilation and how M&As can impact designers’ work and personal growth as individuals cros...\",1,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"\",\"\"],[290,-1,\"s168\",\"Papers\",\"Foundations & Trends in HCI 1\",null,null,10,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Chair\",\"Papers\"],[291,290,\"pn5138\",\"TOCHI\",\"A Survey of Augmented Reality\",\"This paper summarizes almost 50 years of research and development in the field of Augmented Reality (AR). From early research in the 1960’s until widespread availability by the 2010’s there has been steady progress towards the goal of being able to seamlessly combine real and virtual worlds. We provide an overview of the common definitions of AR, and show how AR fits into taxonomies of other related technologies. A history of important milestones in Augmented Reality is followed by sections on the key enabling technologies of tracking, display and input devices. We also review design guidelines and provide some examples of successful AR applications. Finally, we conclude with a summary of directions for future work and a review of some of the areas that are currently being researched.\",\"This paper summarizes almost 50 years of research and development in the field of Augmented Reality (AR). From early research in the 1960’s until widespread availability by the 2010’s there has been steady progress towards the goal of being able to seamlessly combine real and virtual worlds. We provide an overview of the common definitions of AR, and show how AR fits into taxonomies of other related technologies. A history of important milestones in Augmented Reality is followed by sections on t...\",10,\"Tue 11:30 - 11:50 AM\",1429651800,1429653000,\"Authors\",null],[292,290,\"pn5155\",\"TOCHI\",\"Augmented Reality Expert Panel Discussion\",\"-\",\"-...\",10,\"Tue 11:50 - 12:10 PM\",1429653000,1429654200,\"Authors\",null],[293,-1,\"s-crs122-1\",\"Course\",\"Designing & Assessing Task Models 2/2\",null,null,6,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Instructor\",null],[294,293,\"crs122\",\"Course\",\"Designing and Assessing Interactive Systems Using Task Models\",\"This two-part course takes a practical approach to introduce the principles, methods and tools in task modelling. Part 1: A non-technical introduction demonstrates that task models support successful design of interactive systems. Part 2: A more technical interactive hands-on exercise of how to \\\"do it right\\\", such as: How to go from task analysis to task models? How to assess (through analysis and simulation) that a task model is correct? How to identify complexity of user tasks … \",\"This course takes a practical approach to the principles, methods and tools in task modelling. Part 1 is introductory while Part 2 is interactive hands-on exercises about how to \\\"do-it-right\\\"\",6,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Instructor\",null],[295,-1,\"s-crs100-1\",\"Course\",\"Learn to Sketch (Even if You Can’t Draw) 2/2\",null,null,7,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Instructor\",null],[296,295,\"crs100\",\"Course\",\"Learn to Sketch (Even if You Can’t Draw): Hands-on Sketching Course\",\"Sketching as a technique to quickly draw something on a piece of paper can be used to explore and communicate ideas. Practitioners can make use of their ability to draw sketches from an early phase of a project on. It can be valuable not only for the exploration of ideas but also for gathering feedback from stakeholders and to foster a common understanding of requirements and concepts. This course introduces basic sketching techniques and a visual language which participants can immediately apply. It is a hands-on course which allows participants to do a lot of sketching during the session.\",\"Sketching as a technique to quickly draw ideas is used to explore and communicate ideas. This course introduces basic sketching techniques and a visual language, which participants can immediately apply.\",7,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Instructor\",null],[297,-1,\"s-crs129-1\",\"Course\",\"Methods for Child Computer Interaction 2/2\",null,null,14,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Instructor\",null],[298,297,\"crs129\",\"Course\",\"Research Methods for Child Computer Interaction\",\"In this course participants will learn about theory and practice of conducting research in children’s HCI. The course is divided into two sessions: basic principles and theory, and best practices. The instructors have multiple years of experience designing, conducting, and analyzing children-computer interaction (CCI) studies, in the UK, USA, and Israel.\",\"This course introduces participants to ethical and appropriate research with children.  A case study is used to show research methods. The course suits those working with children in HCI.\",14,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Instructor\",null],[299,-1,\"s-crs106-1\",\"Course\",\"Practical UX Research Methodologies 2/2\",null,null,9,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Instructor\",null],[300,299,\"crs106\",\"Course\",\"Practical UX Research Methodologies\",\"Half-Day course on the practical research methods used to understand the changing technology climate.  Experts from UEGroup, a Silicon Valley research and design company, will lead an interactive discussion and give practical suggestions for developing methodologies including: Ethnography, Out of Box Experiences, and Usability Testing. \",\"Walk away from the course with a more complete understanding of the different methodologies and begin to understand when to incorporate each approach to their unique applications.  \",9,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Instructor\",null],[301,-1,\"s-sig4\",\"SIG\",\"Gender-Inclusive Software\",null,null,8,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"\",\"\"],[302,301,\"sig108\",\"SIG\",\"SIG: Gender-Inclusive Software: What We Know About Building It\",\"Recent research has shown that some software that is intended to be gender-neutral is not, in fact, equally inclusive to males and females.  But little is known about how to design software in a gender-aware fashion, and existing research on gender differences relevant to software design is scattered across at least five different academic fields (e.g., psychology, computer science, education, communications, and women's studies).  This research SIG will bring together female and male academics, industry researchers, and practitioners with three goals in mind: (1) to build community across research/practice boundaries; (2) to pool our knowledge on promising practices for design and evaluation of software from a gender perspective; and (3) to begin to build a shared, on-line research and literature base to support solid, well-informed progress on this important issue.\",\"Recent research has shown that some software that is intended to be gender-neutral is not, in fact, equally inclusive to males and females.  But little is known about how to design software in a gender-aware fashion, and existing research on gender differences relevant to software design is scattered across at least five different academic fields (e.g., psychology, computer science, education, communications, and women's studies).  This research SIG will bring together female and male academics,...\",8,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"\",\"\"],[303,-1,\"s154\",\"Papers\",\"Smartwatch Interaction\",null,null,3,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Chair\",\"Papers\"],[304,303,\"pn2218\",\"Note\",\"Investigating the Information Transfer Efficiency of a 3x3 Watch-back Tactile Display\",\"A watch-back tactile display (WBTD) is expected to be a viable supplement to the user interface limitations of a smartwatch. However, its design requires that many design parameters such as tactor types and stimulus patterns be determined. We conducted a series of experiments to explore the design space of a WBTD consisting of 3×3 tactors. We demonstrated that tactor types and the temporal patterns and locus of a stimulus produce statistically significant effects on the efficiency of a WBTD. The experimental results can act as a practical guideline for the design of an efficient WBTD.\",\"We explored the design space of a watch-back tactile display to show that tactor types, temporal patterns, and locus of a stimulus make statistically significant effect on information transfer efficiency.\",3,\"Tue 11:30 - 11:40 AM\",1429651800,1429652400,\"Authors\",null],[305,303,\"pn762\",\"Note\",\"SplitBoard: A Simple Split Soft Keyboard for Wristwatch-sized Touch Screens\",\"Text entry on a smartwatch is a challenging problem due to the device's limited screen area. In this paper, we introduce the SplitBoard, which is a soft keyboard designed for a smartwatch. As the user flicks left or right on the keyboard, it switches between the left and right halves of a QWERTY keyboard. We report the results of two user experiments where the SplitBoard was compared to an ordinary QWERTY keyboard, the ZoomBoard, SlideBoard, and Qwerty-like keypad. We measured the initial performance with new users for each method. The SplitBoard outperformed all other techniques in the experiments. The SplitBoard is expected to be a viable option for smartwatch text entry because of its light processing requirements, good performance, and immediate learnability.\",\"We introduce SplitBoard, a new soft keyboard designed for a smartwatch that uses split QWERTY layout. The performance of new users was compared, and the SplitBoard outperformed all the other techniques in the experiments.\",3,\"Tue 11:40 - 11:50 AM\",1429652400,1429653000,\"Authors\",null],[306,303,\"pn546\",\"Paper\",\"Beats: Tapping Gestures for Smart Watches\",\"Interacting with smartwatches poses new challenges. Although capable of displaying complex content, their extremely small screens poorly match many of the touchscreen interaction techniques dominant on larger mobile devices. Addressing this problem, this paper presents beating gestures, a novel form of input based on pairs of simultaneous or rapidly sequential and overlapping screen taps made by the index and middle finger of one hand. Distinguished simply by their temporal sequence and relative left/right position these gestures are designed explicitly for the very small screens (approx. 40mm square) of smartwatches and to operate without interfering with regular single touch input. This paper presents the design of beating gestures and a rigorous empirical study that characterizes how users perform them – in a mean of 355ms and with an error rate of 5.5%. We also derive thresholds for reliably distinguishing between simultaneous (under 30ms) and sequential (under 400ms) pairs of screen touches or releases. We then present five interface designs and evaluate them in a qualitative study in which users report valuing the speed and ready availability of beating gestures.\",\"This paper contributes beating gestures - a two finger input technique for smartwatches based on simultaneous or sequential taps. It characterizes user performance and presents interface designs for this system.\",3,\"Tue 11:50 - 12:10 PM\",1429653000,1429654200,\"Authors\",null],[307,303,\"pn488\",\"Paper\",\"WatchConnect: A Toolkit for Prototyping Smartwatch-Centric Cross-Device Applications\",\"People increasingly use smartwatches in tandem with other devices such as smartphones, laptops or tablets. This allows for novel cross-device applications that use the watch as both input device and output display. However, despite the increasing availability of smartwatches, prototyping cross-device watch-centric applications remains a challenging task. Developers are limited in the applications they can explore as available toolkits provide only limited access to different types of input sensors for cross-device interactions. To address this problem, we introduce WatchConnect, a toolkit for rapidly prototyping cross-device applications and interaction techniques with smartwatches. The toolkit provides developers with (i) an extendable hardware platform that emulates a smartwatch, (ii) a UI framework that integrates with an existing UI builder, and (iii) a rich set of input and output events using a range of built-in sensor mappings. We demonstrate the versatility and design space of the toolkit with five interaction techniques and applications.\",\"WatchConnect is a toolkit for prototyping smartwatch-centric cross-device applications and interaction techniques, that provides a configurable and extensible hardware platform and software framework for distributed UIs, sensor mappings and gestures.\",3,\"Tue 12:10 - 12:30 PM\",1429654200,1429655400,\"Authors\",null],[308,303,\"pn643\",\"Paper\",\"It's About Time: Smartwatches as Public Displays\",\"Current uses of smartwatches are focused solely around the wearer's content, viewed by the wearer alone. When worn on a wrist, however, watches are often visible to many other people, making it easy to quickly glance at their displays. We explore the possibility of extending smartwatch interactions to turn personal wearables into more public displays. We begin opening up this area by investigating fundamental aspects of this interaction form, such as the social acceptability and noticeability of looking at someone else's watch, as well as the likelihood of a watch face being visible to others. We then sketch out interaction dimensions as a design space, evaluating each aspect via a web-based study and a deployment of three potential designs. We conclude with a discussion of the findings, implications of the approach and ways in which designers in this space can approach public wrist-worn wearables.\",\"This paper introduces a new area of research around smartwatches as public displays, demonstrating their viability, social acceptability and real-world use; and, providing a comprehensive design space to inform future implementations.\",3,\"Tue 12:30 - 12:50 PM\",1429655400,1429656600,\"Authors\",null],[309,-1,\"s111\",\"Papers\",\"Storytelling in InfoVis\",null,null,13,\"Tue 11:30 - 12:50 PM\",1429651800,1429656600,\"Chair\",\"Papers\"],[310,309,\"pn1717\",\"Paper\",\"Storytelling in Information Visualizations: Does it Engage Users to Explore Data?\",\"We present the results of three web-based field experiments, in which we evaluate the impact of using initial narrative visualization techniques and storytelling on user-engagement with exploratory information visualizations. We conducted these experiments on a popular news and opinion outlet, and on a popular visualization gallery website. While data-journalism exposes visualizations to a large public, we do not know how effectively this public makes sense of interactive graphics, and in particular if people explore them to gain additional insight to that provided by the journalists. In contrast to our hypotheses, our results indicate that augmenting exploratory visualizations with introductory `stories' does not seem to increase user-engagement in exploration.\",\"We evaluate the impact of using initial narrative visualization techniques and storytelling on user-engagement with exploratory information visualizations. Our results indicate that introductory ‘stories’ do not increase exploratory behavior.\",13,\"Tue 11:30 - 11:50 AM\",1429651800,1429653000,\"Authors\",null],[311,309,\"pn1606\",\"Paper\",\"Understanding Data Videos: Looking at Narrative Visualization through the Cinematography Lens\",\"Data videos, motion graphics that incorporate visualizations about facts, are increasingly gaining popularity as a means of telling stories with data. However, very little is systematically recorded about (a) what elements are featured in data videos and (b) the processes used to create them. In this article, we provide initial insights to build this knowledge. We first report on a qualitative analysis of 50 professionally designed data videos, extracting and exposing their most salient constituents. Second, we report on a series of workshops with experienced storytellers from cinematography, graphics design and screenplay writing. We provided them with a set of data facts and visualizations and observed them create storyboards for data videos. From these exploratory studies, we derive broader implications for the design of an authoring tool to enable a wide audience to create data videos. Our findings highlight the importance of providing a flexible tool supporting a non-linear creation process and allowing users to iteratively go back to different phases of the process.\",\"Through two exploratory studies: 1) a qualitative analysis of 50 professional data videos and 2) workshops with experienced storytellers, we derive broader implications for the design of an authoring tool.\",13,\"Tue 11:50 - 12:10 PM\",1429653000,1429654200,\"Authors\",null],[312,309,\"pn2637\",\"Paper\",\"How Deceptive are Deceptive Visualizations?: An Empirical Analysis of Common Distortion Techniques\",\"In this paper, we present an empirical analysis of deceptive visualizations. We start with an in-depth analysis of what deception means in the context of data visualization, and categorize deceptive visualizations based on the type of deception they lead to. We identify popular distortion techniques and the type of visualizations those distortions can be applied to, and formalize why deception occurs with those distortions. We create four deceptive visualizations using the selected distortion techniques, and run a crowdsourced user study to identify the deceptiveness of those visualizations. We then present the findings of our study and show how deceptive each of these visual distortion techniques are, and for what kind of questions the misinterpretation occurs. We also analyze individual differences among participants and present the effect of some of those variables on participants' responses. This paper presents a first step in empirically studying deceptive visualizations, and will pave the way for more research in this direction.\",\"Main contributions of this work are: (a) the definition and classification of deceptive methods in visualization; (b) the empirical confirmation and measurement of some of the well-known graphical distortion techniques.\",13,\"Tue 12:10 - 12:30 PM\",1429654200,1429655400,\"Authors\",null],[313,309,\"pn1580\",\"Paper\",\"STRATOS: Using Visualization to Support Decisions in Strategic Software Release Planning\",\"Software is typically developed incrementally and released in stages. Planning these releases involves deciding which features of the system should be implemented for each  release. This is a complex planning process involving  numerous trade-offs—constraints and factors that often make decisions difficult. Since the success of a product  depends on this plan, it is important to understand the trade-offs between different release plans in order to make an  informed choice. We present STRATOS, a tool that simulta-neously visualizes several software release plans. The  visualization shows several attributes about each plan that are important to planners. Multiple plans are shown in a single layout to help planners find and understand the trade-offs  between alternative plans. We evaluated our tool via a  qualitative study and found that STRATOS enables a range of  decision-making processes, helping participants decide on which plan is most optimal.\",\"We contribute the design and qualitative study of STRATOS, an interactive hybrid visualization which supports planners such as project managers in decision-making in how to develop a software.\",13,\"Tue 12:30 - 12:50 PM\",1429655400,1429656600,\"Authors\",null],[314,-1,\"break-5\",\"Breaks\",\"Lunch Break (on your own)\",null,null,15,\"Tue 12:50 - 2:30 PM\",1429656600,1429662600,\"\",\"\"],[315,-1,\"s-case3\",\"Case Studies\",\"Education & Work\",null,null,2,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Chair\",\"Papers\"],[316,315,\"case128\",\"Case Study\",\"Connective MOOC for K-12 Teacher Professional Development in Native American Pueblo Schools\",\"This case study describes preliminary work toward developing a teacher training project that is intended to increase STEM proficiency among elementary and high school teachers in Native American Pueblo schools in New Mexico. This project builds upon prior work that trained K-12 teachers to use investigative teaching, which in turn had a significant positive impact on the math and science proficiency of Native American and Hispanic students. The current project seeks to use Connectivist Massive Open Course (cMOOC) technology to capture and scale this professional development through the use of video, imagery, and community building in order to integrate Native American learning processes.  The overall objective is to enable Pueblo teachers to more effectively teach STEM subject matter, as measured by an increase in both teacher and student content knowledge scores.  If successful, the use of these technologies should facilitate rapid expansion of the program in all Native American reservation schools in United States, Canada, and Mexico.\",\"Indigenous knowledge is an integral part of learning. Our work explores collaborative technologies for building online Native American teacher communities to bridge the gap between formal and indigenous education.\",2,\"Tue 2:30 - 2:50 PM\",1429662600,1429663800,\"Authors\",null],[317,315,\"case129\",\"Case Study\",\"Rapid Usability Assessment of an Enterprise Application in an Agile Environment with CogTool\",\"Lab based user testing with participants quickly becomes a bottleneck for UX teams in the industry that exist in an Agile software development environment characterized by frequent release cycles and continually changing requirements. For such teams to reduce this testing time and to quickly glean usability insights we leverage human performance modeling via CogTool. Our work compares CogTool’s expert user model’s task time with actual user time from lab sessions in two user studies. In these two studies CogTool’s task time estimates were statistically significantly lower when compared to lab based user times but the two task times were positively correlated. We leverage this correlation between CogTool task times and lab user times to build a predictive user model. Next, we apply this user model to rapidly evaluate two new designs without lab based user testing. Based on these results we provide recommendations for Agile UX teams to harness CogTool for enhancing user research efforts and thereby reduce the bottleneck of lab based user testing.\",\"We outline an approach for Agile UX teams to reduce the bottleneck of lab based user testing by leveraging CogTool’s human performance modeling of an expert user. \",2,\"Tue 2:50 - 3:10 PM\",1429663800,1429665000,\"Authors\",null],[318,315,\"case167\",\"Case Study\",\"Testing the Effectiveness of iPad Math Game: Lessons Learned from Running a Multi-Classroom Study\",\"Many educational products designed for young children go through extensive user testing, but rarely through a rigorous examination of whether they improve learning. We describe our experiences and lessons learned from conducting a multi-classroom study to examine learning from an iPad math app we developed for preschool and kindergarten children. Focusing on the research experience itself, we describe six common challenges to conducting learning research with technology and young children, as well as six principles to help mitigate the challenges. This paper is intended to help others who wish to assess learning from educational games for children.\",\"We discuss experiences conducting a multi-classroom study of learning from a math app for 4-5 year olds. We describe challenges of conducting learning research and principles to mitigate the challenges.\",2,\"Tue 3:10 - 3:30 PM\",1429665000,1429666200,\"Authors\",null],[319,315,\"case191\",\"Case Study\",\"Historical Research Using Email Archives\",\"Archives of letters and documents belonging to individuals provide valuable insights into history.  In the digital age, such history is being captured in personal digital archives, especially in the form of email. Archival organizations have recognized the importance of email archives and often collect email when they acquire the papers of eminent donors; however they find it difficult to screen, process and provide access to email for research, due to its sheer volume. We describe the considerations we encountered with the email archives of two prominent individuals in the special collections of Stanford University Libraries. We have designed novel approaches to the challenges of (1) Reconciliation with authority records, (2) Making \\\"finding aids\\\" of the archive available to the general public, without revealing confidential information, and (3) Browsing an email archive when one may not know what exactly to look for. Our solutions have been implemented in a publicly available and open source system called ePADD. As a result, we enable donors and archival organizations to appraise, process and screen large-scale email archives, thereby unlocking the historical value embedded in them. \",\"We present ePADD, a system with novel techniques to enable historical research using long-term email archives of eminent individuals.\",2,\"Tue 3:30 - 3:50 PM\",1429666200,1429667400,\"Authors\",null],[320,-1,\"s-award2\",\"Special\",\"SIGCHI Lifetime Research Award\",null,null,3,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"\",\"\"],[321,320,\"award2\",\"Special\",\"SIGCHI Lifetime Research Award Talk\",\"\",\"...\",3,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"\",\"\"],[322,-1,\"s142\",\"Papers\",\"HCI for the Elderly\",null,null,10,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Chair\",\"Papers\"],[323,322,\"pn5102\",\"TOCHI\",\"An Age Old Problem: Examining the Discourses of Ageing in HCI and Strategies for Future Research\",\"Ageing has become a significant area of interest in HCI in recent years. In this paper we provide a critical analysis of 30 years of ageing research published across the ACM SIGCHI community. Discourse analysis of the content of 644 archival papers highlights how ageing is typically framed as a ‘problem’ that can be managed by technology. We highlight how ageing is typically defined through an emphasis on the economic and societal impact of health and care needs of older people, concerns around socialisation as people age, and declines in abilities and associated reductions in performance when using technology. We draw from research within the fields of social and critical gerontology to highlight how these discourses in SIGCHI literature represent common stereotypes around old age that have also prevailed in the wider literature in gerontology. We conclude by proposing strategies for future research at the intersection of ageing and HCI.\",\"Ageing has become a significant area of interest in HCI in recent years. In this paper we provide a critical analysis of 30 years of ageing research published across the ACM SIGCHI community. Discourse analysis of the content of 644 archival papers highlights how ageing is typically framed as a ‘problem’ that can be managed by technology. We highlight how ageing is typically defined through an emphasis on the economic and societal impact of health and care needs of older people, concerns around ...\",10,\"Tue 2:30 - 2:50 PM\",1429662600,1429663800,\"Authors\",null],[324,322,\"pn105\",\"Paper\",\"Long-Term Use of Motion-Based Video Games in Care Home Settings\",\"Recent research suggests that motion-based video games have the potential to provide both mental and physical stimulation for older adults in residential care. However, little research has explored the practical challenges and opportunities that arise from integrating these games within existing schedules of activities in these contexts. In our work, we report on a qualitative enquiry that was conducted over a three month period at two long-term care facilities. Findings suggest that older adults enjoyed playing video games, and that games can be a valuable means of re-introducing challenge in late life, but that the impact of age-related changes and impairment can influence people’s ability to engage with games in a group setting. We outline core challenges in the design for care context and discuss implications of our work regarding the suitability of games as a self-directed leisure activity.\",\"This paper presents a longitudinal, qualitative enquiry into the experience that older adults in long-term care had when engaging with motion-based video games.\",10,\"Tue 2:50 - 3:10 PM\",1429663800,1429665000,\"Authors\",null],[325,322,\"pn2570\",\"Paper\",\"CoFaçade: A Customizable Assistive Approach for  Elders and Their Helpers\",\"We present CoFaçade, a novel approach to helping elders reach their goals with IT products by working collaboratively with helpers. In this approach, the elder uses an interface with a small number of triggers, where each trigger is a single button (or card) that can execute a procedure. The helper uses a customization interface to link triggers to procedures that accomplish frequently-recurring high-level goals with IT products. Customization can be done either locally or remotely. We conducted an experiment to compare the CoFaçade approach with a baseline approach where helpers taught elders to perform IT tasks. Our results showed that CoFaçade can reduce helpers’ time and effort, reduce elders’ frustration, and improve elders’ success rate in completing IT tasks.\",\"The CoFaçade is a novel approach to helping elders reach their goals with IT products by working collaboratively with helpers, which separates IT task into goal and procedures regarding distinct roles for elders and helpers.\",10,\"Tue 3:10 - 3:30 PM\",1429665000,1429666200,\"Authors\",null],[326,322,\"pn1603\",\"Paper\",\"“My hand doesn’t listen to me!”: Adoption and Evaluation of a Communication Technology for the ‘Oldest Old’\",\"Adoption and use of novel technology by the institutionalized ‘oldest old’ (80+) is understudied. This population is the fastest growing demographic group in developed countries, providing design opportunities and challenges for HCI. Since the recruitment of oldest old people is challenging, research tends to focus on older adults (65+) and their use of and attitudes towards existing communication technologies, or on their caregivers and social ties. Our study deployed a novel communication appliance among five frail oldest old people living in a long-term care facility, which included field observations and usability and accessibility tests. Our findings suggest factors that facilitate and hinder the adoption of communication technologies, such as social, attitudinal, digital literacy, physical, and usability. We also discuss issues that arise in studying technology adoption by the oldest old, including usability and accessibility testing, and suggest solutions that may be helpful to HCI researchers working with this population.\",\"Lessons learnt from designing and evaluating a novel communication appliance for frail oldest old adults, investigating social, usability, demographics, physical, and cultural factors of adoption of such communication technologies.\",10,\"Tue 3:30 - 3:50 PM\",1429666200,1429667400,\"Authors\",null],[327,-1,\"s138\",\"Papers\",\"Grip, Move & Tilt: Novel Interaction\",null,null,4,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Chair\",\"Papers\"],[328,327,\"pn1086\",\"Paper\",\"Supporting Subtlety with Deceptive Devices and Illusory Interactions\",\"Mobile devices offer constant connectivity to the world, which can negatively affect in-person interaction. Current approaches to minimizing the social disruption and improving the subtlety of interactions tend to focus on the development of inconspicuous devices that provide basic input or output. This paper presents a more general approach to subtle interaction and demonstrates how a number of principles from magic can be leveraged to improve subtlety. It also presents a framework that can be used to classify subtle interfaces along with a modular set of novel interfaces that fit within this framework. Lastly, the paper presents a new evaluation paradigm specifically designed to assess the subtlety of interactions. This paradigm is used to compare traditional approaches to our new subtle approaches. We find our new approaches are over five times more subtle than traditional interactions, even when participants are aware of the technologies being used.\",\"We enable subtle interactions using magic-inspired principles and a suite of novel devices.\",4,\"Tue 2:30 - 2:50 PM\",1429662600,1429663800,\"Authors\",null],[329,327,\"pn1577\",\"Paper\",\"Understanding Users’ Touch Behavior on Large Mobile Touch-Screens and Assisted Targeting by Tilting Gesture\",\"As large-screen smartphones are trending, they bring a new set of challenges such as acquiring unreachable screen targets using one hand. To understand users’ touch behavior on large mobile touchscreens, we conducted an empirical experiment to discover their usage patterns of tilting devices toward their thumbs to touch screen regions. Exploiting this natural tilting behavior, we designed three novel mobile interaction techniques: TiltSlide, TiltReduction, and TiltCursor. We conducted a controlled experiment to compare our methods with other existing methods, and then evaluated them in real mobile phone scenarios such as sending an e-mail and web surfing. We constructed a design space for one-hand targeting interactions and proposed design considerations for one-hand targeting in real mobile phone circumstances.\",\"As large-screen smartphones are trending, they bring us the challenge of acquiring unreachable targets using one hand. We suggested novel mobile interactions exploiting users’ tilting behavior to touch such targets.\",4,\"Tue 2:50 - 3:10 PM\",1429663800,1429665000,\"Authors\",null],[330,327,\"pn2102\",\"Paper\",\"One-Handed Bend Interactions with Deformable Smartphones\",\"Smartphones are becoming larger, mainly because bigger screens offer a better experience for viewing content. One drawback of larger screens is that they make single-hand interactions difficult because of hard to reach touch targets and of the need to re-grip the device, both factors significantly reducing their usability. Flexible smartphones offer an opportunity for addressing this issue. We first set out to determine the use of common single-hand mobile interactions through an online survey. Then, we designed and evaluated one-handed deformable gestures that offer the potential for addressing the finger reach limitation on large smartphones. We identified that the top right up bend and the center squeeze up gestures are the fastest and preferred gestures. We found no hand preference, which indicates that the gestures could be implemented to fit the needs of a wider range of the population, instead of favoring right-handed users. Finally, we discuss the impact on deformable gestures on one-handed interactions issues.\",\"We explored the potential of deformable devices to address one-handed interaction issues with smartphones. We evaluated bend gestures for speed and comfort and identified key insights for interaction designers.\",4,\"Tue 3:10 - 3:30 PM\",1429665000,1429666200,\"Authors\",null],[331,327,\"pn380\",\"Note\",\"Grip Change as an Information Side Channel for Mobile Touch Interaction\",\"In order to reach targets with one hand on common large mobile touch displays, users tilt and shift the device in their hand. In this work, we use this grip change as a continuous information stream for detecting where the user will touch while their finger is still en-route. We refer to this as in the air prediction. We show that grip change detected using standard mobile motion sensors produces similar in the air touch point predictions to techniques that use auxiliary sensor arrays, even in varying physical scenarios such as interacting in a moving vehicle. Finally, our model that combines grip change and the resulting touch point predicted where users intended to land, lowering error rates by 41%.\",\"Modeling how users change their grip on mobile devices using internal sensors allows prediction of touch endpoints while finger is en-route, and reduces touch error rates by 41% across various scenarios (e.g. interacting while walking). \",4,\"Tue 3:30 - 3:40 PM\",1429666200,1429666800,\"Authors\",null],[332,327,\"pn548\",\"Note\",\"An Experimental Comparison of Vertical and Horizontal Dynamic Peephole Navigation\",\"Dynamic peephole navigation represents a technique for navigating large information spaces in an egocentric way. Studies have shown cognitive benefits for a vertical peephole orientation, when compared to non-egocentric interaction styles. To see how the aspect of canvas orientation effects user performance, we conducted a study (N=16) which revealed that canvas orientation has no significant effect on either navigation performance or spatial memory. We also found a significantly lower physical demand and a higher mental demand in the horizontal orientation. For short-term activities we therefore propose a vertical orientation, while for long-term activities horizontal dynamic peephole navigation is more suitable.\",\"We investigated the effect of canvas orientation (vertical vs. horizontal) for dynamic peephole navigation. In the horizontal orientation we found a significantly lower physical demand and a higher mental demand.  \",4,\"Tue 3:40 - 3:50 PM\",1429666800,1429667400,\"Authors\",null],[333,-1,\"s164\",\"Papers\",\"The Impact of Crowd Work on Workers\",null,null,15,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Chair\",\"Papers\"],[334,333,\"pn2313\",\"Paper\",\"Working with Machines: The Impact of Algorithmic and Data-Driven Management on Human Workers\",\"Software algorithms are changing how people work in an ever-growing number of fields, managing distributed human workers at a large scale. In these work settings, human jobs are assigned, optimized, and evaluated through algorithms and tracked data. We explore the impact of this algorithmic, data-driven management on human workers and work practices in the context of Uber and Lyft, new ridesharing services. Our findings from a qualitative study describe how drivers responded when algorithms assigned work, provided informational support, and evaluated their performance, and how drivers used online forums to socially make sense of the algorithm features. Implications and future work are discussed.\",\"We present how Uber/Lyft drivers responded when algorithms assigned tasks, presented information to optimize behavior and evaluated performance, and how they socially made sense of the system on online forums.\",15,\"Tue 2:30 - 2:50 PM\",1429662600,1429663800,\"Authors\",null],[335,333,\"pn807\",\"Note\",\"TurkBench: Rendering the Market for Turkers\",\"Crowdsourcing is a relatively new model of labor where both the workers and work providers are experiencing its growing pains.  A dominant platform that implements this model of labor is Amazon Mechanical Turk (AMT).  While AMT has evolved over the years, the changes have focused mainly on work providers and have not addressed the problems workers face (e.g.dealing with market volatility and unpaid time searching for work).  In this paper we present emph{TurkBench}, a tool meant to provide workers with personalized market visualization and session management.  We discuss the design philosophy of the tool, briefly discuss four Turkers' reaction to a demo, and outline future work.  \",\"In this paper, we hope to shine further light on the impact of the design decisions made by the platform developer, particularly in regards to balancing features across roles.\",15,\"Tue 2:50 - 3:00 PM\",1429663800,1429664400,\"Authors\",null],[336,333,\"pn411\",\"Note\",\"Exploring the Role of Activity Trace Design on Evaluations of Online Worker Quality\",\"Websites can record individual users’ activities and display them in a variety of ways. There is a tradeoff between detail and abstraction in visualization, especially when the amount of content increases and becomes more difficult to process.  We conducted an experiment on Mechanical Turk varying the quality, detail, and visual presentation of information about an individual’s past work to see how these design features affected perceptions of the worker. We found that providing detail in the display through text increased processing time and led to less positive evaluations. Visually abstract displays required less processing time but decreased confidence in evaluation. This suggests that different design parameters may engender differing psychological processes that influence reactions towards an unknown person. \",\"Experiment on Mechanical Turk varying the quality, detail, and visual presentation of information about an individual’s past work to see how these design features affected perceptions of the worker. \",15,\"Tue 3:00 - 3:10 PM\",1429664400,1429665000,\"Authors\",null],[337,333,\"pn2032\",\"Paper\",\"We Are Dynamo: Overcoming Stalling and Friction in Collective Action for Crowd Workers\",\"By lowering the costs of communication, the web promises to enable distributed collectives to act around shared issues. However, many collective action efforts never succeed: while the web’s affordances make it easy to gather, these same decentralizing characteristics impede any focus towards action. In this paper, we study challenges to collective action efforts through the lens of online labor by engaging with Amazon Mechanical Turk workers. Through a year of ethnographic fieldwork, we sought to understand online workers’ unique barriers to collective action. We then created Dynamo, a platform to support the Mechanical Turk community in forming publics around issues and then mobilizing. We found that collective action publics tread a precariously narrow path between the twin perils of stalling and friction, balancing with each step between losing momentum and flaring into acrimony. However, specially structured labor to maintain efforts' forward motion can help such publics take action.\",\"Our work details common failure scenarios for online publics that aim for collective action. We recognize and detail the labors that combine with software to bring about change.\",15,\"Tue 3:10 - 3:30 PM\",1429665000,1429666200,\"Authors\",null],[338,333,\"pn1662\",\"Paper\",\"Understanding Malicious Behavior in Crowdsourcing Platforms: The Case of Online Surveys\",\"Crowdsourcing is increasingly being used as a means to tackle problems requiring human intelligence. With the ever-growing worker base that aims to complete microtasks on crowdsourcing platforms in exchange for financial gains, there is a need for stringent mechanisms to prevent exploitation of deployed tasks. Quality control mechanisms need to accommodate a diverse pool of workers, exhibiting a wide range of behavior. A pivotal step towards fraud-proof task design is understanding the behavioral patterns of microtask workers. In this paper, we analyze the prevalent malicious activity on crowdsourcing platforms and study the behavior exhibited by trustworthy and untrustworthy workers, particularly on crowdsourced surveys. Based on our analysis of the typical malicious activity, we define and identify different types of workers in the crowd, propose a method to measure malicious activity, and finally present guidelines for the efficient design of crowdsourced surveys.\",\"By analyzing typical malicious activity, we define and identify different types of workers in the crowd, propose a method to measure malicious activity, and present guidelines for designing crowdsourced surveys efficiently. \",15,\"Tue 3:30 - 3:50 PM\",1429666200,1429667400,\"Authors\",null],[339,-1,\"s-float-38\",\"Papers\",\"Social Media and Mobile Camera Privacy\",null,null,11,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Chair\",\"Papers\"],[340,339,\"pn2244\",\"Note\",\"\\\"I Saw Images I Didn't Even Know I Had\\\" Understanding User Perceptions of Cloud Storage Privacy\",\"Billions of people use cloud-based storage for personal files.  While many are likely aware of the extent to which they store information in the cloud, it is unclear whether users are fully aware of what they are storing online. We recruited 30 research subjects from Craigslist to investigate how users interact with and understand the  privacy issues of cloud storage.  We studied this phenomenon through surveys, an interview, and custom software which lets users see and delete their photos  stored in the cloud.  We found that a majority of users stored private photos in the cloud that they did not intend to upload, and a large portion also chose to permanently delete some of the offending images. We believe our study highlights a mismatch between user expectation and reality. As cloud storage is plentiful and ubiquitous, effective tools for enabling risk self-assessment are necessary to protect users' privacy.\",\"It's unclear whether users are aware of what files they store online. We investigated, through tools and surveys, how much people are aware of, and intend to, save images to the cloud through automated means.\",11,\"Tue 2:30 - 2:40 PM\",1429662600,1429663200,\"Authors\",null],[341,339,\"pn371\",\"Note\",\"Sensitive Lifelogs: A Privacy Analysis of  Photos from Wearable Cameras\",\"While media reports about wearable cameras have focused on the privacy concerns of bystanders, the perspectives of the `lifeloggers' themselves have not been adequately studied.  We report on additional analysis of our previous in-situ lifelogging study in which 36 participants wore a camera for a week and then reviewed the images to specify privacy and sharing preferences. In this Note, we analyze the photos themselves, seeking to understand what makes a photo private, what participants said about their images, and what we can learn about privacy in this new and very different context where photos are captured automatically by one's wearable camera.  We find that these devices record many moments that may not be captured by traditional (deliberate) photography, with camera owners concerned about impression management and protecting private information of both themselves and bystanders. \",\"We report on a lifelogging study, analyzing photos to understand what makes them private, and what we can learn about privacy when photos are captured automatically by a wearable camera.  \",11,\"Tue 2:40 - 2:50 PM\",1429663200,1429663800,\"Authors\",null],[342,339,\"pn287\",\"Paper\",\"Somebody's Watching Me? Assessing the Effectiveness of Webcam Indicator Lights\",\"Most laptops and personal computers have webcams with LED indicators to notify users when they are recording. Because hackers use surreptitiously captured webcam recordings to extort users, we explored the effectiveness of these indicators under varying circumstances and how they could be improved.  We observed that, on average, fewer than half of our participants (45%) noticed the existing indicator during computer-based tasks.  When seated in front of the computer performing a paper-based task, only 5% noticed the indicator.  We performed a followup experiment to evaluate a new indicator and observed that adding onscreen glyphs had a significant impact on both computer-based and non-computer-based tasks (93% and 59% noticed the new indicator, respectively).  We discuss how our results can be integrated into current systems, as well as future ubiquitous computing systems.\",\"Demonstrates that the current webcam LED indicator light is not an effective warning mechanism, assessing both noticeability and comprehensibility; offers a new indicator that significantly improves noticeability without reducing comprehensibility. \",11,\"Tue 2:50 - 3:10 PM\",1429663800,1429665000,\"Authors\",null],[343,339,\"pn2478\",\"Paper\",\"From Third to Surveilled Place: The Mobile in Irish Pubs\",\"A home away from home, the pub is synonymous with good conversation.  Yet, the art of conversation in pubs is changing with the ubiquity of mobile phones.  We present a qualitative study spanning over three years describing experiences and rhetoric surrounding the relationship that mobiles have and should have with our conversation in the pub. We found that mobile phones are able to enhance conversation but can also cause a disruption to the informal and adhoc nature of pubs. The use of Facebook on mobile phones has also changed pubs from what Oldenburg terms a third space to a space that is potentially being surveilled.  We suggest future designs should not necessarily discourage or encourage mobile use in pubs, but rather provoke us into reflecting on how intertwined modern conversation is with mobile technology in the context of the pub space.\",\"Drawing from a three year ethnography of Irish pubs, we examine the role of mobile phones in what Oldenburg called the third place's primary activity, conversation.\",11,\"Tue 3:10 - 3:30 PM\",1429665000,1429666200,\"Authors\",null],[344,339,\"pn655\",\"Paper\",\"Is This Thing On? Crowdsourcing Privacy Indicators for Ubiquitous Sensing Platforms\",\"We are approaching an environment where ubiquitous computing devices will constantly accept input via audio and video channels: kiosks that determine demographic information of passersby, gesture controlled home entertainment systems and audio controlled wearable devices are just a few examples. To enforce the principle of least privilege, recent proposals have suggested technical approaches to limit third-party applications to receiving only the data they need, rather than entire audio or video streams. For users to make informed privacy decisions, applications will still need to communicate what data they are accessing and indicators will be needed to communicate this information. We performed several crowdsourcing experiments to examine how potential users might conceptualize and understand privacy indicators on ubiquitous sensing platforms.\",\"We performed several crowdsourcing experiments to examine how potential users might conceptualize and understand privacy indicators for ubiquitous sensing platforms.\",11,\"Tue 3:30 - 3:50 PM\",1429666200,1429667400,\"Authors\",null],[345,-1,\"s139\",\"Papers\",\"Interactive Video & Collaborative Annotations\",null,null,5,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Chair\",\"Papers\"],[346,345,\"pn382\",\"Paper\",\"RIMES: Embedding Interactive Multimedia Exercises in Lecture Videos\",\"Teachers in conventional classrooms often ask learners to express themselves and show their thought processes by speaking out loud, drawing on a whiteboard, or even using physical objects. Despite the pedagogical value of such activities, interactive exercises available in most online learning platforms are constrained to multiple-choice and short answer questions. We introduce RIMES, a system for easily authoring, recording, and reviewing interactive multimedia exercises embedded in lecture videos. With RIMES, teachers can prompt learners to record their responses to an activity using video, audio, and inking while watching lecture videos. Teachers can then review and interact with all the learners’ responses in an aggregated gallery. We evaluated RIMES with 19 teachers and 25 students. Teachers created a diverse set of activities across multiple subjects that tested deep conceptual and procedural knowledge. Teachers found the exercises useful for capturing students’ thought processes, identifying misconceptions, and engaging students with content.\",\"We introduce RIMES, a system that allows teachers to embed interactive multimedia exercises within online lecture videos. Students can record audio, video, and ink-based answers, and teachers can review the responses. \",5,\"Tue 2:30 - 2:50 PM\",1429662600,1429663800,\"Authors\",null],[347,345,\"pn2492\",\"Paper\",\"A Framework for Automatically Generating Interactive Instructional Scaffolding\",\"Interactive learning environments such as intelligent tutoring systems and software tutorials often teach procedures with step-by-step demonstrations. This instructional scaffolding is typically authored by hand, and little can be reused across problem domains. In this work, we present a framework for generating interactive tutorials from an algorithmic representation of the problem-solving thought process. Given a set of mappings between programming language constructs and user interface elements, we step through this algorithm line-by-line to trigger visual explanations of each step. This approach allows us to automatically generate tutorials for any example problem that can be solved with this algorithm. We describe two prototype implementations in the domains of K-12 mathematics and educational games, and present results from two user studies showing that educational technologists can author thought-process procedures and that generated tutorials can effectively teach a new procedure to students.\",\"We present a new framework for automatically generating interactive instructional scaffolding for educational applications from an algorithmic representation of the problem-solving thought process.\",5,\"Tue 2:50 - 3:10 PM\",1429663800,1429665000,\"Authors\",null],[348,345,\"pn936\",\"Paper\",\"Mudslide: A Spatially Anchored Census of Student Confusion for Online Lecture Videos\",\"Educators have developed an effective technique to get feedback after in-person lectures, called “muddy cards.” Students are given time to reflect and write the “muddiest” (least clear) point on an index card, to hand in as they leave class. This practice of assigning end-of-lecture reflection tasks to generate explicit student feedback is well suited for adaptation to the challenge of supporting feedback in online video lectures. We describe the design and evaluation of Mudslide, a prototype system that translates the practice of muddy cards into the realm of online lecture videos. Based on an in-lab study of students and teachers, we find that spatially contextualizing students’ muddy point feedback with respect to particular lecture slides is advantageous to both students and teachers. We also reflect on further opportunities for enhancing this feedback method based on teachers’ and students’ experiences with our prototype.\",\"This paper describes a new system that implements and expands on a successful educational technique, addressing the problem of teachers receiving feedback in an online lecture environment.\",5,\"Tue 3:10 - 3:30 PM\",1429665000,1429666200,\"Authors\",null],[349,345,\"pn464\",\"Note\",\"Making Software Tutorial Video Responsive\",\"Tutorial videos are widely available to help people use software. These videos, however, are viewed by users as captured and offer little direct interaction between users and software. This paper presents a video navigation method that allows users to interact with software tutorial video as if they were using the software. To make the tutorial video responsive, our method records the user interaction events like mouse click and drag during capturing the video. Our method then analyzes, selects, and visualizes these user interaction events at the event locations. When a user directly interacts with an event visualization, our method automatically navigates to the proper video frame to provide the visual feedback as if the software were responding to the user input. Thus, our method provides the experience of interacting with the software through directly manipulating the tutorial video. Our study shows our method can better help users follow tutorial videos to complete tasks than the baseline timeline interface.\",\"This paper presents a video navigation method that allows users to navigate a software tutorial video as if they were using the software.\",5,\"Tue 3:30 - 3:40 PM\",1429666200,1429666800,\"Authors\",null],[350,345,\"pn738\",\"Note\",\"Gaze-Based Annotations for Reading Comprehension\",\"We study eye gaze movement behavior during paper reading and generate a series of annotations from a user’s reading features: gray shading to indicate reading speed, borders to indicate frequency of re-reading, and lines to indicate transitions between sections of a document. Through a user study, we validate that our SocialReading system that shares teachers’ gaze data for an academic paper can improve students’ reading comprehension of that paper.\",\"We found that the gaze-based annotations resulted in greater reading comprehension and increased the similarity between the reading process for the students and faculty\",5,\"Tue 3:40 - 3:50 PM\",1429666800,1429667400,\"Authors\",null],[351,-1,\"s136\",\"Papers\",\"Innovation in Theories & Products\",null,null,1,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Chair\",\"Papers\"],[352,351,\"pn1528\",\"Paper\",\"From User-Centered to Adoption-Centered Design: A Case Study of an HCI Research Innovation Becoming a Product\",\"As we increasingly strive for scientific rigor and generalizability in HCI research, should we entertain any hope that by doing good science, our discoveries will eventually be more transferrable to industry? We present an in-depth case study of how an HCI research innovation goes through the process of transitioning from a university project to a revenue-generating startup financed by venture capital. The innovation is a novel contextual help system for the Web, and we reflect on the different methods used to evaluate it and how research insights endure attempted dissemination as a commercial product. Although the extent to which any innovation succeeds commercially depends on a number of factors like market forces, we found that our HCI innovation with user-centered origins was in a unique position to gain traction with customers and garner buy-in from investors. However, since end users were not the buyers of our product, a strong user-centered focus obfuscated other critical needs of the startup and pushed out perspectives of non-user-centered stakeholders. To make the research-to-product transition, we had to focus on adoption-centered design, the process of understanding and designing for adopters and stakeholders of the product. Our case study raises questions about how we evaluate the novelty and research contributions of HCI innovations with respect to their potential for commercial impact. \",\"Investigates the transition of an HCI research innovation to a commercial product and highlights the tradeoffs in addressing end user concerns versus the needs of product adopters and stakeholders.\",1,\"Tue 2:30 - 2:50 PM\",1429662600,1429663800,\"Authors\",null],[353,351,\"pn496\",\"Paper\",\"Creating Sustainable Cyberinfrastructures\",\"In this paper we report the results of a qualitative research study of the GENI cyberinfrastructure: a program of four federated cyberinfrastructures. Drawing on theories of stakeholder positioning, we examine how different GENI stakeholders attempt to enlist new participants in the cyberinfrastructures of GENI, and leverage existing relationships to create sustainable infrastructure. This study contributes to our understanding of how cyberinfrastructures emerge over time through processes of stakeholder alignment, enrollment, and through synergies among stakeholder groups. We explore these issues to better understand how cyberinfrastructures can be designed to sustain over time.\",\"We examine how cyberinfrastructures emerge through processes of stakeholder alignment, enrollment, and through synergies among stakeholder groups, so we can understand how to design more sustainable cyberinfrastructures over time.\",1,\"Tue 2:50 - 3:10 PM\",1429663800,1429665000,\"Authors\",null],[354,351,\"pn2421\",\"Paper\",\"Standards and/as Innovation: Protocols, Creativity, and Interactive Systems Development in Ecology\",\"Standards and protocols play important but under-theorized roles in HCI research and design efforts, including those dedicated to the development of new collaborative infrastructures in the sciences. Building on several years of ethnographic fieldwork, this paper examines standardization efforts attached to new forms of design and computational development in American ecology. We explore the role that standards play in large-scale research networks; how standards are enacted and enforced in complex interactive systems like science; how standards struggle and fail (and what happens when they do); and how actors work across the gaps that standards leave to produce more effective forms of practice and design. We also argue for the potentially creative role of standards, including contexts in which they function as fulcrums for change and innovation. We conclude with reflections on how HCI researchers might rethink the nature and possibilities of standards and standardization in their own work.\",\"This paper considers the role and challenges of standards and standardization in large-scale science networks, and provides recommendations for how HCI researchers might better approach and integrate standards in other domains of HCI work.\",1,\"Tue 3:10 - 3:30 PM\",1429665000,1429666200,\"Authors\",null],[355,351,\"pn5111\",\"TOCHI\",\"Does Distance Still Matter? Revisiting the CSCW Fundamentals on Distributed Collaboration\",\"Does distance still matter? Reporting on a comparative analysis of four ethnographic studies of global software development, this paper analyzes the fundamental aspects of distance as depicted in the famous paper ‘Distance matters’. The results suggest that – while common ground, collaboration readiness, and organizational management are still important aspects for distributed collaboration – the arguments concerning coupling of work and collaboration technology readiness need to be refined. We argue that in working remotely, closely coupled work tasks encourage the remote workers to spend the extra effort required in articulation of work to make the collaboration function. Also we find that people in distributed software development have already made collaborative technologies part of their work and individuals are comfortable with them, thus collaboration technology readiness takes a different shape in this setting. \",\"Does distance still matter? Reporting on a comparative analysis of four ethnographic studies of global software development, this paper analyzes the fundamental aspects of distance as depicted in the famous paper ‘Distance matters’. The results suggest that – while common ground, collaboration readiness, and organizational management are still important aspects for distributed collaboration – the arguments concerning coupling of work and collaboration technology readiness need to be refined. We ...\",1,\"Tue 3:30 - 3:50 PM\",1429666200,1429667400,\"Authors\",null],[356,-1,\"s-float-47\",\"Papers\",\"Social Embodied Interaction\",null,null,13,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Chair\",\"Papers\"],[357,356,\"pn1828\",\"Paper\",\"Using an Interactive Avatar's Facial Expressiveness to Increase Persuasiveness and Socialness\",\"Research indicates that the facial expressions of animated characters and agents can influence people's perceptions and interactions with these entities.   We designed an experiment to examine how an interactive animated avatar's facial expressiveness influences dyadic conversations between adults and the avatar.  We animated the avatar in realtime using the tracked facial motion of a confederate. To adjust facial expressiveness, we damped and exaggerated the avatar's facial motion. We found that ratings of the avatar's extroversion were positively related to its expressiveness.  However, impressions of the avatar's realism and naturalness worsened with increased expressiveness. We also found that the confederate was more influential when she appeared as the damped or exaggerated avatar. Adjusting the expressiveness of interactive animated avatars may be a simple way to influence people's social judgments and willingness to collaborate with animated avatars. These results have implications for using avatar facial expressiveness to improve the effectiveness of avatars in various contexts. Adjusting the expressiveness of interactive animated avatars may be a simple way to influence people's social judgments and willingness to collaborate with animated avatars.\",\"We designed an experiment to examine how an interactive animated avatar’s facial expressiveness influences people's social judgments and willingness to collaborate with animated avatars.\",13,\"Tue 2:30 - 2:50 PM\",1429662600,1429663800,\"Authors\",null],[358,356,\"pn1258\",\"Paper\",\"Study on Gaze Direction Perception of Face Image Displayed on Rotatable Flat Display\",\"A long-standing challenge of video-mediated communication systems is to correctly represent remote participant gaze direction in local environments. A telepresence robot with a movable display that shows the face of a remote participant is a promising approach for solving this issue. Researchers generally consider that display orientation is effective for local participants to properly estimate the gaze direction of remote participants. We investigate how subjects estimate gaze direction of a remote participant (“Looker”) when his/her face is displayed on a rotatable flat display. Our experiment reveals that both the Looker’s head-eye rotation in the display and display rotation affect subject estimation, but the effect of the display rotation is relatively small. Furthermore, we reveal that subjects tend to overestimate Looker gaze direction. Based on our results, we propose a design implication for a telepresence robot to reduce overestimation and properly represent the remote participant gaze direction.\",\"This study investigate how the combination of display orientation and face-eye orientation affects viewer perception of a remote participant’s gaze direction and help researchers to designing a telepresence robot.\",13,\"Tue 2:50 - 3:10 PM\",1429663800,1429665000,\"Authors\",null],[359,356,\"pn2536\",\"Paper\",\"DynamicDuo: Co-presenting with Virtual Agents\",\"The quality of most professional oral presentations is often poor, owing to a number of factors, including public speaking anxiety. We present DynamicDuo, a system that uses an automated, life-sized, animated agent to help inexperienced speakers deliver their presentations in front of an audience. The design of the system was informed by an analysis of TED talks given by two human presenters to identify the most common dual-presentation formats and transition behaviors used. In a within-subjects study (N=12) comparing co-presenting with DynamicDuo against solo-presenting with conventional presentation software, we demonstrated that our system led to significant improvements in public speaking anxiety and speaking confidence for non-native English speakers. Judges who viewed videotapes of these presentations rated those with DynamicDuo significantly higher on speech quality and overall presentation quality for all presenters.\",\"We present the design and evaluation of DynamicDuo, a presentation tool that uses an automated, life-sized, animated human character to help speakers deliver their presentations in front of an audience.\",13,\"Tue 3:10 - 3:30 PM\",1429665000,1429666200,\"Authors\",null],[360,356,\"pn5106\",\"TOCHI\",\"My Self and You: Tension in Bodily Sharing of Experience\",\"There is a growing interest in designing systems for sharing experience through bodily interaction. To explore this design space, we built a probe system we named the Lega. In our 2-month-long research design process, we noted that the users’ attention was set on their own reflective experience, rather than attending to the person(s) with which they were sharing their experience. To explain these findings, we present an inductive analysis of the data through a phenomenological lens to pinpoint what causes such behavior. Our analysis extends our understanding of how to design for social embodied interaction, pointing to how we need to embrace the tension between self-reflection and shared experience, making inward listening and social expression visible acts, accessible to social construction and understanding. It entails experiencing our embodied self as others experience us in order to build a dialogue.\",\"There is a growing interest in designing systems for sharing experience through bodily interaction. To explore this design space, we built a probe system we named the Lega. In our 2-month-long research design process, we noted that the users’ attention was set on their own reflective experience, rather than attending to the person(s) with which they were sharing their experience. To explain these findings, we present an inductive analysis of the data through a phenomenological lens to pinpoint w...\",13,\"Tue 3:30 - 3:50 PM\",1429666200,1429667400,\"Authors\",null],[361,-1,\"s-crs133\",\"Course\",\"Mobile Human-Computer Interaction 1/2\",null,null,6,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Instructor\",null],[362,361,\"crs133\",\"Course\",\"Mobile Human-Computer Interaction\",\"The objective of this course is to provide newcomers to Mobile Human-Computer Interaction (Mobile HCI) with an overview of the field. The course will introduce the four grand challenges of Mobile HCI that set this field apart from others and will discuss seven current Mobile HCI research areas that address those challenges.  \",\"The objective of this course is to provide newcomers to Mobile Human-Computer Interaction (Mobile HCI) with an overview of the field. \",6,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Instructor\",null],[363,-1,\"s-crs134\",\"Course\",\"Methods for HCI &nbsp;Research 1/2\",null,null,7,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Instructor\",null],[364,363,\"crs134\",\"Course\",\"Methods for Human-Computer Interaction Research\",\"This course delivers an introduction to a range of methods used in the exploration of Human-Computer Interaction (HCI) problems. Guided by leading HCI researchers and educators, attendees will be introduced to both qualitative and quantitative research methods that have been used to understand people and interactional contexts. We will also consider some of the major philosophical traditions in HCI research along with contemporary framings of HCI approaches, such as Interaction Science.\",\"Course participants will gain a new (or improved!) understanding of a range of methods used in the exploration HCI problems.\",7,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Instructor\",null],[365,-1,\"s-crs109\",\"Course\",\"HCI Lessons: From Earth to Outer Space 1/2\",null,null,14,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Instructor\",null],[366,365,\"crs109\",\"Course\",\"HCI Lessons: From Earth to Outer Space... and Back\",\"This storytelling course will bring, in meaningful terms, insightful concepts, methods and tools that are used in the air and space domains. HCI for complex engineered systems challenges conventional HCI solutions to propose new kinds of approaches that turn out to be very useful for solving HCI complex problems. Participants will design devices usable on Earth using accumulated knowledge and tips from aerospace experience. Creativity, in the sense of synthesis and integration, and design thinking will be at the center of this course, where participants will learn how to state and solve a complex design problem, and deliver the resulting product.\",\"This Course goes beyond the regular user interface paradigm toward human-systems integration as a whole, taking into account high-level requirements and lowest grains of detail.\",14,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Instructor\",null],[367,-1,\"s-crs131\",\"Course\",\"Sketching User Experiences 1/2\",null,null,9,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Instructor\",null],[368,367,\"crs131\",\"Course\",\"Sketching User Experiences: The Hands-on Course\",\"When designing novel user interfaces, paper-pencil sketches can support the design thinking process and are valuable for communicating design ideas to others. This hands-on course will demonstrate how to integrate sketching into researchers’ and interaction designers’ everyday practice – with a particular focus on the design of novel user experiences. Participants will learn essential sketching strategies, apply these in practice during many hands-on exercises, and learn the various ways of using sketches as a tool during all stages of the HCI research and design process. Our emphasis is on quick, easy to learn, and easy to apply methods for generating and refining ideas.\",\"In this hands-on sketching course participants will learn easy to apply sketching methods for generating and refining ideas for HCI research and design.\",9,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Instructor\",null],[369,-1,\"s-float-24\",\"Papers\",\"DIY Healthcare: Apps & Wearables\",null,null,12,\"Tue 2:30 - 3:50 PM\",1429662600,1429667400,\"Chair\",\"Papers\"],[370,369,\"pn780\",\"Paper\",\"Blood Pressure Beyond the Clinic: Rethinking a Health Metric for Everyone\",\"Blood pressure (BP) is typically captured at irregular intervals, mostly in clinic environments. This approach treats BP as a static snapshot for health classification and largely ignores its value as a continuously fluctuat-ing measure. Recognizing that consumers are increasing-ly capturing health metrics through wearable devices, we explored BP measurement in relation to everyday living through a two-week field study with 34 adults. Based on questionnaires, measurement logs, and interviews, we examined participants’ perceptions and attitudes to-wards BP variability and their associations of BP with aspects of their lives. We found that participants modi-fied their use of BP devices in response to BP variabil-ity, made associations with stress, food, and daily rou-tines, and revealed challenges with the design of current BP devices for personal use. We present design recom-mendations for BP use in everyday contexts and de-scribe strategies for re-framing BP capture and reporting.\",\"We explore healthier persons’ attitudes and motivations toward BP monitoring, identify aspects of everyday living that people associate with their BP, and recommend design strategies to make this metric intelligible and relevant for personal use.\",12,\"Tue 2:30 - 2:50 PM\",1429662600,1429663800,\"Authors\",null],[371,369,\"pn1722\",\"Paper\",\"Concealing or Revealing Mobile Medical Devices? Designing for Onstage and Offstage Presentation\",\"Adults with Type 1 Diabetes have choices regarding the technology they use to self-manage their chronic condition. They can use glucose meters, insulin pumps, smartphone apps, and other technologies to support their everyday care. However, little is known about how their social lives might influence what they adopt or how they use technologies. A multi-method study was conducted to examine contextual factors that influence their technology use. While individual differences play a large role in everyday use, social factors were also found to influence use. For example, people can hide their devices in uncertain social situations or show them off to achieve a purpose. We frame these social behaviours using Goffman’s theatre metaphor of onstage and offstage behaviour, and discuss how this kind of analysis can inform the design of future mobile medical devices for self-management of chronic conditions.\",\"We frame the social behaviours of broadcasting versus hiding using Goffman’s theatre metaphor, and discuss how this can inform the design of mobile medical devices for self-management of chronic conditions.\",12,\"Tue 2:50 - 3:10 PM\",1429663800,1429665000,\"Authors\",null],[372,369,\"pn1046\",\"Paper\",\"Understanding Individual Differences for Tailored Smoking Cessation Apps\",\"Finding ways to help people quit smoking is a high priority in health behavior change research. Recent HCI studies involving technologies using specific quitting techniques such as social support and SMS messaging to help people quit have reported some success. Early studies using computer generated print material report significant success of tailored versus non-tailored material, however, there is limited understanding on what aspects of digitally delivered quitting assistance should be tailored and how. To address this, we have conducted an empirical investigation with smokers to identify perceived importance of different types of help when quitting and the potential role of technology in providing such help. We found that people are highly individual in their approach to quitting and the kind of help they regard as relevant to their situation. Our contribution is a collection of empirically derived themes for tailoring smoking cessation apps to individual quitting needs.\",\"We have conducted an empirical investigation with smokers to identify perceived importance of different types of help when quitting and the potential role of technology in providing such help.\",12,\"Tue 3:10 - 3:30 PM\",1429665000,1429666200,\"Authors\",null],[373,369,\"pn1058\",\"Paper\",\"FeedFinder: A Location-Mapping Mobile Application for Breastfeeding Women\",\"Breastfeeding is positively encouraged across many countries as a public health endeavour. The World Health Organisation recommends breastfeeding exclusively for the first six months of an infant’s life. However, women can struggle to breastfeed, and to persist with breastfeeding, for a number of reasons from technique to social acceptance. This paper reports on four phases of a design and research project, from sensitizing user-engagement and user-centred design, to the development and in-the-wild deployment of a mobile phone application called FeedFinder. FeedFinder has been developed with breastfeeding women to support them in finding, reviewing and sharing public breastfeeding places with other breastfeeding women. We discuss how mobile technologies can be designed to support public health endeavours, and suggest that public health technologies are better aimed at communities and societies rather than individual.\",\"This paper contributes the design and deployment of FeedFinder, a mobile application which presently supports over 4000 breastfeeding women. FeedFinder advocates for change within a community rather than the individual. \",12,\"Tue 3:30 - 3:50 PM\",1429666200,1429667400,\"Authors\",null],[374,-1,\"break-6\",\"Breaks\",\"Coffee Break\",null,null,15,\"Tue 3:50 - 4:30 PM\",1429667400,1429669800,\"\",\"\"],[375,-1,\"wip-2\",\"WIPs\",\"Work in Progress Exhibit\",null,null,15,\"Tue 3:50 - 4:30 PM\",1429667400,1429669800,\"\",\"\"],[376,-1,\"int-2\",\"Interactivity\",\"Interactivity Demos Exhibit\",null,null,15,\"Tue 3:50 - 4:30 PM\",1429667400,1429669800,\"\",\"\"],[377,-1,\"s117\",\"Papers\",\"Design and 3D Object Fabrication\",null,null,3,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Chair\",\"Papers\"],[378,377,\"pn2494\",\"Paper\",\"Tactum: A Skin-Centric Approach to  Digital Design and Fabrication\",\"Skin-based input has become an increasingly viable interaction model for user interfaces, however it has yet to be explored outside the domain of mobile computing.  In this paper, we examine skin as an interactive input surface for gestural 3D modeling-to-fabrication systems. When used as both the input surface and base canvas for digital design, skin-input can enable non-experts users to intuitively create precise forms around highly complex physical contexts: our own bodies. In this paper, we outline design considerations when creating interfaces for such systems.  We then discuss interaction techniques for three different modes of skin-centric modeling: direct, parametric, and generative. We also present Tactum, a new fabrication-aware design system that captures a user’s skin-centric gestures for 3D modeling directly on the body.  Lastly, we show sample artifacts generated with our system, and share a set of observations from design professionals.\",\"Tactum examines skin as an interactive input surface for gestural 3D modeling-to-fabrication systems.\",3,\"Tue 4:30 - 4:50 PM\",1429669800,1429671000,\"Authors\",null],[379,377,\"pn1055\",\"Paper\",\"A Layered Fabric 3D Printer for Soft Interactive Objects\",\"We present a new type of 3D printer that can form precise, but soft and deformable 3D objects from layers of off-the-shelf fabric. Our printer employs an approach where a sheet of fabric forms each layer of a 3D object. The printer cuts this sheet along the 2D contour of the layer using a laser cutter and then bonds it to previously printed layers using a heat sensitive adhesive. Surrounding fabric in each layer is temporarily retained to provide a removable support structure for layers printed above it. This process is repeated to build up a 3D object layer by layer. Our printer is capable of automatically feeding two separate fabric types into a single print. This allows specially cut layers of conductive fabric to be embedded in our soft prints. Using this capability we demonstrate 3D models with touch sensing capability built into a soft print in one complete printing process, and a simple LED display making use of a conductive fabric coil for wireless power reception.\",\"We present a new type of 3D printer that can form precise, but soft and deformable interactive objects from layers of off-the-shelf fabric.\",3,\"Tue 4:50 - 5:10 PM\",1429671000,1429672200,\"Authors\",null],[380,377,\"pn545\",\"Paper\",\"Platener: Low-Fidelity Fabrication of 3D Objects by Substituting 3D Print with Laser-Cut Plates\",\"This paper presents Platener, a system that allows quickly fabricating intermediate design iterations of 3D models, a process also known as low-fidelity fabrication. Platener achieves its speed-up by extracting straight and curved plates from the 3D model and substituting them with laser cut parts of the same size and thickness. Only the regions that are of relevance to the current design iteration are executed as full-detail 3D prints. Platener connects the parts it has created by automatically inserting joints. To help fast assembly it engraves instructions. Platener allows users to customize substitution results by (1) specifying fidelity-speed tradeoffs, (2) choosing whether or not to convert curved surfaces to plates bent using heat, and (3) specifying the conversion of individual plates and joints interactively.  Platener is designed to best preserve the fidelity of func-tional objects, such as casings and mechanical tools, all of which contain a large percentage of straight/rectilinear elements. Compared to other low-fab systems, such as faBrickator and WirePrint, Platener better preserves the stability and functionality of such objects: the resulting assemblies have fewer parts and the parts have the same size and thickness as in the 3D model.  To validate our system, we converted 2.250 3D models downloaded from a 3D model site (Thingiverse). Platener achieves a speed-up of 10 or more for 39.5% of all objects. \",\"Platener allows quickly fabricating intermediate design iterations of 3D models. Platener achieves speed-up by extracting straight and curved plates from the 3D model and substituting them with laser cut parts.\",3,\"Tue 5:10 - 5:30 PM\",1429672200,1429673400,\"Authors\",null],[381,377,\"pn1316\",\"Paper\",\"D-Coil: A Hands-on Approach to Digital 3D Models Design\",\"We introduce D-Coil, a new digital 3D modeling approach using wax coiling to bring tangibility to the design of digital models. After defining a shape to extrude, the users follow the lead of a hand-held actuated extruder to instantiate the actual extrusion using wax. The tangibility of the wax extrusion sets the stage to create the next components until the digital model is completed. The digital model affords all digital attributes (ease of transformation, distribution, and 3D printing) while the wax artifact can be discarded or kept as a one-of-a-kind memento. We present a proof-of-concept implementation of D-Coil and showcase how this additive approach can also be extended to a subtractive process using a digitally actuated cutter. By adding a 6DOF mouse, users can also include scaling, rotation, and bending effects to create a wide variety of shapes often difficult for novices to produce in standard CAD software. \",\"We introduce D-Coil, a new digital 3D modeling approach using wax coiling to bring tangibility to the design of digital models. \",3,\"Tue 5:30 - 5:50 PM\",1429673400,1429674600,\"Authors\",null],[382,-1,\"s-float-20\",\"Papers\",\"Sports Tracking & Training\",null,null,12,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Chair\",\"Papers\"],[383,382,\"pn611\",\"Paper\",\"Keepin’ it Real: Challenges when Designing Sports-Training Games\",\"Using game elements and mechanics in sports training holds great potential for increasing player enjoyment, but also introduces a risk of reducing training relevance. This paper describes a novel training installation for individual handball training, called “The Bouncer”, and the design process behind three training games. In order to investigate how game elements can affect the training experience, we conducted a study with 10 experienced amateur handball players, eliciting responses regarding the training relevance of the games. Based on the study and our design insights, we propose three challenges that designers of interactive sports-training games need to consider: 1) Maintaining relevance when translating physical elements into digital representations. 2) Choosing an appropriate level of sensing as game input. 3) Introducing points in training exercises without reducing sport relevance. For the three challenges, we propose strategies to help future designers of training games. \",\"Presents design process and study of an interactive handball-training game, offering observations of players’ experiences; highlights challenges emerging when designing interactive sports-training games and proposes strategies for addressing them. \",12,\"Tue 4:30 - 4:50 PM\",1429669800,1429671000,\"Authors\",null],[384,382,\"pn2289\",\"Paper\",\"Flow is Not Enough: Understanding the Needs of Advanced Amateur Runners to Design Motivation Technology\",\"Motivation studies on running are often focused on how to convince non-runners to run, mainly through designing for extrinsic motivations such as health concerns or external reward systems. In contrast, we conducted a structured inquiry into understanding how to design technology for those whom are already committed to running and participate in organized races. Through interviews, focus groups, ethnographic observation, questionnaires, and design-based research over the course of two years, we investigated the needs of the advanced amateur runner community. An analysis of the gathered data led to five design themes – Festival, Competition, Practicalities, Togetherness, and Support – to inform future runner motivation technology. While flow theory appears to be a convenient tool to understand support during a race, we observed a number of other factors that need to be considered. Through combining the themes with previous research, we conclude by presenting nine guidelines for designing technology for this domain. \",\"We conducted a structured inquiry into designing for those already committed to running and participate in organized races. In two years, we created guidelines for future runner support technology.\",12,\"Tue 4:50 - 5:10 PM\",1429671000,1429672200,\"Authors\",null],[385,382,\"pn1856\",\"Paper\",\"Jogging with a Quadcopter\",\"Jogging is a popular exertion activity. The abundance of jogging apps suggests to us that joggers can appreciate the opportunity for technology to support the jogging experience. We want to take this investigation a step further by exploring if, and how, robotic systems can support the jogging experience. We designed and built a flying robotic system, a quadcopter, as a jogging companion and studied its use with 13 individual joggers. By analyzing their experiences, we derived three design dimensions that describe a design space for flying robotic jogging companions: Perceived Control, Focus and Bodily Interaction. Additionally, we articulate a series of design tactics, described by these dimensions, to guide the design of future systems. With this work we hope to inspire and guide designers interested in creating robotic systems to support exertion experiences.\",\"Presents strategies for embodied exertion interactions based on a study around a novel quadcopter that served as companion for joggers.  Guides designers interested in creating robotic systems to support sports. \",12,\"Tue 5:10 - 5:30 PM\",1429672200,1429673400,\"Authors\",null],[386,382,\"pn1010\",\"Paper\",\"ClimbSense - Automatic Climbing Route Recognition using Wrist-worn Inertia Measurement Units\",\"Today, sports and activity trackers are ubiquitous. Especially runners and cyclists have a variety of possibilities to record and analyze their workouts. In contrast, climbing did not find much attention in consumer electronics and human-computer interaction. If quantified data similar to cycling or running data were available for climbing, several applications would be possible, ranging from simple training diaries to virtual  coaches or usage analytics for gym operators. This paper introduces a system that automatically recognizes climbed routes using wrist-worn inertia measurement units (IMUs). This is achieved by extracting features of a recorded ascent and use them as training data for the recognition system. To verify the recognition system, cross-validation methods were applied to a set of ascent recordings that were assessed during a user study with eight climbers in a local climbing gym. The evaluation resulted in a high recognition rate, thus proving that our approach is possible and operational.\",\"This paper introduces a system that automatically recognizes climbed routes using wrist-worn Inertia Measurement Units. Recordings of ascents are compared by a modified edit distance as a measure of similarity.\",12,\"Tue 5:30 - 5:50 PM\",1429673400,1429674600,\"Authors\",null],[387,-1,\"s102\",\"Papers\",\"Feeling & Communicating Emotions\",null,null,13,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Chair\",\"Papers\"],[388,387,\"pn859\",\"Paper\",\"Towards Multimodal Affective Feedback - Interaction between Visual and Haptic Modalities\",\"We explored how emotional cues presented in visual and haptic modalities interact. We constructed an affective haptic dataset, and used the emotional visual stimuli from the International Affective Picture System (IAPS). Participants were asked to rate the visual stimuli, haptic stimuli and visualhaptic stimuli. Analysis of the results indicates that the presence of haptic stimulus affects the arousal of the visual stimulus, but does not affect the valence significantly. We further explored this interaction in terms of the intensity, frequency, waveform and rhythm of the haptic stimuli. We then provide a set of guidelines on visual-haptic interaction that could be used in design of multimodal affective feedback.\",\"We explored how emotional cues presented in visual and haptic modalities interact. We further explored this interaction in terms of the intensity, frequency, waveform and rhythm of the haptic stimuli.\",13,\"Tue 4:30 - 4:50 PM\",1429669800,1429671000,\"Authors\",null],[389,387,\"pn1195\",\"Paper\",\"Emotions Mediated Through Mid-Air Haptics\",\"Touch is a powerful vehicle for communication between humans. The way we touch (how) embraces and mediates certain emotions such as anger, joy, fear, or love. While this phenomenon is well explored for human interaction, HCI research is only starting to uncover the fine granularity of sensory stimulation and responses in relation to certain emotions. Within this paper we present the findings from a study exploring the communication of emotions through a haptic system that uses tactile stimulation in mid-air. Here, haptic descriptions for specific emotions (e.g., happy, sad, excited, afraid) were created by one group of users to then be reviewed and validated by two other groups of users. We demonstrate the non-arbitrary mapping between emotions and haptic descriptions across three groups. This points to the huge potential for mediating emotions through mid-air haptics. We discuss specific design implications based on the spatial, directional, and haptic parameters of the created haptic descriptions and illustrate their design potential for HCI based on two design ideas.\",\"HCI is only starting to uncover the fine granularity of sensory stimulation in relation to emotions. We explored the communication of emotions in mid-air through a novel haptic system.\",13,\"Tue 4:50 - 5:10 PM\",1429671000,1429672200,\"Authors\",null],[390,387,\"pn507\",\"Paper\",\"In the Heat of the Moment: Subjective Interpretations of Thermal Feedback During Interaction\",\"Research has shown that thermal feedback can be an engaging and convincing means of conveying experimenter-predefined meanings, e.g., material properties or message types. However, thermal perception is subjective and its meaning in interaction can be ambiguous. Interface designers may not be sure how users could naïvely interpret thermal feedback during interaction. Little is also known about how users would choose thermal cues to convey their own meanings. The research in this paper tested subjective interpretations of thermal stimuli in three different scenarios: social media activity, a colleague’s presence and the extent of use of digital content. Participants were also asked to assign their own thermal stimuli to personal experiences, to help us understand what kinds of stimuli people associate with different meanings. The results showed strong agreement among participants concerning what warmth (presence, activity, quality) and cool mean (absence, poor quality). Guidelines for the design of thermal feedback are presented to help others create effective thermal interfaces.\",\"This paper tested the subjective responses of participants to thermal feedback in a range of common interaction scenarios, to understand how naïve users naturally interpret and design thermal feedback.\",13,\"Tue 5:10 - 5:30 PM\",1429672200,1429673400,\"Authors\",null],[391,387,\"pn2050\",\"Paper\",\"EnviroPulse: Providing Feedback about the Expected Affective Valence of the Environment\",\"Interacting with nature is beneficial to a person’s mental-state, but it can sometimes be difficult to find environments that will induce positive affect (e.g., when planning a run). In this paper, we describe EnviroPulse—a system for auto-matically determining and communicating the expected affective valence (EAV) of environments to individuals. We describe a prototype that allows this to be used in real-time on a smartphone, but EnviroPulse could easily be incorporated into GPS systems, mapping services, or image-based systems. Our work differs from existing work in af-fective computing in that, rather than detecting a user’s affect directly, we automatically determine the EAV of the environment through visual analysis. We present results that suggest our system can determine the EAV of envi-ronments. We also introduce real-time affective visual feedback of the calculated EAV of the images, and present results from an informal study suggesting that real-time visual feedback can be used for induction of affect.\",\"In this paper, we describe EnviroPulse—a system for automatically determining and communicating the expected affective valence of environments to individuals, and present results from a validation study.\",13,\"Tue 5:30 - 5:50 PM\",1429673400,1429674600,\"Authors\",null],[392,-1,\"s-float-17\",\"Papers\",\"Families and Their Use of Technology\",null,null,10,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Chair\",\"Papers\"],[393,392,\"pn1051\",\"Paper\",\"Managing Children’s Online Identities: How Parents Decide what to Disclose about their Children Online\",\"While extensive research has investigated the risks of children sharing their personal information online, little work has investigated the implications of parents sharing personal information about their children online. Drawing on 102 interviews with parents in the U.S., we investigate how parents decide what to disclose about their children on social network sites (SNSs). We find that mothers take on the responsibility of sharing content about their children more than fathers do. Fathers are more restrictive about sharing to broad and professional audiences and are concerned about sharing content that could be perceived as sexually suggestive. Both mothers and fathers work to leverage affordances of SNSs to limit oversharing. Building on prior work, we explore parental disclosure management, which describes how parents decide what to share about their children online. We also describe an emerging third shift of work that highlights the additional work parents take on to manage children’s identities online. We conclude with theoretical and practical implications for designing SNSs to better support family life online.\",\"Describes the challenges parents face when choosing to share information about their children online. \",10,\"Tue 4:30 - 4:50 PM\",1429669800,1429671000,\"Authors\",null],[394,392,\"pn450\",\"Paper\",\"Understanding and Supporting Fathers and Fatherhood on Social Media Sites\",\"Fathers are taking on more childcare and household responsibilities than they used to and many non-profit and government organizations have pushed for changes in policies to support fathers. Despite this effort, little research has explored how fathers go online related to their roles as fathers. Drawing on an interview study with 37 fathers, we find that they use social media to document and archive fatherhood, learn how to be a father, and access social support. They also go online to support diverse family needs, such as single fathers’ use of Reddit instead of Facebook, fathers raised by single mothers’ search for role models online, and stay-at-home fathers’ use of father blogs. However, fathers are constrained by privacy concerns and perceptions of judgment relating to sharing content online about their children. Drawing on theories of fatherhood, we present theoretical and design ideas for designing online spaces to better support fathers and fatherhood. We conclude with a call for a research agenda to support fathers online.\",\"Understand how fathers use social media related to fatherhood. \",10,\"Tue 4:50 - 5:10 PM\",1429671000,1429672200,\"Authors\",null],[395,392,\"pn5123\",\"TOCHI\",\"Family Rituals and the Potential For Interaction Design: A Study of Christmas\",\"Drawing on a field study with eight families in northern England, we explore the traditions and rituals carried out at Christmas, looking at the artefacts and processes that constitute family life at this time of year. Besides individual differences, a common pattern emerges: an extended preparation is carried out by the hosting household over a few weeks to set up the celebration and build expectations; preparation gives way to a short but intense celebration shared with the family or intimate friends; then decorations are stored and there is a return to normal life. The celebration is across generations and everyone takes part. We note examples of new and evolving rituals. Starting from the three identified phases, we discuss the theoretical and technical implications of our findings for the design of more sympathetic technology that holds potential for augmenting family rituals sensitively and possibly creating new ones.\",\"Drawing on a field study with eight families in northern England, we explore the traditions and rituals carried out at Christmas, looking at the artefacts and processes that constitute family life at this time of year. Besides individual differences, a common pattern emerges: an extended preparation is carried out by the hosting household over a few weeks to set up the celebration and build expectations; preparation gives way to a short but intense celebration shared with the family or intimate ...\",10,\"Tue 5:10 - 5:30 PM\",1429672200,1429673400,\"Authors\",null],[396,392,\"pn716\",\"Paper\",\"Look, My Baby Is Using an iPad!  An Analysis of YouTube Videos of Infants and Toddlers Using Tablets\",\"We know very little about the use of computers by children under the age of three. While few children in that age range used computers before the advent of smartphones and tablets, these devices have made computers much more accessible to infants and toddlers. In this paper, we provide a window into how these children are using tablets through an analysis of relevant YouTube videos. A majority of children aged 12 to 17 months in the videos in our dataset showed at least moderate ability to use the tablets. For children aged two, it was over 90 percent who displayed at least moderate ability. Our analysis also includes trends in interaction styles, child and device positioning, social aspects, and app genres. These findings point both to opportunities for research and starting points for design.\",\"Analysis includes age, gender, ability to use tablet and apps, use of hands and gestures, app genres, physical position of device and child, social and physical context, and emotions displayed.\",10,\"Tue 5:30 - 5:50 PM\",1429673400,1429674600,\"Authors\",null],[397,-1,\"s-float-8\",\"Papers\",\"Understanding & Extending Touch Interfaces\",null,null,4,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Chair\",\"Papers\"],[398,397,\"pn2629\",\"Paper\",\"Performance and Ergonomics of Touch Surfaces: A Comparative Study using Biomechanical Simulation\",\"Although different types of touch surfaces have gained extensive attention in HCI, this is the first work to directly compare them for two critical factors: performance and ergonomics. Our data come from a pointing task (N=40) carried out on five common touch surface types: public display (large, vertical, standing), tabletop (large, horizontal, seated), laptop (medium, adjustably tilted, seated), tablet (seated, in hand), and smartphone (single- and two-handed input). Ergonomics indices were calculated from biomechanical simulations of motion capture data combined with recordings of external forces. We provide an extensive dataset for researchers and report the first analyses of similarities and differences that are attributable to the different postures and movement ranges.\",\"This paper applies optical motion capture and biomechanical simulation for simultaneous assessment of performance and ergonomics of 6 types of touch screens: tablet, tabletop, laptop, public display, smartphone 2 hands, and 1 hand. \",4,\"Tue 4:30 - 4:50 PM\",1429669800,1429671000,\"Authors\",null],[399,397,\"pn922\",\"Paper\",\"How Much Faster is Fast Enough? User Perception of Latency & Latency Improvements in Direct and Indirect Touch\",\"This paper reports on two experiments designed to further our understanding of users’ perception of latency in touch- based systems. The first experiment extends previous efforts to measure latency perception by reporting on a unified study in which direct and indirect form-factors are compared for both tapping and dragging tasks. Our results show significant effects from both form-factor and task, and inform system designers as to what input latencies they should aim to achieve in a variety of system types. A follow-up experiment investigates peoples’ ability to perceive small improvements to latency in direct and indirect form-factors for tapping and dragging tasks. Our results provide guidance to system designers of the relative value of making improvements in latency that reduce but do not fully eliminate lag from their systems.\",\"We examined latency perception for dragging and tapping tasks on both direct and indirect touch devices, and show that even single-frame improvements in 60 Hz systems are generally perceptible.\",4,\"Tue 4:50 - 5:10 PM\",1429671000,1429672200,\"Authors\",null],[400,397,\"pn1644\",\"Paper\",\"The Effect of Edge Targets on Touch Performance\",\"Edge targets, such as buttons or menus along the edge of a screen, are known to afford fast acquisition performance in desktop mousing environments. As the popularity of touch-based devices continues to grow, understanding the affordances of edge targets on touchscreen is needed. This paper describes results from two controlled experiments that examine in detail the effect of edge targets on performance in touch devices. Our results shows that on touch devices, a target’s proximity to the edge may have a significant negative effect on reaction time. We examine the effect in detail and explore mitigating factors. We discuss potential explanations for the effect and propose implications for the design of efficient interfaces for touch devices.\",\"Results from two experiments demonstrating that, unlike in traditional desktop mousing environments, a touch target’s proximity to the edge of a touchscreen has a significant negative effect on acquisition performance.\",4,\"Tue 5:10 - 5:30 PM\",1429672200,1429673400,\"Authors\",null],[401,397,\"pn2495\",\"Note\",\"FlickBoard: Enabling Trackpad Interaction with Automatic Mode Switching on a Capacitive-sensing Keyboard\",\"We present FlickBoard, which combines a touchpad and a keyboard into the same interaction area to reduce hand movement between a separate keyboard and touchpad. Our main contribution is automatic mode switching between typing and pointing, and the first system capable of combining a trackpad and a keyboard into an single interaction area without the need for external switches. We developed a prototype by embedding a 58x20 capacitive sensing grid into a soft keyboard cover, and used machine learning to distinguish between moving a cursor (touchpad mode) and entering text (keyboard mode). We conducted experimental studies that show automatic mode switching classification accuracies of 98% are achievable with our technology. Finally, our prototype has a thin profile and can be placed over existing keyboards.\",\"Our main contribution is automatic mode switching between typing and pointing, and the first system capable of combining a trackpad and a keyboard into an single interaction area without the need for external switches. \",4,\"Tue 5:30 - 5:40 PM\",1429673400,1429674000,\"Authors\",null],[402,397,\"pn1979\",\"Note\",\"ExtensionSticker: A Proposal for a Striped Pattern Sticker to Extend Touch Interfaces and its Assessment\",\"In this study, we propose a striped pattern sticker called ExtensionSticker that allows a touch input to be transferred from an external source by simply attaching the sticker to a touch panel.  This allows the user to input touches or continuous scrolling actions by touching a sticker printed with stripes of conductive ink, without directly touching the touch panel. This method could be applied to the sides or back of a touch panel, or even the surface upon which a device is located as a touch interface, allowing us to freely construct interfaces in shapes matching the demands of the user. This paper also reports the results of evaluation experiments conducted to assess the recognition accuracy of scroll and tap actions using the proposed method.\",\"Proposed method allows the user to create a variety of interfaces easily and to extend a touch panel devices only attaching the sticker.\",4,\"Tue 5:40 - 5:50 PM\",1429674000,1429674600,\"Authors\",null],[403,-1,\"s-float-13\",\"Papers\",\"Understanding Crowdwork in Many Domains\",null,null,15,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Chair\",\"Papers\"],[404,403,\"pn2423\",\"Paper\",\"Apparition: Crowdsourced User Interfaces That Come To Life As You Sketch Them\",\"Prototyping allows designers to quickly iterate and gather feedback, but the time it takes to create even a Wizard-of-Oz prototype reduces the utility of the process. In this paper, we introduce crowdsourcing  techniques and tools for prototyping interactive systems in the time it takes to describe the idea. Our Apparition system uses paid microtask crowds to make even hard-to-automate functions work immediately, allowing more fluid prototyping of interfaces that contain interactive elements and complex behaviors. As users sketch their interface and describe it aloud in natural language, crowd workers and sketch recognition algorithms translate the input into user interface elements, add animations, and provide Wizard-of-Oz functionality. We discuss how design teams can use our approach to reflect on prototypes or begin user studies within seconds, and how, over time, Apparition prototypes can become fully-implemented versions of the systems they simulate. Powering Apparition is the first self-coordinated, real-time crowdsourcing infrastructure. We anchor this infrastructure on a new, lightweight write-locking mechanism that workers can use to signal their intentions to each other.\",\"Apparition uses paid crowds to make even hard-to-automate functions work immediately, allowing more fluid prototyping from sketch and speech of interfaces that contain interactive elements and complex behaviors.\",15,\"Tue 4:30 - 4:50 PM\",1429669800,1429671000,\"Authors\",null],[405,403,\"pn1539\",\"Paper\",\"Zensors: Adaptive, Rapidly Deployable, Human-Intelligent Sensor Feeds\",\"The promise of “smart” homes, workplaces, schools, and other environments has long been championed. Unattractive, however, has been the cost to run wires and install sensors. More critically, raw sensor data tends not to align with the types of questions humans wish to ask, e.g., do I need to restock my pantry? Although techniques like computer vision can answer some of these questions, it requires significant effort to build and train appropriate classifiers. Even then, these systems are often brittle, with limited ability to handle new or unexpected situations, including being repositioned and environmental changes (e.g., lighting, furniture, seasons). We propose Zensors, a new sensing approach that fuses real-time human intelligence from online crowd workers with automatic approaches to provide robust, adaptive, and readily deployable intelligent sensors. With Zensors, users can go from question to live sensor feed in less than 60 seconds. Through our API, Zensors can enable a variety of rich end-user applications and moves us closer to the vision of responsive, intelligent environments.\",\"Zensors is a new approach and architecture for hybrid crowd-ML powered sensors, with an API to enable modular access to sensor data streams. Our human-powered sensors can be used to train CV approaches in situ.\",15,\"Tue 4:50 - 5:10 PM\",1429671000,1429672200,\"Authors\",null],[406,403,\"pn2626\",\"Paper\",\"Exploring Privacy and Accuracy Trade-Offs in Crowdsourced Behavioral Video Coding\",\"Coding behavioral video is an important method used by researchers to understand social phenomenon. Unfortunately, traditional hand-coding approaches can take days or weeks of time to complete. Recent work has shown that these tasks can be completed quickly by leveraging the parallelism of large online crowds, but using the crowd introduces new concerns about accuracy, reliability, privacy, and cost. To explore these issues, we conducted interviews with 12 researchers who frequently code behavioral video, to investigate common practices and challenges with video coding. We find accuracy and privacy to be the researchers' primary concerns. To explore this more concretely, we used sample videos to investigate whether crowds can accurately recognize instances of commonly coded behaviors, and show that the crowd yields accurate results. Then, we demonstrate a method for obfuscating participant identity with a video blur filter, and find, as expected, that workers' ability to identify participants decreases as blur level increases. The workers' ability to accurately and reliably code behaviors also decreases, but not as steeply as the identity test. This trade-off between coding quality and privacy protection suggests that researchers can use online crowds to code for some key behaviors in video without compromising participant identity. We conclude with a discussion of how researchers can balance privacy and accuracy on their own data using a system we introduce called Incognito.\",\"We show that crowd-powered behavioral video coding can be effectively used with privacy filters (e.g., image blurring) for the most commonly-coded behaviors found in interviews with 12 socio-technical researchers.\",15,\"Tue 5:10 - 5:30 PM\",1429672200,1429673400,\"Authors\",null],[407,403,\"pn239\",\"Paper\",\"Crowdsourcing Stereotypes: Linguistic Bias in Metadata Generated via GWAP\",\"Games with a Purpose (GWAP) is a popular approach for metadata creation, enabling institutions to collect descriptions of digital artifacts on a mass scale. Creating metadata is challenging not only because one must recognize the artifact; the description must then be encoded into natural language. Language behaviors are influenced by many social factors, particularly when we are asked to describe other people. We consider labels for images of people generated via the ESP Game. While ESP has been shown to produce relevant labels, critics claim they are obvious and stereotypical. Based on theories of linguistic biases, we examine whether there are systematic differences in the ways players describe images of men versus women. Our first analysis considers images of people generally, and reveals a tendency for women to be described with subjective adjectives. A second analysis compares images depicting men and women within each of six occupational roles. Images of women receive more labels related to appearance, whereas those depicting men receive more occupation-related labels. Our work exposes the presence of gender-based stereotypes through linguistic biases, illustrates the forms in which they manifest, and raises important implications for those who design systems or train algorithms using data produced via GWAP.\",\"Our work exposes gender-based stereotypes expressed through linguistic biases, illustrates the forms in which they manifest, and raises implications for those who design systems or train algorithms using data produced via GWAP.\",15,\"Tue 5:30 - 5:50 PM\",1429673400,1429674600,\"Authors\",null],[408,-1,\"s113\",\"Papers\",\"Eco-Green: Encouraging Energy Conservation\",null,null,11,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Chair\",\"Papers\"],[409,408,\"pn849\",\"Paper\",\"Tiree Energy Pulse: Exploring Renewable Energy Forecasts on the Edge of the Grid.\",\"In many parts of the world, the electricity supply industry makes the task of dealing with unpredictable spikes and dips in production and demand invisible to consumers, maintaining a seemingly unlimited supply. A future increase in reliance on time-variable renewable sources of electricity may lead to greater fluctuations in supply. We engaged remote islanders as equal partners in a research project that investigated through technology-mediated enquiry the topic of synchronising energy consumption with supply, and together built a prototype renewable energy forecast display. A number of participants described a change in their practices, saving high energy tasks for times when local renewable energy was expected to be available, despite having no financial incentive to do so. The main contributions of this paper are in: 1) the results of co-development sessions exploring systems supporting synchronising consumption with supply and 2) the findings arising from the deployment of the prototype.\",\"Alongside Tiree islanders we investigated technologies for synchronising energy consumption with supply, co-developing a local renewable energy forecast display.  We present the results and the findings arising from this process.\",11,\"Tue 4:30 - 4:50 PM\",1429669800,1429671000,\"Authors\",null],[410,408,\"pn1218\",\"Paper\",\"Designing Persuasive Technology to Manage Peak Electricity Demand in Ontario Homes\",\"When it comes to environmental sustainability, the time that electricity is consumed matters. For example, using an air conditioner on a hot summer afternoon as the power grid is strained necessitates the use of more polluting sources to meet demand. In this paper, we analyze end-user response to two utility-driven conservation programs in Ontario, Canada: Time-of-Use pricing and the peaksaver program. We find that time-of-use pricing encourages shifting some electricity demand, but only when it is convenient. We also find that while potentially effective at a larger scale, the peaksaver program in its current form is unattractive to participants. These results are discussed in the context of Fogg’s Behavior Model for Persuasive Design, which allows us to explore the design space for improvement to these programs and ground our design implications for the design of technologies to encourage reduction of peak electricity demand.\",\"We analyze end-user response to utility-driven demand shifting programs. We discuss our findings in the context of Fogg’s Behavior Model for Persuasive Design, and explore the design space for improvement.\",11,\"Tue 4:50 - 5:10 PM\",1429671000,1429672200,\"Authors\",null],[411,408,\"pn1033\",\"Note\",\"Eco-Forecasting for Domestic Electricity Use\",\"Over the past decade we have seen an increased awareness about domestic energy consumption and a growing focus on eco-feedback displays. In this paper we explore the concept of providing forecasts in such displays as a supplement to information about past usage. Our prototype, eForecast, extends the display of past electricity usage with forecasts about expected usage, electricity price, availability of wind power, and expected demand drops and peaks. Building on previous eco-feedback display research, our approach specifically enables people to use electricity at more opportune times – when it is cheap, green, or when there is an abundance of capacity. We evaluated eForecast in real world use in three domestic households for 22 weeks, where we explored potentials and limitations of forecasting for shifting electricity consumption. In this way, families were able to act in a more sustainable way – without necessarily reducing the amount of electricity consumed.\",\"eForecast, extends the display of past electricity usage with forecasts about expected usage, electricity price, availability of wind power, and expected demand drops and peaks.\",11,\"Tue 5:10 - 5:20 PM\",1429672200,1429672800,\"Authors\",null],[412,408,\"pn731\",\"Note\",\"Beyond Eco-Feedback: Adding Online Manual and Automated Controls to Promote Workplace Sustainability\",\"Whereas eco-feedback has been widely studied in HCI and environmental psychology, online manual control and automated control have been rarely studied with a focus on their long-term quantitative impact and usability. To address this, an intervention was tested with eighty office workers for twenty-seven weeks. Through the long-term field test, it was found that the addition of online controls in the feedback intervention led to more energy savings than feedback only and worked better for light and phone usage than computer and monitor usage. The addition of automated control led to the greatest savings but was less effective for efficient users than inefficient ones.\",\"This paper has explored the effectiveness of adding online manual and automated controls to traditional eco-feedback strategies towards sustainability in the workplace.\",11,\"Tue 5:20 - 5:30 PM\",1429672800,1429673400,\"Authors\",null],[413,408,\"pn2212\",\"Paper\",\"Understanding the Role of Thermography in Energy Auditing: Current Practices and the Potential for Automated Solutions\",\"The building sector accounts for 41% of primary energy consumption in the US, contributing an increasing portion of the country’s carbon dioxide emissions. With recent sensor improvements and falling costs, auditors are increasingly using thermography—infrared (IR) cameras—to detect thermal defects and analyze building efficiency. Research in automated thermography has grown commensurately, aimed at reducing manual labor and improving thermal models. Though promising, we could find no prior work exploring the professional auditor’s perspectives of thermography or reactions to emerging automation. To address this gap, we present results from two studies: a semi-structured interview with 10 professional energy auditors, which includes design probes of five automated thermography scenarios, and an observational case study of a residential audit. We report on common perspectives, concerns, and benefits related to thermography and summarize reactions to our automated scenarios. Our findings have implications for thermography tool designers as well as researchers working on automated solutions in robotics, computer science, and engineering.\",\"Our contributions include an assessment of energy auditing and thermography’s role, a critical examination of the potential for automated thermography, a set of reflections and guidelines to help inform future tools.\",11,\"Tue 5:30 - 5:50 PM\",1429673400,1429674600,\"Authors\",null],[414,-1,\"s-float-5\",\"Papers\",\"Sharing & Collaboration @ Work\",null,null,5,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Chair\",\"Papers\"],[415,414,\"pn581\",\"Paper\",\"MUBox: Multi-User Aware Personal Cloud Storage\",\"Personal cloud services such as Dropbox are used increasingly to support collaborative work, even though they typically have poor support for tracking files and users' activities and collaborators often rely on other communication channels to be notified of changes. We present a meta-cloud storage service, MUBox, that, independent of a particular cloud storage service, provides improved support for collaboration. First, users can switch to activity views that list user activities rather than files, which is an example of an increasingly available feature in popular cloud storage clients. Second, MUBox introduces multi-user aware folder views that embed information on the last changes performed by collaborators. These folder views are enhanced based on a new concept of shadow files which act as placeholders for files that have been moved or renamed. A user study (N=16) with realistic folder exploration tasks shows that activity views have a significant effect on the accuracy and confidence of users in workspace awareness tasks, while shadow files significantly improve the speed, accuracy and confidence of users in traceability tasks. We describe how existing services could implement these features as well as a new concept for voting on changes to shared folders that could improve asynchronous collaboration.\",\"MUBox adds minimally invasive features for collaboration on top of personal cloud storage services such as Dropbox without adding unnecessary complexity. Controlled experiments demonstrate improved workspace awareness and file traceability.\",5,\"Tue 4:30 - 4:50 PM\",1429669800,1429671000,\"Authors\",null],[416,414,\"pn2126\",\"Paper\",\"DocuViz:  Visualizing Collaborative Writing\",\"Collaborative writing is on the increase. In order to write well together, authors often need to be aware of who has done what recently. We offer a new tool, DocuViz, that displays the entire revision history of Google Docs, showing more than the one-step-at–a-time view now shown in revision history and tracking changes in Word. We introduce the tool and present cases in which the tool has the potential to be useful: To authors themselves to see recent “seismic activity,” indicating where in particular a co-author might want to pay attention, to instructors to see who has contributed what and which changes were made to comments from them, and to researchers interested in the new patterns of collaboration made possible by simultaneous editing capabilities. \",\"DocuViz is a visualization tool to show who wrote what when in Google Docs to help researchers see patterns, writers know others are doing, and instructors focus on development.\",5,\"Tue 4:50 - 5:10 PM\",1429671000,1429672200,\"Authors\",null],[417,414,\"pn1226\",\"Paper\",\"Communication through Boundary Objects in Distributed Agile Teams\",\"Personal communication between User-Centered Design (UCD) specialists and developers is important for communicating user needs and design solutions in agile development. In distributed projects where opportunities for personal communication are limited, the design documentation is an important surrogate. This study has investigated the perceived effectiveness of boundary objects in a distributed agile team, and their role in communicating target user needs. Six in-depth interviews with UCD specialists showed that the boundary objects rarely communicate underlying needs of the users but rather focus on interaction with the system that is being developed. The used boundary objects also do not work as stand-alone deliverables; they need to be explained and elaborated. Making the boundary objects comprehensive enough to be stand-alone is seen as too time consuming and not worth the effort. For agile projects with distributed teams, this creates hand-over and follow-up problems.\",\"Suggestions for effective design documentation that enhance communication quality among distributed agile teams.\",5,\"Tue 5:10 - 5:30 PM\",1429672200,1429673400,\"Authors\",null],[418,414,\"pn973\",\"Paper\",\"How to Drive a London Bus: Measuring Performance in a Mobile and Remote Workplace\",\"This paper examines how London bus drivers have responded to performance monitoring via a telematics device called Drivewell. This device calculates a score based on various recordable driving-related events like abrupt braking or irregular turning actions. Our qualitative methodology incorporated semi-structured interviews and ethnographic fieldwork, in order to explore drivers’ attitudes towards the system and its effect on driving behaviour and working conditions. Our findings illustrate how bus operators simultaneously accommodate and resist the demands Drivewell places upon them. Our work also demonstrates how this digital intervention acts in conjunction with other driver-related technologies, creating a unique digital ecosystem on the modern London bus. Our research contributes to HCI understandings of digital surveillance and performance monitoring in the modern workplace.\",\"Our paper contributes to understandings of surveillance and performance measurement at work. We demonstrate how London bus drivers respond to digital monitoring and how it affects their work and wellbeing. \",5,\"Tue 5:30 - 5:50 PM\",1429673400,1429674600,\"Authors\",null],[419,-1,\"s-float-39\",\"Papers\",\"Critical Design\",null,null,1,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Chair\",\"Papers\"],[420,419,\"pn1641\",\"Paper\",\"Expanding and Refining Design and Criticality in HCI\",\"The term ‘critical design’ is on the upswing in HCI. We analyze how discourses around ‘critical design’ are diverging in Design and HCI. We argue that this divergence undermines HCI’s ability to learn from and appropriate the design approaches signaled by this term.  Instead, we articulate two ways to broaden and deepen connections between Design and HCI: (1) develop a broader collective understanding of what these design approaches can be, without forcing them to be about ‘criticality’ or ‘critical design,’ narrowly construed; and (2) shape a variation of design criticism to better meet Design practices, terms, and ways of knowing.\",\"Develops a broader collective understanding different design approaches without forcing them to be about ‘criticality’ or ‘critical design’. Helps develop HCI design criticism to better meet Design practices, terms, and ways of knowing. \",1,\"Tue 4:30 - 4:50 PM\",1429669800,1429671000,\"Authors\",null],[421,419,\"pn1426\",\"Paper\",\"Immodest Proposals:  Research Through Design and Knowledge\",\"The paper offers theoretical support for research through design (RtD) by arguing that in order to legitimize and make use of research through design as research, HCI researchers need to explore and clarify how RtD objects might contribute to knowledge. Leveraging the tradition of aesthetics in the arts and humanities, we argue that while the intentions of the object’s designer are important and while annotations are a good mechanism to articulate them, the critical reception of objects is equally foundational to RtD’s broader knowledge impacts within HCI. Such a scholarly critical reception is needed precisely because of the potential inexhaustibility of design objects’ meanings; their inability to be paraphrased simply and adequately. Offering a multilevel analysis of the (critical) design fiction Menstruation Machine by Sputniko!, the paper explores how design objects co-produce knowledge, by working through complex design problem spaces in non-reductive ways, proposing new connections and distinctions, and embodying design ideas and processes across time and minds. \",\"We consider ways that research through design can contribute to knowledge, arguing for the importance of critical reception of design objects, and offer a sample critical interpretation.\",1,\"Tue 4:50 - 5:10 PM\",1429671000,1429672200,\"Authors\",null],[422,419,\"pn1486\",\"Paper\",\"Making Multiple Uses of the Obscura 1C Digital Camera: Reflecting on the Design, Production, Packaging and Distribution of a Counterfunctional Device\",\"This paper describes and explains details of the design, production and packaging of a counterfunctional device: The Obscura 1C Digital Camera. We further describe a small-scale distribution of Obscura 1C packages into everyday contexts. The paper then reflects on the various types of conceptual, imaginary and firsthand uses made of the Obscura 1C. These include its uses for everyday audiences as a unique camera and as a conceptually usable device. But we also prioritize uses particular to the HCI and design audience. These include using the Obscura 1C to articulate the concepts of inhibitive interfaces, counterfunctionality, and enabling limitations. The Obscura 1C is further used to articulate how abstract ideas can be translated into material forms, to rethink the role of packaging in user studies, and to draw attention to how discursive design objects are packaged and presented. \",\"Contributes a discussion of limitations and design by presenting details of the design, production and packaging of a counterfunctional device.\",1,\"Tue 5:10 - 5:30 PM\",1429672200,1429673400,\"Authors\",null],[423,419,\"pn1623\",\"Note\",\"Pause Moment Experience in SNS Communication\",\"The evolution of SNS applications has focused on the increasing pace of communication. Accordingly, adopting pause moment design for the SNS domain becomes significant, considering its worth for mental well-being and diversity of experience. Nonetheless, the vision is currently controversial, as it is lacking in attempts to examine the worth of pause moment design for SNS communication. Therefore, we discussed the benefits of pause moment design as an SNS application, based on the case of Ripening Room. From observation, we have identified three benefits of pause moment design; preserving room for solitude, expanding time experience, and providing additional indirect cues for communication. Nevertheless, the benefits also imply limitations of the current design, thus require following attempts to adopt a pause moment design for the SNS domain.\",\"This paper assessed the benefit and limitation of slow design as an alternative design philosophy for SNS applications, in concern of mental well-being and diversity of experience in SNS.\",1,\"Tue 5:30 - 5:40 PM\",1429673400,1429674000,\"Authors\",null],[424,-1,\"s167\",\"Papers\",\"Human Computer Interaction Journal 1\",null,null,2,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Chair\",\"Papers\"],[425,424,\"pn5151\",\"TOCHI\",\"Providing Adaptive Health Updates Across the Personal Social Network\",\"This article presents research conducted to establish how information is shared across the personal social network in the sensitive context of a health crisis. We worked with parents of very sick babies who were cared for in a hospital's Neonatal Unit (NNU). Through a combination of interviews, a focus group, and surveys, we developed a user model of the information that parents wanted to share, and how they adapted this information to individual recipients. We then developed a prototype software tool which created adaptive updates for members of the parents' social network. The updates contained summaries of large volumes of complex medical data about the baby, nonmedical information about the parents, and practical information about the hospital. Updates were automatically adapted to individual members of parents' social networks, based on our user model. The tool was evaluated in a large NNU in the United Kingdom with parents of babies who were currently being cared for in the unit. We found that parents adapted the information that they shared about themselves and their babies based on the emotional proximity of their network members. They gave most detail to those who were emotionally closest to them and least to those who were less close. Parents also adapted information content to the recipient's tendency to worry and empathize. Two adaptive strategies were deployed by parents, (a) benign deceit — not telling the whole truth — and (b) promotion of empathetic members of the social network to a higher level of emotional proximity, so that they were given more information. We generated a number of directions for future work, and issues to consider around designing adaptive mediated communications systems for sensitive contexts. These include the potential to generalize our model to other medical contexts and considerations to apply when deliberately designing deceit into adaptive systems.\",\"This article presents research conducted to establish how information is shared across the personal social network in the sensitive context of a health crisis. We worked with parents of very sick babies who were cared for in a hospital's Neonatal Unit (NNU). Through a combination of interviews, a focus group, and surveys, we developed a user model of the information that parents wanted to share, and how they adapted this information to individual recipients. We then developed a prototype softwar...\",2,\"Tue 4:30 - 4:50 PM\",1429669800,1429671000,\"Authors\",null],[426,424,\"pn5147\",\"TOCHI\",\"User Experience of On-Screen Interaction Techniques: An Experimental Investigation of Clicking, Sliding, Zooming, Hovering, Dragging, and Flipping\",\"From scrolling and clicking to dragging, flipping, sliding, hovering and zooming, the wide array of interaction techniques has vastly expanded the range of user actions on an interface. Each of these interaction techniques affords a distinct action. But, do these techniques differ in their ability to engage users and contribute to their user experience? Furthermore, do they affect how users view the content and how much they learn from it? We address these questions via two between-subjects laboratory experiments. Study 1 (N = 128) investigated the relative effects of six on-screen interaction techniques (click-to-download, drag, mouseover, slide, zoom and 3D carousel) on users’ assessment of—as well as their engagement with—an informational Website. The site for each condition was identical in content and design, except for the interaction technique used, so that we could isolate the effects of each technique on various cognitive, attitudinal and behavioral outcomes. Study 2 (N = 127) examined the relative effects of four combinations of interaction techniques (slide+click, slide+mouseover, drag+mouseover and drag+zoom) on the same dependent variables. Data from Study 1 suggest that while the 3D carousel generates more user action, the slide is better at aiding memory. The zoom-in/out tool was the least favored whereas the mouseover feature fostered greater engagement among power-users. Findings from Study 2, which was conducted with a different content domain, replicated the positive effects of slide and negative effects of drag in influencing user experience. Path analyses, using structural equation modeling, revealed the importance of users’ assessment of the interface (perceived levels of natural mapping, intuitiveness and ease of use), which can have significant consequences for user engagement as well as resulting attitudes and behavioral outcomes. Design insights, theories and techniques to test and capture user experience are discussed.\",\"From scrolling and clicking to dragging, flipping, sliding, hovering and zooming, the wide array of interaction techniques has vastly expanded the range of user actions on an interface. Each of these interaction techniques affords a distinct action. But, do these techniques differ in their ability to engage users and contribute to their user experience? Furthermore, do they affect how users view the content and how much they learn from it? We address these questions via two between-subjects labo...\",2,\"Tue 4:50 - 5:10 PM\",1429671000,1429672200,\"Authors\",null],[427,424,\"pn5148\",\"TOCHI\",\"WallTop: Manage Overflowing Windows on a Large Display\",\"With the ever increasing amount of digital information, users desire more screen real estate to process daily desktop computing work, and might well benefit from using a large high-resolution display for information management. Unfortunately, we know very little about users’ behaviors when using such a display for daily computing, and current user interfaces are mainly designed for normal-sized desktop monitors, which might not well suit a large display. In this paper, we firstly present a longitudinal study that investigates how users manage overflowing digital information on a wall-sized display in a personal desktop computing context by comparing it with single and dual desktop monitors. Results showed users’ unanimous preferences of working on a large display, and revealed large-display users’ unique activity patterns of managing windows. Guided by the study results, we designed a set of interaction techniques that provide greater flexibility in managing multiple windows. They include facile methods for selecting, moving and resizing multiple windows using the active window boundary called Fringe, rearranging selected windows using multi- and single-window marking menus, packing/unpacking the selected windows using easily activated icons, and freely adjusting window overlapping order with a Jab-to-Lift operation. We coherently integrated these techniques with traditional operations in a large-display window management prototype called WallTop. Two rounds of usability testing showed that users can quickly and easily learn the new interaction techniques and apply them to realistic window management tasks on a large display with increased efficiency.\",\"With the ever increasing amount of digital information, users desire more screen real estate to process daily desktop computing work, and might well benefit from using a large high-resolution display for information management. Unfortunately, we know very little about users’ behaviors when using such a display for daily computing, and current user interfaces are mainly designed for normal-sized desktop monitors, which might not well suit a large display. In this paper, we firstly present a longi...\",2,\"Tue 5:10 - 5:30 PM\",1429672200,1429673400,\"Authors\",null],[428,-1,\"s-crs133-1\",\"Course\",\"Mobile Human-Computer Interaction 2/2\",null,null,6,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Instructor\",null],[429,428,\"crs133\",\"Course\",\"Mobile Human-Computer Interaction\",\"The objective of this course is to provide newcomers to Mobile Human-Computer Interaction (Mobile HCI) with an overview of the field. The course will introduce the four grand challenges of Mobile HCI that set this field apart from others and will discuss seven current Mobile HCI research areas that address those challenges.  \",\"The objective of this course is to provide newcomers to Mobile Human-Computer Interaction (Mobile HCI) with an overview of the field. \",6,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Instructor\",null],[430,-1,\"s-crs134-1\",\"Course\",\"Methods for HCI &nbsp;Research 2/2\",null,null,7,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Instructor\",null],[431,430,\"crs134\",\"Course\",\"Methods for Human-Computer Interaction Research\",\"This course delivers an introduction to a range of methods used in the exploration of Human-Computer Interaction (HCI) problems. Guided by leading HCI researchers and educators, attendees will be introduced to both qualitative and quantitative research methods that have been used to understand people and interactional contexts. We will also consider some of the major philosophical traditions in HCI research along with contemporary framings of HCI approaches, such as Interaction Science.\",\"Course participants will gain a new (or improved!) understanding of a range of methods used in the exploration HCI problems.\",7,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Instructor\",null],[432,-1,\"s-crs109-1\",\"Course\",\"HCI Lessons: From Earth to Outer Space 2/2\",null,null,14,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Instructor\",null],[433,432,\"crs109\",\"Course\",\"HCI Lessons: From Earth to Outer Space... and Back\",\"This storytelling course will bring, in meaningful terms, insightful concepts, methods and tools that are used in the air and space domains. HCI for complex engineered systems challenges conventional HCI solutions to propose new kinds of approaches that turn out to be very useful for solving HCI complex problems. Participants will design devices usable on Earth using accumulated knowledge and tips from aerospace experience. Creativity, in the sense of synthesis and integration, and design thinking will be at the center of this course, where participants will learn how to state and solve a complex design problem, and deliver the resulting product.\",\"This Course goes beyond the regular user interface paradigm toward human-systems integration as a whole, taking into account high-level requirements and lowest grains of detail.\",14,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Instructor\",null],[434,-1,\"s-crs131-1\",\"Course\",\"Sketching User Experiences 2/2\",null,null,9,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Instructor\",null],[435,434,\"crs131\",\"Course\",\"Sketching User Experiences: The Hands-on Course\",\"When designing novel user interfaces, paper-pencil sketches can support the design thinking process and are valuable for communicating design ideas to others. This hands-on course will demonstrate how to integrate sketching into researchers’ and interaction designers’ everyday practice – with a particular focus on the design of novel user experiences. Participants will learn essential sketching strategies, apply these in practice during many hands-on exercises, and learn the various ways of using sketches as a tool during all stages of the HCI research and design process. Our emphasis is on quick, easy to learn, and easy to apply methods for generating and refining ideas.\",\"In this hands-on sketching course participants will learn easy to apply sketching methods for generating and refining ideas for HCI research and design.\",9,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"Instructor\",null],[436,-1,\"s-sig1\",\"SIG\",\"Start and Run a SIGCHI Local Chapter\",null,null,8,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"\",\"\"],[437,436,\"sig102\",\"SIG\",\"How and Why to Start and Run a SIGCHI Local Chapter\",\"There is a vast and increasing interest towards local HCI communities around the globe and in particular on geographical areas in which HCI has only recently started to gain increasing interest by local industries as well as academic institutions. A SIGCHI Local Chapter is one of the ways a local HCI community can organize and get visibility and support for their activities. However, many active volunteers in this field might not be aware of this possibility. The main goal of the Chapters’ SIG in CHI’15 is to inform interested parties of SIGCHI Local Chapters and to find ways in which SIGCHI could better support local HCI communities with their various needs all over the world.\",\"There is a vast and increasing interest towards local HCI communities around the globe and in particular on geographical areas in which HCI has only recently started to gain increasing interest by local industries as well as academic institutions. A SIGCHI Local Chapter is one of the ways a local HCI community can organize and get visibility and support for their activities. However, many active volunteers in this field might not be aware of this possibility. The main goal of the Chapters’ SIG i...\",8,\"Tue 4:30 - 5:50 PM\",1429669800,1429674600,\"\",\"\"],[438,-1,\"special-2\",\"Special\",\"Job Fair\",null,null,15,\"Tue 6:00 - 7:30 PM\",1429675200,1429680600,\"\",\"\"],[439,-1,\"keynote-3\",\"Keynote\",\"Plenary Session - Journey to a Better Life\",null,null,15,\"Wed 8:30 - 9:20 AM\",1429727400,1429730400,\"Speaker\",null],[440,439,\"key3\",\"Keynote\",\"Journey to a Better Life\",\"New technologies and devices are coming out every day along with the rapid growth of the internet and enhancement of hardware performance. These trends are connected and tangled with each other. This era of \\\"Smart\\\" brings us great benefits and convenience, but there are still many technical hurdles and interface obstacles to be crossed. Now we are able to access massive amount of data, but at the expense of privacy and security. How can we untie this knot? We all strive for the same goal: “to make people’s lives better,” no matter how we define our role in life. In this talk, we will present what we do in LG Electronics to address this goal within the aspects of software engineering and UX design, and also discuss what we should care about when delivering innovative products to the world.\",\"New technologies and devices are coming out every day along with the rapid growth of the internet and enhancement of hardware performance. These trends are connected and tangled with each other. This era of \\\"Smart\\\" brings us great benefits and convenience, but there are still many technical hurdles and interface obstacles to be crossed. Now we are able to access massive amount of data, but at the expense of privacy and security. How can we untie this knot? We all strive for the same goal: “to ma...\",15,\"Wed 8:30 - 9:20 AM\",1429727400,1429730400,\"Speaker\",null],[441,-1,\"s-crs101\",\"Course\",\"Intro to Creating Musical Interfaces 1/2\",null,null,6,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Instructor\",null],[442,441,\"crs101\",\"Course\",\"Introduction to Creating Musical Interfaces\",\"This course provides a gentle and fun introduction to the theory and practice of interface design for creating and performing music. Our intended audience consists of those who are interested in starting projects relating to music technology. Those with a general interest are also welcome. Participants will learn key aspects of the theory and practice of musical interface design, sufficient to begin to create their own original new musical interfaces.  \",\"This course provides a gentle and fun introduction to the practice of musical interface design. Participants will gain sufficient knowledge of tools and methods to start their own projects.\",6,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Instructor\",null],[443,-1,\"s101\",\"Papers\",\"Accessibility at Home & on The Go\",null,null,12,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Chair\",\"Papers\"],[444,443,\"pn1638\",\"Paper\",\"RegionSpeak: Quick Comprehensive Spatial Descriptions of Complex Images for Blind Users\",\"Blind people often seek answers to their visual questions from remote sources, however, the commonly adopted single-image, single-response model does not always guarantee enough bandwidth between users and sources. This is especially true when questions concern large sets of information, or spatial layout,  e.g., where is there to sit in this area, what tools are on this work bench, or what do the buttons on this machine do? Our RegionSpeak system addresses this problem by providing an accessible way for blind users to (i) combine visual information across multiple photographs via image stitching, em (ii) quickly collect labels from the crowd for all relevant objects contained within the resulting large visual area in parallel, and (iii) then interactively explore the spatial layout of the objects that were labeled. The regions and descriptions are displayed on an accessible touchscreen interface, which allow blind users to interactively explore their spatial layout. We demonstrate that workers from Amazon Mechanical Turk are able to quickly and accurately identify relevant regions, and that asking them to describe only one region at a time results in more comprehensive descriptions of complex images. RegionSpeak can be used to explore the spatial layout of the regions identified. It also demonstrates  broad potential for helping blind users to answer difficult spatial layout questions.\",\"This paper introduces RegionSpeak: a system enables blind users to quickly receive answers to their complex visual questions from crowd workers. It improves and outperforms existing applications.\",12,\"Wed 9:30 - 9:50 AM\",1429731000,1429732200,\"Authors\",null],[445,443,\"pn5132\",\"TOCHI\",\"An Assisted Photography Framework to Help Visually Impaired Users Properly Aim a Camera\",\"We propose an assisted photography framework to help visually impaired users properly aim a camera and evaluate our implementation in the context of documenting public transportation accessibility. Our framework integrates user interaction during the image capturing process to help users take better pictures in real time. We use an image composition model to evaluate picture quality and suggest providing audiovisual feedback to improve users’ aiming position. With our particular framework implementation, blind participants were able to take pictures of similar quality to those taken by low vision participants without assistance. Likewise, our system helped low vision participants take pictures as good as those taken by fully sighted users. Our results also show a positive trend in favor of spoken directions to assist visually impaired users in comparison to tone and silent feedback. Positive usefulness ratings provided by full vision users further suggest that assisted photography has universal appeal.\",\"We propose an assisted photography framework to help visually impaired users properly aim a camera and evaluate our implementation in the context of documenting public transportation accessibility. Our framework integrates user interaction during the image capturing process to help users take better pictures in real time. We use an image composition model to evaluate picture quality and suggest providing audiovisual feedback to improve users’ aiming position. With our particular framework implem...\",12,\"Wed 9:50 - 10:10 AM\",1429732200,1429733400,\"Authors\",null],[446,443,\"pn1559\",\"Paper\",\"FingerReader: A Wearable Device to Explore Printed Text on the Go\",\"Accessing printed text in a mobile context is a major challenge for the blind. A preliminary study with blind people reveals numerous difficulties with existing state-of-the-art technologies including problems with alignment, focus, accuracy, mobility and efficiency. In this paper, we present a finger-worn device, FingerReader, that assists blind users with reading printed text on the go. We introduce a novel computer vision algorithm for local-sequential text scanning that enables reading single lines, blocks of text or skimming the text with complementary, multimodal feedback. This system is implemented in a small finger-worn form factor, that enables a more manageable eyes-free operation with trivial setup. We offer findings from three studies performed to determine the usability of the FingerReader.\",\"FingerReader is a finger-worn system for progressive text scanning, where the  recognized words are synthesized to audible speech. We present the computational elements and findings from evaluations with blind participants.\",12,\"Wed 10:10 - 10:30 AM\",1429733400,1429734600,\"Authors\",null],[447,443,\"pn2072\",\"Paper\",\"Collaborative Accessibility: How Blind and Sighted Companions Co-Create Accessible Home Spaces\",\"In recent decades, great technological strides have been made toward enabling people who are blind to live independent, successful lives. However, there has been relatively little progress towards understanding the social, collaborative needs of this population, particularly in the domestic setting. We conducted semi-structured interviews in the homes of 10 pairs of close companions in which one partner was blind and one was not. We found that partners engaged in collaborative accessibility by taking active roles in co-creating an accessible environment. Due to their different visual abilities, however, partners sometimes encountered difficulties managing divergent needs and engaging in shared experiences. We describe outstanding challenges to creating accessible shared home spaces and outline new research and technology opportunities for supporting collaborative accessibility in the home.\",\"This paper explores the co-constructed, collaborative nature of accessibility in the homes of couples in which one partner is blind and the other is sighted.\",12,\"Wed 10:30 - 10:50 AM\",1429734600,1429735800,\"Authors\",null],[448,-1,\"s-float-36\",\"Papers\",\"Tangible Interaction with Phones\",null,null,4,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Chair\",\"Papers\"],[449,448,\"pn1533\",\"Paper\",\"Acoustruments: Passive, Acoustically-Driven, Interactive Controls for Handheld Devices\",\"We introduce Acoustruments: low-cost, passive, and power-less mechanisms, made from plastic, that can bring rich, tangible functionality to handheld devices. Through a structured exploration, we identified an expansive vocabulary of design primitives, providing building blocks for the construction of tangible interfaces utilizing smartphones’ exist-ing audio functionality. By combining design primitives, familiar physical mechanisms can all be constructed from passive elements. On top of these, we can create end-user applications with rich, tangible interactive functionalities. Our experiments show that Acoustruments can achieve 99% accuracy with minimal training, is robust to noise, and can be rapidly prototyped. Acoustruments adds a new method to the toolbox HCI practitioners and researchers can draw upon, while introducing a cheap and passive method for adding interactive controls to consumer products.\",\"Acoustruments adds a new method to the rapid-prototyping toolbox HCI practitioners and researchers can draw upon, while introducing a cheap and passive method for adding interactive controls to consumer products.\",4,\"Wed 9:30 - 9:50 AM\",1429731000,1429732200,\"Authors\",null],[450,448,\"pn783\",\"Paper\",\"HaptiCase: Back-of-Device Tactile Landmarks for Eyes-Free Absolute Indirect Touch\",\"Using a smartphone for touch input to control apps and games mirrored to a distant screen is difficult, as the user cannot see where she is touching while looking at the distant display. We present HaptiCase, an interaction technique that provides back-of-device tactile landmarks that the user senses with her fingers to estimate the location of her finger in relation to the touchscreen. By pinching the thumb resting above the touch- screen to a finger at the back, the finger position is transferred to the front as the thumb touches the screen. In a study, we compared touch performance of different landmark layouts with a regular landmark-free mobile device. Using a land- mark design of dots on a 3x5 grid significantly improves eyes-free tapping accuracy and allows targets to be as small as 17.5 mm---a 14% reduction in target size---to cover 99% of all touches. When users can look at the touchscreen, land- marks have no significant effect on performance. HaptiCase is low-cost, requires no electronics, and works with unmodified software.\",\"An interaction technique for eyes-free absolute indirect touch based on back-of-device tactile landmarks and proprioception. Improves tapping accuracy significantly (14% target size reduction) without software modification.\",4,\"Wed 9:50 - 10:10 AM\",1429732200,1429733400,\"Authors\",null],[451,448,\"pn1054\",\"Paper\",\"The Trial of Bendi in a Coffeehouse: Use of a Shape-Changing Device for a Tactile-Visual Phone Conversation\",\"We present Bendi, a shape-changing device for a tactile-visual phone conversation. Bendi enables users to deliver shape-changing movements (e.g., upward or downward bending, left or right tilting, and shrinking) from the user’s joystick input to the other party’s device in real time during phone conversations. We conducted a user study to observe how seven couples used it over three days in a coffeehouse. Our field trial of Bendi in a coffeehouse showed the private and natural uses, and integrated uses of tactile and visual expressions along with the uses of the vocabularies developed through Bendi. In addition, there were active uses even in negative and serious conversational context with its pleasant tactile feelings and movement representations. Lastly, we discuss issues for the future designs and real-world deployment of shape-changing mobile devices for daily use.\",\"Presents Bendi, a shape-changing device for a tactile-visual phone conversation. The field trial results in a coffeehouse provide insights for the designs and real-world deployment of future shape-changing devices.\",4,\"Wed 10:10 - 10:30 AM\",1429733400,1429734600,\"Authors\",null],[452,448,\"pn312\",\"Paper\",\"SpecTrans: Versatile Material Classification for Interaction with Textureless, Specular and Transparent Surfaces\",\"Surface and object recognition is of significant importance in ubiquitous and wearable computing. While various techniques exist to infer context from material properties and appearance, they are typically neither designed for real-time applications nor for optically complex surfaces that may be specular, textureless, and even transparent. These materials are, however, becoming increasingly relevant in HCI for transparent displays, interactive surfaces, and ubiquitous computing. We present SpecTrans, a new sensing technology for surface classification of exotic materials, such as glass, transparent plastic, and metal. The proposed technique extracts optical features by employing laser and multi-directional, multi-spectral LED illumination that leverages the material's optical properties. The sensor hardware is small in size, and the proposed classification method requires significantly lower computational cost than conventional image-based methods, which use texture features or reflectance analysis, thereby providing real-time performance for ubiquitous computing. Our evaluation of the sensing technique for nine different transparent materials, including air, shows a promising recognition rate of 99.0%. We demonstrate a variety of possible applications using SpecTrans' capabilities.\",\"We present a new surface classification technology of exotic materials such as glass, transparent plastic, and metal. It extracts material’s optical properties by employing laser and multi-directional, multi-spectral LED illumination.\",4,\"Wed 10:30 - 10:50 AM\",1429734600,1429735800,\"Authors\",null],[453,-1,\"s-float-10\",\"Papers\",\"Neighborhoods & Disadvantaged Communities\",null,null,15,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Chair\",\"Papers\"],[454,453,\"pn262\",\"Paper\",\"Exploring Learning Ecologies among People Experiencing Homelessness\",\"Non-homeless youths outperform their homeless peers in school even if they live in extreme poverty. This disadvantage can have long-term consequences for engagement with and navigation of wider society.  In this paper we examine how differences in achievement could be tackled outside of school through the re-envisioning of ecologies of digital education. Through interviews, design workshops, and a street visit with a total of 20 homeless young adults during a three-week engagement with a centre for people of low social stability in Bucharest, Romania, we examine the perceptions of education among street involved youth or adults. We identify the core values, aspirations, opportunities and barriers for education among these people, including survival, friendship, learning networks, and curiosity. These findings resulted in five implications for design: learning ‘happens’, learning ‘works’, designing for distanced learning, designing for the social politics of learning, and designing artefacts of everyday learning. These show the importance and necessity of educational reform in the field of HCI. \",\"We explore educational needs, interests, and current involvement in learning among adults experiencing homelessness in Bucharest, Romania as a means to support them in the context of progression opportunity environments. \",15,\"Wed 9:30 - 9:50 AM\",1429731000,1429732200,\"Authors\",null],[455,453,\"pn389\",\"Paper\",\"The Promise of the Sharing Economy among Disadvantaged Communities\",\"The digital-sharing economy presents opportunities for individuals to find temporary employment, generate extra income, increase reciprocity, enhance social interaction, and access resources not otherwise attainable. Although the sharing economy is profitable, little is known about its use among the unemployed or those struggling financially. This paper describes the results of a participatory-design based workshop to investigate the perception and feasibility of finding temporary employment and sharing spare resources using sharing-economy applications. Specifically, this study included 20 individuals seeking employment in a U.S. city suffering economic decline. We identify success factors of the digital-sharing economy to these populations, identify shortcomings and propose mitigation strategies based on prior research related to trust, social capital and theories of collective efficacy. Finally, we contribute new principles that may foster collaborative consumption within this population and identify new concepts for practical employment applications among these populations.\",\"To the best of our knowledge, this is the first study to identify success factors of the digital-sharing economy for individuals that are un(der)employed, financially constrained, or from disadvantaged neighborhoods. \",15,\"Wed 9:50 - 10:10 AM\",1429732200,1429733400,\"Authors\",null],[456,453,\"pn1689\",\"Paper\",\"Practice-based Design of a Neighborhood Portal: Focusing on Elderly Tenants in a City Quarter Living Lab\",\"This paper contributes to the current discourse on practice-based research in HCI paying particular attention to the overall temporal and situational conditions which frame an R&D project. We present a Living Lab study situated in an arbitrary neighborhood of a German city which develops ICT support to foster informal help and social interaction with a special, but not exclusive, focus on elderly tenants. We demonstrate that practice-based, long-term research in a city quarter goes beyond those challenges already described in the current Living Lab and PD literature. The long-term study’s positioning in a real-world context is contoured not only by a high diversity of stakeholders and their individual interests and motivation for participation but also by their individual skill sets and learning needs. These distinct and often contradictive perspectives have to be permanently counterbalanced. Thus attention has to be focused on how related strategies and decisions impact on the design of the project as well as on the final ICT product. To enable all tenants, irrespective of age and technical skill, to participate in a long-term ICT-based community development project, we applied the format of ‘experience-based PD workshops’ to foster confidence in ICT usage and encourage the competency of the elderly and non-tech-savvy tenants.   \",\"We present a large-scale and long-term partipatory design project developing a socio-technical infrastructure to support a local neighborhood. Special emphasis is set on stakeholder interactions in the living lab.\",15,\"Wed 10:10 - 10:30 AM\",1429733400,1429734600,\"Authors\",null],[457,453,\"pn2238\",\"Paper\",\"This Digital Life: A Neighborhood-Based Study of Adolescents’ Lives Online\",\"In this paper, we present the results of a multi-year study of the social computing practices of 179 adolescents (Mage=12.4 years, SD=1.3; range: 10-14) living in a majority-minority lower-income urban neighborhood in the Southeast U.S. We investigate shifting social media practices using annual surveys and focus groups. We describe participants’ social media use and motivations and show how that use has shifted over time. We show how participants identify social pressures and influences as well as specific behaviors including computer-mediated risky behaviors and self-harm. We discuss the implications of our findings for the CHI research community, including methodological challenges and the need for further study of computer-mediated harmful behaviors in youth populations. By demonstrating how large-scale trends are enacted on the ground, we describe participants’ uses, motivations and behaviors as they deal with the increasing influence of technology in their social lives.\",\"This paper contributes by contextualizing social media and wireless communications technology usage trends of adolescents and uncovering certain trends associated with their emotional health and wellbeing.\",15,\"Wed 10:30 - 10:50 AM\",1429734600,1429735800,\"Authors\",null],[458,-1,\"s152\",\"Papers\",\"Enhanced Security with Passwords & CAPTCHAs\",null,null,11,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Chair\",\"Papers\"],[459,458,\"pn602\",\"Paper\",\"Towards Making Random Passwords Memorable: Leveraging Users' Cognitive Ability Through Multiple Cues\",\"Given the choice, users produce passwords reflecting common strategies and patterns that ease recall but offer uncertain and often weak security. System-assigned passwords provide measurable security but suffer from poor memorability. To address this usability-security tension, we argue that systems should assign random passwords but also help with memorization and recall. We investigate the feasibility of this approach with CuedR, a novel cued-recognition authentication scheme that provides users with multiple cues (visual, verbal, and spatial) and lets them choose the cues that best fit their learning process for later recognition of system-assigned keywords. In our lab study, all 37 of our participants could log in within three attempts one week after registration (mean login time: 38.0 seconds). A pilot study on using multiple CuedR passwords also showed 100% recall within three attempts. Based on our results, we suggest appropriate applications for CuedR, such as financial and e-commerce accounts.\",\"We design and evaluate a cued-recognition authentication scheme in which images, phrases, and spatial position combine to help users recognize system-assigned passwords with 100% accuracy in our study.\",11,\"Wed 9:30 - 9:50 AM\",1429731000,1429732200,\"Authors\",null],[460,458,\"pn1743\",\"Paper\",\"ActivPass: Your Daily Activity is Your Password\",\"This paper explores the feasibility of automatically extracting passwords from a user's daily activity logs, such as her Facebook activity, phone activity etc. As an example, a smartphone might ask the user: \\\"Today morning from whom did you receive an SMS ?\\\" In this paper, we observe that infrequent activities (i.e., outliers) can be memorable and unpredictable. Building on this observation, we have developed an end to end system ActivPass and experimented with 70 users. With activity logs from Facebook, browsing history, call logs, and SMSs, the system achieves 95% success (authenticates legitimate users) and is compromised in 5.5% cases (authenticates impostors). While this level of security is obviously inadequate for serious authentication systems, certain practices such as password sharing can immediately be thwarted from the dynamic nature of passwords. With security improvements in the future, activity-based authentication could fill in for the inadequacies in today's password-based systems.\",\"This paper explores feasibility of automatically extracting passwords from user's capture-able daily activity. This system is not secure as password but can restrict password sharing, replace hint-question based password recovery.  \",11,\"Wed 9:50 - 10:10 AM\",1429732200,1429733400,\"Authors\",null],[461,458,\"pn114\",\"Note\",\"Constructing Secure Audio CAPTCHAs by Exploiting Differences between Humans and Machines\",\"To prevent abuses of Internet services, CAPTCHAs are used to distinguish humans from programs where an audio-based scheme is beneficial to support visually impaired people. Previous studies show that most audio CAPTCHAs, albeit hard to solve for humans, are lacking security strength. In this work we propose an audio CAPTCHA that is far more robust against automated attacks than it is reported for current CAPTCHA schemes. The CAPTCHA exhibits a good trade-off between human usability and security. This is achieved by exploiting the fact that the human capabilities of language understanding and speech recognition are clearly superior compared to current machines. We evaluate the CAPTCHA security by using a state-of-the-art attack and assess the intelligibility by means of a large-scale listening experiment.\",\"An audio CAPTCHA is proposed that exploits differences in the speech recognition capabilities of humans and computers, yielding a better trade-off between usability and security compared to current schemes.\",11,\"Wed 10:10 - 10:20 AM\",1429733400,1429734000,\"Authors\",null],[462,458,\"pn434\",\"Note\",\"Easy to Draw, but Hard to Trace? On of the Observability of Grid-based (Un)lock Patterns\",\"We performed a systematic evaluation of the shoulder surfing susceptibility of the Android pattern (un)lock. The results of an online study (n=298) enabled us to quantify the influence of pattern length, line visibility, number of knight moves, number of overlaps and number of intersections on observation resistance. The results show that all parameters have a highly significant influence, with line visibility and pattern length being most important. We discuss implications for real-world patterns and present a linear regression model that can predict the observability of a given pattern. The model can be used to provide proactive security measurements for (un)lock patterns, in analogy to password meters.\",\"We performed a systematic evaluation of the shoulder surfing susceptibility of the Android pattern (un)lock. We present a prediction model and discuss implications for real-world patterns.\",11,\"Wed 10:20 - 10:30 AM\",1429734000,1429734600,\"Authors\",null],[463,458,\"pn1221\",\"Paper\",\"On the Effectiveness of Pattern Lock Strength Meters - Measuring the Strength of Real World Pattern Locks\",\"We propose an effective pattern lock strength meter to help users choose stronger pattern locks on Android devices.  To evaluate the effectiveness of the proposed meter with a real world dataset (i.e., with complete ecological validity), we created an Android application called EnCloud that allows users to encrypt their Dropbox files. 101 pattern locks generated by real EnCloud users were collected and analyzed, where some portion of the users were provided with the meter support. Our statistical analysis indicates that about 10% of the pattern locks that were generated without the meter support could be compromised through just 16 guessing attempts. As for the pattern locks that were generated with the meter support, that number goes up to 48 guessing attempts, showing significant improvement in security. Our recommendation is to implement a strength meter in the next version of Android.\",\"We evaluated the effectiveness of a pattern strength meter with complete ecological validity, showing that users find the meter useful and the meter is effective in strengthening security pattern locks.\",11,\"Wed 10:30 - 10:50 AM\",1429734600,1429735800,\"Authors\",null],[464,-1,\"s-float-28\",\"Papers\",\"UI Impact on Performance & Decisions\",null,null,5,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Chair\",\"Papers\"],[465,464,\"pn1889\",\"Paper\",\"Displayed Uncertainty Improves Driving Experience and Behavior: The Case of Range Anxiety in an Electric Car\",\"We explore the impact of the displayed precision of instrumentation estimates of range and state-of-charge on drivers’ attitudes towards an all-electric vehicle (EV), on their driving experience, and driving behavior under varying conditions of resource availability. Participants (N=73) completed a 19-mile long drive through highway, rural town and mountain road conditions in an EV that displayed high vs. low remaining range, and gave estimates of that range with high and low information ambiguity. We found that an ambiguous display of range preserved drivers’ feelings of trust towards the vehicle, despite encountering situations intended to induce severe range anxiety. Furthermore, compared to drivers facing an unambiguous display of range, drivers presented with an ambiguous range display reported improved driving experience, and exhibited driving behavior better adapted to road and remaining range conditions.\",\"We found that driving behavior and experience when operating an electric vehicle can be improved by highlighting the uncertainty of the range prediction and displaying information about remaining range ambiguously.  \",5,\"Wed 9:30 - 9:50 AM\",1429731000,1429732200,\"Authors\",null],[466,464,\"pn595\",\"Paper\",\"Designing Information for Remediating Cognitive Biases in Decision-Making\",\"Software is playing an increasingly important role in supporting human decision-making.  Previous HCI research on decision support systems (DSS) has improved the information visualization aspect of DSS information design, but has somewhat overlooked the cognitive aspect of decision-making, namely that human reasoning is heuristic and reflects systematic errors or cognitive biases. We report on an empirical study of two cognitive biases: conservatism and loss aversion. Two remediation techniques recommended by previous research were tested: the expected return method, an actuarial-inspired approach presenting objective metrics; and bootstrapping, a technique successful in improving judgment consistency. The results show that the two biases can occur simultaneously and can have a huge impact on decision-making. The results also show that the two debiasing techniques are only partly effective. These findings suggest a need for more research on debiasing, and indicate some directions for exploring debiasing techniques and building decision support systems.\",\"This study demonstrates that cognitive biases limit people's ability to make good judgments and decisions, and the debiasing methods proposed by previous research are only partly effective in remediating biases.\",5,\"Wed 9:50 - 10:10 AM\",1429732200,1429733400,\"Authors\",null],[467,464,\"pn1571\",\"Paper\",\"Quick Affective Judgments: Validation of a Method for Primed Product Comparisons\",\"A method for primed product comparisons was developed, based on the methodological considerations of emotional appraisal process and affective mental contents. The method was implemented as a computer tool, which was utilised in two experiments (N = 18 for both). Ten adjectives served as primes, and five drinking glass pictures as stimuli. Participants’ task was to choose a preference between two glasses, given the priming adjective. The results validate the method by providing test-retest reliability measures and showing convergence with questionnaires. Further, different evaluation times between the primes and the stimuli reveal the existence of different mental processes associated with various aspects of product experience, as predicted by appraisal theory. The results have various implications for experience research and development in HCI, as they demonstrate how the method can be used for product evaluation and the analysis of the mental processes, which users use to evaluate the products.\",\"A method of primed product comparisons is presented. It allows the analysis of the thinking process that occurs when products are evaluated, and the evaluation of the products themselves.\",5,\"Wed 10:10 - 10:30 AM\",1429733400,1429734600,\"Authors\",null],[468,464,\"pn1189\",\"Note\",\"Effects of Ad Quality & Content-Relevance on Perceived Content Quality.\",\"Native advertising, ads that are highly cohesive with actual content in format and style, is a pervasive online trend. We report on a two-stage Mechanical Turk experiment exploring the effects of perceived quality of native ads on perceptions of site quality. First, a set of native ads was rated (N=98) for perceived annoyance and trust. Second, we compare four conditions of an aggregation of news headlines (N=237): ‘no ads’, ‘low quality ads’, ‘high quality ads + content-relevant’, ‘high-quality ads + not content-relevant’. Our results indicate that native ads, which in isolation have been rated as high quality, could still have a negative effect on perceived site credibility and perceived site quality if they are too content-relevant. In addition to the effect of ad quality alone (e.g. non-annoying, trustworthy ads), there is an additional impact for ads that are too similar to content; avoiding confusion is important for quality perceptions.\",\"Ad experiment indicating that native ads, rated as high quality, could still have a negative effect on site perceptions if ads are too similar to content.\",5,\"Wed 10:30 - 10:40 AM\",1429734600,1429735200,\"Authors\",null],[469,-1,\"s-float-15\",\"Papers\",\"Experience Design for Games\",null,null,1,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Chair\",\"Papers\"],[470,469,\"pn1061\",\"Paper\",\"Automatic Game Progression Design through Analysis of Solution Features\",\"A long-term goal of game design research is to achieve end-to-end automation of much of the design process, one aspect of which is creating effective level progressions. A key difficulty is getting the player to practice with interesting combinations of learned skills while maintaining their engagement. Although recent work in task generation and sequencing has reduced this effort, we still lack end-to-end automation of the entire content design process. We approach this goal by incorporating ideas from intelligent tutoring systems and proposing progression strategies that seek to achieve mastery of not only base concepts but arbitrary combinations of these concepts. The input to our system is a model of what the player needs to do to complete each level, expressed as either an imperative procedure for producing solutions or a representation of features common to all solutions. The output is a progression of levels that can be adjusted by changing high-level parameters. We apply our framework to a popular math puzzle game and present results from 2,377 players showing that our automatic level progression is comparable to expert-crafted progression after a few design iterations based on a key engagement metric. \",\"We present a framework for automatically creating game progressions by analyzing the structure of solutions and compare this framework to a human-authored progression for a popular math puzzle game.\",1,\"Wed 9:30 - 9:50 AM\",1429731000,1429732200,\"Authors\",null],[471,469,\"pn2483\",\"Paper\",\"Pass the Ball: Enforced Turn-Taking in Activity Tracking\",\"We have developed a mobile application called Pass The Ball that enables users to track, reflect on, and discuss physical activity with others. We followed an iterative design process, trialling a first version of the app with 20 people and a second version with 31. The trials were conducted in the wild, on users’ own devices. The second version of the app enforced a turn-taking system that meant only one member of a group of users could track their activity at any one time. This constrained tracking at the individual level, but more successfully led users to communicate and interact with each other. We discuss the second trial with reference to two concepts: social-relatedness and individual-competence. We discuss six key lessons from the trial, and identify two high-level design implications: attend to “practices” of tracking; and look within and beyond “collaboration” and “competition” in the design of activity trackers.\",\"We have developed and evaluated a mobile application called Pass The Ball that enables users to track, reflect on, and discuss physical activity with others. \",1,\"Wed 9:50 - 10:10 AM\",1429732200,1429733400,\"Authors\",null],[472,469,\"pn1296\",\"Paper\",\"The Data Driven Lives of Wargaming Miniatures\",\"We present an ethnographic study of the practice of miniature wargaming in order to shed light onto the complex lives of physical things and the ways in which they acquire data footprints. We take an extended view of the practice, revealing how people invest great effort into crafting miniatures, playing with them, curating and telling stories about them, and passing them on. Throughout, we emphasise the use of both traditional and digital technologies to build rich data footprints. In discussing our findings, we adopt a ‘thing-centric’ perspective that focuses on the extended lifetimes of the miniatures themselves. This enables us to identify opportunities for digital augmentation in support of capturing ‘life away from the table’ and a need for HCI to focus on designing trajectories of things. \",\"An Internet of Things informed investigation of the complex lives of physical objects and their data footprints using wargaming miniatures.\",1,\"Wed 10:10 - 10:30 AM\",1429733400,1429734600,\"Authors\",null],[473,469,\"pn1727\",\"Paper\",\"Provenance for the People: An HCI Perspective on the W3C PROV Standard through an Online Game\",\"In the information age, tools for examining the validity of data are invaluable. Provenance is one such tool, and the PROV model proposed by the World Wide Web Consortium in 2013 offers a means of expressing provenance in a machine readable format. In this paper, we examine from a user’s standpoint notions of provenance, the accessibility of the PROV model, and the general attitudes towards history and the verifiability of information in modern data society. We do this through the medium of an online-game designed to explore these issues and present the findings of the study along with a discussion of some of its implications.\",\"This paper examines the W3C PROV Standard through an online game and offers insight on its accessibility as well as general user perceptions to its use in the real world.\",1,\"Wed 10:30 - 10:50 AM\",1429734600,1429735800,\"Authors\",null],[474,-1,\"s-alt4\",\"alt.chi\",\"Arts and Philosophy\",null,null,2,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Authors\",\"Papers\"],[475,474,\"alt142\",\"alt.chi\",\"Reimagining Digital Fabrication as Performance Art\",\"\",\"...\",2,\"Wed 9:30 - 9:50 AM\",1429731000,1429732200,\"Authors\",\"Papers\"],[476,474,\"alt157\",\"alt.chi\",\"Behind The Scenes at HCI’s Turn To The Arts\",\"\",\"...\",2,\"Wed 9:50 - 10:10 AM\",1429732200,1429733400,\"Authors\",\"Papers\"],[477,474,\"alt152\",\"alt.chi\",\"Touch Of The Eye: Does Observation Reflect Haptic Metaphors In Art Drawing?\",\"\",\"...\",2,\"Wed 10:10 - 10:30 AM\",1429733400,1429734600,\"Authors\",\"Papers\"],[478,474,\"alt159\",\"alt.chi\",\"Games Against Health: A Player-Centered Design Philosophy\",\"\",\"...\",2,\"Wed 10:30 - 10:50 AM\",1429734600,1429735800,\"Authors\",\"Papers\"],[479,-1,\"s-float-16\",\"Papers\",\"Player Performance & Experience in Games\",null,null,10,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Chair\",\"Papers\"],[480,479,\"pn2627\",\"Paper\",\"The Goal of Scoring: Exploring the Role of Game Performance in Educational Games\",\"In this paper the role of game performance as an assessment tool is explored and an approach is presented for designing and assessing learning-centered game scores. In recent years, attention has shifted from focusing on games for learning to games for assessment. The research question this paper tries to address is how valid games are as an assessment tool, and more specifically, how valid the use of game scores are as a measure of assessment. To explore this use, we looked at the role of game performance in a game where the goals were designed based on its learning objectives. We hypothesized that because of this design the scores could be used as a measure of learning. The results of our mixed-methods study confirmed this hypothesis. However, the scores are influenced by factors such as computer skills and age. Further analysis revealed that the design of the game and the game-based training were also of influence. These insights will help in designing better predictive game scores in the future.\",\"A need exists for guidelines and evidence for games for assessment. We present a design approach for creating learning-centered game scores and validated this through a unique mixed-methods study.\",10,\"Wed 9:30 - 9:50 AM\",1429731000,1429732200,\"Authors\",null],[481,479,\"pn448\",\"Paper\",\"Moving Beyond Fun: Evaluating Serious Experience in Digital Games\",\"Games are normally considered to be “fun”, though recently there is growing interest in how gameplay can promote empathy and encourage reflection through “serious experience”. However, when looking beyond enjoyment, it is not clear how to actually evaluate serious experience. We present an evaluation of four games that were submitted to a student game design competition; the competition challenged teams to design a game that inspired curiosity around human error and blame culture within the context of healthcare. The entries were judged by a panel of six experts and subjected to a round of play testing by twelve participants. Methods included gameplay observation, questionnaires, post-play interviews and follow-up email questions. We discuss the utility of these methods, with particular emphasis on how they enabled a consideration of the immediate and longer term impact of serious experience on players. \",\"We present a methodology for evaluating serious experience in digital games and discuss how our methods enabled a consideration of gameplay in terms of immediate and longer term impact.\",10,\"Wed 9:50 - 10:10 AM\",1429732200,1429733400,\"Authors\",null],[482,479,\"pn605\",\"Paper\",\"Now You Can Compete With Anyone: Balancing Players of Different Skill Levels in a First-Person Shooter Game\",\"When player skill levels differ widely in a competitive First-Person Shooter (FPS) game, enjoyment suffers: weaker players become frustrated and stronger players become less engaged. Player balancing techniques attempt to assist the weaker player and make games more competitive, but these techniques have limitations for deployment when skill levels vary substantially. We developed new player balancing schemes to deal with a range of FPS skill difference, and tested these techniques in one-on-one deathmatches using a commercial-quality FPS game developed with the UDK engine. Our results showed that the new balancing schemes are extremely effective at balancing, even for players with large skill differences. Surprisingly, the techniques that were most effective at balancing were also rated as most enjoyable by both players – even though these schemes were the most noticeable. Our study is the first to show that player balancing can work well in realistic FPS games, providing developers with a way to increase the audience for this popular genre. In addition, our results demonstrate the idea that successful balancing is as much about the way the technique is applied as it is about the specific manipulation.\",\"We developed and tested new player balancing techniques for First Person Shooters, which we found were effective at balancing players with largely different skill levels and increasing game enjoyment.\",10,\"Wed 10:10 - 10:30 AM\",1429733400,1429734600,\"Authors\",null],[483,479,\"pn1687\",\"Paper\",\"All about that Base: Differing Player Experiences in Video Game Genres and the Unique Case of MOBA Games\",\"Video games provide unique interactive player experiences (PX) often categorised into different genres. Prior research has looked at different game genres, but rarely through a PX lens. Especially, PX in the emerging area of massive online battle arena (MOBA) games is not well understood by researchers in the field. We address this knowledge gap by presenting a PX study of different game genres, which we followed up with a second semi-structured interview study about PX in MOBA games. Among the results of our analyses are that games that are likely played with other players, such as MOBA games, stimulate less immersion and presence for players. Additionally, while challenge and frustration are significantly higher in this genre, players get a sense of satisfaction from teamwork, competition and mastery of complex gameplay interactions. Our study is the first to contribute a comprehensive insight into key motivators of MOBA players and how PX in this genre is different from other genres.\",\"The study explored variations in player experience of videogames and an interesting pattern of results with respect to MOBA games (compared to other genres) was explored in greater detail. \",10,\"Wed 10:30 - 10:50 AM\",1429734600,1429735800,\"Authors\",null],[484,-1,\"s-crs116\",\"Course\",\"Speech-based Interaction 1/2\",null,null,14,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Instructor\",null],[485,484,\"crs116\",\"Course\",\"Speech-based Interaction: Myths, Challenges, and Opportunities\",\"HCI research has for long been dedicated to better and more naturally facilitating information transfer between humans and machines. Unfortunately, humans' most natural form of communication, speech, is also one of the most difficult modalities to be understood by machines – despite, and perhaps, because it is the highest-bandwidth communication channel we possess. While significant research efforts, from engineering, to linguistic, and to cognitive sciences, have been spent on improving machines' ability to understand speech, the HCI community has been relatively timid in embracing this modality as a central focus of research. This can be attributed in part to the relatively discouraging levels of accuracy in understanding speech, in contrast with often-unfounded claims of success from industry, but also to the intrinsic difficulty of designing and especially evaluating speech and natural language interfaces.  The goal of this course is to inform the CHI community of the current state of speech and natural language research, to dispel some of the myths surrounding speech-based interaction, as well as to provide an opportunity for researchers and practitioners to learn more about how speech recognition and speech synthesis work, what are their limitations, and how they could be used to enhance current interaction paradigms. Through this, we hope that CHI researchers and general HCI, UI, and UX practitioners will learn how to combine recent advances in speech processing with user-centred principles in designing more usable and useful speech-based interactive systems.\",\"Learn how speech recognition and synthesis works, what are its limitations and usability challenges, how can it enhance interaction paradigms, and what is the current research and commercial state-of-the-art.\",14,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Instructor\",null],[486,-1,\"s-crs121\",\"Course\",\"Designing Surveys for HCI Research 1/2\",null,null,9,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Instructor\",null],[487,486,\"crs121\",\"Course\",\"Designing Surveys for HCI Research\",\"Online surveys are widely used in human-computer interaction (HCI) to gather feedback and measure satisfaction; at a glance many tools are available and the cost of conducting surveys appears low. However, there is a wide gap between quick-and-dirty surveys, and surveys that are properly planned, constructed, and analyzed. This course examines survey research approaches that meet HCI goals, selecting the appropriate sampling method, questionnaire design best practices, identifying and avoiding common survey biases, and questionnaire evaluation. Attendees will gain an appreciation for the breadth and depth of surveys in HCI, combined with keys to conducting valid, reliable, and impactful survey research themselves.\",\"Through both lecture material and interactive group activities, gain a practical understanding of the survey research lifecycle, including sampling considerations, questionnaire design, questionnaire biases, and evaluation.\",9,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Instructor\",null],[488,-1,\"s166\",\"Papers\",\"HMDs in Augmented & Virtual Reality\",null,null,3,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Chair\",\"Papers\"],[489,488,\"pn954\",\"Paper\",\"Eye-Wearable Technology for Machine Maintenance: Effects of Display Position and Hands-free Operation\",\"Exciting developments in eye-wearable technology and its potential industrial applications warrant a thorough understanding of its advantages and drawbacks through empirical evidence. We conducted an experiment to investigate what characteristics of eye-wearable technology impact user performance in machine maintenance, which included a representative set of car maintenance tasks involving Locate, Manipulate, and Compare actions. Participants were asked to follow instructions displayed on one of four technologies: a peripheral eye-wearable display, a central eye-wearable display, a tablet, or a paper manual. We found a significant effect of display position: the peripheral eye-wearable display resulted in longer completion time than the central display; but no effect of hands-free operation. The technology effects were also modulated by different Tasks and Action types. We discuss the human factors implications for designing more effective eye-wearable technology, including display position, issues of monocular display, and how the physical proximity of the technology affects users’ reliance level.  \",\"We conducted an experiment to investigate what characteristics of eye-wearable technology impact user performance in machine maintenance. We found a significant effect of display position, but no effect of hands-free operation.\",3,\"Wed 9:30 - 9:50 AM\",1429731000,1429732200,\"Authors\",null],[490,488,\"pn1709\",\"Note\",\"Belt: An Unobtrusive Touch Input Device for Head-worn Displays\",\"Belt is a novel unobtrusive input device for wearable displays that incorporates a touch surface encircling the user's hip. The wide input space is leveraged for a horizontal spatial mapping of quickly accessible information and applications. We discuss social implications and interaction capabilities for unobtrusive touch input and present our hardware implementation and a set of applications that benefit from the quick access time. In a qualitative user study with 14 participants we found out that for short interactions (2-4 seconds), most of the surface area is considered as appropriate input space, while for longer interactions (up to 10 seconds), the front areas above the trouser pockets are preferred.\",\"We introduce a touch-enabled belt as a novel unobtrusive input device for headworn-displays with immediate access to information leveraging users’ spatial mapping around their hip.\",3,\"Wed 9:50 - 10:00 AM\",1429732200,1429732800,\"Authors\",null],[491,488,\"pn273\",\"Note\",\"Content Destabilization for Head-Mounted Displays\",\"With recent progress in display technology, visual see-through head-mounted displays are beginning to enter our everyday lives. Especially in cars they may replace head-up displays, as they can theoretically perfectly imitate them but are more flexible to use. However, prior work has shown that both screen- and vehicle-stabilized content suffer from drawbacks such as occlusion or technological limitations. As a potential alternative, we propose three concept alternatives, in which head rotation is used to manipulate the displayed content differently from both of the known stabilization techniques. In a qualitative user study, we identify the best concept proposal and then evaluate it against the established content stabilization techniques. The presented concept is perceived to be more applicable for the proposed use case and effectively reduces some of the known problems of both stabilization techniques.\",\"We present new concept approaches for presenting content in a Head-mounted Display for car drivers. The best concept efficiently reduces known problems of screen- and vehicle-stabilized content (occlusion, tracking-related problems).\",3,\"Wed 10:00 - 10:10 AM\",1429732800,1429733400,\"Authors\",null],[492,488,\"pn1323\",\"Paper\",\"A Dose of Reality: Overcoming Usability Challenges in VR Head-Mounted Displays\",\"We identify usability challenges facing consumers adopting Virtual Reality (VR) head-mounted displays (HMDs) in a survey of 108 VR HMD users. Users reported significant issues in interacting with, and being aware of their real-world context when using a HMD. Building upon existing work on blending real and virtual environments, we performed three design studies to address these usability concerns. In a typing study, we show that augmenting VR with a view of reality significantly corrected the performance impairment of typing in VR. We then investigated how much reality should be incorporated and when, so as to preserve users' sense of presence in VR. For interaction with objects and peripherals, we found that selectively presenting reality as users engaged with it was optimal in terms of performance and users' sense of presence. Finally, we investigated how this selective, engagement-dependent approach could be applied in social environments, to support the user's awareness of the proximity and presence of others.\",\"Elicits the usability issues with consumer VR headsets. Explores how to interact with reality from VR, proposing reality be incorporated selectively, based on users’ engagement, preserving their sense of presence. \",3,\"Wed 10:10 - 10:30 AM\",1429733400,1429734600,\"Authors\",null],[493,488,\"pn182\",\"Note\",\"Accuracy of Pedometry on a Head-mounted Display\",\"The accuracy of pedometry varies depending on where an inertial sensor is located on the body. Motivated by the increasing popularity of wearable computing, this paper investigates the accuracy with which pedometry can be achieved on a head-mounted device: something previous research has not investigated. A study with 16 subjects compares the accuracy of pedometry for walking and running with an inertial sensor located at the head, pocket and hand/arm. Our study did not detect a significant difference in step counting accuracy between sensor locations, which demonstrates the feasibility of pedometry-based apps for head-mounted displays. \",\"The accuracy of pedometry varies with where an inertial sensor is worn. With the increasing popularity of smart glass devices, we investigate the accuracy of pedometry for the head location and find no accuracy difference.\",3,\"Wed 10:30 - 10:40 AM\",1429734600,1429735200,\"Authors\",null],[494,488,\"pn665\",\"Note\",\"Level-Ups: Motorized Stilts that Simulate Stair Steps in Virtual Reality\",\"We present “Level-Ups”, computer-controlled stilts that allow virtual reality users to experience walking up and down steps. Each Level-Up unit is a self-contained device worn like a boot. Its main functional element is a vertical actuation mechanism mounted to the bottom of the boot that extends vertically. Unlike traditional solutions that are integrated with locomotion devices, Level-Ups allow users to walk around freely (“real-walking”). We present Level-Ups in a demo environment based on a head-mounted display, optical motion capture, and integrated with two different game engines. In a user study, participants rated the realism of stepping onto objects 6.0 out of 7.0 when wearing Level-Ups compared to 3.5 without.\",\"Introducing Level-Ups, motorized stilts that allow virtual reality users to experience walking up and down steps. The main benefit of our approach is its applicability to real-walking in virtual worlds.\",3,\"Wed 10:40 - 10:50 AM\",1429735200,1429735800,\"Authors\",null],[495,-1,\"s159\",\"Papers\",\"Telepresence Video, Robots, and Walls\",null,null,13,\"Wed 9:30 - 10:50 AM\",1429731000,1429735800,\"Chair\",\"Papers\"],[496,495,\"pn271\",\"Paper\",\"ImmerseBoard: Immersive Telepresence Experience using a Digital Whiteboard\",\"ImmerseBoard is a system for remote collaboration through a digital whiteboard that gives participants a 3D immersive experience, enabled only by an RGBD camera (Microsoft Kinect) mounted on the side of a large touch display. Using 3D processing of the depth images, life-sized rendering, and novel visualizations, ImmerseBoard emulates writing side-by-side on a physical whiteboard, or alternatively on a mirror. User studies involving three tasks show that compared to standard video conferencing with a digital whiteboard, ImmerseBoard provides participants with a quantitatively better ability to estimate their remote partners’ eye gaze direction, gesture direction, intention, and level of agreement. Moreover, these quantitative capabilities translate qualitatively into a heightened sense of being together and a more enjoyable experience. ImmerseBoard’s form factor is suitable for practical and easy installation in homes and offices.\",\"ImmerseBoard emulates writing side-by-side on a physical whiteboard, or alternatively on a mirror for remote collaboration, enabled by an RGBD camera mounted on the side of a large touch display.\",13,\"Wed 9:30 - 9:50 AM\",1429731000,1429732200,\"Authors\",null],[497,495,\"pn1688\",\"Note\",\"Accuracy of Deictic Gestures to Support Telepresence on Wall-sized Displays\",\"This paper presents a controlled experiment assessing the accuracy when interpreting remote users showing a shared object on a large wall-sized display, either by looking at it or by looking and pointing at it. We analyze both distance and angle errors and how they are sensitive to the relative position be- tween the remote viewer and the video feed. We show that the remote user can accurately determine the target, that eye gaze alone is more accurate than combined with the hand, and that the relative position between the viewer and the video feed has little effect on accuracy. These findings can inform the design of future telepresence systems for wall-sized displays.\",\"A controlled experiment assessing how accurately a user can interpret the video feed of a remote user pointing or looking at a shared object on a large wall-sized display.\",13,\"Wed 9:50 - 10:00 AM\",1429732200,1429732800,\"Authors\",null],[498,495,\"pn2196\",\"Paper\",\"Can You See Me Now? How Field of View Affects Collaboration in Robotic Telepresence\",\"Robotic telepresence systems-videoconferencing systems that allow a remote user to drive around in another location-are an emerging technology for supporting geographically-distributed teams. Thus far, many of these systems rely on affordances designed for stationary systems, such as a single, narrow-view camera to provide vision for the remote user. Teleoperation has offered some solutions to this via an augmented field-of-view, but how these solutions support task outcomes in collaborative mobile telepresence tasks has yet to be understood. To investigate this, we conducted a three condition (field-of-view: narrow (45°) vs. wide-angle (180°) vs. panoramic (360°)) between-participants controlled laboratory experiment. We asked participants (N=24) to collaborate with a confederate via a robotic telepresence system while using one of these views in a redecoration task.  Our results showed that wider views supported task efficiency and fewer collisions, but were perceived as more difficult to use.\",\"We present the results of an experiment examining the effects of field-of-view on collaborative outcomes in the context of robotic telepresence systems.\",13,\"Wed 10:00 - 10:20 AM\",1429732800,1429734000,\"Authors\",null],[499,495,\"pn5112\",\"TOCHI\",\"Sharing Domestic Life through Long-Term Video Connections\",\"Video chat systems such as Skype, Google+ Hangouts, and FaceTime have been widely adopted by family members and friends to connect with one another over distance. We have conducted a corpus of studies that explore how various demographics make use of such video chat systems where this usage moves beyond the paradigm of conversational support to one in which aspects of everyday life are shared over long periods of time, sometimes in an almost passive manner.  We describe and reflect on studies of long-distance couples, teenagers, and major life events, along with design research focused on new video communication systems—the Family Window, Family Portals, and Perch—that explicitly support ‘always-on video’ for awareness and communication. Overall, our findings show that people highly value long-term video connections and have appropriated them in a number of different ways.  Designers of future video communication systems need to consider: ways of supporting the sharing of everyday life, rather than just conversation; providing different design solutions for different locations and situations; providing appropriate audio control and feedback; and, supporting expressions of intimacy over distance.\",\"Video chat systems such as Skype, Google+ Hangouts, and FaceTime have been widely adopted by family members and friends to connect with one another over distance. We have conducted a corpus of studies that explore how various demographics make use of such video chat systems where this usage moves beyond the paradigm of conversational support to one in which aspects of everyday life are shared over long periods of time, sometimes in an almost passive manner.  We describe and reflect on studies of...\",13,\"Wed 10:20 - 10:40 AM\",1429734000,1429735200,\"Authors\",null],[500,-1,\"wip-3\",\"WIPs\",\"Work in Progress Exhibit\",null,null,15,\"Wed 10:50 - 11:30 AM\",1429735800,1429738200,\"\",\"\"],[501,-1,\"int-3\",\"Interactivity\",\"Interactivity Demos Exhibit\",null,null,15,\"Wed 10:50 - 11:30 AM\",1429735800,1429738200,\"\",\"\"],[502,-1,\"break-7\",\"Breaks\",\"Coffee Break\",null,null,15,\"Wed 10:50 - 11:30 AM\",1429735800,1429738200,\"\",\"\"],[503,-1,\"s103\",\"Papers\",\"Quantified Self&nbsp;for Humans &&nbsp;Pets&nbsp;\",null,null,12,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Chair\",\"Papers\"],[504,503,\"pn413\",\"Paper\",\"Change of Heart: Emotion Tracking to Promote Behavior Change\",\"Preventable behaviors contribute to many life threatening health problems. Behavior-change technologies have been deployed to modify these, but such systems typically draw on traditional behavioral theories that overlook affect. We examine the importance of emotion tracking for behavior change. First, we conducted interviews to explore how emotions influence unwanted behaviors. Next, we deployed a system intervention, in which 35 participants logged information for a self-selected, unwanted behavior (e.g., smoking or overeating) over 21 days. 16 participants engaged in standard behavior tracking using a Fact-Focused system to record objective information about goals. 19 participants used an Emotion-Focused system to record emotional consequences of behaviors. Emotion-Focused logging promoted more successful behavior change and analysis of logfiles revealed mechanisms for success: greater engagement of negative affect for unsuccessful days and increased insight were key to motivating change. We present design implications to improve behavior-change technologies with emotion tracking.\",\"Compared the reduction of undesired behaviors through use of a factual, self-monitoring system against one that emphasized emotional reflection. Emotional reflection corresponded to greater success, suggesting design improvements for behavior-change technologies.\",12,\"Wed 11:30 - 11:50 AM\",1429738200,1429739400,\"Authors\",null],[505,503,\"pn563\",\"Paper\",\"Beyond Self-Tracking and Reminders: Designing Smartphone Apps That Support Habit Formation\",\"Habit formation is an important part of behavior change interventions: to ensure an intervention has long-term effects, the new behavior has to turn into a habit and become automatic. Smartphone apps could help with this process by supporting habit formation. To better understand how, we conducted a 4-week study exploring the influence of different types of cues and positive reinforcement on habit formation and reviewed the functionality of 115 habit formation apps. We discovered that relying on reminders supported repetition but hindered habit development, while the use of event-based cues led to increased automaticity; positive reinforcement was ineffective. The functionality review revealed that existing apps focus on self-tracking and reminders, and do not support event-based cues. We argue that apps, and technology-based interventions in general, have the potential to provide real habit sup¬port, and present design guidelines for interventions that could support habit formation through contextual cues and implementation intentions.\",\"Habit formation apps focus on self-tracking and reminders: functionality that does not support the process of habit formation. We present design guidelines for apps that help people form new habits.\",12,\"Wed 11:50 - 12:10 PM\",1429739400,1429740600,\"Authors\",null],[506,503,\"pn688\",\"Paper\",\"Problematising Upstream Technology through Speculative Design: The Case of Quantified Cats and Dogs\",\"There is growing interest in technology that quantifies aspects of our lives. This paper draws on critical practice and speculative design to explore, question and problematise the ultimate consequences of such technology using the quantification of companion animals (pets) as a case study. We apply the concept of ‘moving upstream’ to study such technology and use a qualitative research approach in which both pet owners, and animal behavioural experts, were presented with, and asked to discuss, speculative designs for pet quantification applications, the design of which were extrapolated from contemporary trends. Our findings indicate a strong desire among pet owners for technology that has little scientific justification, whilst our experts caution that the use of technology to augment human-animal communication has the potential to disimprove animal welfare, undermine human-animal bonds, and create human-human conflicts. Our discussion informs wider debates regarding quantification technology.\",\"We use speculative design to explore and question the ultimate consequences of quantifying everything in our lives, using pets as a case study.\",12,\"Wed 12:10 - 12:30 PM\",1429740600,1429741800,\"Authors\",null],[507,503,\"pn2412\",\"Paper\",\"Re-Centering Multispecies Practices: A Canine Interface for Cancer Detection Dogs\",\"We report on participatory design research where interaction designers, and canine behavioral specialists, together with their cancer detection dogs, teamed up to better support the dogs’ life-saving work. We discuss interspecies communication challenges in cancer detection training, requiring the dogs to use human signaling conventions that perturb their detection work. We describe our effort to develop a technology that could resolve those challenges, and how in the process our design focus gradually shifted from a human-centered to a canine-centered interaction model. The resulting interface, based on honest signaling, re-centers cancer detection practices on the dogs themselves, enabling them to better express their potential as cancer detection workers; it also provides a model for re-thinking human-computer interactions.\",\"We present a canine-centered interface enabling cancer detection dogs to express more reliably and precisely their responses about the content of the biological samples that they screen. \",12,\"Wed 12:30 - 12:50 PM\",1429741800,1429743000,\"Authors\",null],[508,-1,\"s143\",\"Papers\",\"Visualizing Statistics & Graphs\",null,null,13,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Chair\",\"Papers\"],[509,508,\"pn697\",\"Paper\",\"(s|qu)eries: Visual Regular Expressions for Querying and Exploring Event Sequences\",\"Many different domains collect event sequence data and rely on finding and analyzing patterns within it to gain meaningful insights. Current systems that support such queries either provide limited expressiveness, hinder exploratory workflows or present interaction and visualization models which do not scale well to large and multi-faceted data sets. In this paper we present (s|qu)eries (pronounced \\\"Squeries\\\"), a visual query interface for creating queries on sequences (series) of data, based on regular expressions. (s|qu)eries is a touch-based system that exposes the full expressive power of regular expressions in an approachable way and interleaves query specification with result visualizations. Being able to visually investigate the results of different query-parts supports debugging and encourages iterative query-building as well as exploratory work-flows. We validate our design and implementation through a set of informal interviews with data scientists that analyze event sequences on a daily basis. \",\"(s|qu)eries is a visual query interface for creating queries over event sequences based on regular expressions. It interleaves query specification with result visualizations for iterative query-building as well as exploratory work-flows.\",13,\"Wed 11:30 - 11:50 AM\",1429738200,1429739400,\"Authors\",null],[510,508,\"pn1142\",\"Paper\",\"Statsplorer: Guiding Novices in Statistical Analysis\",\"Each step of statistical analysis requires researchers to make decisions based on both statistical knowledge and the knowledge of their own data. For novice analysts, this is cognitively demanding and can lead to mistakes and misinterpretations of the results. We present Statsplorer, a software that helps novices learn and perform inferential statistical tests. It lets the user kick-start data analysis from their research questions. Statsplorer automatically tests necessary statistical assumptions and uses visualizations to guide the user in both selecting statistical tests and interpreting the results. We compared Statsplorer with a statistics lecture and investigated how Statsplorer prepares novices for learning statistics in an AB/BA crossover experiment. The results indicates that using Statsplorer prior to the lecture leads to significantly better test scores in understanding statistical assumptions and choosing appropriate statistical tests. Statsplorer is open-source and is available online at: http://hci.rwth-aachen.de/statsplorer. \",\"Presents Statsplorer, a software tool that helps novices perform and learn statistical analysis. \",13,\"Wed 11:50 - 12:10 PM\",1429739400,1429740600,\"Authors\",null],[511,508,\"pn592\",\"Note\",\"Investigating the Direct Manipulation of Ranking Tables for Time Navigation\",\"We introduce a novel time navigation technique to update ranking tables by direct manipulation. The technique allows users to drag a table's cells to change the time period, while a line chart overlays on top of the table to provide an overview of the changes. The line chart is also a visual hint to control the pace at which data are updated. We explore the design and usability of this technique for table variations in size, time spans and data variability. We report the results of a usability study, using academic citation rankings and economic complexity datasets, and discuss design implications coming with real-world scenarios such as missing data and affordance.\",\"We introduce a novel time navigation technique to update ranking tables by direct manipulation using a line chart to display changes and control animation.\",13,\"Wed 12:10 - 12:20 PM\",1429740600,1429741200,\"Authors\",null],[512,508,\"pn2539\",\"Note\",\"Dynamic Opacity Optimization for Scatter Plots\",\"Scatterplots are an effective and commonly used technique to show the relationship between two variables. However, as the number of data points increases, the chart suffers from “over-plotting” which obscures data points and makes the underlying distribution of the data difficult to discern. Reducing the opacity of the data points is an effective way to address over-plotting, however, setting the individual point opacity is a manual task performed by the chart designer. We present a user-driven model of opacity scaling for scatter plots built from crowd-sourced responses to opacity scaling tasks using several synthetic data distributions, and then test our model on a collection of real-world data sets.\",\"We present a model of opacity-scaling for scatter plots derived from user preferences. The output from our model can be easily integrated into existing scatter plot implementations, making them more useful in over-plotting scenarios.\",13,\"Wed 12:20 - 12:30 PM\",1429741200,1429741800,\"Authors\",null],[513,508,\"pn1289\",\"Paper\",\"Evaluating How Level of Detail of Visual History Affects Process Memory\",\"Visual history tools provide visual representations of the workflow during data analysis tasks. While there is an established need for reviewing analytic processes, and many visual history tools provide visualizations to do so, it is not well known how helpful the tools actually are for process recall. Through a controlled experiment, we evaluated how the presence of a visual history aid and varying levels of visual detail affect process memory. Participants conducted an analysis task using a visual text-document analysis tool. We evaluated their memories of the process both immediately after the analysis and then again one week later. Results showed that even visual history views with reduced data-resolution were effective for aiding process memory. Further, even without inclusion of any data in the visual history aids, the visual cues alone from the final workspace were enough to improve memory of the main themes of analyses.\",\"We evaluated how the presence of a visual history aid and varying levels of visual detail affect process memory. Even visual history views with reduced details were helpful for recall.\",13,\"Wed 12:30 - 12:50 PM\",1429741800,1429743000,\"Authors\",null],[514,-1,\"s104\",\"Papers\",\"Art & Performance\",null,null,10,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Chair\",\"Papers\"],[515,514,\"pn2300\",\"Note\",\"What if HCI Becomes a Fashion Driven Discipline?\",\"Recent research shows that fashion already exists in the HCI domain and influences and affects design and designers’ thinking and practices throughout the design process. In this note, we draw our insights from fashion related research within HCI and interaction design, provide some observations about fashion-related design and research practices, raise questions about our field as moving forward towards fashion driven discipline. \",\"Our paper provides some insights about fashion-related design and research practices, raises questions about our field as moving forward towards fashion driven discipline.\",10,\"Wed 11:30 - 11:40 AM\",1429738200,1429738800,\"Authors\",null],[516,514,\"pn2272\",\"Note\",\"The Smartphone Project - An Augmented Dance Performance\",\"The Smartphone Project (TSP) is an interactive dance-performance in a professional setting that exploits the communication channels provided by smartphone-apps as a new material in the dance-theatre domain. We present an account of the experience and its staging. Based on an initial study with 36 participants from the audience, we present results and discuss lessons learned from this project that might guide similar future work. \",\"The Smartphone Project is a novel interactive dance-performance in a professional theatre setting that explores the smartphone as a material and an artistic medium. It premiered at the Pina40 festival.\",10,\"Wed 11:40 - 11:50 AM\",1429738800,1429739400,\"Authors\",null],[517,514,\"pn682\",\"Paper\",\"I’d Hide You: Performing Live Broadcasting in Public\",\"We present a study of a mixed reality game called 'I'd Hide You' that involves live video streaming from the city streets. We chart the significant challenges facing performers on the streets who must simultaneously engage in the game, stream compelling video footage featuring themselves, and interact with a remote online audience. We reveal how these street performers manage four key tensions: between their body and camera; between the demands of online audiences and what takes place on-the-street; between what appears 'frontstage' on camera versus what happens 'backstage'; and balancing being a player of the game with being a performer. By reflecting on how they achieve this, we are able to draw out wider lessons for future interfaces aimed at supporting people broadcasting video of themselves to online audiences while engaged in games, sports and other demanding real-world activities.\",\"Ethnographic study of a mixed reality game involving live video broadcast from city streets. Identifies key tensions that broadcasters must manage and develops implications for future broadcasting scenarios.\",10,\"Wed 11:50 - 12:10 PM\",1429739400,1429740600,\"Authors\",null],[518,514,\"pn383\",\"Paper\",\"Making the Invisible Visible: Design to Support the Documentation of Participatory Arts Experiences\",\"We explore how digital technology might support the documentation of experiences of participatory arts engagement. During a fourteen session workshop series, we worked with artists, project managers, support workers and participants to explore the integration of digital media capture and presentation technologies into participatory arts workshops, and the implications that this would have for the experiences and practices of key stakeholders involved. We contribute insight into the social and practical challenges faced when using digital technology to create documentation of participatory arts. Our findings highlight the importance of situating documentation, sense making and re-telling of experiences in sensitive contexts such as participatory arts within the practices of skilled interpreters that are mindful of the complexities involved.\",\"Reveals the importance of situating documentation, sense making and re-telling of experiences in sensitive contexts such as participatory arts within the practices of skilled interpreters, mindful of the complexities involved.\",10,\"Wed 12:10 - 12:30 PM\",1429740600,1429741800,\"Authors\",null],[519,514,\"pn517\",\"Paper\",\"Trap it! : A Playful Human-Biology Interaction for a Museum Installation\",\"We developed Trap it!, a human-biology interaction (HBI) medium encompassing a touchscreen interface, microscopy, and light projection. Users can interact with living cells by drawing on a touchscreen displaying the microscope view of the cells. These drawings are projected onto the microscopy field as light patterns, prompting observable movement in phototactic responses. The system design enables stable and robust HBI and a wide variety of programmed activities (art, games, and experiments). We investigated its affordances as an exhibit in a science museum in both facilitated and unfacilitated contexts. Overall, it had a low barrier of entry and fostered rich communication among visitors. Visitors were particularly excited upon realizing that the interaction involved real organisms, an understanding that was facilitated by the eyepiece on the physical system. With the results from user study, we provide our observations, insights and guidelines for designing HBI as a permanent museum exhibit.\",\"Describes construction of an interactive installation encompassing living microorganisms, opto-electronic hardware, touchscreen interface and playful activities; Presents the system’s affordances in a museum environment\",10,\"Wed 12:30 - 12:50 PM\",1429741800,1429743000,\"Authors\",null],[520,-1,\"s160\",\"Papers\",\"Tactile Notifications for Phones & Wearables\",null,null,4,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Chair\",\"Papers\"],[521,520,\"pn1114\",\"Paper\",\"OmniVib: Towards Cross-body Spatiotemporal Vibrotactile Notifications for Mobile Phones\",\"Previous works illustrate that one’s palm can reliably recognize 10 or more spatiotemporal vibrotactile patterns. However, recognition of the same patterns on other body parts is unknown. In this paper, we investigate how users perceive spatiotemporal vibrotactile patterns on the arm, palm, thigh, and waist. Results of the first two experiments indicate that precise recognition of either position or orientation is difficult across multiple body parts. Nonetheless, users were able to distinguish whether two vibration pulses were from the same location when played in quick succession. Based on this finding, we designed eight spatiotemporal vibrotactile patterns and evaluated them in two additional experiments. The results demonstrate that these patterns can be reliably recognized (>80%) across the four tested body parts, both in the lab and in a more realistic context.\",\"OmniVib is a set of spatiotemporal vibrotactile patterns for mobile devices that can be accurately recognized on four body sites: arm, palm, thigh and waist.\",4,\"Wed 11:30 - 11:50 AM\",1429738200,1429739400,\"Authors\",null],[522,520,\"pn1149\",\"Note\",\"NotiRing: A Comparative Study of Notification Channels for Wearable Interactive Rings\",\"We conducted an empirical investigation of wearable interactive rings on the noticeability of four instantaneous notification channels (light, vibration, sound, poke) and a channel with gradually increased temperature (thermal) during five levels of physical activity (laying down, sitting, standing, walking, and running). Results showed that vibration was the most reliable and fastest channel to convey notification, followed by poke and sound which shared similar noticeability. The noticeability of these three channels was not affected by the level of physical activity. The other two channels, light and thermal, were less noticeable and were affected by the level of physical activity. Our post-experimental survey indicates that while noticeability has a significant influence on user preference, each channel has its own unique advantages that make it suitable for different notification scenarios.\",\"In NotiRing, we investigated the noticeability of five notifications channels over five levels of physical activity.\",4,\"Wed 11:50 - 12:00 PM\",1429739400,1429740000,\"Authors\",null],[523,520,\"pn1763\",\"Note\",\"Skin Drag Displays: Dragging a Physical Tactor across the User’s Skin Produces a Stronger Tactile Stimulus than Vibrotactile\",\"We propose a new type of tactile displays that drag a physical tactor across the skin in 2D. We call this skin drag. We demonstrate how this allows us to communicate geometric shapes or characters to users. The main benefit of our approach is that it simultaneously produces two types of stimuli, i.e., (1) it moves a tactile stimulus across skin locations and (2) it stretches the user’s skin. Skin drag thereby combines the essential stimuli produced by vibrotactile and skin stretch. In our study, skin drag allowed participants to recognize tactile shapes significantly better than a vibrotactile array of comparable size. We present two arm-worn prototype devices that implement our concept.\",\"We propose skin drag, a new type of tactile display that drags a physical tactor across the skin in 2D. We demonstrate how it outperforms vibrotactile for communicating geometric shapes.\",4,\"Wed 12:00 - 12:10 PM\",1429740000,1429740600,\"Authors\",null],[524,520,\"pn399\",\"Paper\",\"Cruise Control for Pedestrians: Controlling Walking Direction using Electrical Muscle Stimulation\",\"Pedestrian navigation systems require users to perceive, interpret, and react to navigation information. This can tax cognition as navigation information competes with information from the real world. We propose actuated navigation, a new kind of pedestrian navigation in which the user does not need to attend to the navigation task at all. An actuation signal is directly sent to the human motor system to influence walking direction. To achieve this goal we stimulate the sartorius muscle using electrical muscle stimulation. The rotation occurs during the swing phase of the leg and can easily be counteracted. The user therefore stays in control. We discuss the properties of actuated navigation and present a lab study on identifying basic parameters of the technique as well as an outdoor study in a park. The results show that our approach changes a user’s walking direction by about 16°/m on average and that the system can successfully steer users in a park with crowded areas, distractions, obstacles, and uneven ground.\",\"Actuated navigation is a new kind of pedestrian navigation that automatically controls walking direction by direct stimulation of the human locomotion system. This approach reduces cognitive load.\",4,\"Wed 12:10 - 12:30 PM\",1429740600,1429741800,\"Authors\",null],[525,520,\"pn115\",\"Paper\",\"Affordance++: Allowing Objects to Communicate Dynamic Use\",\"We propose extending the affordance of objects by allowing them to communicate dynamic use, such as (1) motion (e.g., spray can shakes when touched), (2) multi-step processes (e.g., spray can sprays only after shaking), and (3) behaviors that change over time (e.g., empty spray can does not allow spraying anymore). Rather than enhancing objects directly, however, we implement this concept by enhancing the user. We call this affordance++. By stimulating the user’s arms using electrical muscle stimulation, our prototype allows objects not only to make the user actuate them, but also perform required movements while merely approaching the object, such as not to touch objects that do not “want” to be touched. In our user study, affordance++ helped participants to successfully operate devices of poor natural affordance, such as a multi-functional slicer tool or a magnetic nail sweeper, and to stay away from cups filled with hot liquids.\",\"Affordance++ allows everyday objects to communicate dynamic use: motion (spray can shakes when touched), multi-step processes (peeling an avocado), and behaviors that change over time (don't grab the hot cup by its body!).  \",4,\"Wed 12:30 - 12:50 PM\",1429741800,1429743000,\"Authors\",null],[526,-1,\"s-float-27\",\"Papers\",\"Bridging People & Beliefs with Social Media\",null,null,15,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Chair\",\"Papers\"],[527,526,\"pn409\",\"Paper\",\"Modeling Ideology and Predicting Policy Change with Social Media: Case of Same-Sex Marriage\",\"Social media has emerged as a prominent platform where people can express their feelings about social and political issues of our time. We study the many voices discussing an issue within a constituency and how they reflect ideology and may signal the outcome of important policy decisions. Focusing on the issue of same-sex marriage legalization, we examine almost 2 million public Twitter posts related to same-sex marriage in the U.S. states over the course of 4 years starting from 2011. Among other findings, we find evidence of moral culture wars between ideologies and show that constituencies that express higher levels of emotion and have fewer actively engaged participants often precede legalization efforts that fail. From our measures, we build statistical models to predict the outcome of potential policy changes, with our best model achieving 87% accuracy. We also achieve accuracies of 70%, comparable to public opinion surveys, many months before a policy decision. We discuss how these analyses can augment traditional political science techniques as well as assist activists and policy analysts in understanding discussions on important issues at a population scale.\",\"We study discussions related to the issue of same-sex marriage within constituencies on Twitter and analyze how they reflect ideology and may signal the outcome of important policy decisions.\",15,\"Wed 11:30 - 11:50 AM\",1429738200,1429739400,\"Authors\",null],[528,526,\"pn1506\",\"Paper\",\"“Is it Weird to Still Be a Virgin?:” Anonymous, Locally Targeted Questions on Facebook Confession Boards\",\"People have long sought answers to questions online, typically using either anonymous or pseudonymous forums or social network platforms that primarily use real names. Systems that allow anonymous communication afford freedom to explore identity and discuss taboo topics, but can result in negative disinhibited behavior such as cyberbullying. Identifiable communication systems allows one to reach a known audience and avoid negative disinhibition, but can constrain behavior with concerns about privacy and reputation. One persistent design issue is understanding how to leverage the benefits of anonymity without suffering its drawbacks. This paper presents a case study analysis of question asking on Facebook confession boards (FCBs), a tool popular on some college campuses. FCBs present a unique configuration in which members of an offline community (e.g., a university) anonymously submit content to a moderator who posts it to a Facebook page where others in the community can view it and respond. Response is via identifiable Facebook comments and likes. Our results show users asking about taboo and stigmatized topics with local others, and receiving relevant responses with little cyberbullying or negativity.\",\"Examines social media question asking by college students on anonymous, locally targeted forums; results show constructive information seeking about taboo topics and stigmatized identity.\",15,\"Wed 11:50 - 12:10 PM\",1429739400,1429740600,\"Authors\",null],[529,526,\"pn1032\",\"Paper\",\"Social Media Dynamics of Global Co-presence During the 2014 FIFA World Cup\",\"Sporting championships and other media events can induce very strong feelings of co-presence that can change communication patterns within large communities. Live tweeting reactions to media events provide high-resolution data with time-stamps to understand these behavioral dynamics. We employ a computational focus group method to identify a population of 790,744 international Twitter users, and we track their behavior before, during, and after the 2014 FIFA World Cup. We pick, in particular, a set of Twitter users who specified the teams that they are supporting, such that we can identify communities of fans of the teams, as well as the entire community of World Cup fans. The structure, dynamics, and content of communication of these communities of users are analyzed to compare behavior outside of the matches to behavior during the event and to examine behavioral responses across languages. Specifically, the temporal patterns of the tweeting volume, topics, retweet- ing, and mentioning behaviors are analyzed. We find there are similarities in the responses to media events, characteristic changes in activity patterns of users, and substantial differences in linguistic features. These findings have implications for designing more resilient socio-technical systems during crises and developing better models of complex social behavior.\",\"We employ a computational focus group method to identify a population of 790,744 international Twitter users, and track their behavior before, during, and after the 2014 FIFA World Cup.\",15,\"Wed 12:10 - 12:30 PM\",1429740600,1429741800,\"Authors\",null],[530,526,\"pn242\",\"Paper\",\"Bridges into the Unknown: Personalizing Connections to Little-known Countries\",\"How are you related to Malawi? Do recent events on the Comoros effect you in any subtle way? Who in your extended social network is in Croatia? We seldom ask ourselves these questions, yet a \\\"long tail\\\" of content beyond our everyday knowledge is waiting to be explored. In this work we propose a recommendation task of creating interest in little-known content by building personalized \\\"bridges\\\" to users. We consider an example task of interesting users in little-known countries, and propose a system which aggregates a user's Twitter profile, network, and tweets to create an interest model, which is then matched to a library of knowledge about the countries. We perform a user study of 69 participants and conduct 11 in-depth interviews in order to evaluate the efficacy of the proposed approach and gather qualitative insight into the effect of multi-faceted use of Twitter on the perception of the bridges. We find the increase in interest concerning little-known content to greatly depend on the pre-existing disposition to it. Additionally, we discover a set of vital properties good bridges must possess, including recency, novelty, emotiveness, and a proper selection of language. Using the proposed approach we aim to harvest the \\\"invisible connections\\\" to make explicit the idea of a \\\"small world\\\" where even a faraway country is more closely connected to you than you might have imagined.\",\"We propose a task of encouraging interest in little- or un-known information by providing personalized \\\"bridges\\\" to users, utilizing their social media presence, including their posts and social connections.\",15,\"Wed 12:30 - 12:50 PM\",1429741800,1429743000,\"Authors\",null],[531,-1,\"s169\",\"Papers\",\"Foundations & Trends in HCI 2\",null,null,11,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Chair\",\"Papers\"],[532,531,\"pn5137\",\"TOCHI\",\"Choice Architecture for Human-Computer Interaction\",\"People in human-computer interaction have learned a great deal about how to persuade and influence users of computing technology. They have much less well-founded knowledge about how to help users choose for themselves. It's time to correct this imbalance. A first step is to organize the vast amount of relevant knowledge that has been built up in psychology and related fields in terms of two comprehensive but easy-to-remember models: The ASPECT model answers the question \\\"How do people make choices?\\\" by describing six choice patterns that choosers apply alternately or in combination, based on Attributes, Social influence, Policies, Experience, Consequences, and Trial and error. The ARCADE model answers the question \\\"How can we help people make better choices?\\\" by describing six general high-level strategies for supporting choice: Access information and experience, Represent the choice situation, Combine and compute, Advise about processing, Design the domain, and Evaluate on behalf of the chooser. These strategies can be implemented with straightforward interaction design, but for each one there are also specifically relevant technologies. Combining these two models, we can understand virtually all existing and possible approaches to choice support as the application of one or more of the ARCADE strategies to one or more of the ASPECT choice patterns. After introducing the idea of choice architecture for human-computer interaction and the key ideas of the ASPECT and ARCADE models, we discuss each of the ASPECT patterns in detail and show how the high-level ARCADE strategies can be applied to it to yield specific tactics. We then apply the two models in the domains of online communities and privacy. Most of our examples concern choices about the use of computing technology, but the models are equally applicable to everyday choices made with the help of computing technology. \",\"People in human-computer interaction have learned a great deal about how to persuade and influence users of computing technology. They have much less well-founded knowledge about how to help users choose for themselves. It's time to correct this imbalance. A first step is to organize the vast amount of relevant knowledge that has been built up in psychology and related fields in terms of two comprehensive but easy-to-remember models: The ASPECT model answers the question \\\"How do people make choi...\",11,\"Wed 11:30 - 11:50 AM\",1429738200,1429739400,\"Authors\",null],[533,531,\"pn5154\",\"TOCHI\",\"Designing for Healthy Lifestyles: Design Considerations for Mobile Technologies to Encourage Consumer Health and Wellness\",\"As the rates of lifestyle diseases such as obesity, diabetes, and heart disease continue to rise, the development of effective tools that can help people adopt and sustain healthier habits is becoming ever more important. Mobile computing holds great promise for providing effective support for helping people manage their health in everyday life. Yet, for this promise to be realized, mobile wellness systems need to be well designed, not only in terms of how they implement specific behavior-change techniques but also, among other factors, in terms of how much burden they put on the user, how well they integrate into the user’s daily life, and how they address the user’s privacy concerns. Designing for all of these constraints is difficult, and it is often not clear what tradeoffs particular design decisions have on how a wellness application is experienced and used. In this monograph, we provide an account of different design approaches to common features of mobile wellness applications and we discuss the tradeoffs inherent in those approaches. We also outline the key challenges that HCI researchers and designers will need to address to move the state of the art for mobile wellness technologies forward.\",\"As the rates of lifestyle diseases such as obesity, diabetes, and heart disease continue to rise, the development of effective tools that can help people adopt and sustain healthier habits is becoming ever more important. Mobile computing holds great promise for providing effective support for helping people manage their health in everyday life. Yet, for this promise to be realized, mobile wellness systems need to be well designed, not only in terms of how they implement specific behavior-change...\",11,\"Wed 11:50 - 12:10 PM\",1429739400,1429740600,\"Authors\",null],[534,-1,\"s-float-46\",\"Papers\",\"Automation and Interactive Feedback\",null,null,5,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Chair\",\"Papers\"],[535,534,\"pn2147\",\"Paper\",\"“Automation Surprise” in Aviation: Real-Time Solutions\",\"Conflicts between the pilot and the automation, when pilots detect but do not understand them, cause “automation surprise” situations and jeopardize flight safety. We conducted an experiment in a 3-axis motion flight simulator with 16 pi- lots equipped with an eye-tracker to analyze their behavior and eye movements during the occurrence of such a situation. The results revealed that this conflict engages participant’s attentional abilities resulting in excessive and inefficient visual search patterns. This experiment confirmed the crucial need to design solutions for detecting the occurrence of conflictual situations and to assist the pilots. We therefore proposed an approach to formally identify the occurrence of “automation surprise” conflicts based on the analysis of “silent mode changes” of the autopilot. A demonstrator was implemented and allowed for the automatic trigger of messages in the cockpit that explains the autopilot behavior. We implemented a real-time demonstrator that was tested as a proof-of-concept with 7 subjects facing 3 different conflicts with automation. The results shown the efficacy of this approach which could be implemented in existing cockpits.\",\"This research assesses the cognitive impact of automation surprises on pilots’ cognitive abilities. A real-time demonstrator is then implemented to assist pilots when facing conflicts with automation.  \",5,\"Wed 11:30 - 11:50 AM\",1429738200,1429739400,\"Authors\",null],[536,534,\"pn2651\",\"Paper\",\"The Role of Environmental Predictability and Costs in Relying on Automation\",\"There is a growing need to understand how automated decision aids are implemented and relied upon by users. Past research has focused on factors associated with the user and automation technology to explain reliance. The purpose of the present study was determining how the predictability of the environment affects reliance. In this paper, we present the results from an experiment using a digital game where participants had access to a free environmental cue of varying predictive validity. Some participants also had access to automated advice at varying costs. We found that participants underutilized automated advice in more predictable environments and when advice was more costly; however, when costs were low and the environment was less predictable, participants tended to overutilize automated advice. These findings provide insights for a more complete model of automation use, and offer a framework for understanding automation biases by considering how automation use compares to a model of optimality.\",\"This work adds to a framework for understanding when automation biases occur and a model for identifying that biases have occurred while suggesting a possible design solution by implementing costs.\",5,\"Wed 11:50 - 12:10 PM\",1429739400,1429740600,\"Authors\",null],[537,534,\"pn551\",\"Paper\",\"An Architecture for Generating Interactive Feedback in Probabilistic User Interfaces\",\"Increasingly natural, sensed, and touch-based input is being integrated into devices. Along the way, both custom and more general solutions have been developed for dealing with the uncertainty that is associated with these forms of input. However, it is difficult to provide dynamic, flexible, and continuous feedback about uncertainty using traditional interactive infrastructure. Our contribution is a general architecture with the goal of providing support for continual feedback about uncertainty. Our architecture is based on prior work in modeling uncertainty using Monte Carlo sampling, and tracks multiple interfaces – one for each plausible and differentiable sequence of input that the user may have intended. Importantly, it considers how the presentation of uncertainty can be organized and implemented in a general way. Our primary contribution is a method for reducing the number of alternative interfaces and fusing possible interfaces into a single interface that both communicates uncertainty and allows for disambiguation. We demonstrate the value of this result through a collection of 11 new and existing feedback techniques along with two applications demonstrating the use of the feedback architecture.\",\"General user interface architecture with the goal of providing support for continual feedback about uncertainty.\",5,\"Wed 12:10 - 12:30 PM\",1429740600,1429741800,\"Authors\",null],[538,534,\"pn361\",\"Paper\",\"IDSense: A Human Object Interaction Detection System Based on Passive UHF RFID\",\"In order to enable unobtrusive human object interaction detection, we propose a minimalistic approach to instrumenting everyday objects with passive (i.e. battery-free) UHF RFID tags. By measuring the changes in the physical layer of the communication channel between the RFID tag and reader (such as RSSI, RF phase, and read rate) we are able to classify, in real time, tag/object motion events along with two types of touch events. Through a user study, we demonstrate that our real-time classification engine is able to simultaneously track 20 objects and identify four movement classes with 93% accuracy. To demonstrate how robust this general-purpose interaction mechanism is, we investigate three usage scenarios 1) interactive storytelling with toys 2) inference of daily activities in the home 3) identification of customer browsing habits in a retail setting.  \",\"IDSense is capable of detecting and classifying, in real-time, tag/object motion events along with two types of touch events by minimally augmenting objects with low cost and long-lived RFID tags\",5,\"Wed 12:30 - 12:50 PM\",1429741800,1429743000,\"Authors\",null],[539,-1,\"s-panel3\",\"Panel\",\"Transdisciplinary Design in Education\",null,null,1,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"\",\"\"],[540,539,\"pan109\",\"Panel\",\"Transdisciplinary Interaction Design in Design Education\",\"Transdisciplinary design—which is the idea of design that transcends disciplinary boundaries—has been proposed as a fourth design paradigm of interaction design education, scholarship, and practice alongside the technical, cognitive, and ethnographic paradigms. As an educational concern in particular, its aim is to teach students how to bring a values orientation to interaction design. Its focuses are design frameworks, values and ethics, design for important themes such as sustainability, equity, adaptation, justice, and social responsibility. This panel maps the state of the art in transdisciplinary interaction design education, considering also design scholarship and practice in relation to design education. The panel collects together a group of educators from chosen to provide a global perspective, with panelists from Canada, Denmark, Hong Kong, Korea, and Taiwan.\",\"Transdisciplinary design—which is the idea of design that transcends disciplinary boundaries—has been proposed as a fourth design paradigm of interaction design education, scholarship, and practice alongside the technical, cognitive, and ethnographic paradigms. As an educational concern in particular, its aim is to teach students how to bring a values orientation to interaction design. Its focuses are design frameworks, values and ethics, design for important themes such as sustainability, equit...\",1,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"\",\"\"],[541,-1,\"s156\",\"Papers\",\"Human Computer Interaction Journal 2\",null,null,2,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Chair\",\"Papers\"],[542,541,\"pn5149\",\"TOCHI\",\"What Designers Talk About When They Talk About Context\",\"Context has long been considered an important component of design, but as technology becomes more capable of inferring the user’s behavior and environment, what constitutes context has become an increasingly pressing concern to designers. Although design frameworks and models have been proposed for context-aware computing systems, there has not yet been research that focuses on understanding context empirically from the perspective of the designer. To address this, we present an analysis of 11 in-depth interviews we conducted with designers of a variety of context-aware systems. Our analysis of the artifacts and interviews reveal five concerns designers address in their work. Furthermore, we present a process model that illustrates how context-aware system designers address these concerns. Our findings demonstrate the central role that designers’ views of context plays in (a) framing a design space, (b) encoding the relevant features of context, (c) unifying possible solutions within that design space, and (d) evaluating designs. These findings suggest that context is a dynamic concept that evolves over the course of a design project, generally from a more phenomenological perspective toward a positivist interpretation. This, and the process by which it occurs, contributes insight into context-aware design with implications for both academics and practitioners.\",\"Context has long been considered an important component of design, but as technology becomes more capable of inferring the user’s behavior and environment, what constitutes context has become an increasingly pressing concern to designers. Although design frameworks and models have been proposed for context-aware computing systems, there has not yet been research that focuses on understanding context empirically from the perspective of the designer. To address this, we present an analysis of 11 i...\",2,\"Wed 11:30 - 11:50 AM\",1429738200,1429739400,\"Authors\",null],[543,541,\"pn5150\",\"TOCHI\",\"Multi-sited Design: An Analytical Lens for Transnational HCI\",\"In this article, we present and articulate the analytical lens of multi-sited design to illuminate transnational connections between sites of design, and aid in the translation of knowledge between designers and ethnographers. This position emerges from the authors’ respective engagements in ethnographic research and design engagements with a slum community center in Bangkok, Thailand, and with ‘‘makers’’ and entrepreneurs in Shanghai and Shenzhen, China. In both cases,we found design to be a site of engagement with and interpretation of wider connections between different locales, and between local and global networks. We identify four crucial aspects of design for the purposes of this discussion: It is normative, concerned with function and the attainment of goals; it is practical, and oriented toward constraints and opportunities; it frames and defines problems concurrently with solving them; and it takes a systems approach that accounts for the broad context of the design situation. Approaching and participating in these aspects of design evolved in concert with our ethnographic fieldwork and analysis, allowing us to take design seriously without sacrificing an ethnographic commitment to nuanced description. We conclude by touching on the epistemological similarities, rather than conflicts, between ethnography and design.\",\"In this article, we present and articulate the analytical lens of multi-sited design to illuminate transnational connections between sites of design, and aid in the translation of knowledge between designers and ethnographers. This position emerges from the authors’ respective engagements in ethnographic research and design engagements with a slum community center in Bangkok, Thailand, and with ‘‘makers’’ and entrepreneurs in Shanghai and Shenzhen, China. In both cases,we found design to be a si...\",2,\"Wed 11:50 - 12:10 PM\",1429739400,1429740600,\"Authors\",null],[544,541,\"pn5145\",\"TOCHI\",\"A Design Thinking Rationality Framework: Framing and Solving Design Problems in Early Concept Generation\",\"The concept of “Design Thinking” opens up debate regarding the prevalent human–computer interaction design practice. This article focuses specifically on the cognitive processes of designers during their early design activities. Two groups of designers—experts and novices—were asked to develop a fictitious vacuum cleaner. We then examined the different ways in which these groups manage their design thinking processes and how the groups choose design concepts. The empirical study revealed that expert designers are effective at framing design problems. They make quick decisions (through the use of the affect heuristic) but are more wedded to their own previously developed design concepts, which they do not change in subsequent design stages. In contrast, novice designers are less skilled in framing new design problems but better able to renounce their initial design concepts. These diverse design thinking approaches are linked to potential problems. We then discuss how to address these concerns in conjunction with empathy for the artifact (i.e., artifact empathy via the mediated self) or user (i.e., user empathy via the simulated self), problem framing with second-order semantic connotations, and irrationality when analyzing design solutions. Finally, we propose a design thinking rationality framework that can establish a designer's view of design activities and thereby assist designers educated in both creative and rational design decisions.\",\"The concept of “Design Thinking” opens up debate regarding the prevalent human–computer interaction design practice. This article focuses specifically on the cognitive processes of designers during their early design activities. Two groups of designers—experts and novices—were asked to develop a fictitious vacuum cleaner. We then examined the different ways in which these groups manage their design thinking processes and how the groups choose design concepts. The empirical study revealed that ex...\",2,\"Wed 12:10 - 12:30 PM\",1429740600,1429741800,\"Authors\",null],[545,541,\"pn5146\",\"TOCHI\",\"A Situated Approach of Roles and Participation in Open Source Software Communities\",\"Our research aims at understanding the various forms of participation in Open Source Software (OSS) design, seen as distributed design in online spaces of actions - discussion, implementation and boundary between these spaces. We propose a methodology - based on situated analyses of a formal design process used in the Python project- to identify the distribution of actual roles (implementation, interactive, group and design oriented) performed by participants into and between the spaces (defining boundary spaces). This notion of roles is grounded in collaborative design activities performed online by participants. This way, our findings complete the core-periphery model of participation in OSS. Concerning the distribution of roles between spaces, we reveal a map of participation in OSS: the majority of participants are pure discussants but all participants in the implementation spaces do also act in the discussion space and only few participants act at boundary spaces. Concerning the distribution of roles between participants in the discussion space, we reveal that interactions are structured by a central hub (occupied by key-participants) and that, whereas design-oriented roles are spread among all participants, group-oriented roles are performed by one or two participants in the respective spaces and at their boundary. Finally, combination of roles reveals five individual profiles performed by participants. Our approach could be extended to other design situations to explore relationships between forms of participation- in particular those revealing use-oriented contributions- performance, and quality of the design product. Finally, it could be a basis for specifying tools to monitor and manage community activity for both research issues and support of online community. \",\"Our research aims at understanding the various forms of participation in Open Source Software (OSS) design, seen as distributed design in online spaces of actions - discussion, implementation and boundary between these spaces. We propose a methodology - based on situated analyses of a formal design process used in the Python project- to identify the distribution of actual roles (implementation, interactive, group and design oriented) performed by participants into and between the spaces (definin...\",2,\"Wed 12:30 - 12:50 PM\",1429741800,1429743000,\"Authors\",null],[546,-1,\"s-float-49\",\"Papers\",\"Digital & Materials Fabrication\",null,null,3,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Chair\",\"Papers\"],[547,546,\"pn1088\",\"Paper\",\"Foundations of Materials Experience: An Approach for HCI\",\"A growing number of HCI scholars have started to take materiality as an entry point for acquiring a deeper understanding of the possibilities and constraints of design. Steadily moving beyond a distinction between the physical and the digital, a few have also started to look at materials as part of the unfolding of social and cultural practices. Yet, to date, relatively little is known about how these practices develop within the situated experience of materials, and how this situational whole can be supported by design. By contributing to both growing materiality scholarship and emerging practice-oriented approaches in HCI, this paper articulates a framework of materials experience that discusses how materials shape ways of doing and ultimately, practice, and how this is rooted in the experience of those materials. \",\"The proposed framework of materials experience discusses how materials shape 'ways of doing' and ultimately social and cultural practices, and how this is rooted in the experience of those materials.\",3,\"Wed 11:30 - 11:50 AM\",1429738200,1429739400,\"Authors\",null],[548,546,\"pn1911\",\"Paper\",\"PaperPulse: An Integrated Approach for Embedding Electronics in Paper Designs\",\"We present PaperPulse, a design and fabrication approach that enables designers without a technical background to produce standalone interactive paper artifacts by augmenting them with electronics. With PaperPulse, designers overlay pre-designed visual elements with widgets available in our design tool. PaperPulse provides designers with three families of widgets designed for smooth integration with paper, for an overall of 20 different interactive components. We also contribute a logic demonstration and recording approach, Pulsation, that allows for specifying functional relationships between widgets. Using the final design and the recorded Pulsation logic, PaperPulse generates layered electronic circuit designs, and code that can be deployed on a microcontroller. By following automatically generated assembly instructions, designers can seamlessly integrate the microcontroller and widgets in the final paper artifact.\",\"PaperPulse a design and fabrication tool that enables designers without a technical background to produce standalone interactive paper artifacts using printed electronics.\",3,\"Wed 11:50 - 12:10 PM\",1429739400,1429740600,\"Authors\",null],[549,546,\"pn631\",\"Paper\",\"Data-Things: Digital Fabrication Situated within Participatory Data Translation Activities\",\"This paper explores a design-led approach to digital fabrication which situates it in participatory data translation activities to demonstrate that this technology can find application beyond its use as tool for manufacture. We present two contrasting design contexts in which, respectively, data from conference twitter conversations and craft practitioners’ movements are translated into interactively generated and fabricated physical artefacts. We argue that direct involvement in such digital fabrication activities can help people invest meaning into artefacts and facilitate social interaction and reflection upon their activities, while encouraging practitioners to incorporate new forms into their own work. On this basis, we reconsider digital fabrication within data translation activities as situated along an extended ‘trajectory of use’ in which reflective, meaningful ‘data-things’ can be created.\",\"This design-led paper explores how direct involvement in digital fabrication through data translation activities can help people invest meaning into artefacts, facilitate reflection and encourages hybrid research practices.\",3,\"Wed 12:10 - 12:30 PM\",1429740600,1429741800,\"Authors\",null],[550,546,\"pn2312\",\"Paper\",\"Being the Machine: Reconfiguring Agency and Control in Hybrid Fabrication\",\"This paper details the design and evaluation of Being the Machine, a portable digital fabrication system that places digital fabrication activity outside of the traditional fab lab environment. Being the Machine invites people to (re)consider materials found in their everyday and personal environment as part of the fabrication activity. We expand the design space involving hybrid (physical-digital) fabrication by describing how our system draws from art to support critical and reflective modes of making. In interaction with our system, participants distributed control between human and machine actors to support their preferred mode of making. These patterns reveal new opportunities and challenges for future hybrid fabrication systems, and suggest that designing for qualities of experience, like meditation and reflection, could support meaningful making experiences for many different kinds of makers.\",\"We present a hybrid-fabrication system that subverts an expected relationship between humans and machines in making. Our study revealed new roles for fabrication systems to play within physical making practices.\",3,\"Wed 12:30 - 12:50 PM\",1429741800,1429743000,\"Authors\",null],[551,-1,\"s-src\",\"Special\",\"Student Research Competition Finals\",null,null,7,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"\",\"\"],[552,551,\"src\",\"Special\",\"Student Research Competition\",\"\",\"...\",7,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"\",\"\"],[553,-1,\"s-crs116-1\",\"Course\",\"Speech-based Interaction 2/2\",null,null,14,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Instructor\",null],[554,553,\"crs116\",\"Course\",\"Speech-based Interaction: Myths, Challenges, and Opportunities\",\"HCI research has for long been dedicated to better and more naturally facilitating information transfer between humans and machines. Unfortunately, humans' most natural form of communication, speech, is also one of the most difficult modalities to be understood by machines – despite, and perhaps, because it is the highest-bandwidth communication channel we possess. While significant research efforts, from engineering, to linguistic, and to cognitive sciences, have been spent on improving machines' ability to understand speech, the HCI community has been relatively timid in embracing this modality as a central focus of research. This can be attributed in part to the relatively discouraging levels of accuracy in understanding speech, in contrast with often-unfounded claims of success from industry, but also to the intrinsic difficulty of designing and especially evaluating speech and natural language interfaces.  The goal of this course is to inform the CHI community of the current state of speech and natural language research, to dispel some of the myths surrounding speech-based interaction, as well as to provide an opportunity for researchers and practitioners to learn more about how speech recognition and speech synthesis work, what are their limitations, and how they could be used to enhance current interaction paradigms. Through this, we hope that CHI researchers and general HCI, UI, and UX practitioners will learn how to combine recent advances in speech processing with user-centred principles in designing more usable and useful speech-based interactive systems.\",\"Learn how speech recognition and synthesis works, what are its limitations and usability challenges, how can it enhance interaction paradigms, and what is the current research and commercial state-of-the-art.\",14,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Instructor\",null],[555,-1,\"s-crs121-1\",\"Course\",\"Designing Surveys for HCI Research 2/2\",null,null,9,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Instructor\",null],[556,555,\"crs121\",\"Course\",\"Designing Surveys for HCI Research\",\"Online surveys are widely used in human-computer interaction (HCI) to gather feedback and measure satisfaction; at a glance many tools are available and the cost of conducting surveys appears low. However, there is a wide gap between quick-and-dirty surveys, and surveys that are properly planned, constructed, and analyzed. This course examines survey research approaches that meet HCI goals, selecting the appropriate sampling method, questionnaire design best practices, identifying and avoiding common survey biases, and questionnaire evaluation. Attendees will gain an appreciation for the breadth and depth of surveys in HCI, combined with keys to conducting valid, reliable, and impactful survey research themselves.\",\"Through both lecture material and interactive group activities, gain a practical understanding of the survey research lifecycle, including sampling considerations, questionnaire design, questionnaire biases, and evaluation.\",9,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Instructor\",null],[557,-1,\"s-sig2\",\"SIG\",\"Online Deliberative Processes and Tech\",null,null,8,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"\",\"\"],[558,557,\"sig104\",\"SIG\",\"Design for Online Deliberative Processes and Technologies: Towards a Multidisciplinary Research Agenda\",\"There has been rapidly growing interest in studying and designing online deliberative processes and technologies. This SIG aims at providing a venue for continuous and constructive dialogue between social, political and cognitive sciences as well as computer science, HCI, and CSCW. Through an online community and a modified version of world cafe discussions, we contribute to the definition of the theoretical building blocks, the identification of a research agenda for the CHI community, and the network of individuals from academia, industry, and the public sector who share interests in different aspects of online deliberation.\",\"There has been rapidly growing interest in studying and designing online deliberative processes and technologies. This SIG aims at providing a venue for continuous and constructive dialogue between social, political and cognitive sciences as well as computer science, HCI, and CSCW. Through an online community and a modified version of world cafe discussions, we contribute to the definition of the theoretical building blocks, the identification of a research agenda for the CHI community, and the ...\",8,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"\",\"\"],[559,-1,\"s-crs101-1\",\"Course\",\"Intro to Creating Musical Interfaces 2/2\",null,null,6,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Instructor\",null],[560,559,\"crs101\",\"Course\",\"Introduction to Creating Musical Interfaces\",\"This course provides a gentle and fun introduction to the theory and practice of interface design for creating and performing music. Our intended audience consists of those who are interested in starting projects relating to music technology. Those with a general interest are also welcome. Participants will learn key aspects of the theory and practice of musical interface design, sufficient to begin to create their own original new musical interfaces.  \",\"This course provides a gentle and fun introduction to the practice of musical interface design. Participants will gain sufficient knowledge of tools and methods to start their own projects.\",6,\"Wed 11:30 - 12:50 PM\",1429738200,1429743000,\"Instructor\",null],[561,-1,\"break-8\",\"Breaks\",\"Lunch Break (on your own)\",null,null,15,\"Wed 12:50 - 2:30 PM\",1429743000,1429749000,\"\",\"\"],[562,-1,\"s-crs104\",\"Course\",\"Experience Sampling to Collect Deep Data 1/2\",null,null,6,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Instructor\",null],[563,562,\"crs104\",\"Course\",\"Using Experience Sampling Methodology to Collect Deep Data About Your Users\",\"Experience Sampling Methodology (ESM) is a type of longitudinal diary study that allows one to understand a person’s experience in the moment. It combines the qualitative richness of longitudinal diary studies, artifacts of a field study, and quantitative data of a large-scale survey or app tracker. Using a free, open-source mobile app called “PACO (Personal Analytics COmpanion),” we can conduct ESM studies with participants anywhere in the world. These studies can be conducted after qualitative studies (e.g., ethnography, interviews) to ascertain how broadly your observations apply to your user population or they can be done in advance to identify insights you want to study in-person, in-depth. By combining these methodologies, you create a, deeper, more holistic understanding of your users. This workshop will give attendees the skills to design, conduct, and analyze data from ESM studies at any scale.\",\"Attendees will obtain the skills to design, conduct, and analyze data from an ESM study in order to capture a deeper, more holistic understanding of their users.\",6,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Instructor\",null],[564,-1,\"s127\",\"Papers\",\"Wellness & Wearables\",null,null,12,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Chair\",\"Papers\"],[565,564,\"pn1894\",\"Paper\",\"Snot, Sweat, Pain, Mud, and Snow - Performance and Experience in the Use of Sports Watches\",\"We have conducted interviews with ten elite and recreational athletes to understand their experiences and engagement with endurance sport and personal and wearable sports technology. The athletes emphasized the experiential aspects of doing sports and the notion of feeling was repeatedly used to talk about their activities. Technology played both an instrumental role in measuring performance and feeding bio-data back to them, and an experiential role in supporting and enhancing the sport experience. To guide further interaction design research in the sports domain, we suggest two interrelated ways of looking at sports performances and experiences, firstly through the notion of a measured sense of performance, and secondly as a lived-sense of performance.\",\"We propose \\\"measured-sense of performance\\\" and \\\"lived-sense of performance\\\" as notions to characterize sports experiences in relation to sensor-based performance technologies, such as heart-rate monitors, GPS:es, and sports watches.\",12,\"Wed 2:30 - 2:50 PM\",1429749000,1429750200,\"Authors\",null],[566,564,\"pn1336\",\"Paper\",\"Contextual Influences on the Use and Non-Use of Digital Technology While Exercising at the Gym\",\"The use of wearable technology will become significantly more prevalent in the coming years, with major companies releasing devices such as the Samsung Gear Fit. With sensors, such as pedometers and heart rate monitors, embedded in these devices it is possible to use them for fitness purposes. However, little is known about how wearable adopters actually use wearable and existing technologies during exercise. In an exploratory situated study of technology use and non-use in the context of the gym, fitness informatics adopters showed varied practices related to distraction, appropriating technology into their routines, and information needs. We discuss this variance in relation to individual differences and the impact of the physical nature of the gym. Although further research might show other influencing factors such as the social context, we make a case for the use of situated studies to uncover tensions that lead to use and non-use of technology that arise in the different unfolding situations of using wearables in everyday life, including at the gym, which is a surprisingly complex context.\",\"We explored how the gym context influenced people's adoption, use and non-use of digital technologies for purposes ranging from tracking to entertainment during individual physical activity.\",12,\"Wed 2:50 - 3:10 PM\",1429750200,1429751400,\"Authors\",null],[567,564,\"pn414\",\"Paper\",\"TastyBeats: Designing Palatable Representations of Physical Activity\",\"In this paper, we introduce palatable representations that besides improving the understanding of physical activity through abstract visualization also provide an appetizing drink to celebrate the experience of being physically active. By designing such palatable representations, our aim is to offer novel opportunities for reflection on one’s physical activities. We present TastyBeats, a fountain-based interactive system that creates a fluidic spectacle of mixing sport drinks based on heart rate data of physical activity, which the user can later consume to replenish the loss of body fluids due to the physical activity. We articulate our experiences in designing the system as well as learning gained through field deployments of the system in participants’ homes for a period of two weeks. We found that our system increased participants’ awareness of physical activity and facilitated a shared social experience, while the prepared drink was treated as a hedonic reward that motivated participants to exercise more. Ultimately, with this work, we aim to inspire and guide design thinking on palatable representations, which we believe opens up new interaction possibilities to support physical activity experience.\",\"This work contributes first conceptual understanding on designing palatable representations of physical activity. This work inspires design thinking towards palatable representations which opens up new interaction possibilities to support physical activity experience.\",12,\"Wed 3:10 - 3:30 PM\",1429751400,1429752600,\"Authors\",null],[568,564,\"pn1280\",\"Paper\",\"As Light as your Footsteps: Altering Walking Sounds to Change Perceived Body Weight, Emotional State and Gait\",\"An ever more sedentary lifestyle is a serious problem in our society. Enhancing people’s exercise adherence through technology remains an important research challenge. We propose a novel approach for a system supporting walking that draws from basic findings in neuroscience research. Our shoe-based prototype senses a person’s footsteps and alters in real-time the frequency spectra of the sound they produce while walking. The resulting sounds are consistent with those produced by either a lighter or heavier body. Our user study showed that modified walking sounds change one’s own perceived body weight and lead to a related gait pattern. In particular, augmenting the high frequencies of the sound leads to the perception of having a thinner body and enhances the motivation for physical activity inducing a more dynamic swing and a shorter heel strike. We here discuss the opportunities and the questions our findings open. \",\"Augmenting the high frequencies of the sounds produced while walking leads to the perception of having a thinner body and enhances the motivation for physical activity and related gait patterns.\",12,\"Wed 3:30 - 3:50 PM\",1429752600,1429753800,\"Authors\",null],[569,-1,\"s-float-18\",\"Papers\",\"Kids Social, Emotional & Special Needs\",null,null,10,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Chair\",\"Papers\"],[570,569,\"pn1337\",\"Note\",\"Designing Social and Emotional Skills Training: The Challenges and Opportunities for Technology Support\",\"Social and emotional skills are crucial for all aspects of our everyday life. However, understanding how digital technology can facilitate the development and learning of such skills is yet an under-researched area in HCI. To start addressing this gap, this paper reports on a series of interviews and design workshops with the leading researchers and developers of 'Social and Emotional Learning' (SEL) curricula. SEL is a subfield of educational psychology with a long history of teaching such skills, and a range of evidence based curricula that are widely deployed in  primary and secondary schools. We identify the shared challenges across existing curricula that digital technology might help address: the support for out-of-session learning, scaffolding for parental engagement, and feedback for the curricula developers. We argue how this presents an opportunity for mutually beneficial collaborations, with the potential for significant real-world impact of novel HCI systems, and can inform HCI work on supporting social and emotional skills development in other domains. \",\"Drawing on interviews and participatory workshops with 14 leading experts, we identify the key challenges and opportunities for digital technology in supporting learning of social and emotional skills (SEL), illustrating these with three exemplary projects. \",10,\"Wed 2:30 - 2:40 PM\",1429749000,1429749600,\"Authors\",null],[571,569,\"pn1848\",\"Note\",\"Designing Autism Research for Maximum Impact\",\"In recent decades, rates of autism spectrum disorder (ASD) have risen dramatically, and research into assistive technologies for this population has similarly escalated. For technology to be adopted, technologists need to communicate with practitioners across fields and match methodological and evaluation standards. We provide a set of recommendations for researchers to bridge the gap between fields and maximize the impact of their research, including instructions on how to identify and describe research participants and how to avoid research confounds and challenges specific to this population. We also advocate that researchers in ASD maintain a nimble, adaptable approach when performing experiments.    \",\"This paper presents recommendations for increasing the impact of HCI/HRI research on autism spectrum disorders through better interdisciplinary communication and standardization of research methods. \",10,\"Wed 2:40 - 2:50 PM\",1429749600,1429750200,\"Authors\",null],[572,569,\"pn1049\",\"Paper\",\"Networked Empowerment on Facebook Groups for Parents of Children with Special Needs\",\"Theories of empowerment explain how people gain personal and political control to take action to improve their lives. However, empowerment theories were developed prior to the Internet and fail to account for the speed and scale that people can find one another online. One domain where empowerment is critical is caring for children with special needs, in which parents are required to navigate a complex maze of services and processes to access care for their child. We conducted 43 interviews with parents of children with special needs to investigate whether using social media sites helps them to perform this caregiving work. Critically, parents are able to do this through almost real-time access to other parents on Facebook. This work introduces the concept of networked empowerment, that describes how parents find other parents, access resources, and explore new ways for promoting health advocacy among caregivers at a local and national level. We conclude with design implications for facilitating faster and better access to information and support for caregivers.  \",\"Describes how parents of children with special needs use social media to access caregiving resources and support. \",10,\"Wed 2:50 - 3:10 PM\",1429750200,1429751400,\"Authors\",null],[573,569,\"pn189\",\"Paper\",\"Toward 3D-Printed Movable Tactile Pictures for Children with Visual Impairments\",\"Many children’s books contain movable pictures with elements that can be physically opened, closed, pushed, pulled, spun, flipped, or swung. But these tangible, interactive reading experiences are inaccessible to children with visual impairments. This paper presents a set of 3D-printable models designed as building blocks for creating movable tactile pictures that can be touched, moved, and understood by children with visual impairments. Examples of these models are canvases, connectors, hinges, spinners, sliders, lifts, walls, and cutouts. They can be used to compose movable tactile pictures to convey a range of spatial concepts, such as in/out, up/down, and high/low. The design and development of these models were informed by three formative studies including 1) a survey on popular moving mechanisms in children’s books and 3D-printed parts to implement them, 2) two workshops on the process creating movable tactile pictures by hand (e.g., Lego, Play-Doh), and 3) creation of wood-based prototypes and an informal testing on sighted preschoolers. Also, we propose a design language based on XML and CSS for specifying the content and structure of a movable tactile picture. Given a specification, our system can generate a 3D-printable model. We evaluate our approach by 1) transcribing six children’s books, and 2) conducting six interviews on domain experts including four teachers for the visually impaired, one blind adult, two publishers at the National Braille Press, a renowned tactile artist, and a librarian.\",\"We propose a suite of reusable 3D structures that can be composed into movable tactile pictures, and a new design language based on XML/CSS that ease process of 3D design.\",10,\"Wed 3:10 - 3:30 PM\",1429751400,1429752600,\"Authors\",null],[574,569,\"pn1885\",\"Note\",\"Multimodal Analysis in Participatory Design with Children:  A Primary School Case Study\",\"We describe a multimodal method for the analysis of co-design outcomes in participatory design (PD) with children. The multimodal approach we take allows researchers to treat both verbal (notes, writings) and tangible material out-comes as complementary ways of communicating design ideas. We argue that an integrated approach in which both PD outcomes are compared and contrasted can result in a richer analysis, in which underlying values can be identified more clearly. To illustrate the method, we describe a PD process with primary school children.\",\"We describe a multimodal method for the analysis of co-design outcomes in participatory design. The approach results in a richer analysis, in which underlying values can be identified more clearly.\",10,\"Wed 3:30 - 3:40 PM\",1429752600,1429753200,\"Authors\",null],[575,569,\"pn2134\",\"Note\",\"The Fun-Serious Ambiguity in Educational Games\",\"We describe a study of Monkey Tales, an educational game targeted at primary school children. Starting from the assumption that all meaning is socially constructed, we focus our attention on the way an educational game, and its balance between fun and serious aspects, is constructed in public texts (game manufacturer’s communication and game reviews) and in individual use (the way players and their parents talk about the game). Through an analysis of public texts and individual use, we show how the balance between the fun and the serious in Monkey Tales is constructed in different ways. \",\"We describe a study of Monkey Tales, an educational game. An analysis of the discourse surrounding the game shows how the game’s fun-serious balance is constructed in diverse ways. \",10,\"Wed 3:40 - 3:50 PM\",1429753200,1429753800,\"Authors\",null],[576,-1,\"s137\",\"Papers\",\"Understanding Everyday Use of Mobile Phones\",null,null,4,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Chair\",\"Papers\"],[577,576,\"pn277\",\"Paper\",\"Demand in My Pocket:  Mobile Devices and the Data Connectivity Marshalled in Support of Everyday Practice\",\"This paper empirically explores the role that mobile devices have come to play in everyday practice, and how this links to demand for network connectivity and online services. After a preliminary device-logging period, thirteen participants were interviewed about how they use their iPhones or iPads. Our findings build a picture of how, through use of such devices, a variety of daily practices have come to depend upon a working data connection, which sometimes surges, but is at least always a trickle. This aims to inform the sustainable design of applications, services and infrastructures for smartphones and tablets. By focusing our analysis in this way, we highlight a little-explored challenge for sustainable HCI and discuss ideas for (re)designing around the principle of ‘light-weight’ data ‘needs’. \",\"Curious about the direct and indirect energy impacts of apps on mobile devices?  We trace the apps and delve into the the social practices they enable to inform sustainable design.\",4,\"Wed 2:30 - 2:50 PM\",1429749000,1429750200,\"Authors\",null],[578,576,\"pn1907\",\"Paper\",\"An In-Situ Study of Mobile App & Mobile Search Interactions\",\"When trying to satisfy an information need, smartphone users frequently transition from mobile search engines to mobile apps and vice versa. However, little is known about the nature of these transitions nor how mobile search and mobile apps interact. We report on a 2-week, mixed-method study involving 18 Android users, where we collected real-world mobile search and mobile app usage data alongside subjective insights on why certain interactions between apps and mobile search occur. Our results show that when people engage with mobile search they tend to interact with more mobile apps and for longer durations. We found that certain categories of apps are used more intensely alongside mobile search. Furthermore we found differences in app usage before and after mobile search and show how mobile app interactions can both prompt mobile search and enable users to take action. We conclude with a discussion on what these patterns mean for mobile search and how we might design mobile search experiences that take these app interactions into account.\",\"We present an in-depth investigation of cross mobile app and mobile search use and discuss what these findings mean for mobile information seeking and for improving future search experiences.\",4,\"Wed 2:50 - 3:10 PM\",1429750200,1429751400,\"Authors\",null],[579,576,\"pn369\",\"Paper\",\"The Composition and Use of Modern Mobile Phonebooks\",\"Over the past decade, the mobile phonebook has evolved from a relatively short list of people that one calls and texts to a many-hundred person list of aggregated contacts from around the web. This is happening at a time when an increasing number of mobile applications are relying on the mobile phonebook to create one’s social network in their services. Through a large-scale study of the phonebooks of 200 diverse participants, containing 65,940 contacts, we set out to understand today’s mobile contact lists. Our participants reported that they did not recognize the names of 29% of their contacts and we found that the most frequently contacted five contacts represent greater than 80% of all calls and text messages with phonebook contacts. We conclude with implications for the design of mobile applications that rely on phonebook data.\",\"We provide an analysis of social mobile phonebooks showing that 29% of contacts are completely unknown to the user and that more than 80% of communications go to five people.\",4,\"Wed 3:10 - 3:30 PM\",1429751400,1429752600,\"Authors\",null],[580,576,\"pn5127\",\"TOCHI\",\"To Call or to Recall? That’s the Research Question\",\"We present findings of a study with 62 subjects who had 796 of their outgoing mobile phone calls recorded and transcribed for their later annotation—by highlighting important information shared during calls. We found that patterns in these calls (numbers, names, interrogative adverbs) as well as some contextual parameters are better indicators of annotation needs than the callers’ profile or call quality. Callers highlight information in both parties’ turns (caller and callee) more often than highlighting solely information provided by the callee, which is mostly due to annotating questions with contextual information for the highlights in the callee’s turns. We discuss how this behavior changes according to call purpose. Finally, we found that annotation needs change over time: while some annotations might not be considered relevant after weeks, others originally considered irrelevant might become important archival notes. We present implications of these findings for the design of mobile phone annotation tools.\",\"We present findings of a study with 62 subjects who had 796 of their outgoing mobile phone calls recorded and transcribed for their later annotation—by highlighting important information shared during calls. We found that patterns in these calls (numbers, names, interrogative adverbs) as well as some contextual parameters are better indicators of annotation needs than the callers’ profile or call quality. Callers highlight information in both parties’ turns (caller and callee) more often than hi...\",4,\"Wed 3:30 - 3:50 PM\",1429752600,1429753800,\"Authors\",null],[581,-1,\"s107\",\"Papers\",\"HCI for Civic Engagement\",null,null,15,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Chair\",\"Papers\"],[582,581,\"pn677\",\"Paper\",\"HCI, Civic Engagement & Trust\",\"There is a widespread belief that pervasive technologies will encourage and facilitate partnerships between citizens and civic authorities, enabling individuals to play a greater role in civic planning, service delivery and infrastructure management. However, at present sustained use and perceived value of civic engagement technologies remains low because the design space is poorly understood by system developers who focus almost exclusively on empowering citizens rather than adopting an informed, inclusive approach that addresses the needs of both citizens and civic authorities, and helps establish trusted relationships between these different stakeholders. We report on an extensive study of civic engagement in the domain of public infrastructure maintenance and provide insights into the civic management processes to support future design of trusted civic engagement interactions.\",\"We report an empirical investigation into the complex domain of urban maintenance and the role of trust in designing engagement technologies that support trust relationships between citizens & civic authorities\",15,\"Wed 2:30 - 2:50 PM\",1429749000,1429750200,\"Authors\",null],[583,581,\"pn1156\",\"Paper\",\"Factful: Engaging Taxpayers in the Public Discussion of a Government Budget\",\"While a government budget determines how taxpayers’ money is allocated to various programs and stakeholders that compete for limited resources, the extensiveness and complexity of the budget and its process hinder taxpayers from understanding the budget information and participating in the public discussion. To engage taxpayers in the public discussion around budgetary issues, we leverage news articles containing budgetary information for design opportunities. We present Factful, a web-based annotative article reading interface that enhances the article with fact-checking support and contextual budgetary information by processing open government data. In our lab study, participants using Factful discussed more critically with more fact-based supporting statements. They built a rich context surrounding the relevant budget facts beyond what was presented in the article. Factful presents a simple yet powerful model for supporting fact-oriented budgetary discussions online by leveraging open government data.\",\"We introduce Factful, a web-based annotative article reading interface for supporting budgetary discussions online. It leverages open government data, adds contextual budget information to the article, and supports fact-checking while reading.\",15,\"Wed 2:50 - 3:10 PM\",1429750200,1429751400,\"Authors\",null],[584,581,\"pn354\",\"Paper\",\"Contesting the City: Enacting the Political Through Digitally Supported Urban Walks\",\"We present a method for the situated discovery and articulation of issues at the intersection between the politics of place making and city planning. We describe the construction and use of designed tools, such as historical political archives; counterfactual maps; and cards to invite situated dialogue between the social and institutional practices and mechanisms that produce our cities. Grounded in an account of the political as vernacular and embodied, our analysis advance understandings on the politics of design, and on the complex interrelationship between places and political spaces. We outline how HCI can adopt methods and develop sensitivities to support democratic practices and publics envisioning their urban futures.\",\"We contribute a method for the situated articulation of issues at the intersection of the politics of place making and city planning and an analysis of the method’s political work.\",15,\"Wed 3:10 - 3:30 PM\",1429751400,1429752600,\"Authors\",null],[585,581,\"pn2352\",\"Paper\",\"Data-in-Place: Thinking through the Relations Between Data and Community\",\"We present findings from a year-long engagement with a street and its community. The work explores how the production and use of data is bound up with place, both in terms of physical and social geography. We detail three strands of the project. First, we consider how residents have sought to curate existing data about the street in the form of an archive with physical and digital components. Second, we report endeavours to capture data about the street’s environment, especially of vehicle traffic. Third, we draw on the possibilities afforded by technologies for polling opinion. We reflect on how these engagements have: materialised distinctive relations between the community and their data; surfaced flows and contours of data, and spatial, temporal and social boundaries; and enacted a multiplicity of ‘small worlds’. We consider how such a conceptualisation of data-in-place is relevant to the design of technology.\",\"Presents results from a year-long study with the residents of Tenison Road (Cambridge, UK) and their uses of local data. Draws out implications for a reconceptualisation of data as ‘data-in-place’.\",15,\"Wed 3:30 - 3:50 PM\",1429752600,1429753800,\"Authors\",null],[586,-1,\"s-float-32\",\"Papers\",\"Security Feedback & Warnings\",null,null,11,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Chair\",\"Papers\"],[587,586,\"pn652\",\"Paper\",\"Scaling the Security Wall: Developing a Security Behavior Intentions Scale (SeBIS)\",\"Despite the plethora of security advice and online education materials offered to end-users, there exists no standard measurement tool for end-user security behaviors.  We present the creation of such a tool.  We surveyed the most common computer security advice that experts offer to end-users in order to construct a set of Likert scale questions to probe the extent to which respondents claim to follow this advice.  Using these questions, we iteratively surveyed a pool of 3,619 computer users to refine our question set such that each question was applicable to a large percentage of the population, exhibited adequate variance between respondents, and had high reliability (i.e., desirable psychometric properties).  After performing both exploratory and confirmatory factor analysis, we identified a 16-item scale consisting of four sub-scales that measures attitudes towards choosing passwords, device securement, staying up-to-date, and proactive awareness.\",\"We document the development of a new scale to measure users' self-reported computer security behaviors. We show how our scale is reliable and correlates with several well-established psychometrics.\",11,\"Wed 2:30 - 2:50 PM\",1429749000,1429750200,\"Authors\",null],[588,586,\"pn1047\",\"Paper\",\"How Polymorphic Warnings Reduce Habituation in the Brain—Insights from an fMRI Study\",\"Research on security warnings consistently points to habituation as a key reason why users ignore security warnings. However, because habituation as a mental state is difficult to observe, previous research has examined habituation indirectly by observing its influence on security behaviors. This study addresses this gap by using functional magnetic resonance imaging (fMRI) to open the “black box” of the brain to observe habituation as it develops in response to security warnings. Our results show a dramatic drop in the visual processing centers of the brain after only the second exposure to a warning, with further decreases with subsequent exposures. To combat the problem of habituation, we designed a polymorphic warning that changes its appearance. We show in two separate experiments using fMRI and mouse cursor tracking that our polymorphic warning is substantially more resistant to habituation than conventional warnings. Together, our neurophysiological findings illustrate the considerable influence of human biology on users’ habituation to security warnings.\",\"We use fMRI and mouse tracking to show that polymorphic warnings are substantially more resistant to habituation than conventional warnings. Our findings illustrate the considerable influence of biology on habituation.\",11,\"Wed 2:50 - 3:10 PM\",1429750200,1429751400,\"Authors\",null],[589,586,\"pn1656\",\"Paper\",\"Improving SSL Warnings: Comprehension and Adherence\",\"Browsers warn users when the privacy of an SSL/TLS connection might be at risk. An ideal SSL warning would empower users to make informed decisions and, failing that, guide confused users to safety. Unfortunately, users struggle to understand and often disregard real SSL warnings. We report on the task of designing a new SSL warning, with the goal of improving comprehension and adherence. We designed a new SSL warning based on recommendations from warning literature and tested our proposal with microsurveys and a field experiment. We ultimately failed at our goal of a well-understood warning. However, nearly 30% more total users chose to remain safe after seeing our warning. We attribute this success to opinionated design, which promotes safety with visual cues. Subsequently, our proposal was released as the new Google Chrome SSL warning. We raise questions about warning comprehension advice and recommend that other warning designers use opinionated design.\",\"We designed a new SSL warning and tested it with microsurveys and a field experiment. Adherence increased from 37% to 62% in the field.  It's now the Chrome SSL warning.\",11,\"Wed 3:10 - 3:30 PM\",1429751400,1429752600,\"Authors\",null],[590,586,\"pn2548\",\"Paper\",\"A Spoonful of Sugar? The Impact of Guidance and Feedback on Password-Creation Behavior\",\"Users often struggle to create passwords under strict requirements. To make this process easier, some providers present real-time feedback during password creation, indicating which requirements are not yet met. Other providers guide users through a multi-step password-creation process. Our 6,435-participant online study examines how feedback and guidance affect password security and usability. We find that real-time password-creation feedback can help users create strong passwords with fewer errors. We also find that although guiding participants through a three-step password-creation process can make creation easier, it may result in weaker passwords. Our results suggest that service providers should present password requirements with feedback to increase usability. However, the presentation of feedback and guidance must be carefully considered, since identical requirements can have different security and usability effects depending on presentation.\",\"Our 6,435-participant online study examines how feedback and guidance affect password security and usability.\",11,\"Wed 3:30 - 3:50 PM\",1429752600,1429753800,\"Authors\",null],[591,-1,\"s125\",\"Papers\",\"GUI Size, Resolution & Layout\",null,null,5,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Chair\",\"Papers\"],[592,591,\"pn1492\",\"Paper\",\"Effects of Display Size and Resolution on User Behavior and Insight Acquisition in Visual Exploration\",\"Large high-resolution displays are becoming increasingly common in research settings, providing data scientists with visual interfaces for the analysis of large datasets. Numerous studies have demonstrated unique perceptual and cognitive benefits afforded by these displays in visual analytics and information visualization tasks. However, the effects of these displays on knowledge discovery in exploratory visual analysis are still poorly understood. We present the results of a small-scale study to better understand how display size and resolution affect insight. Analyzing participants' verbal statements, we find preliminary evidence that larger displays with more pixels can significantly increase the number of discoveries reported during visual exploration, while yielding broader, more integrative insights. Furthermore, we find important differences in how participants performed the same visual exploration task using displays of varying sizes. We tie these results to extant work and propose explanations by considering the cognitive and interaction costs associated with visual exploration.\",\"We contribute a study examining the effects of increasing the size and resolution of the display on insight acquisition and user behavior in exploratory visual analysis.\",5,\"Wed 2:30 - 2:50 PM\",1429749000,1429750200,\"Authors\",null],[593,591,\"pn1361\",\"Note\",\"Subjective and Objective Effects of Tablet's Pixel Density\",\"Pixel densities are increasing rapidly. We can observe this trend in particular for mobile devices like smartphones and tablets. Previous work revealed an effect of pixel density on subjective feedback and objective performance only for low resolution cathode ray tube screens. It is unclear if this effect persists for the four times higher pixel densities of current mobile devices. Therefore, we conducted a study to compare four pixel densities with 359, 180, 120, and 90 pixels per inch. While participants performed three tasks involving images, text and videos on a tablet, we measured perceived effort, perceived visual quality, task completion time, error rate, and body pose. Our results show that the effect of the pixel density highly depends on the content. We found that only for text, the four pixel densities have clearly different perceived media qualities. Pixel density seems to have a smaller effect on perceived media quality for images and videos and we found no effect on objective measures. Results show that text should be displayed in high resolution, while this is less important for images and videos.\",\"This note discusses the effect of pixel density of tablet screens on perceived quality, perceived effort, task completion time and error rate.\",5,\"Wed 2:50 - 3:00 PM\",1429750200,1429750800,\"Authors\",null],[594,591,\"pn139\",\"Note\",\"Push-Edge and Slide-Edge: Scrolling by Pushing Against the Viewport Edge\",\"Edge-scrolling allows users to scroll a viewport while simultaneously dragging near or beyond a window’s edge. Common implementations rely on rate control, mapping the distance between the pointer and the edge of the viewport to the scrolling velocity. While ubiquitous in operating systems, edge-scrolling has received little attention, even though previous works suggest that (1) rate control may be suboptimal for isotonic pointing devices like mice and trackpads and (2) space beyond the window’s edge might be scarce, limiting scrolling control. To address these problems, we developed Push-edge scrolling (and Slide-edge scrolling, its inertial variant), two novel position-based techniques that allow scrolling by ‘pushing’ against the viewport edge. A controlled experiment shows that our techniques reduce overshoots and offer performance improvements by up to 13% over traditional edge-scrolling.\",\"Presents push-edge and slide-edge scrolling, two position-based edge-scrolling (a.k.a autoscroll) techniques that reduce overshoots and improve performance over traditional rate-based edge-scrolling. \",5,\"Wed 3:00 - 3:10 PM\",1429750800,1429751400,\"Authors\",null],[595,591,\"pn1284\",\"Paper\",\"Investigating Visual Feedforward  for Target Expansion Techniques\",\"Target expansion techniques facilitate the pointing task by enlarging the effective sizes of targets. When the target expansion is applied to both the motor and visual spaces, the visual feedforward mechanism is key: Indeed it provides a visual aid to the user on the effective expanded targets prior to the execution or completion of the pointing task, enabling the user to take full advantage of the target expansion technique. Focusing on feedforward mechanisms, we introduce a design space that allows us to describe, classify and design target expansion techniques. To do so we first introduce and characterize the concept of atomic feedforward mechanism along three design axes. We then describe a target expansion technique as a combination of atomic feedforward mechanisms using a matrix-based notation. We provide an analytical exploration of the design space by classifying existing techniques and by designing six new techniques. We also provide a first experimental exploration of the design space in the context of distant pointing. The experimental protocol includes an innovative target layout for handling non-centroidal target expansion. The results show that feedforward dynamicity increases movement time and decreases subjective usability, while explicit expansion observability efficiently supports error prevention for distant pointing.\",\"Provides a design space for target expansion techniques, introduces the concept of atomic feedforward mechanism and presents six new techniques along with a new target layout for non-centroidal target expansion.\",5,\"Wed 3:10 - 3:30 PM\",1429751400,1429752600,\"Authors\",null],[596,591,\"pn416\",\"Paper\",\"GACA: Group-Aware Command-based Arrangement of Graphic Elements\",\"Many graphic applications rely on command-based arrangement tools to achieve precise layouts. Traditional tools are designed to operate on a single group of elements that are distributed consistently with the arrangement axis implied by a command. This often demands a process with repeated element selections and arrangement commands to achieve 2D layouts involving multiple rows and/or columns of well aligned and/or distributed elements. Our work aims to reduce the numbers of selection operation and command invocation, since such reductions are particularly beneficial to professional designers who design lots of layouts. Our key idea is that an issued arrangement command is in fact very informative, instructing how to automatically decompose a 2D layout into multiple 1D groups, each of which is compatible with the command. We present a parameter-free, command-driven grouping approach so that users can easily predict our grouping results. We also design a simple user interface with pushpins to enable explicit control of grouping and arrangement. Our user study confirms the intuitiveness of our technique and its performance improvement over traditional command-based arrangement tools. \",\"We presented a novel group-aware command-based arrangement technique called GACA. It helps to achieve layouts involving multiple rows and/or columns of well aligned and/or distributed elements.\",5,\"Wed 3:30 - 3:50 PM\",1429752600,1429753800,\"Authors\",null],[597,-1,\"s-panel4\",\"Panel\",\"10 Years of alt.chi\",null,null,1,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"\",\"\"],[598,597,\"pan119\",\"Panel\",\"10 Years of alt.chi: Reflections and Outlook\",\"\",\"...\",1,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"\",\"\"],[599,-1,\"s-award1\",\"Special\",\"SIGCHI Lifetime Practice Award\",null,null,3,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"\",\"\"],[600,599,\"award1\",\"Special\",\"SIGCHI Lifetime Practice Award Talk\",\"\",\"...\",3,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"\",\"\"],[601,-1,\"s140\",\"Papers\",\"Task Interruption & Resumption\",null,null,13,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Chair\",\"Papers\"],[602,601,\"pn2281\",\"Paper\",\"SwitchBack: Using Focus and Saccade Tracking to Guide Users’ Attention for Mobile Task Resumption\",\"Smartphones and tablets are often used in dynamic environments that force users to break focus and attend to their surroundings, creating a form of “situational impairment.” Current mobile devices have no ability to sense when users divert or restore their attention, let alone provide support for resuming tasks. We therefore introduce SwitchBack, a system that allows mobile device users to resume tasks more efficiently. SwitchBack is built upon Focus and Saccade Tracking (FAST), which uses the front-facing camera to determine when the user is looking and how their eyes are moving across the screen. In a controlled study, we found that FAST can identify how many lines the user has read in a body of text within a mean absolute percent error of just 3.9%. We then tested SwitchBack in a dual focus-of-attention task, finding that SwitchBack improved average reading speed by 7.7% in the presence of distractions.\",\"We introduce SwitchBack, a system that allows mobile device users to resume tasks more efficiently using gaze-tracking, and demonstrate a 7.7% improvement in reading speed in the presence of distractions.\",13,\"Wed 2:30 - 2:50 PM\",1429749000,1429750200,\"Authors\",null],[603,601,\"pn1103\",\"Note\",\"EyeBookmark: Assisting Recovery from Interruption during Reading\",\"In this paper, we present gaze-based bookmarking, EyeBookmark, to mitigate the deleterious effect of interruption during reading. The key idea of EyeBookmark is to provide a visual cue to help people decide where to resume reading. We design four highlighting methods and conduct a controlled user study with a proof-of-concept design to verify the usefulness of EyeBookmark. The user study demonstrates not only that participants preferred our highlighting methods but also that such highlighting methods significantly reduced the time taken to resume reading after interruption regardless of the difficulty of text.\",\"We propose a gazed-based bookmarking method, EyeBookmark, which highlights the last reading position to help users resume reading after interruption. Also, we present two user studies to confirm the efficacy of EyeBookmark.\",13,\"Wed 2:50 - 3:00 PM\",1429750200,1429750800,\"Authors\",null],[604,601,\"pn1256\",\"Note\",\"The Effects of Chronic Multitasking on Analytical Writing\",\"Chronic multitaskers perform worse on core multitasking skills: memory management, cognitive filtering and task switching, likely due to their inability to filter irrelevant stimuli [17]. Our experiment examines effects of chronic multitasking with task-relevant and irrelevant distractors on analytical writing quality. We found a general switch cost and, when controlling for that cost, effects of chronic multitasking habits: heavy multitaskers write worse essays in the irrelevant condition and better essays in the relevant condition. Our study changes multitasking research paradigms in two fundamental ways: it studied a realistic writing scenario including access to both irrelevant and relevant distractors. We found that the effect of chronic multitasking is complex; heavy multitaskers are seduced by unrelated distractors but able to integrate multiple sources of relevant information.\",\"Is multitasking good or bad for you? Both. When writing, chronic multitaskers are worse at ignoring distractions but better at integrating multiple sources of relevant information, compared to low multitaskers. \",13,\"Wed 3:00 - 3:10 PM\",1429750800,1429751400,\"Authors\",null],[605,601,\"pn261\",\"Paper\",\"What Makes Interruptions Disruptive? A Process-Model Account of the Effects of the Problem State Bottleneck on Task Interruption and Resumption\",\"In this paper we present a computational cognitive model of task interruption and resumption, focusing on the effects of the problem state bottleneck. Previous studies have shown that the disruptiveness of interruptions is for an important part determined by three factors: interruption duration, interrupting-task complexity, and moment of interruption. However, an integrated theory of these effects is still missing. Based on previous research into multitasking, we propose a first step towards such a theory in the form of a process model that attributes these effects to problem state requirements of both the interrupted and the interrupting task. Subsequently, we tested two predictions of this model in two experiments. The experiments confirmed that problem state requirements are an important predictor for the disruptiveness of interruptions. This suggests that interfaces should be designed to a) interrupt users at low-problem state moments and b) maintain the problem state for the user when interrupted.\",\"We report a process model of task interruption and resumption. This detailed model attributes the disruptiveness of interruptions to working memory requirements of the primary and the interrupting task.\",13,\"Wed 3:10 - 3:30 PM\",1429751400,1429752600,\"Authors\",null],[606,601,\"pn2587\",\"Paper\",\"Interruptibility of Software Developers and its Prediction Using Psycho-Physiological Sensors\",\"Interruptions of knowledge workers are common and can cause a high cost if they happen at inopportune moments. With recent advances in psycho-physiological sensors and their link to cognitive and emotional states, we are interested whether such sensors might be used to measure interruptibility of a knowledge worker. In a lab and a field study with a total of twenty software developers, we examined the use of psycho-physiological sensors in a real-world context. The results show that a Naive Bayes classifier based on psycho-physiological features can be used to automatically assess states of a knowledge worker's interruptibility with high accuracy in the lab as well as in the field. Our results demonstrate the potential of these sensors to avoid expensive interruptions in a real-world context. Based on brief interviews, we further discuss the usage of such an interruptibility measure and interruption support for software developers.\",\"Presents results from a lab and a field study on the feasibility of using psycho-physiological sensors to predict a knowledge worker's interruptibility. Can help in predicting interruptibility in real-world context.\",13,\"Wed 3:30 - 3:50 PM\",1429752600,1429753800,\"Authors\",null],[607,-1,\"s-sdc\",\"Special\",\"Student Design Competition Finals\",null,null,7,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"\",\"\"],[608,607,\"sdc\",\"Special\",\"Student Design Competition\",\"\",\"...\",7,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"\",\"\"],[609,-1,\"s-crs117\",\"Course\",\"Rapid Design Labs - Design-Led Innovation 1/2\",null,null,14,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Instructor\",null],[610,609,\"crs117\",\"Course\",\"Rapid Design Labs—A Tool to Turbocharge Design-Led Innovation\",\"We as researchers and User Experience (UX) designers want to identify and create products that change the world and therefore, we choose to engage in strategic research and design. In the real world though, coming up with a breakthrough idea or transformative design doesn’t mean it will automatically be accepted or get to market. By definition, innovative ideas represent new ways of thinking. Organizations by nature seem to have anti-innovation antibodies [1] that often kill new ideas [2]—even disruptive innovations [3] that could help companies differentiate themselves from their competition. As difficult as coming up with a game-changing idea can be, getting an organization to act on the idea often seems impossible. Perhaps we find ourselves in work routines that do not provide space to think differently. Our experience is that practitioners and academics alike need new tools to meet this challenge—tools that empower UX teams in both business and universities to identify transformative new ideas, and then to get these big ideas and designs accepted. This course proposes rapid design labs—a design-led, facilitative, cross-functional, iterative approach to innovation that aligns organizations and generates value at each step. It provides tools and methods that turn attendees into catalysts, who systemically identify new ideas, and align multi-disciplinary teams around their ideas. Attendees learn how to lead workshops that foster ideation, collaboration, trust, and free expression. These workshops enable intensive brainstorming, purposeful play, design, user testing, and rapid prototyping. Learn how innovative companies and universities, such as Splunk, Deutsche Telekom Laboratories, the Berlin Technical University, Yahoo!, Mindjet, zSpace, HP, and more identify, design, and bring great products to market.\",\"Rapid design labs are a design-led, cross-functional approach to innovation that enables attendees to identify innovations and align multi-disciplinary teams. They foster ideation, collaboration, design, user testing, and prototyping.\",14,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Instructor\",null],[611,-1,\"s-crs107\",\"Course\",\"Conceptual Models: Core to Good Design 1/2\",null,null,9,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Instructor\",null],[612,611,\"crs107\",\"Course\",\"Conceptual Models: Core to Good Design\",\"A crucial step in designing a user interface for a software application is to design a coherent, task-focused conceptual model (CM).  With a CM, designers design better, developers develop better, and users learn and use better.  Unfortunately, this step is often skipped, resulting in incoherent, arbitrary, inconsistent, overly-complex applications that impede design, development, learning, understanding, and use.  This course covers what CMs are, how they help, how to develop them, and provides hands-on experience.\",\"Teaches the benefits of designing a conceptual model (CM) of apps before designing the UI, the components of CMs and how to create them, and provides experience designing a CM. \",9,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Instructor\",null],[613,-1,\"s-sig6\",\"SIG\",\"Games Research Subcommittee\",null,null,8,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"\",\"\"],[614,613,\"sig111\",\"SIG\",\"Games Research Subcommittee SIG\",\"For CHI 2016, there will be a subcommittee devoted to research in the area of computer games, centralizing games submissions into a single process, rather than having them be distributed across the other subcommittees. Although game-related CHI submissions have much in common, there are also big differences in terms of methodology, approach, standards, contribution, and outcome. In this SIG, the CHI games community will talk about what this new change means for moving games research forward at CHI.\",\"For CHI 2016, there will be a subcommittee devoted to research in the area of computer games, centralizing games submissions into a single process, rather than having them be distributed across the other subcommittees. Although game-related CHI submissions have much in common, there are also big differences in terms of methodology, approach, standards, contribution, and outcome. In this SIG, the CHI games community will talk about what this new change means for moving games research forward at C...\",8,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"\",\"\"],[615,-1,\"s-crs115\",\"Course\",\"Designing Wearable Interfaces 1/2\",null,null,2,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Instructor\",null],[616,615,\"crs115\",\"Course\",\"The Glass Class: Designing Wearable Interfaces\",\"This course will teach how to design and develop effective interfaces for head mounted or wrist worn wearable computers through the application of user-centered design principles. It will enable existing HCI practitioners to enter the fast growing area of wearable computing. Attendees will gain the knowledge and tools needed to develop prototype applications, and an understanding of the important areas of current research and development.\",\"Attendees will learn how to design effective interfaces for head mounted and body worn wearable computers and will enable HCI practitioners to enter the wearable field and explore research applications.\",2,\"Wed 2:30 - 3:50 PM\",1429749000,1429753800,\"Instructor\",null],[617,-1,\"break-9\",\"Breaks\",\"Coffee Break\",null,null,15,\"Wed 3:50 - 4:30 PM\",1429753800,1429756200,\"\",\"\"],[618,-1,\"wip-4\",\"WIPs\",\"Work in Progress Exhibit\",null,null,15,\"Wed 3:50 - 4:30 PM\",1429753800,1429756200,\"\",\"\"],[619,-1,\"int-4\",\"Interactivity\",\"Interactivity Demos Exhibit\",null,null,15,\"Wed 3:50 - 4:30 PM\",1429753800,1429756200,\"\",\"\"],[620,-1,\"s106\",\"Papers\",\"Using Random Body Parts for Input\",null,null,3,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Chair\",\"Papers\"],[621,620,\"pn1367\",\"Paper\",\"iSkin: Flexible, Stretchable and Visually Customizable On-Body Touch Sensors for Mobile Computing\",\"We propose iSkin, a novel class of skin-worn sensors for touch input on the body.  iSkin is a very thin sensor overlay, made of biocompatible materials, and is flexible and stretchable. It can be produced in different shapes and sizes to suit various locations of the body such as the finger, forearm, or ear. Integrating capacitive and resistive touch sensing, the sensor is capable of detecting touch input with two levels of pressure, even when stretched  by 30% or when bent with a radius of 0.5cm. Furthermore, iSkin supports single or multiple touch areas of custom shape and arrangement, as well as more complex widgets, such as sliders and click wheels. Recognizing the social importance of skin, we show visual design patterns to customize functional touch sensors and allow for a visually aesthetic appearance. Taken together, these contributions enable new types of on-body devices. This includes finger-worn devices, extensions to conventional wearable devices, and touch input stickers, all fostering direct, quick, and discreet input for mobile computing.\",\"iSkin is a soft-matter touch sensor for on-body input. The thin and elastic sensor film is customizable in shape and visual appearance. It enables novel types of skin-worn devices.\",3,\"Wed 4:30 - 4:50 PM\",1429756200,1429757400,\"Authors\",null],[622,620,\"pn1809\",\"Paper\",\"Cyclops: Wearable and Single-Piece Full-Body Gesture Input Devices\",\"This paper presents Cyclops, a single-piece wearable device that sees its user's whole body postures through an ego-centric view of the user that is obtained through a fisheye lens at the center of the user's body, allowing it to see only the user’s limbs and interpret body postures effectively. Unlike currently available body gesture input systems that depend on external cameras or distributed motion sensors across the user's body, Cyclops is a single-piece wearable device that is worn as a pendant or a badge. The main idea proposed in this paper is the observation of limbs from a central location of the body. Owing to the ego-centric view, Cyclops turns posture recognition into a highly controllable computer vision problem. This paper demonstrates a proof-of-concept device, and an algorithm for recognizing static and moving bodily gestures based on motion history images (MHI) and a random decision forest (RDF). Four example applications of interactive bodily workout, a mobile racing game that involves hands and feet, a full-body virtual reality system, and interaction with a tangible toy are presented. The experiment on the bodily workout demonstrates that, from a database of 20 body workout gestures that were collected from 20 participants, Cyclops achieved a recognition rate of 79% using MHI and simple template matching, which increased to 92% with the more advanced machine learning approach of RDF. \",\"Cyclops is a single-piece wearable device that sees its user’s whole body postures through an ego-centric view of the user, allowing it to see only the users limbs and interpret body postures effectively.\",3,\"Wed 4:50 - 5:10 PM\",1429757400,1429758600,\"Authors\",null],[623,620,\"pn2131\",\"Note\",\"Bodyprint: Biometric User Identification on Mobile Devices Using the Capacitive Touchscreen to Scan Body Parts\",\"Recent mobile phones integrate fingerprint scanners to authenticate users biometrically and replace passwords, making authentication more convenient for users. However, due to their cost, capacitive fingerprint scanners have been limited to top-of-the-line phones, a result of the required resolution and quality of the sensor. We present Bodyprint, a biometric authentication system that detects users’ biometric features using the same type of capacitive sensing, but uses the touchscreen as the image sensor instead. While the input resolution of a touchscreen is ~6 dpi, the surface area is larger, allowing the touch sensor to scan users’ body parts, such as ears, fingers, fists, and palms by pressing them against the display. Bodyprint compensates for the low input resolution with an increased false rejection rate, but does not compromise on authentication precision: In our evaluation with 12 participants, Bodyprint classified body parts with 99.98% accuracy and identifies users with 99.52% accuracy with a retry likelihood of 26.82% to prevent false positives, thereby bringing reliable biometric user authentication to a vast number of commodity devices. \",\"Bodyprint performs biometric authentication on commodity mobile devices by turning the capacitive touchscreen into an image sensor and scanning users' body parts for identification.\",3,\"Wed 5:10 - 5:20 PM\",1429758600,1429759200,\"Authors\",null],[624,620,\"pn2473\",\"Note\",\"NailO: Fingernails as an Input Surface\",\"We present NailO, a nail-mounted gestural input surface. Using capacitive sensing on printed electrodes, the interface can distinguish on-nail finger swipe gestures with high accuracy (>92%). NailO works in real-time: we miniaturized the system to fit on the fingernail, while wirelessly transmitting the sensor data to a mobile phone or PC. NailO allows one-handed and always-available input, while being unobtrusive and discrete. Inspired by commercial nail stickers, the device blends into the user's body, is customizable, fashionable and even removable. We show example applications of using the device as a remote controller when hands are busy and using the system to increase the input space of mobile phones. \",\"We present novel input interface that leverages fingernails as input surface and develop a nail-mounted wireless and real-time capable prototype. We perform user studies to assess performance and appeal, and implement scenarios to explore interactions. \",3,\"Wed 5:20 - 5:30 PM\",1429759200,1429759800,\"Authors\",null],[625,620,\"pn979\",\"Paper\",\"Exploring Subtle Foot Plantar-based Gestures with Sock-placed Pressure Sensors\",\"We propose subtle foot-based gestures named foot plantar-based (FPB) gestures (FPB gestures) that are usingused with sock-placed pressure sensors. In this system, the user can control a computing device by changing his or her foot plantar distributions, (e.g., pressing a the floor with his/her toe). Because such foot movement is subtle, it is suitable for use especially in a public space such as a crowdinged train. In this study, we first conduct a guessability study to design a user-defined gesture set for interaction with a computing device. Then, we implement a gesture recognizer with a machine learning technique. To avoid unexpected gesture activations, we also collect foot plantar pressure patterns made during daily activities (such as walking), as negative training data. Additionally, we evaluate the unobservabililtyty of FPB gestures by using crowdsourcing. Finally, we conclude with several applications to further illustrate the utility of FPB gestures.\",\"We proposed a subtle and private foot-based gestures, named FPB gestures, using sock-placed pressure sensors. We conducted four studies to investigate how practical FPB gestures are.\",3,\"Wed 5:30 - 5:50 PM\",1429759800,1429761000,\"Authors\",null],[626,-1,\"s128\",\"Papers\",\"Understanding Health through Online Behavior\",null,null,12,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Chair\",\"Papers\"],[627,626,\"pn808\",\"Paper\",\"Recognizing Depression from Twitter Activity\",\"In this paper, we extensively evaluate the effectiveness of using a user's social media activities for estimating degree of depression.  As ground truth data, we use the results of a web-based questionnaire for measuring degree of depression of Twitter users.  We extract several features from the activity histories of Twitter users.  By leveraging these features, we construct models for estimating the presence of active depression.  Through experiments, we show that (1) features obtained from user activities can be used to predict depression of users with an accuracy of 69%, (2) topics of tweets estimated with a topic model are useful features, (3) approximately two months of observation data are necessary for recognizing depression, and longer observation periods do not contribute to improving the accuracy of estimation for current depression; sometimes, longer periods worsen the accuracy.\",\"We extensively evaluate the effectiveness of using a user's social media activities for estimating degree of depression.  Summary: 69% accuracy, demonstrating effectiveness of topic modeling, examining the timeframe effects.\",12,\"Wed 4:30 - 4:50 PM\",1429756200,1429757400,\"Authors\",null],[628,626,\"pn243\",\"Paper\",\"You Tweet What You Eat: Studying Food Consumption Through Twitter\",\"Food is an integral part of our lives, cultures, and well-being, and is of major interest to public health. The collection of daily nutritional data involves keeping detailed diaries or periodic surveys and is limited in scope and reach. Alternatively, social media is infamous for allowing its users to update the world on the minutiae of their daily lives, including their eating habits. In this work we examine the potential of Twitter to provide insight into US-wide dietary choices by linking the tweeted dining experiences of 210K users to their interests, demographics, and social networks. We validate our approach by relating the caloric values of the foods mentioned in the tweets to the state-wide obesity rates, achieving a Pearson correlation of 0.77 across the 50 US states and the District of Columbia. We then build a model to predict county-wide obesity and diabetes statistics based on a combination of demographic variables and food names mentioned on Twitter. Our results show significant improvement over previous CHI research (Culotta 2014). We further link this data to societal and economic factors, such as education and income, illustrating that areas with higher education levels tweet about food that is significantly less caloric. Finally, we address the somewhat controversial issue of the social nature of obesity (Christakis & Fowler 2007) by inducing two social networks using mentions and reciprocal following relationships.\",\"Creating an enriched vocabulary of foods, we correlate food-mentions of 210K Twitter users with CDC obesity and diabetes rates, and relate demographics like income and education, user-specific interests, and social connections with obesity-related behavior.\",12,\"Wed 4:50 - 5:10 PM\",1429757400,1429758600,\"Authors\",null],[629,626,\"pn245\",\"Paper\",\"Rethinking the Mobile Food Journal: Exploring Opportunities for Lightweight Photo-Based Capture\",\"Food choices are among the most frequent and important health decisions in everyday life, but remain notoriously difficult to capture. This work examines opportunities for lightweight photo-based capture in mobile food journals. We first report on a survey of 257 people, examining how they define healthy eating, their experiences and challenges with existing food journaling methods, and their ability to interpret nutritional information that can be captured in a food journal. We then report on interviews and a field study with 27 participants using a lightweight, photo-based food journal for between 4 to 8 weeks. We discuss mismatches between motivations and current designs, challenges of current approaches to food journaling, and opportunities for photos as an alternative to the pervasive but often inappropriate emphasis on quantitative tracking in mobile food journals.\",\"Examines opportunities for photo-based capture and reflection as an alternative to the pervasive but often inappropriate emphasis on quantitative tracking in mobile food journals.\",12,\"Wed 5:10 - 5:30 PM\",1429758600,1429759800,\"Authors\",null],[630,626,\"pn2424\",\"Paper\",\"Collective Sensemaking in Online Health Forums\",\"Online health communities collect vast amounts of information and opinions in regards to health and wellness management. However, these opinions are usually stored within lengthy and loosely structured discussion threads; synthesizing information in these threads can be challenging. In this mixed-methods study, grounded in the theoretical perspective of collective sensemaking, we examined patterns of communication within an online diabetes community TuDiabetes. The results of the study suggest that members of TuDiabetes often construct shared meaning through deep discussions, back and forth negotiation of perspectives, and resolution of conflicts in opinions. However, unlike participants of other sensemaking communities, members of TuDiabetes often value multiplicity of opinions rather than consensus. We use study results to draw implications for the design of computing platforms for facilitating collective sensemaking that promote construction of shared knowledge yet embrace diversity of opinions.\",\"The paper presents an account of collective sensemaking within an online diabetes community TuDiabetes and draws implications for the design of future computing platforms for online health forums.\",12,\"Wed 5:30 - 5:50 PM\",1429759800,1429761000,\"Authors\",null],[631,-1,\"s162\",\"Papers\",\"Natural User Interfaces for InfoVis\",null,null,13,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Chair\",\"Papers\"],[632,631,\"pn365\",\"Paper\",\"Opportunities and Challenges for Data Physicalization\",\"Physical representations of data have existed for thousands of years. Yet it is now that advances in digital fabrication, actuated tangible interfaces, and shape-changing displays are spurring an emerging area of research that we call Data Physicalization. It aims to help people explore, understand, and communicate data using computer-supported physical data representations. We call these representations physicalizations, analogously to visualizations – their purely visual counterpart. In this article, we go beyond the focused research questions addressed so far by delineating the research area, synthesizing its open challenges and laying out a research agenda.\",\"Introduces Data Physicalization, an emerging area of research that studies physical data representations. Motivates and delineates the research area, synthesizes its open challenges and lays out a research agenda.\",13,\"Wed 4:30 - 4:50 PM\",1429756200,1429757400,\"Authors\",null],[633,631,\"pn2625\",\"Paper\",\"Exploring Interactions with Physically Dynamic Bar Charts\",\"Visualizations such as bar charts help users reason about data, but are mostly screen-based, rarely physical, and almost never physical and dynamic. This paper investigates the role of physically dynamic bar charts and evaluates new interactions for exploring and working with datasets rendered in dynamic physical form. To facilitate our exploration we constructed a 10x10 interactive bar chart and designed interactions that supported fundamental visualisation tasks, specifically; annotation, filtering, organization, and navigation. The interactions were evaluated in a user study with 17 participants. Our findings identify the preferred methods of working with the data for each task i.e. directly tapping rows to hide bars, highlight the strengths and limitations of working with physical data, and discuss the challenges of integrating the proposed interactions together into a larger data exploration system. In general, physical interactions were intuitive, informative, and enjoyable, paving the way for new explorations in physical data visualizations.\",\"This paper provides baseline interaction techniques and a user evaluation for data-analysis tasks using EMERGE, a physically dynamic bar chart.\",13,\"Wed 4:50 - 5:10 PM\",1429757400,1429758600,\"Authors\",null],[634,631,\"pn650\",\"Note\",\"Evaluating the Memorability of Physical Visualizations\",\"Physical Visualizations are currently mostly used in casual contexts, e.g., as artistic data sculptures. However, their measurable benefits for traditional information visualization are largely unexplored. As a step in this direction, we compared the memorability of physical visualizations to that of digital visualizations. We conducted a user study with 40 participants in which we measured the recall of three types of information immediately after exploration and with a delay of two weeks. The results show that the physical visualization led to significantly less information decay within this time span. Our results build on known effects from cognitive psychology and provide a first indicator for measurable benefits of physical visualizations regarding memorability.\",\"We compared the memorability of a physical bar chart to that of a digital one and the results show that the physical visualization led to significantly less information decay.\",13,\"Wed 5:10 - 5:20 PM\",1429758600,1429759200,\"Authors\",null],[635,631,\"pn2578\",\"Note\",\"Personality as a Predictor of User Strategy: How Locus of Control Affects Search Strategies on Tree Visualizations\",\"Individual differences matter. While this has been the theme for many recent works in the Visualization and HCI communities, the mystery of how to develop personalized visualizations remains. This is largely because very little is known about how users actually use visualizations to solve problems and even less is known about how individual differences affect these problem-solving strategies. In this paper, we provide evidence that strategies are indeed influenced by individual differences. We demonstrate how the personality trait locus of control impacts strategies on hierarchical visualizations, and we introduce design recommendations for personalized visualizations.\",\"We demonstrate how personality affects speed and search strategies on visualizations. Our work is a significant step toward understanding how we can design visualizations that better facilitate users' cognitive needs.\",13,\"Wed 5:20 - 5:30 PM\",1429759200,1429759800,\"Authors\",null],[636,631,\"pn123\",\"Paper\",\"SketchSliders: Sketching Widgets for Visual Exploration on Wall Displays\",\"We introduce a mobile sketching interface for exploring multi-dimensional datasets on wall displays. We demonstrate the idea of SketchSliders, range sliders that users can freely sketch on a mobile surface to customize their exploration. A small combination of sketches and gestures allows the creation of complex interactive sliders, such as circular sliders for periodic data, slider branches for detailed interaction, and fisheye transformation sliders. We augment sliders with a suite of tools, such as markers, slider cursors, and approximate views of data distributions. Our designs are inspired by a design study with three visualization experts and validated through a user study with six experts using our system. Our findings indicate that our sketching interface accommodates a wide range of exploration strategies, helping users customize as well as focus their visual explorations.\",\"We introduce SketchSliders, a mobile sketching interface for exploring multi-dimensional datasets on wall displays. \",13,\"Wed 5:30 - 5:50 PM\",1429759800,1429761000,\"Authors\",null],[637,-1,\"s-float-3\",\"Papers\",\"HCI at Home\",null,null,10,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Chair\",\"Papers\"],[638,637,\"pn2282\",\"Paper\",\"Investigating Genres and Perspectives in HCI Research on the Home\",\"The home and domestic experiences have been studied from multiple points of view and disciplines, with an array of methodologies in the past twenty-five years in HCI. Given the attention to the home and the volume of research, what further areas of research might there be? Based on a critical analysis of 121 works on the topic, we present seven genres of domestic technology research in HCI: social routines in the home, ongoing domestic practices, the home as a testing ground, smart homes, contested values of a home, the home as a site for interpretation, and speculative visions of the home. We articulate dominant research perspectives in HCI, and we offer two complementary perspectives about how to investigate the domestic experience in future research: the material perspective and the first person perspective.\",\"We offer a critical literature review that articulates seven genres of domestic technology research in HCI. We identified dominant and complementary perspectives to orient future HCI research about the home.\",10,\"Wed 4:30 - 4:50 PM\",1429756200,1429757400,\"Authors\",null],[639,637,\"pn2611\",\"Paper\",\"Building Change: Constructive Design of Smart Domestic Environments for Goal Achievement\",\"This paper presents the constructive design research (CDR) of smart domestic environments comprised of smart home infrastructure, smart domestic artifacts and digital services. CDR is an approach that focuses on imagining futures and learning through the making and testing of prototypes to construct new knowledge about how people engage with the world. While the body of research on smart domestic environments includes a wealth of human-centered research, the use of CDR is marginal. Our work demonstrates how such a process engages residents in activities to imagine why people might value smart domestic environments and how they might want to interact with them. Through goal setting activities, paper prototyping, and field-testing of resident designed technology probes, we present use cases, design principles and experiential insights. After sharing these findings, we introduce the emergence of smart domestic environments as possessing persuasive, personified and artful qualities.\",\"Through the use of constructive design research, this paper presents a resident-centered rationale on smart domestic environments for goal achievement. It positions such environments as persuasive, personified and artful.\",10,\"Wed 4:50 - 5:10 PM\",1429757400,1429758600,\"Authors\",null],[640,637,\"pn504\",\"Paper\",\"uCap: An Internet Data Management Tool for the Home\",\"Internet Service Providers (ISPs) have introduced “data caps”, or quotas on the amount of data that a customer can download during a billing cycle. Under this model, Internet users who reach a data cap can be subject to degraded performance, extra fees, or even temporary interruption of Internet service. For this reason, users need better visibility into and control over their Internet usage to help them understand what uses up data and control how these quotas are reached. In this paper, we present the design and implementation of a tool, called uCap, to help home users manage Internet data. We conducted a field trial of uCap in 21 home networks in three countries and performed an in-depth qualitative study of ten of these homes. We present the results of the evaluation and implications for the design of future Internet data management tools.\",\"We describe the design, implementation, and evaluation of a home Internet data management tool–uCap. uCap was well received and demonstrates an increasing need for tools to manage Internet data. \",10,\"Wed 5:10 - 5:30 PM\",1429758600,1429759800,\"Authors\",null],[641,637,\"pn787\",\"Note\",\"Mediating Attention for Second Screen Companion Content\",\"There is increasing interest in providing content to users on secondary devices while they watch TV. This material, termed companion content, can be anything from textual information, to interactive quiz games. It can be delivered throughout a broadcast and often directly relates to specific scenes in a show. This new scenario has exposed a challenging design space for creators of both the content and the enabling technology.   A key question when introducing content on a secondary device is how much it detracts from, or enhances, the show the user is currently engaged with. To examine this, we investigated methods for mediating attention from the TV and onto a secondary device. By examining a typical use case we have been able to gain new insights into how best to design additional stimuli to alert users to companion content from both a broadcasting, and an HCI perspective. \",\"In this paper we conduct an experiment to investigate methods to mediate attention between devices in dual screen media scenarios and describe the implications for application designers and broadcasters alike. \",10,\"Wed 5:30 - 5:40 PM\",1429759800,1429760400,\"Authors\",null],[642,-1,\"s144\",\"Papers\",\"Brain & Physiological Data use for HCI\",null,null,4,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Chair\",\"Papers\"],[643,642,\"pn1723\",\"Paper\",\"Classification Accuracy from the Perspective of the User: Real-Time Interaction with Physiological Computing\",\"The accurate classification of psychophysiological data is an important determinant of the quality when interacting with a physiological computing system. Previous research has focused on classification accuracy of psychophysiological data in purely mathematical terms but little is known about how accuracy metrics relate to users’ perceptions of accuracy during real-time interaction.  A group of 14 participants watched a series of movie trailers and were asked to subjectively indicate their level of interest in a binary high/low fashion. Psychophysiological data (EEG, ECG and SCL) were used to create a binary classification of interest via a Support Vector Machine (SVM) algorithm. After a period of training, participants received real-time feedback from the classification algorithm and perceptions of accuracy were assessed.  The purpose of the study was to compare mathematical classification accuracy with the perceived accuracy of the system as experienced by the users.  Results indicated that perceived accuracy was subject to a number of psychological biases resulting from expectations, entrainment and development of trust.  The F1 score was generally a significant predictor of perceived accuracy. \",\"This paper is concerned with the measurement of interest when viewing movies using psychophysiological data and how users perceive the accuracy of this type of physiological computing system.\",4,\"Wed 4:30 - 4:50 PM\",1429756200,1429757400,\"Authors\",null],[644,642,\"pn5105\",\"TOCHI\",\"Measurable Decision Making with GSR and Pupillary Analysis for Intelligent User Interface\",\"This paper presents a framework of adaptive, measurable decision making for multi-attribute decision making (MADM) by varying decision factors in their types, numbers, and values. Under this framework, decision making is measured using physiological sensors such as Galvanic Skin Response (GSR) and eye-tracking while users are subjected to varying decision quality and difficulty levels. Following this quantifiable decision making, users are allowed to refine several decision factors in order to make decisions with high quality and low difficulty levels. A case study of driving route selection is used to set up an experiment to test our hypotheses. In this study, GSR features exhibit the best performance in indexing decision quality. These results can be used to guide the design of intelligent user interfaces for decision related applications in HCI, which can adapt to user behavior and decision making performance. \",\"This paper presents a framework of adaptive, measurable decision making for multi-attribute decision making (MADM) by varying decision factors in their types, numbers, and values. Under this framework, decision making is measured using physiological sensors such as Galvanic Skin Response (GSR) and eye-tracking while users are subjected to varying decision quality and difficulty levels. Following this quantifiable decision making, users are allowed to refine several decision factors in order to m...\",4,\"Wed 4:50 - 5:10 PM\",1429757400,1429758600,\"Authors\",null],[645,642,\"pn5114\",\"TOCHI\",\"Designing Implicit Interfaces for Physiological Computing: Guidelines and Lessons Learned using fNIRS\",\"A growing body of recent work has shown the feasibility of brain and body sensors as input to interactive systems. However, the interaction techniques and design decisions for their effective use are not well-defined. We present a conceptual framework for considering implicit input from the brain, along with design principles and patterns we have developed from our work. We also describe a series of controlled, offline studies that lay the foundation for our work with functional near-infrared spectroscopy (fNIRS) neuroimaging, as well as our real-time platform that serves as a testbed for exploring brain-based adaptive interaction techniques. Finally, we present case studies illustrating the principles and patterns for effective use of brain data in human-computer interaction. We focus on signals coming from the brain, but these principles apply broadly to other sensor data and in domains such as aviation, education, medicine, driving, and anything involving multi-tasking or varying cognitive workload.\",\"A growing body of recent work has shown the feasibility of brain and body sensors as input to interactive systems. However, the interaction techniques and design decisions for their effective use are not well-defined. We present a conceptual framework for considering implicit input from the brain, along with design principles and patterns we have developed from our work. We also describe a series of controlled, offline studies that lay the foundation for our work with functional near-infrared sp...\",4,\"Wed 5:10 - 5:30 PM\",1429758600,1429759800,\"Authors\",null],[646,642,\"pn1026\",\"Note\",\"Examining the Reliability of Using fNIRS in Realistic HCI Settings for Spatial and Verbal Tasks\",\"Recent efforts have shown that functional near-infrared spectroscopy (fNIRS) has potential value for brain sensing in HCI user studies. Research has shown that, although large head movement significantly affects fNIRS data, typical keyboard use, mouse movement, and non-task-related verbalisations do not affect measurements during Verbal tasks. This work aims to examine the Reliability of fNIRS, by 1) confirming these prior findings, and 2) significantly extending our understanding of how artefacts affect recordings during Spatial tasks, since much of user interfaces and interaction is inherently spatial. Our results show that artefacts have a significantly different impact during Verbal and Spatial tasks. We contribute clearer insights into using fNIRS as a tool within HCI user studies.\",\"This work provides more detailed guidance for user studies on how physical actions affect fNIRS measurements for both verbal and spatially oriented tasks.\",4,\"Wed 5:30 - 5:40 PM\",1429759800,1429760400,\"Authors\",null],[647,-1,\"s-float-50\",\"Papers\",\"Voting & Volunteerism\",null,null,15,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Chair\",\"Papers\"],[648,647,\"pn2348\",\"Paper\",\"Social Media Effectiveness for Public Engagement: Example of Small Nonprofits\",\"Social media sites are increasingly adopted by small nonprofit organizations (NPOs) to help them meet their public engagement goals. However, several characteristics of small organizations make it hard for them to effectively use social media sites. We present findings from interviews with 26 small NPOs’ social media professionals on how they use multiple social media sites to support public engagement. Small NPOs use multiple social media sites to engage with different stakeholders toward various ends. However, these NPOs are not using social media to its full potential with regard to community-building and action mobilization. Several challenges in small NPOs, such as ineffective measurement of social media performance, deficient organizational resources, and lack of control over work, lead to strong tensions between social media engagement strategies and outcomes. Drawing on these findings, we present several practical implications for the design of successful public engagement social media tools.\",\"Extends the understanding of social media use for public engagement by interviews with small nonprofits. Can assist in developing effective organizational social media tools for public engagement purpose. \",15,\"Wed 4:30 - 4:50 PM\",1429756200,1429757400,\"Authors\",null],[649,647,\"pn1299\",\"Paper\",\"Exploring Barriers to the Adoption of Mobile Technologies for Volunteer Data Collection Campaigns\",\"Volunteer campaigns for data collection make it possible for non-profit organizations to extend their ability to monitor and respond to critical environmental and societal issues. Yet mobile data collection technologies that have the potential to lower the costs and increase the accuracy of volunteer-collected data are not commonly used in these campaigns. In this paper we conduct a series of studies that reveal the complex issues affecting technology adoption in this domain. First, we surveyed and interviewed existing volunteering campaigns to map out current technology usage within volunteer campaigns. Next, we provided two organizations with a customizable tool for data collection (Sensr) and studied its use and non-use across six real volunteer-driven campaigns over six months. Our study explored success and failure across the first few phases of the campaign lifecycle (campaign creation, initial deployment, and adoption). Our results highlight the impact of resource constraints, cognitive factors, the depth of volunteer engagement, and stakeholders’ perspective on technology as important factors contributing to the adoption and usage of mobile data collection technologies.  We use these findings to argue for specific design features to accelerate the adoption and use of such tools in volunteer data collection campaigns.\",\"This paper explored the adoption and use practices of a mobile application on volunteer data collection campaigns, and provided design implications for future digital volunteering systems.\",15,\"Wed 4:50 - 5:10 PM\",1429757400,1429758600,\"Authors\",null],[650,647,\"pn699\",\"Paper\",\"“Everyone Is Talking about It!”: A Distributed Approach to Urban Voting Technology and Visualisations\",\"The deployment of technology interventions, such as public displays and mobile apps, in community settings has been found to engage people in sharing and comparing their opinions. Our research is concerned with how to extend this to community-wide participation by devising and deploying multiple voting devices and visualisations. We present an in-the-wild study where a number of shopkeepers along a street participated by placing a novel voting device in their shops to collect locals' opinions. Results were displayed outside the shops, on the pavement. This distributed set-up was found to promote public debate on local issues, particularly around the perceived divide between people on either end of the street. We outline our design process and describe the impact of distributing voting devices and situated visualisations in a local community. \",\"We present an in-the-wild study in which voting technology and public visualisations were distributed throughout a locale to achieve community-wide participation.\",15,\"Wed 5:10 - 5:30 PM\",1429758600,1429759800,\"Authors\",null],[651,647,\"pn1751\",\"Paper\",\"Design Challenges in Supporting Distributed Knowledge: An Examination of Organizing Elections\",\"This paper identifies the design challenges for creating collaborative technologies supporting the practices of organizing elections. We ethnographically investigate the distributed nature of knowledge as enacted between heterogeneous groups over the course of three elections in Denmark. We 1) identify fundamental characteristics of elections, 2) provide a comprehensive account of the distributed nature of knowledge in organizing and executing elections, and 3) point to new challenging areas for human-computer interaction (HCI) design supporting distributed collaborative knowledge practices. We found that organizational pattern of elections complicates the embodiment of nomadic knowledge, which is crucial for managing the effective organization of an election. Thus, one of the relevant design challenges is finding out how to support the timely distribution of large amounts of information, while still ensuring it is appropriately divided and delivered to various groups participating in planning and executing elections.\",\"We identify fundamental characteristics of elections, provide a comprehensive account of the distributed nature of knowledge in elections, and point to new challenging areas for HCI design supporting knowledge practices. \",15,\"Wed 5:30 - 5:50 PM\",1429759800,1429761000,\"Authors\",null],[652,-1,\"s145\",\"Papers\",\"Socio-Political Interactions\",null,null,11,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Chair\",\"Papers\"],[653,652,\"pn917\",\"Paper\",\"The Politics of Measurement and Action\",\"Contemporary decisions about the management of populations, public services, security, and the environment are increasingly made through knowledge gleaned from ‘big data’ and its attendant infrastructures and algorithms. Though often described as ‘raw,’ this data is produced by techniques of measurement that are imbued with judgments and values that dictate what is counted and what is not, what is considered the best unit of measurement, and how different things are grouped together and “made” into a measureable entity. In this paper, we analyze these politics of measurement and how they relate to action through two case studies involving high stake public health measurements where experts intentionally leverage measurement to change definitions of harm and health. That is, they use measurement for activism. The case studies offer a framework for thinking about of how the politics of measurement are present in user interfaces. It is usually assumed that the human element has been scrubbed from the database and that significant political and subjective interventions come from the analysis or use of data after the fact. Instead, we argue that human-computer interactions start before the data reaches the computer because various measurement interfaces are the invisible premise of data and databases, and these measurements are political.\",\"Measurement interfaces are the invisible premise of data and databases.  Via an analysis of two case studies of health measurements, we expose the politics of measurement and how they relate to action. \",11,\"Wed 4:30 - 4:50 PM\",1429756200,1429757400,\"Authors\",null],[654,652,\"pn439\",\"Paper\",\"Beyond Participatory Production: Digitally Supporting Grassroots Documentary\",\"We conducted a study to explore the values and qualities of ‘grassroots documentaries’, framed around the production of two parallel documentary films with a London-based opera company. A team of professional filmmakers produced one film and the other was an exploratory form of grassroots documentary. We studied the different production activities through observations, interviews and a reflective workshop at the end of the study and evaluated the resulting films. Our analysis reveals critical insights that could inform the next generation of technological systems to support user-generated video content (UGVC) production, particularly in collaborative contexts such as grassroots communities.\",\"A filmmaking project, designed to explore the relative 'values' and 'qualities' of professional and non-professional/grassroots documentary; suggests a paradigm-shift is needed in the design of tools for user-generated media production.\",11,\"Wed 4:50 - 5:10 PM\",1429757400,1429758600,\"Authors\",null],[655,652,\"pn1458\",\"Paper\",\"Designing Political Deliberation Environments to Support Interactions in the Public Sphere\",\"Little is known about the challenges and successes people face when piecing together multiple social media to interact in the online public sphere when: seeking information, disseminating information, and engaging in political discussions. We interviewed 29 US citizens and conducted 17 talk-out-loud sessions with people who were using one or more social media technologies, such as Facebook and Twitter, to interact in the online public sphere. We identified a number of challenges and workarounds related to public sphere interactions, and used our findings to formulate requirements for new political environments that support the interactions in the public sphere. Through evolving requirements generation, we developed a new political deliberation technology, dubbed Poli, which is an integrated social media environment with the potential to enable more effective interactions in the public sphere. We discuss several remaining questions and limitations to our tool that will drive future work.\",\"Not everyone can stitch together multiple social media for civic engagement. We developed a political deliberation technology, dubbed Poli, which is an integrated social media environment with the potential to enable more effective political interactions.\",11,\"Wed 5:10 - 5:30 PM\",1429758600,1429759800,\"Authors\",null],[656,652,\"pn880\",\"Paper\",\"Debating Poverty Porn on Twitter: Social Media as a Place for Everyday Socio-Political Talk\",\"This paper presents an empirical investigation of how people appropriated Twitter for socio-political talk in response to a television (TV) portrayal of people supported by state welfare and benefits. Our findings reveal how online discussion during, and in-between, TV broadcasts was characterised by distinctly different qualities, topics and user behaviours. These findings offer design opportunities for social media services to (i) support more balanced real-time commentaries of politically-charged media, (ii) actively promote discussion to continue after, and between, programming; and (iii) incorporate different motivations and attitudes towards socio-political concerns, as well as different practices of communicating those concerns. We contribute to the developing HCI literature on how social media intersects with political and civic engagement and specifically highlight the ways in which Twitter interacts with other forms of media as a site of everyday socio-political talk and debate.\",\"We analyse how people used Twitter to discuss TV poverty porn portrayals of welfare claimants, and suggest design approaches to further facilitate everyday socio-political discussion across broadcast and social media.\",11,\"Wed 5:30 - 5:50 PM\",1429759800,1429761000,\"Authors\",null],[657,-1,\"s147\",\"Papers\",\"Software Engineering Tools\",null,null,5,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Chair\",\"Papers\"],[658,657,\"pn2575\",\"Paper\",\"StructJumper: A Tool to Help Blind Programmers Navigate and Understand the Structure of Code\",\"It can be difficult for a blind developer to understand and navigate through a large amount of code quickly, as they are unable to skim as easily as their sighted counterparts. To help blind developers overcome this problem, we present StructJumper, an Eclipse plugin that creates a hierarchical tree based on the nesting structure of a Java class. The programmer can use the TreeView to get an overview of the code structure of the class (including all the methods and control flow statements) and can quickly switch between the TreeView and the Text Editor to get an idea of where they are within the nested structure. To evaluate StructJumper, we had seven blind programmers complete three tasks with and without our tool. We found that the users thought they would use StructJumper and there was a trend that they were faster completing the tasks with StructJumper.\",\"Navigation of code is difficult with screen readers due to their linear nature. We present StructJumper, a tool that allows blind programmers to navigate using the nesting structure of code.\",5,\"Wed 4:30 - 4:50 PM\",1429756200,1429757400,\"Authors\",null],[659,657,\"pn5101\",\"TOCHI\",\"OverCode: Visualizing Variation in Student Solutions to Programming Problems at Scale\",\"In MOOCs, a single programming exercise may produce thousands of solutions from learners. Understanding solution variation is important for providing appropriate feedback to students at scale.  The wide variation among these solutions can be a source of pedagogically valuable examples, and can be used to refine the autograder for the exercise by exposing corner cases.  We present OverCode, a system for visualizing and exploring thousands of programming solutions. OverCode uses both static and dynamic analysis to cluster similar solutions, and lets teachers further filter and cluster solutions based on different criteria. We evaluated OverCode against a non-clustering baseline in a within-subjects study with 24 teaching assistants, and found that the OverCode interface allows teachers to more quickly develop a high-level view of students' understanding and misconceptions, and to provide feedback that is relevant to more students' solutions.\",\"In MOOCs, a single programming exercise may produce thousands of solutions from learners. Understanding solution variation is important for providing appropriate feedback to students at scale.  The wide variation among these solutions can be a source of pedagogically valuable examples, and can be used to refine the autograder for the exercise by exposing corner cases.  We present OverCode, a system for visualizing and exploring thousands of programming solutions. OverCode uses both static and dy...\",5,\"Wed 4:50 - 5:10 PM\",1429757400,1429758600,\"Authors\",null],[660,657,\"pn1038\",\"Paper\",\"An Interactive System for Data Structure Development\",\"Data structure algorithms are of fundamental importance in teaching and software development, yet are difficult to understand. We propose a new approach for understanding, debugging and developing heap manipulating data structures. The key technical idea of our work is to combine deep parametric abstraction techniques emerging from the area of static analysis with interactive abstraction manipulation. Our approach bridges program analysis with HCI and enables new capabilities not possible before: i) online automatic visualization of the data structure in a way which captures its essential operation, thus enabling powerful local reasoning, and ii) fine grained pen and touch gestures allowing for interactive control of the abstraction -- at any point the developer can pause the program, graphically interact with the data, and continue program execution. These features address some of the most pressing challenges in developing data structures. We implemented our approach in a Java-based system called FluiEdt and evaluated it with $27$ developers. The results indicate that FluiEdt is more effective in helping developers find data structure errors than existing state of the art IDEs (e.g. Eclipse) or pure visualization based approaches.\",\"A new approach for understanding, debugging and developing heap manipulating data structures. Our work combines deep parametric abstraction techniques emerging from the area of static analysis with interactive abstraction manipulation.\",5,\"Wed 5:10 - 5:30 PM\",1429758600,1429759800,\"Authors\",null],[661,657,\"pn932\",\"Paper\",\"Polymorphic Blocks: Formalism-Inspired UI for Structured Connectors\",\"We present a novel block-based UI called Polymorphic Blocks, in which a connector's shape visually represents the structure of the data being passed through the connector. We use Polymorphic Blocks to add visual type information to block-based programming environments like Blockly or Scratch. We also use Polymorphic Blocks to represent logical proofs. In this context, if we erase all symbols, our UI becomes a puzzle game, where solving the puzzle amounts to building a proof. We show through a user study that our Logical Puzzle Game is faster, more fun, and more engaging than an equivalent pen-and-paper interface. \",\"We present a block-based UI in which a connector's shape represents the data passing through the connector. We use this UI to build a puzzle game that encodes logical proofs.\",5,\"Wed 5:30 - 5:50 PM\",1429759800,1429761000,\"Authors\",null],[662,-1,\"s165\",\"Papers\",\"UX Methods 4\",null,null,1,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Chair\",\"Papers\"],[663,662,\"pn308\",\"Paper\",\"Two-Level Personas for Nested Design Spaces\",\"The persona approach is often treated as a single user-centered design method, but there are variations and adaptations for different design contexts which go beyond local customization. The paper discusses a set of dimensions and success criteria for describing the different persona uses, presenting a new framework. It then specifically investigates personas in the context of end-user development. Professional designers need to consider the design space for potential end-user tools. In addition they need to understand that their users are often designers themselves (they are designer-users), requiring that they also consider the design spaces of their users. Two-level personas are introduced to make professional designers more aware of such nested design spaces. A two-level persona consists of one first-level persona and a set of second-level personas to additionally represent complex designer-user relationships. The effectiveness of the  approach is investigated in an exploratory empirical study. The results suggest that two-level personas add value when designing end-user design tools.\",\"Two-level personas are introduced in the context of end-user development and an exploratory empirical study is presented. The approach is motivated by a new framework for the different persona uses.\",1,\"Wed 4:30 - 4:50 PM\",1429756200,1429757400,\"Authors\",null],[664,662,\"pn1944\",\"Paper\",\"The Work of Mad Men that Makes the Methods of Math Men Work: Practically Occasioned Segment Design\",\"This study concerns the practical methods used to design segmentation models for digital advertising. I illuminate some of the collaborative activities workers rely on to create these web analytics based groupings. This work remains overlooked as the popularity of automation and statistical methods for segmenting customers continues to grow. I explain some of the ways the advertising customer is present as a background expectancy while workers make segment composition decisions. This approach is meant to complement established evaluative, technical, and statistical methods used to create segments and personas in design and marketing. This may inspire similar approaches to designing for specific groups of people while working with large data sets. Incorporating these customer-orienting practices in design and advertising processes could lead to novel approaches for both segment targeting and customer relationship management (CRM) software.\",\"I describe practical methods used to design advertising segmentation. Incorporating these practices in design and advertising processes could lead to novel approaches for both segmentation and customer relationship management software.\",1,\"Wed 4:50 - 5:10 PM\",1429757400,1429758600,\"Authors\",null],[665,662,\"pn2491\",\"Paper\",\"Flow of Competence in UX Design Practice\",\"UX and design culture are beginning to dominate corporate priorities, but despite the current hype there is often a disconnect between the organizational efficiencies desired by executives and the knowledge of how UX can or should address these issues. This exploratory study addresses this space by reframing the concept of competence in UX to include the flow of competence between individual designers and the companies in which they work. Our reframing resulted in a preliminary schema based on interviews conducted with six design practitioners, which allows this flow to be traced in a performative way on the part of individuals and groups over time. We then trace this flow of individual and organizational competence through three case studies of UX adoption. Opportunities for use of this preliminary schema as a generative, rhetorical tool for HCI researchers to further interrogate UX adoption are considered, including accounting for factors that affect adoption.\",\"This exploratory study addresses UX adoption by reframing the concept of competence to include the flow of competence between individual designers and the companies in which they work.\",1,\"Wed 5:10 - 5:30 PM\",1429758600,1429759800,\"Authors\",null],[666,662,\"pn227\",\"Note\",\"Usees\",\"HCI has developed a powerful vocabulary for thinking about, and methods for engaging with, users. Similarly, recent work has advanced complementary understanding of technology non-use. However, other spaces of interaction with technology may occur that sit uncomfortably between these two poles. This paper presents two case studies highlighting individuals who neither are clearly users of a system nor are clearly non-users. Based on these cases, the paper develops the concept of usee to help account for such situations that lie between existing analytic categories.\",\"Uses two case studies illustrating instances of human-computer interaction that fit well neither as “use” nor as “non-use.” Suggests and defines the term “usee” to describe such situations.\",1,\"Wed 5:30 - 5:40 PM\",1429759800,1429760400,\"Authors\",null],[667,-1,\"s-crs115-1\",\"Course\",\"Designing Wearable Interfaces 2/2\",null,null,2,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Instructor\",null],[668,667,\"crs115\",\"Course\",\"The Glass Class: Designing Wearable Interfaces\",\"This course will teach how to design and develop effective interfaces for head mounted or wrist worn wearable computers through the application of user-centered design principles. It will enable existing HCI practitioners to enter the fast growing area of wearable computing. Attendees will gain the knowledge and tools needed to develop prototype applications, and an understanding of the important areas of current research and development.\",\"Attendees will learn how to design effective interfaces for head mounted and body worn wearable computers and will enable HCI practitioners to enter the wearable field and explore research applications.\",2,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Instructor\",null],[669,-1,\"s-crs104-1\",\"Course\",\"Experience Sampling to Collect Deep Data 2/2\",null,null,6,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Instructor\",null],[670,669,\"crs104\",\"Course\",\"Using Experience Sampling Methodology to Collect Deep Data About Your Users\",\"Experience Sampling Methodology (ESM) is a type of longitudinal diary study that allows one to understand a person’s experience in the moment. It combines the qualitative richness of longitudinal diary studies, artifacts of a field study, and quantitative data of a large-scale survey or app tracker. Using a free, open-source mobile app called “PACO (Personal Analytics COmpanion),” we can conduct ESM studies with participants anywhere in the world. These studies can be conducted after qualitative studies (e.g., ethnography, interviews) to ascertain how broadly your observations apply to your user population or they can be done in advance to identify insights you want to study in-person, in-depth. By combining these methodologies, you create a, deeper, more holistic understanding of your users. This workshop will give attendees the skills to design, conduct, and analyze data from ESM studies at any scale.\",\"Attendees will obtain the skills to design, conduct, and analyze data from an ESM study in order to capture a deeper, more holistic understanding of their users.\",6,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Instructor\",null],[671,-1,\"s-sgc\",\"Special\",\"Student Game Competition Finals\",null,null,7,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"\",\"\"],[672,671,\"sgc\",\"Special\",\"Student Game Competition\",\"\",\"...\",7,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"\",\"\"],[673,-1,\"s-crs117-1\",\"Course\",\"Rapid Design Labs - Design-Led Innovation 2/2\",null,null,14,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Instructor\",null],[674,673,\"crs117\",\"Course\",\"Rapid Design Labs—A Tool to Turbocharge Design-Led Innovation\",\"We as researchers and User Experience (UX) designers want to identify and create products that change the world and therefore, we choose to engage in strategic research and design. In the real world though, coming up with a breakthrough idea or transformative design doesn’t mean it will automatically be accepted or get to market. By definition, innovative ideas represent new ways of thinking. Organizations by nature seem to have anti-innovation antibodies [1] that often kill new ideas [2]—even disruptive innovations [3] that could help companies differentiate themselves from their competition. As difficult as coming up with a game-changing idea can be, getting an organization to act on the idea often seems impossible. Perhaps we find ourselves in work routines that do not provide space to think differently. Our experience is that practitioners and academics alike need new tools to meet this challenge—tools that empower UX teams in both business and universities to identify transformative new ideas, and then to get these big ideas and designs accepted. This course proposes rapid design labs—a design-led, facilitative, cross-functional, iterative approach to innovation that aligns organizations and generates value at each step. It provides tools and methods that turn attendees into catalysts, who systemically identify new ideas, and align multi-disciplinary teams around their ideas. Attendees learn how to lead workshops that foster ideation, collaboration, trust, and free expression. These workshops enable intensive brainstorming, purposeful play, design, user testing, and rapid prototyping. Learn how innovative companies and universities, such as Splunk, Deutsche Telekom Laboratories, the Berlin Technical University, Yahoo!, Mindjet, zSpace, HP, and more identify, design, and bring great products to market.\",\"Rapid design labs are a design-led, cross-functional approach to innovation that enables attendees to identify innovations and align multi-disciplinary teams. They foster ideation, collaboration, design, user testing, and prototyping.\",14,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Instructor\",null],[675,-1,\"s-crs107-1\",\"Course\",\"Conceptual Models: Core to Good Design 2/2\",null,null,9,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Instructor\",null],[676,675,\"crs107\",\"Course\",\"Conceptual Models: Core to Good Design\",\"A crucial step in designing a user interface for a software application is to design a coherent, task-focused conceptual model (CM).  With a CM, designers design better, developers develop better, and users learn and use better.  Unfortunately, this step is often skipped, resulting in incoherent, arbitrary, inconsistent, overly-complex applications that impede design, development, learning, understanding, and use.  This course covers what CMs are, how they help, how to develop them, and provides hands-on experience.\",\"Teaches the benefits of designing a conceptual model (CM) of apps before designing the UI, the components of CMs and how to create them, and provides experience designing a CM. \",9,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"Instructor\",null],[677,-1,\"s-sig3\",\"SIG\",\"Understanding Sports\",null,null,8,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"\",\"\"],[678,677,\"sig105\",\"SIG\",\"Understanding Sports-HCI by Going Jogging at CHI\",\"More and more technologies are emerging that aim to support sports activities, for example there are jogging apps, cycling computers and quadcopters for sportspeople to videorecord their actions. These new technologies appear to become more and more popular, yet interaction design knowledge how to support the associated exertion experiences is still limited. In order to bring practitioners and academics interested in sports-HCI together and examine the topic “in the wild”, we propose to go outside and jog around the CHI venue while using and discussing some of these new technologies. The goal is to investigate and shape the future of the field of sports-HCI.\",\"More and more technologies are emerging that aim to support sports activities, for example there are jogging apps, cycling computers and quadcopters for sportspeople to videorecord their actions. These new technologies appear to become more and more popular, yet interaction design knowledge how to support the associated exertion experiences is still limited. In order to bring practitioners and academics interested in sports-HCI together and examine the topic “in the wild”, we propose to go outsi...\",8,\"Wed 4:30 - 5:50 PM\",1429756200,1429761000,\"\",\"\"],[679,-1,\"keynote-4\",\"Keynote\",\"Plenary Session - ACM-W Athena Lecture: Large-Scale Behavioral Data: Potential and Pitfalls\",null,null,15,\"Thu 8:30 - 9:20 AM\",1429813800,1429816800,\"Speaker\",null],[680,679,\"key4\",\"Keynote\",\"ACM-W Athena Lecture: Large-Scale Behavioral Data: Potential and Pitfalls\",\"Over the last decade, the rise of web services has made it possible to gather traces of human behavior in situ at a scale and fidelity previously unimaginable. Large-scale behavioral data enables researchers and practitioners to detect adverse drug reactions and interactions, to understand how information diffuses through social networks, how people browse and search for information, how individual learning strategies are related to educational outcome, etc. Using examples from search, I will highlight how observational logs provide a rich new lens onto the diversity of searchers, tasks, and interactivity that characterize information systems today, and how experimental logs have revolutionized the way in which web-based systems are designed and evaluated. Although logs provide a great deal of information about what people are doing, they provide little insight about why they are doing so or whether they are satisfied. Complementary methods from observations, laboratory studies and panels are necessary to provide a more complete understanding of and support for search which is increasingly a core fabric of people’s everyday lives. The CHI community should lead the way in shaping best practices and policy in behavioral log studies.\",\"Over the last decade, the rise of web services has made it possible to gather traces of human behavior in situ at a scale and fidelity previously unimaginable. Large-scale behavioral data enables researchers and practitioners to detect adverse drug reactions and interactions, to understand how information diffuses through social networks, how people browse and search for information, how individual learning strategies are related to educational outcome, etc. Using examples from search, I will hi...\",15,\"Thu 8:30 - 9:20 AM\",1429813800,1429816800,\"Speaker\",null],[681,-1,\"s105\",\"Papers\",\"Augmented & Virtual Reality in the Real World\",null,null,3,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Chair\",\"Papers\"],[682,681,\"pn1357\",\"Paper\",\"Substitutional Reality: Using the Physical Environment to Design Virtual Reality Experiences\",\"Experiencing Virtual Reality in domestic and other uncontrolled settings is challenging due to the presence of physical objects and furniture that are not usually defined in the Virtual Environment. To address this challenge, we explore the concept of Substitutional Reality in the context of Virtual Reality: a class of Virtual Environments where every physical object surrounding a user is paired, with some degree of discrepancy, to a virtual counterpart. We present a model of potential substitutions and validate it in two user studies. In the first study we investigated factors that affect participants' suspension of disbelief and ease of use. We systematically altered the virtual representation of a physical object and recorded responses from 20 participants. The second study investigated users' levels of engagement as the physical proxy for a virtual object varied. From the results, we derive a set of guidelines for the design of future Substitutional Reality experiences.\",\"Substitutional Reality: a class of Virtual Environments where every physical object is paired, with some degree of discrepancy, to a virtual counterpart. We studied how this mismatch affects the user experience.\",3,\"Thu 9:30 - 9:50 AM\",1429817400,1429818600,\"Authors\",null],[683,681,\"pn525\",\"Paper\",\"The Semantic Paintbrush: Interactive 3D Mapping and Recognition in Large Outdoor Spaces\",\"We present an augmented reality system for large scale 3D reconstruction and recognition in outdoor scenes. Unlike existing prior work, which tries to reconstruct scenes using active depth cameras, we use a purely passive stereo setup, allowing for outdoor use and extended sensing range. Our system not only produces a map of the 3D environment in real-time, it also allows the user to draw (or `paint') with a laser pointer directly onto the reconstruction to segment the model into objects. Given these examples our system then learns to segment other parts of the 3D map during online acquisition. Unlike typical object recognition systems, ours therefore very much places the user `in the loop' to segment particular objects of interest, rather than learning from predefined databases. The laser pointer additionally helps to `clean up' the stereo reconstruction and final 3D map, interactively. Using our system, within minutes, a user can capture a full 3D map, segment it into objects of interest, and refine parts of the model during capture. We provide full technical details of our system to aid replication, as well as quantitative evaluation of system components. We demonstrate the possibility of using our system for helping the visually impaired navigate through spaces. Beyond this use, our system can be used for playing large-scale augmented reality games, shared online to augment streetview data, and used for more detailed car and person navigation.\",\"We present an augmented reality system for large scale 3D reconstruction and recognition in outdoor scenes.\",3,\"Thu 9:50 - 10:10 AM\",1429818600,1429819800,\"Authors\",null],[684,681,\"pn487\",\"Paper\",\"User-Defined Game Input for Smart Glasses in Public Space\",\"Smart glasses, such as Google Glass, provide always-available displays not offered by console and mobile gaming devices, and could potentially offer a pervasive gaming experience. However, research on input for games on smart glasses has been constrained by the available sensors to date.  To help inform design directions, this paper explores user-defined game input for smart glasses beyond the capabilities of current sensors, and focuses on the interaction in public settings. We conducted a user-defined input study with 24 participants, each performing 17 common game control tasks using 3 classes of interaction and 2 form factors of smart glasses, for a total of 2448 trials. Results show that users significantly preferred non-touch and non-handheld interaction over using handheld input devices, such as in-air gestures. Also, for touch input without handheld devices, users preferred interacting with their palms over wearable devices (51% vs 20%). In addition, users preferred interactions that are less noticeable due to concerns with social acceptance, and preferred in-air gestures in front of the torso rather than in front of the face (63% vs 37%). \",\"We present a very intensive user study to better understand a good user interface for smart glasses in a public space. \",3,\"Thu 10:10 - 10:30 AM\",1429819800,1429821000,\"Authors\",null],[685,681,\"pn1936\",\"Paper\",\"Retargeting Technical Documentation to Augmented Reality\",\"We present a system which automatically transfers printed technical documentation, such as handbooks, to three-dimensional Augmented Reality. Our system identifies the most frequent forms of instructions found in printed documentation, such as image sequences, explosion diagrams, textual annotations and arrows indicating motion. The analysis of the printed documentation works automatically, with minimal user input. The system only requires the documentation itself and a CAD model or 3D scan of the object described in the documentation. The output is a fully interactive Augmented Reality application, presenting the information from the printed documentation in 3D, registered to the real object.\",\"We present a system which automatically transfers printed technical documentation to a fully interactive Augmented Reality application, presenting the information from the printed documentation in 3D.\",3,\"Thu 10:30 - 10:50 AM\",1429821000,1429822200,\"Authors\",null],[686,-1,\"s122\",\"Papers\",\"Interactive & Multi-Surface Maps\",null,null,13,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Chair\",\"Papers\"],[687,686,\"pn1892\",\"Paper\",\"TerraGuide: Design and Evaluation of a Multi-Surface Environment for Terrain Visibility Analysis\",\"Terrain visibility analysis is a challenging task that is currently supported by complex digital tools with cumbersome interfaces. In this paper, we present TerraGuide, a novel multi-surface environment for exploratory terrain analysis. TerraGuide provides three tightly coupled displays including a real-time viewshed, a 3D panoramic view, and a helicopter view controlled by an optically tracked tablet. A user study compared these techniques and identified users’ strategies in solving a complex terrain analysis problem. Users overwhelmingly adopted a bi-manual use of the tabletop viewshed and tablet-based helicopter techniques. This paper gives insight into how multi-surface environments can be designed to allow complementary use of and fluid switching between techniques.\",\"A multi-surface environment aids in terrain analysis. Fluid interaction between views helps rapid exploration of terrains. Users adopt bi-manual interaction involving a tablet and tabletop viewshed visualization.\",13,\"Thu 9:30 - 9:50 AM\",1429817400,1429818600,\"Authors\",null],[688,686,\"pn328\",\"Paper\",\"Lightweight Relief Shearing for Enhanced Terrain Perception on Interactive Maps\",\"We explore interactive relief shearing, a set of non-intrusive, direct manipulation interactions that expose depth and shape information in terrain maps using ephemeral animations. Reading and interpreting topography and relief on terrain maps is an important aspect of map use, but extracting depth information from 2D maps is notoriously difficult. Modern mapping software attempts to alleviate this limitation by presenting digital terrain using 3D views. However, 3D views introduce occlusion, complicate distance estimations, and typically require more complex interactions. In contrast, our approach reveals depth information via shearing animations on 2D maps, and can be paired with existing interactions such as pan and zoom. We examine explicit, integrated, and hybrid interactions for triggering relief shearing and present a version that uses device tilt to control depth effects. Our evaluation shows that these interactive techniques improve depth perception when compared to standard 2D and perspective views.\",\"We present interactive relief shearing, a set of non-intrusive, direct manipulation interactions that expose depth and shape information in terrain maps using ephemeral animations.\",13,\"Thu 9:50 - 10:10 AM\",1429818600,1429819800,\"Authors\",null],[689,686,\"pn134\",\"Paper\",\"An Evaluation of Interactive Map Comparison Techniques\",\"Geovisualization applications typically organize data into layers. These layers hold different types of geographical features, describe different characteristics of the same features, or represent those features at different points in time. Layers can be composited in various ways, most often employing a juxtaposition or superimposition strategy, to produce maps that users can explore interactively. From an HCI perspective, one of the main challenges is to design interactive compositions that optimize the legibility of the resulting map and that ease layer comparison. We characterize five representative techniques, and empirically evaluate them using a set of real-world maps in which we purposefully introduce six types of differences amenable to inter-layer visual comparison. We discuss the merits of these techniques in terms of visual interference, user attention and scanning strategy. Our results can help inform the design of map-based visualizations for supporting geo-analysis tasks in many application areas.\",\"We characterize and empirically evaluate interaction techniques for map comparison using real-world maps. We discuss the merits of these techniques in terms of visual interference, user attention and scanning strategy.\",13,\"Thu 10:10 - 10:30 AM\",1429819800,1429821000,\"Authors\",null],[690,686,\"pn2245\",\"Paper\",\"Ethermap - Real-time Collaborative Map Editing\",\"Real-time synchronization is increasingly available in web-based environments for editing textual data, and this has changed how groups of people collaborate. We present a novel approach for real-time collaborative editing of geo-data. We introduce Ethermap, an open source web-application that implements this approach and enables multiple users to map data concurrently. It supports synchronous and collaborative mapping in several ways: it visually highlights mapping activities, it allows for fine-grained reviewing of all changes, and it enhances text-based communication with cross-modal references to geo-objects. We report on key results from a multi-tiered evaluation of Ethermap  based on a user-study and on expert interviews. The concept of real-time collaborative editing was received favorably by users and experts. Participants of the study learned to use Ethermap quickly, and successfully completed a collaborative mapping task. Experts and users agreed that, given the right scenario (e.g., disaster mapping, teaching, planning), the approach could benefit the process of working on geo-data collaboratively.\",\"We present Ethermap, an open source web-application that enables real-time collaborative map editing. The presentation reports on key results from a multi-tiered evaluation.\",13,\"Thu 10:30 - 10:50 AM\",1429821000,1429822200,\"Authors\",null],[691,-1,\"s115\",\"Papers\",\"Digital Collections, Practice & Legacy\",null,null,10,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Chair\",\"Papers\"],[692,691,\"pn1312\",\"Paper\",\"Digital Collections and Digital Collecting Practices\",\"Reference is increasingly made to ‘digital collections’, yet this term encompasses accumulated digital objects of var-ying form, purpose and value. We review social science literature on material collections and draw from in-depth interviews with 20 people in the UK in order to offer a clearer understanding of what constitutes a digital collec-tion and what does not. We develop a taxonomy that pre-sents three distinct types of digital collection and demon-strate ways in which the affordances of digital environ-ments may facilitate or impede meaningful practices of acquisition, curation and exhibition in each case. Through doing so, we present a framework for design in support of collecting practices and the development of more mean-ingful and valued digital collections.\",\"This study advances emerging work on digital possessions by distinguishing digital collections from other digital accumulations and presenting a framework for design in support of more meaningful, valued digital collections.\",10,\"Thu 9:30 - 9:50 AM\",1429817400,1429818600,\"Authors\",null],[693,691,\"pn594\",\"Paper\",\"Medium, Access, and Obsolescence: What Kinds of Objects are Lasting Objects?\",\"This paper presents findings from a field study of records managers that provides context for understanding how people see objects on varying media as long-lasting objects (or not). Part of the mandate of the profession of records management is long-term preservation of digital and paper records. At the site of the fieldwork for this study, research participants’ tasks primarily consisted of examining individual case files to determine if the files should be kept or destroyed under the relevant rules set by higher-level management according to legal requirements. Close observation of work practices showed that application of records management rules varied depending on the medium of the records, despite the policy that records on varying media are equal in importance. The results of the study suggest that the perceived accessibility and obsolescence of digital objects deserve more attention in the exploration of the place of digital objects in human lives over the long-term.\",\"This paper investigates human understandings of digital and physical objects as long-lasting in a workplace where object preservation is central to the mission of the organization: a records management office.\",10,\"Thu 9:50 - 10:10 AM\",1429818600,1429819800,\"Authors\",null],[694,691,\"pn1764\",\"Paper\",\"Things That Make Us Reminisce: Everyday Memory Cues as Opportunities for Interaction Design\",\"Interactive devices can support personal remembering to benefit well-being. These designs require insight into what brings the past to mind, and how people relate to such cues. Prior work focused on mementos in the home; instead, this paper presents a diary and interview study of involuntary memory cueing in everyday life. Data was collected from fifteen adult individuals, using sentence completion diaries, combined with debriefing interviews. Qualitative analysis of the data showed that these participants were relying on everyday physical objects like food items for cueing memories during everyday life, locations and (repeated) activities, while digital items and photos were shown to be less frequent stimulants. Meaningful relations to memory cues can be partially explained from a memory cueing perspective. We discuss how design for remembering can benefit from our insights, through careful trade-offs in timing, exposure to cues, and supporting a process of personal attachment with items invoking memories.\",\"We discuss a diary study in which participants captured involuntary memory cues, plus follow-up interviews. We discuss how design for remembering can benefit from our insights.\",10,\"Thu 10:10 - 10:30 AM\",1429819800,1429821000,\"Authors\",null],[695,691,\"pn910\",\"Paper\",\"Curatorial Agents: How Systems Shape Our Understanding of Personal and Familial Digital Information\",\"As people increasingly turn to digital channels to share, store, and reflect on their lives and experiences, the processes by which they manage the diverse collection of information generated over the course of their lives are changing. These processes, once a matter of hands-on curation and personal meaning making, are now deeply rooted in interactions with digital systems. In this work, we drew from prior research from personalization, memory, and information management to create four interactive, provocative systems. Through sessions with 12 adults from Pittsburgh, PA we used a combination of these systems and interviews to examine how systems might play a role in the near and long term resurfacing of personal and familial digital information. Findings point to an opportunity to create systems that can openly mediate the curation and transmission of digital content, and ways to draw meaning from the differences between how systems and people recall and represent their experiences.\",\"We utilize a collection of provocative interactive systems that we developed to investigate how systems might make sense of unwieldy, diverse collections of personal and familial digital information. \",10,\"Thu 10:30 - 10:50 AM\",1429821000,1429822200,\"Authors\",null],[696,-1,\"s123\",\"Papers\",\"Gesture Elicitation & Recognition\",null,null,4,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Chair\",\"Papers\"],[697,696,\"pn2504\",\"Note\",\"Using Soft-Constraints to Reduce Legacy and Performance Bias in Gesture Elicitation Studies\",\"Participant biases can influence proposed gestures in elicitation studies. There is a legacy bias from previous experience with, or even knowledge of, existing input devices, interfaces, and technologies. There is also a performance bias, where the artificial study setting does not encourage consideration of long-term aspects such as fatigue. These biases make it especially difficult to uncover gestures appropriate for whole-body gestural input. We propose using soft constraints to correct for legacy and performance biases by penalizing physical movements. We use wrist weights as a soft constraint to elicit whole-body gestures with low arm fatigue. We show soft constraints encourage a wider range of gestures using subtler arm movements or alternate body parts and lower consumed endurance for arm movements.\",\"We propose using soft constraints to correct for legacy and performance biases in elicitation studies by penalizing physical movements. \",4,\"Thu 9:30 - 9:40 AM\",1429817400,1429818000,\"Authors\",null],[698,696,\"pn2004\",\"Note\",\"Unistroke Gesture Recognition Through Polyline Approximation and Alignment\",\"We present a novel gesture recognizer suitable for fast prototyping of gesture-based applications. The recognizer uses a nearest neighbor approach, and requires a small number of samples for each class. The similarity between two gestures is calculated through a three steps procedure: firstly, each gesture is approximated to a polyline, in order to extract its main movements; then, the two polylines are aligned to obtain an equal number of segments from both of them; lastly, the distance is found by summing the contribution of each pair of segments. We tested the recognizer on two different datasets and found that it performs more accurately than a state-of-art method.\",\"We present a novel gesture recognizer suitable for fast prototyping of gesture-based applications. The recognizer is suitable for fast prototyping and performs more accurately than a state-of-art method.\",4,\"Thu 9:40 - 9:50 AM\",1429818000,1429818600,\"Authors\",null],[699,696,\"pn2678\",\"Paper\",\"Gesture On: Enabling Always-On Touch Gestures for Fast Mobile Access from the Device Standby Mode\",\"A significant percentage of mobile interaction involves short-period usages that originate from the standby mode—users wake up a device by pressing the power button, unlock the device by authenticating themselves, and then search for a target app or functionality on the device. These additional steps preceding a target task imposes significant overhead on users for each mobile device access. To address the issue, we developed Gesture On, a system that enables gesture shortcuts in the standby mode by which a user can draw a gesture on the touchscreen before the screen is turned on. Based on the gesture, our system directly brings up a target item onto the screen that bypasses all these additional steps in a mobile access. This paper examines several challenges in realizing Gesture On, including robustly rejecting accidental touches when the device is in standby, battery consumption incurred for continuous sensing and gesture-based user authentication methods for automatically device unlocking. Our analyses based on a set of user data indicated that Gesture On demonstrates a feasible approach for leveraging the standby mode for fast access to mobile content.\",\"We contribute Gesture On, a system that allows fast mobile access by enabling and utilizing touchscreen gestures when a device is in the standby mode.\",4,\"Thu 9:50 - 10:10 AM\",1429818600,1429819800,\"Authors\",null],[700,696,\"pn1184\",\"Paper\",\"Optimizing Touchscreen Keyboards for Gesture Typing\",\"Despite its growing popularity, gesture typing suffers from a major problem not present in touch typing: gesture ambiguity on the Qwerty keyboard. By applying rigorous mathematical optimization methods, this paper systematically investigates the optimization space related to the accuracy, speed, and Qwerty similarity of a gesture typing keyboard. Our investigation shows that optimizing the layout for gesture clarity (a metric measuring how unique word gestures are on a keyboard) drastically improves the accuracy of gesture typing. Moreover, if we also accommodate gesture speed, or both gesture speed and Qwerty similarity, we can still reduce error rates by 52% and 37% over Qwerty, respectively. In addition to investigating the optimization space, this work contributes a set of optimized layouts such as GK-D and GK-T that can immediately benefit mobile device users.\",\"We explore the layout optimization space related to the accuracy, speed, and Qwerty similarity of a gesture typing keyboard by applying rigorous mathematical optimization methods.\",4,\"Thu 10:10 - 10:30 AM\",1429819800,1429821000,\"Authors\",null],[701,696,\"pn373\",\"Paper\",\"Design and Evaluation of a Self-Correcting Gesture Interface based on Error Potentials from EEG\",\"Any user interface which automatically interprets the user's input using natural modalities like gestures makes mistakes. System behavior depending on such mistakes will confuse the user and lead to an erroneous interaction flow. The automatic detection of error potentials in electroencephalographic data recorded from a user allows the system to detect such states of confusion and automatically bring the interaction back on track. In this work, we describe the design of such a self-correcting gesture interface, implement different strategies to deal with detected errors, use a simulation approach to analyze performance and costs of those strategies and execute a user study to evaluate user satisfaction. We show that self-correction significantly improves gesture recognition accuracy at lower costs and with higher acceptance than manual correction.\",\"This paper compares different strategies for automatic recovery from input recognition errors which are detected from EEG. We use comprehensive simulation and multiple user studies to evaluate different performance measures.\",4,\"Thu 10:30 - 10:50 AM\",1429821000,1429822200,\"Authors\",null],[702,-1,\"s-float-11\",\"Papers\",\"Multilingual Communication\",null,null,15,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Chair\",\"Papers\"],[703,702,\"pn1972\",\"Paper\",\"Improving Multilingual Collaboration by Displaying How Non-native Speakers Use Automated Transcripts and Bilingual Dictionaries\",\"Conversational grounding, or establishing mutual knowledge that messages have been understood as intended, can be difficult to achieve when some conversational participants are using a non-native language. These difficulties in grounding can be challenging for native speakers to detect. In this paper, we examine the value of signaling potential grounding problems to native speakers (NS) by displaying how non-native speakers (NNS) use automated transcripts and bilingual dictionaries. We conducted a laboratory experiment in which NS and NNS of English collaborated via audio conferencing on a map navigation task. Triads of one NS guider, one NS follower, and one NNS follower performed the task using one of three awareness displays: (a) a no awareness display that showed only the automated transcripts, (b) a general awareness display that showed whether each follower was reading the automated transcripts and/or translating a word; or (c) a detailed awareness display that showed which line of the transcripts a follower was reading and/or which words he/she was translating. NS guiders and NNS followers collaborated most successfully with the detailed awareness display, while NS guiders and NS followers performed equally across conditions. Our findings suggest several ways to improve systems to support multilingual collaboration.\",\"We examine the value of signaling grounding problems to native speakers by displaying how non-native speakers use automated transcripts and bilingual dictionaries. Our findings suggest ways to improve collaboration systems .\",15,\"Thu 9:30 - 9:50 AM\",1429817400,1429818600,\"Authors\",null],[704,702,\"pn1497\",\"Paper\",\"Effect of Machine Translation in Interlingual Conversation: Lessons from a Formative Study\",\"Language barrier is the primary challenge for effective cross-lingual conversations. Spoken language translation (SLT) is perceived as a cost-effective alternative to less affordable human interpreters, but little research has studied how people interact with such technology. Using a prototype translator application, we performed a formative evaluation to elicit how people interact with the technology and adapt their conversation style. We conducted two sets of studies with a total of 23 pairs (46 participants). Participants worked on storytelling tasks to simulate natural conversations with 3 different interface settings. Our findings show that collocutors naturally adapt their style of speech production and comprehension to compensate for inadequacies in SLT. We conclude the paper with design guidelines that emerged from the analysis.\",\"The design guidelines based on our findings contribute to the better design of spoken language translation systems.\",15,\"Thu 9:50 - 10:10 AM\",1429818600,1429819800,\"Authors\",null],[705,702,\"pn2288\",\"Paper\",\"Supporting the Modern Polyglot - A Comparison of Multilingual Search Interfaces\",\"The unrelenting rise in online user diversification has generated tremendous new challenges for search system providers. Among these, the need to address multiple user language abilities and preferences is paramount. The majority of research on multilingual search has so far focused on improving retrieval and translation techniques in cross-language information retrieval. However, less research has focused on the human-computer interaction aspects of multilingual search, particularly in terms of multilingual result display interfaces. To address this research gap, this paper presents a comparison of 5 different search interface designs for multilingual search. We analyze and evaluate these interfaces through a crowd-based experiment involving 885 participants. Our results show that the common approach of interleaving multilingual results is in fact the least preferred, whereas single-page displays with clear language separation are most preferred. In addition, we show that user proficiency and search content type play an important role in user preferences, and that different interfaces elicit different user behaviors.\",\"This crowd-based study compares five commonly-used interface techniques for multilingual search, showing that the most preferred approach groups results by language, in separate panels, and on one screen.\",15,\"Thu 10:10 - 10:30 AM\",1429819800,1429821000,\"Authors\",null],[706,702,\"pn1095\",\"Paper\",\"New Interaction Tools for Preserving an Old Language\",\"The Penan people of Malaysian Borneo were traditionally nomads of the rainforest. They would leave messages in the jungle for each other by shaping natural objects into language tokens and arranging these symbols in specific ways – much like words in a sentence. With settlement, the language is being lost as it is not being used by the younger generation. We report here, a tangible system designed to help the Penan preserve their unique object writing language. The key features of the system are that: its tangibles are made of real objects; it works in the wild; and new tangibles can be fabricated and added to the system by the users. Our evaluations show that the system is engaging and encourages intergenerational knowledge transfer and thus has the potential to help preserve this language. \",\"This system encourages learning engagement of the object language of Penan of Borneo using tangible and touch interaction. It works in the wild and users can add new tangible objects. \",15,\"Thu 10:30 - 10:50 AM\",1429821000,1429822200,\"Authors\",null],[707,-1,\"s114\",\"Papers\",\"Empowering Users\",null,null,11,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Chair\",\"Papers\"],[708,707,\"pn5133\",\"TOCHI\",\"Quantifying the Creativity Support of Digital Tools through the Creativity Support Index\",\"Creativity support tools help people engage creatively with the world, but measuring how well a tool supports creativity is challenging since creativity is ill-defined. To this end, we developed the Creativity Support Index (CSI), which is a psychometric survey designed for evaluating the ability of a creativity support tool to assist a user engaged in creative work. The CSI measures six dimensions of creativity support: Exploration, Expressiveness, Immersion, Enjoyment, Results Worth Effort, and Collaboration. The CSI allows researchers to understand not just how well a tool supports creative work overall, but what aspects of creativity support may need attention. In this article, we present the CSI, along with scenarios for how it can be deployed in a variety of HCI research settings and how the CSI scores can help target design improvements. We also present the iterative, rigorous development and validation process used to create the CSI.\",\"Creativity support tools help people engage creatively with the world, but measuring how well a tool supports creativity is challenging since creativity is ill-defined. To this end, we developed the Creativity Support Index (CSI), which is a psychometric survey designed for evaluating the ability of a creativity support tool to assist a user engaged in creative work. The CSI measures six dimensions of creativity support: Exploration, Expressiveness, Immersion, Enjoyment, Results Worth Effort, an...\",11,\"Thu 9:30 - 9:50 AM\",1429817400,1429818600,\"Authors\",null],[709,707,\"pn2327\",\"Paper\",\"Mixed-Initiative Approaches to Global Editing in Slideware\",\"Good alignment and repetition of objects across presentation slides can facilitate visual processing and contribute to audience understanding. However, creating and maintaining such consistency during slide design is difficult. To solve this problem, we present two complementary tools: (1) StyleSnap, which increases the alignment and repetition of objects by adaptively clustering object edge positions and allowing parallel editing of all objects snapped to the same spatial extent; and (2) FlashFormat, which infers the least-general generalization of editing examples and applies it throughout the selected range. In user studies of repetitive styling task performance, StyleSnap and FlashFormat were 4-5 times and 2-3 times faster respectively than conventional editing. Both use a mixed-initiative approach to improve the consistency of slide decks and generalize to any situations involving direct editing across disjoint visual spaces.\",\"Presents the design and evaluation of two mixed-initiative tools for cross-slide editing in slideware – StyleSnap and FlashFormat – that help to create and maintain visual consistency throughout a slide deck.\",11,\"Thu 9:50 - 10:10 AM\",1429818600,1429819800,\"Authors\",null],[710,707,\"pn2172\",\"Paper\",\"“For Telling” the Present: Using the Delphi Method to  Understand Personal Information Management Practices\",\"Researchers have been studying personal information management (PIM) for many years, but little exists by way of practical advice for how individuals should manage their own information. We employed the Delphi Method to engage PIM researchers with expertise in a variety of relevant areas in a five-round extended dialog about PIM practices. Participants identified key everyday choices of PIM, suggested alternatives, and identified pros and cons of each alternative. Our contributions include: 1) a set of 36 PIM practices, along with pros, cons, and recommendations for or against each practice, 2) directions of future research and development including “near-future” improvements in tool support and 3) a detailed description of how we applied the Delphi Method to study PIM and how it might be used more widely in HCI research as a complement to more established methods of inquiry.  \",\"We employed the Delphi Method with PIM experts to assess current PIM practices and to uncover fruitful directions for future research. The method has wider application in HCI research. \",11,\"Thu 10:10 - 10:30 AM\",1429819800,1429821000,\"Authors\",null],[711,707,\"pn5103\",\"TOCHI\",\"On the benefits of providing versioning support for end users: An empirical study\",\"End users with little formal programming background are creating software in many different forms, including spreadsheets, web macros, and web mashups. Web mashups are particularly popular because they are relatively easy to create, and because many programming environments that support their creation are available. These programming environments, however, provide no support for tracking versions or provenance of mashups. We believe that versioning support can help end users create, understand, and debug mashups. To investigate this belief, we have added versioning support to a popular wire-oriented mashup environment, Yahoo! Pipes. Our enhanced environment, which we call “Pipes Plumber,” automatically retains versions of pipes and provides an interface with which pipe programmers can browse histories of pipes and retrieve specific versions. We have conducted two studies of this environment: an exploratory study and a larger controlled experiment. Our results provide evidence that versioning helps pipe programmers create and debug mashups. Subsequent qualitative results provide further insights into the barriers faced by pipe programmers, the support for reuse provided by our approach, and the support for debugging provided.\",\"End users with little formal programming background are creating software in many different forms, including spreadsheets, web macros, and web mashups. Web mashups are particularly popular because they are relatively easy to create, and because many programming environments that support their creation are available. These programming environments, however, provide no support for tracking versions or provenance of mashups. We believe that versioning support can help end users create, understand, ...\",11,\"Thu 10:30 - 10:50 AM\",1429821000,1429822200,\"Authors\",null],[712,-1,\"s-float-37\",\"Papers\",\"Programming Environments\",null,null,5,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Chair\",\"Papers\"],[713,712,\"pn1948\",\"Paper\",\"Constructing Conceptual Knowledge Artefacts: Activity Patterns in the Ontology Authoring Process\",\"Ontologies are complex knowledge representation artefacts used widely across biomedical, media and industrial domains. They are used for defining terminologies and providing metadata, especially for linked open data, and as such their use is rapidly increasing, but so far development tools have not benefited from empirical research into the ontology authoring process. This paper presents the results of a study that identifies common activity patterns through analysis of eye-tracking data and the event logs of the popular authoring tool, Protégé. Informed by the activity patterns discovered, we propose design guidelines for bulk editing, efficient reasoning and increased situational awareness. Methodological implications go beyond the remit of knowledge artefacts: we establish a method for studying the usability of software designed for highly specialised complex domains.\",\"We propose a method (1) for studying the usability of software designed for highly specialised complex domains and (2) for investigating the authoring patterns when constructing complex structured data.\",5,\"Thu 9:30 - 9:50 AM\",1429817400,1429818600,\"Authors\",null],[714,712,\"pn1618\",\"Note\",\"Helping Users Bootstrap Ontologies: An Empirical Investigation\",\"An ontology is a machine processable artifact that captures knowledge about some domain of interest. Ontologies are used in various domains including healthcare, science, and commerce. In this paper we examine the ontology bootstrapping problem. Specifically, we look at an approach that uses both competency questions and knowledge source reuse via recommendations to address the \\\"cold start problem\\\" - that is, the task of creating an ontology from scratch. We describe this approach, an implementation of it, and we present an evaluation in the form of a controlled user study. We find that the approach leads users into creating significantly more detailed initial ontologies that have a greater domain coverage than ontologies produced without this support. Furthermore, in spite of a more involved workflow, the usability and user satisfaction of the bootstrapping approach is as good as a state-of-the-art ontology editor with no additional support.\",\"We investigated an approach that combines competency questions and knowledge reuse via recommendations to help users bootstrap ontologies. We present our approach, its implementation, and an evaluation in the form of a controlled user study.\",5,\"Thu 9:50 - 10:00 AM\",1429818600,1429819200,\"Authors\",null],[715,712,\"pn2560\",\"Note\",\"A Spreadsheet Model for Handling Streaming Data\",\"We present a spreadsheet model for working with streaming data. Our prototype tool presents techniques to let the user stream data from web services and web input elements to a spreadsheet without preprogramming those sources into the tool. Spreadsheet cells record metadata about where and when the data came from, allowing the user to view and manipulate streaming data using temporal information. Starting and pausing a data stream in the spreadsheet can be controlled programmatically using values computed by spreadsheet cells, making the spreadsheet program highly dynamic and interactive. We demonstrate the range of our design with a series of examples highlighting its ability to create different kinds of applications that process real-time data from the web using simple spreadsheet formulas. \",\"This paper contributes a spreadsheet model for using streaming data, introducing novel ways to stream data from web sources, control streaming timing and manipulate data using temporal information in spreadsheets. \",5,\"Thu 10:00 - 10:10 AM\",1429819200,1429819800,\"Authors\",null],[716,712,\"pn160\",\"Paper\",\"TextAlive: Integrated Design Environment for Kinetic Typography\",\"This paper presents TextAlive, a graphical tool that allows interactive editing of kinetic typography videos in which lyrics or transcripts are animated in synchrony with the corresponding music or speech. While existing systems have allowed the designer and casual user to create animations, most of them do not take into account synchronization with audio signals. They allow predefined motions to be applied to objects and parameters to be tweaked, but it is usually impossible to extend the predefined set of motion algorithms within these systems. We therefore propose an integrated design environment featuring (1) GUIs that designers can use to create and edit animations synchronized with audio signals, (2) integrated tools that programmers can use to implement animation algorithms, and (3) a framework for bridging the interfaces for designers and programmers. A preliminary user study with designers, programmers, and casual users demonstrated its capability in authoring various kinetic typography videos.\",\"We discuss an integrated design environment that allows {automatic composition, interactive editing, live programming} of kinetic typography videos in which lyrics or transcripts are animated synchronously with music or speech.\",5,\"Thu 10:10 - 10:30 AM\",1429819800,1429821000,\"Authors\",null],[717,712,\"pn1652\",\"Paper\",\"Power, Empowerment and Open Source Usability\",\"Open source software (OSS) projects are often seen as participatory and egalitarian settings where people collaboratively develop software to serve their needs as well as the needs of others. In this paper, however, we argue that power and politics also characterize OSS development, and that this has serious implications for OSS usability. The existing Human–Computer Interaction (HCI) research on OSS usability has already shown that power and politics play a role; this study offers a theoretical treatment of the matter. A theoretical framework on power and empowerment is utilized in analyzing empirical data on OSS usability as well as the existing body of knowledge on the topic. With the help of this framework, HCI research can address the aspects of power and empowerment in OSS usability in a more systematic and comprehensive manner.\",\"A thorough theoretical treatment of power dynamics is lacking in HCI research on OSS usability. We utilize a theoretical framework on power and empowerment to make sense of the phenomenon.\",5,\"Thu 10:30 - 10:50 AM\",1429821000,1429822200,\"Authors\",null],[718,-1,\"s-float-1\",\"Papers\",\"Accessibility for Vision Impaired Users\",null,null,12,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Chair\",\"Papers\"],[719,718,\"pn1077\",\"Paper\",\"Privacy Concerns and Behaviors of People with Visual Impairments\",\"Various technologies have been developed to help make the world more accessible to visually impaired people, and recent advances in low-cost wearable and mobile computing are likely to drive even moreadvances. However, the unique privacy and security needs of visually impaired people remain largely unaddressed. We conducted an exploratory user study with 14 visually impaired participants to understand the techniques they currently use for protecting privacy, their remaining privacy concerns,and how new technologies may be able to help. The interviews explored privacy not only in the physical world (e.g., bystanders overhearing private conversations) and the online world (e.g., determining if a URL is legitimate), but also in the interface between the two (e.g. bystanders `shoulder-surfing' data from screens). The study revealed serious concerns that are not adequately solved by current technology, and suggested new directions for improving the privacy  of this significant fraction of the population.\",\"This paper studies the unique privacy concerns of people with visual impairments,the techniques they currently use for protecting privacy,and how new technologies may assist them.\",12,\"Thu 9:30 - 9:50 AM\",1429817400,1429818600,\"Authors\",null],[720,718,\"pn691\",\"Paper\",\"Participatory Design of Therapeutic Video Games for Young People with Neurological Vision Impairment\",\"Neurological Vision Impairment (NVI) detrimentally impacts upon quality of life, as daily activities such as reading and crossing the road often become significantly impaired. Therapy strategies for NVI based on visual scanning of on-screen stimuli have recently been demonstrated as effective at improving functional vision. However, these strategies are repetitive, monotonous and unsuitable for use with children and young adults. This project explores the design of a game-based therapy programme that aims to support participant engagement and adherence. We first outline requirements for this software, before reporting on the iterative design process undertaken in collaboration with young people, therapists and teachers at a centre for vision impairment. Our work provides insights into the participatory design of games in collaboration with young people with special needs, and reflects upon the tension of balancing game challenge, therapy goals, and accessibility. Furthermore, it highlights the potential of games to empower special populations by providing a medium through which to communicate the subjective experience of specific impairments.\",\"Documents and discusses the challenges faced and lessons learned in designing and developing eye movement based therapeutic video games for young people with vision impairments. \",12,\"Thu 9:50 - 10:10 AM\",1429818600,1429819800,\"Authors\",null],[721,718,\"pn2486\",\"Paper\",\"ColourID: Improving Colour Identification for People with Impaired Colour Vision\",\"Being able to identify colours is a fundamental human activity; colour identification helps us work, get dressed, prepare food, and keep safe. But for the 5% of the world with impaired colour vision (ICV), colour identification is often a challenge, resulting in frustration and confusion with sometimes dangerous consequences. Colour namer tools have been proposed as a solution, however these are often slow to use and imprecise. To address these shortcomings, we developed three new colour identification techniques (ColourNames, ColourMeters, ColourPopper) using a new colour name dictionary based on the largest colour naming experiment to date. We compared our techniques to colour namers using participants with ICV in desktop and mobile conditions, and found that ColourNames and ColourPopper resulted in ~99% colour identification accuracy (10% higher than the colour namer), ColourMeters and ColourPopper were three times faster, and ColourPopper had lower perceived effort and was ranked significantly higher. With the benefits provided by our new colour identification techniques, people with ICV are one step closer to seeing the world like everyone else.\",\"Presents three new colour identification techniques that help people with impaired colour vision rapidly identify challenging colours with almost 100% accuracy.\",12,\"Thu 10:10 - 10:30 AM\",1429819800,1429821000,\"Authors\",null],[722,718,\"pn5107\",\"TOCHI\",\"ColorBless: Augmenting Visual Information for Colorblind People with Binocular Luster Effect\",\"Binocular disparity allows interesting visual effects visible only to people with stereoscopic 3D displays. Here, we studied and applied one such effect, binocular luster, to the application of digital colorblind aids with active shutter 3D. We developed two prototype techniques, ColorBless and PatternBless, to investigate the effectiveness of such aids and to explore the potential applications of luster effect in stereoscopic 3D beyond highlighting. User studies and interviews revealed that luster-based aids were fast and required lower cognitive effort than existing aids, and were preferred over other aids by the majority of colorblind participants. We infer design implications of luster effect from the study and propose potential applications in augmented visualization.\",\"Binocular disparity allows interesting visual effects visible only to people with stereoscopic 3D displays. Here, we studied and applied one such effect, binocular luster, to the application of digital colorblind aids with active shutter 3D. We developed two prototype techniques, ColorBless and PatternBless, to investigate the effectiveness of such aids and to explore the potential applications of luster effect in stereoscopic 3D beyond highlighting. User studies and interviews revealed that lus...\",12,\"Thu 10:30 - 10:50 AM\",1429821000,1429822200,\"Authors\",null],[723,-1,\"s-case4\",\"Case Studies\",\"Observation & Interaction\",null,null,2,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Chair\",\"Papers\"],[724,723,\"case131\",\"Case Study\",\"The 6th Finger: Practical Challenges in the Design of a Multitouch Audio Appliance\",\"Effective multitouch interaction does not reduce itself to a simple tracking of five fingers, there are several emerging effects that could prevent intuitive interaction in industrial appliances. This use-case describes practical challenges that were documented during the design and implementation of a holistic user interaction design in the domain of high-end audio equipments. The engineering process had to combine tangible user interface controls with state-of-the-art multitouch software fader panels in an intuitive way. This work also gives some background information about complex distributed audio routing equipment and user interaction along with technology and usability issues that appear during the design of a multitouch appliance. Several experiments were implemented in order to gain empiric data to substantiate our practical findings.    \",\"This case study gives a detailed description about practical issues during the design of a multitouch appliance in the domain of audio editing and routing. \",2,\"Thu 9:30 - 9:50 AM\",1429817400,1429818600,\"Authors\",null],[725,723,\"case136\",\"Case Study\",\"Photo Based Observation Method: How to quickly observe the behavior of the user\",\"Although users are still important in ever-changing mobile market, the time for understanding needs of the users is limited. In this context, we have utilized photos in observing the users in PBO method (Photo Based Observation Method) with which the behavioral pattern of the users can be easily and quickly discovered. PBO method has a 5-step research process – prediction, collection, classification, deduction and verification. Our 10 examiners, respectively, have taken photos of easily-witnessed user behaviors around each of them with their own smartphones for 7 days and we have collected and analyzed the photos. As a result, we found out 7 different patterns on how the users utilize their mobile devices. We expect such methodology to be useful in easily and quickly observing and collecting a common behavioral pattern of multiple users, providing us an opportunity to discover the users’ needs through their natural actions. \",\"This case study suggests a method for easily and quickly observing user’s behavior through the photos collected by examiner without an additional research tool.\",2,\"Thu 9:50 - 10:10 AM\",1429818600,1429819800,\"Authors\",null],[726,723,\"case138\",\"Case Study\",\"Representation Strategies Adopted by Participants in a Population Stereotype Hunt: A Case Study for Icon Design\",\"Population Stereotype tells interaction designers just one-half of the complete story. It informs them only about the level of general consensus regarding each representation generated by different participants. It does not provide answers to those questions, which ask how the representation is to be achieved. Identification of different representation strategies adopted by different participants can reveal the rest of the story. In the presence of more than one or no strong contenders (population stereotype), adoption of the right representation strategy can be really beneficial. As most of the representational strategies are complementary to each other, the combination of different representational strategies can lead towards a more representative icon development.\",\"Identification of different representation strategies adopted by different participants can reveal an effective and complementary method for designing icons. Know ‘how’ (which strategy to use) along with ‘what’ (representation).\",2,\"Thu 10:10 - 10:30 AM\",1429819800,1429821000,\"Authors\",null],[727,723,\"case153\",\"Case Study\",\"When Value is Greater than Money: a Micropayment System in Uganda\",\"The Pay-E-Safe system is a token-based car battery powered electronic micropayment system for emerging markets in East Africa. This is the story of how it was developed with different ethnic groups in Kasese, Uganda, combining methods from HCI, software development, and business modeling. We created a system that is inexpensive to implement, sensitive to the Ugandan context (e.g. low incomes, unreliable power supplies and unstable Internet connections) and provides benefits to local vendors as well as added value to users and their families. Using observations, interviews and prototype evaluations with local Ugandans we studied people’s spending behaviors and then explored alternative design solutions with them. Along the way, we discovered that a micropayment system could actually add value to the user experience beyond the exchange of money for services. This case study reports on how we designed the system and the additional value it afforded users.\",\"We created a system that is inexpensive to implement, sensitive to the Ugandan context and provides benefits to local vendors as well as added value to users and their families.\",2,\"Thu 10:30 - 10:50 AM\",1429821000,1429822200,\"Authors\",null],[728,-1,\"s-crs138\",\"Course\",\"Vision-Driven: Beyond Tangible Bits\",null,null,7,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Instructor\",null],[729,728,\"crs138\",\"Course\",\"Vision-Driven: Beyond Tangible Bits, Towards Radical Atoms\",\"Our vision-driven design research is carried out through an artistic approach. Whereas much of today’s mainstream Human Computer Interaction (HCI) research addresses functional concerns – the needs of users, practical applications, and usability evaluation – Tangible Bits and Radical Atoms (transformable physical materials) are driven by vision [Fig.1]. This is because today's technologies will become obsolete in one year, and today's applications will be replaced in 10 years, but true visions – we believe – can last longer than 100 years. This course introduces the trajectory of our vision-driven design research from Tangible Bits towards Radical Atoms, and a variety of interaction design projects that were presented and exhibited in Media Arts, Design, and HCI communities. Especially, we focus on the recent development in the two streams of Radical Atoms: 1) Dynamic Shape Display, and 2) Programmable Materials.\",\"This course introduces the trajectory of our vision-driven research from Tangible Bits towards Radical Atoms, and a variety of design projects presented and exhibited in Arts, Design and HCI communities.\",7,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Instructor\",null],[730,-1,\"s-crs119\",\"Course\",\"Interaction Design for Reading Devices\",null,null,14,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Instructor\",null],[731,730,\"crs119\",\"Course\",\"Interaction Design for Reading Devices and Apps\",\"This course presents opportunities within the space of digital reading systems for supporting better readability and accessibility than current approaches. A wide range of material will be covered, from dedicated e-reading devices to best practices for presenting reading material on screens and in apps. The course will review the history and flow of paper-based reading through the ages, using this to motivate and illustrate better digital reading designs for the future. Attendees will be introduced, interactively, to the many issues that are present when displaying text on screens, including poor interface choices, and affordances that have been badly migrated from paper. In the process, we will explore how future designs can support greater immersion and accessibility without compromising on readability. By the end, attendees will have learnt several techniques for designing better future digital reading systems.\",\"This course presents opportunities for supporting better digital readability and accessibility than at present. From paper history to digital future, attendees will learn how to design better future e-reading systems.\",14,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Instructor\",null],[732,-1,\"s-crs110\",\"Course\",\"Introduction to Positive Computing\",null,null,9,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Instructor\",null],[733,732,\"crs110\",\"Course\",\"Introduction to Positive Computing – Technology that fosters wellbeing\",\"A growing number of HCI professionals are interested in how we might design technology to foster psychological wellbeing.  Meeting such an aim will involve a crossing of disciplines, of methods, and a new way of thinking about what technology should be doing for us. By turning to the well-established research and methods available in psychology, education, neuroscience, and HCI, we can begin to cultivate a field dedicated to the design and development of technology that supports wellbeing and human potential, a field we refer to as positive computing [1]. In this course we will explore multidisciplinary approaches to evaluating and designing for digital experience that supports wellbeing determinants like self-awareness, autonomy, resilience, mindfulness, and altruism. The objective of this course is to provide participants with: a theoretical foundation, a practical framework, a look at the state of the art, and group-generated design strategies to better support wellbeing in their current and future projects.\",\"If we want technology to increase worldwide wellbeing, we have to design for wellbeing directly. Positive computing – the development of technology to support psychological wellbeing and human potential \",9,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"Instructor\",null],[734,-1,\"s-panel5\",\"Panel\",\"Mobile Devices Revolutionizing UI\",null,null,1,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"\",\"\"],[735,734,\"pan120\",\"Panel\",\"How Mobile Devices are Revolutionizing User Interaction\",\"\",\"...\",1,\"Thu 9:30 - 10:50 AM\",1429817400,1429822200,\"\",\"\"],[736,-1,\"break-10\",\"Breaks\",\"Coffee Break\",null,null,15,\"Thu 10:50 - 11:30 AM\",1429822200,1429824600,\"\",\"\"],[737,-1,\"int-4\",\"Interactivity\",\"Interactivity Demos Exhibit\",null,null,15,\"Thu 10:50 - 11:30 AM\",1429822200,1429824600,\"\",\"\"],[738,-1,\"s150\",\"Papers\",\"Robot Personalities\",null,null,3,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"Chair\",\"Papers\"],[739,738,\"pn1538\",\"Paper\",\"Too Much Humanness for Human-Robot Interaction: Exposure to Highly Humanlike Robots Elicits Aversive Responding in Observers\",\"People tend to anthropomorphize agents that look and/or act human, and further, they tend to evaluate such agents more positively. This, in turn, has motivated the development of robotic agents that are humanlike in appearance and/or behavior. Yet, some agents -- often those with highly humanlike appearances -- have been found to elicit the opposite, wherein they are evaluated more negatively than their less humanlike counterparts. These trends are captured by Masahiro Mori's uncanny valley hypothesis, which describes a (uncanny) valley in emotional responding - a switch from affinity to dislike - elicited by agents that are ``too humanlike''. However, while the valley phenomenon has been repeatedly observed via subjective measures, it remains unknown as to whether such evaluations reflect a potential impact to a person's behavior (i.e., aversion). We attempt to address this gap in the literature via a novel experimental paradigm employing both traditional subjective ratings, as well as measures of peoples' behavioral and phsyiological responding. The results show that not only do people rate highly humanlike robots as uncanny, but moreover, they exhibit greater avoidance of such encounters than encounters with less humanlike and human agents. Thus, the findings not only support Mori's hypothesis, but further, they indicate the valley should be taken as a serious consideration for peoples' interactions with humanlike agents.\",\"We sought to determine whether the uncanny valley presents a serious consideration for human-agent interactions. Specifically, we investigated whether highly humanlike robots could be so unnerving that they motivate people to avoid them.\",3,\"Thu 11:30 - 11:50 AM\",1429824600,1429825800,\"Authors\",null],[740,738,\"pn2586\",\"Paper\",\"Look Like Me: Matching Robot Personality via Gaze to Increase Motivation\",\"Socially assistive robots are envisioned to provide social and cognitive assistance where they will seek to motivate and engage people in therapeutic activities. Due to their physicality, robots serve as a powerful technology for motivating people. Prior work has shown that effective motivation requires adaption to user needs and characteristics, but how robots might successfully achieve such adaptation is still unknown. In this paper, we present work on matching a robot's personality-expressed via its gaze behavior-to that of its users. We confirmed in an online study with 22 participants that the robot's gaze behavior can successfully express either an extroverted or introverted personality. In a laboratory study with 40 participants, we demonstrate the positive effect of personality matching on a user's motivation to engage in a repetitive task. These results have important implications for the design of adaptive robot behaviors in assistive human-robot interaction.\",\"Presents work on matching a robot's personality, expressed via gaze behavior, to that of its users. Demonstrates the positive effect of personality matching on a user's task motivation.\",3,\"Thu 11:50 - 12:10 PM\",1429825800,1429827000,\"Authors\",null],[741,738,\"pn366\",\"Paper\",\"The Social Impact of a Robot Co-Worker in Industrial Settings\",\"Across history and cultures, robots have been envisioned as assistants working alongside people. Following this vision, an emerging family of products-collaborative manufacturing robots-is enabling human and robot workers to work side by side as collaborators in manufacturing tasks. Their introduction presents an opportunity to better understand people's interactions with and perceptions of a robot \\\"co-worker\\\" in a real-world setting to guide the design of these products. In this paper, we present findings from an ethnographic field study at three manufacturing sites and a Grounded Theory analysis of observations and interviews. Our results show that, even in this safety-critical manufacturing setting, workers relate to the robot as a social entity and rely on cues to understand the robot's actions, which we observed to be critical for workers to feel safe when near the robot. These findings contribute to our understanding of interactions with robotic products in real-world settings and offer important design implications.\",\"We present results from a field study at three manufacturing sites examining the social relationship between a collaborative manufacturing robot and human workers.\",3,\"Thu 12:10 - 12:30 PM\",1429827000,1429828200,\"Authors\",null],[742,738,\"pn2328\",\"Paper\",\"Robots, Pancakes, and Computer Games: Designing Serious Games for Robot Imitation Learning\",\"Autonomous manipulation robots can be valuable aids as interactive agents in the home, yet it has proven extremely difficult to program their behavior. Imitation learning uses data on human demonstrations to build behavioral models for robots. In order to cover a wide range of action strategies, data from many individuals is needed. Acquiring such large amounts of data can be a challenge. Tools for data capturing in this domain must thus implement a good user experience. We propose to use human computation games in order to gather data on human manual behavior. We demonstrate the idea with a strategy game that is operated via a natural user interface. A comparison between using the game for action execution and demonstrating actions in a virtual environment shows that people interact longer and have a better experience when playing the game.\",\"We designed a motion-based human computation game to gather demonstration data for robot imitation learning. This improves demonstrator experience over data acquisition in non-game virtual environments, while maintaining data quality.\",3,\"Thu 12:30 - 12:50 PM\",1429828200,1429829400,\"Authors\",null],[743,-1,\"s129\",\"Papers\",\"Coping & Wellbeing Through HCI\",null,null,12,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"Chair\",\"Papers\"],[744,743,\"pn2085\",\"Paper\",\"Finding the Adaptive Sweet Spot: Balancing Compliance and Achievement in Automated Stress Reduction\",\"Automated coaching systems offer a convenient, cost-effective way to reduce stress, which can be a serious health issue. However, one concern with such systems is compliance; users fail to achieve daily stress reduction goals because goals are too easy or too difficult. To address this, we built DStress (Design for Stress), a theoretically grounded system that sets adaptive goals in three coaching dimensions: Exercise, Meditation and Accessibility. DStress modifies goal-difficulty based on the individual’s immediately previous performance. In a 28-day deployment with 65 users, DStress reduced scores on one direct measure of stress almost in half, significantly more than two other non-adaptive coaching strategies. However, on a second direct stress measure, no improvement was found. There were also no improvements on other indirect stress measures. Analysis of 2842 user-generated reports suggests our findings were the result of DStress balancing compliance against the degree of challenge of the goals it would set.  \",\"Describes a theoretically-grounded system to reduce stress by adapting goal difficulty and accessibility of exercise and meditation. The system reduces stress by balancing individual compliance with degree of challenge. \",12,\"Thu 11:30 - 11:50 AM\",1429824600,1429825800,\"Authors\",null],[745,743,\"pn862\",\"Paper\",\"SoberDiary: A Phone-based Support System for Assisting Recovery from Alcohol Dependence\",\"Alcohol dependence is a chronic disorder associated with severe harm in multiple areas, and relapsing is easy, despite treatment. This study proposes SoberDiary, a phone-based support system that enables alcohol-dependent patients to self-monitor and -manage their own alcohol behavior, and remain sober in their daily lives. We tested SoberDiary in a real-life 12-week user study involving 27 clinical patients. The quantitative and qualitative results revealed that SoberDiary helped patients self-monitor and -manage their alcohol-use behavior, and reduced their total alcohol consumption as well as the number of heavy drinking days. Compared with patients who received standard treatment alone, this study demonstrated SoberDiary successfully complemented current alcohol treatment in reducing patients' alcoholic cravings and dropout rate over 3-month study period. Follow-up interviews further revealed the sophisticated use practices and value of SoberDiary.\",\"The contributions are the design, prototype, and evaluation of SoberDiary, which is a phone-based support system to help alcohol-dependent patients maintain sobriety in daily life once completing alcohol withdrawal treatment.\",12,\"Thu 11:50 - 12:10 PM\",1429825800,1429827000,\"Authors\",null],[746,743,\"pn1940\",\"Paper\",\"Solutionism, the Game: Design Fictions for Positive Aging\",\"This paper reports a qualitative study of thriving older people and illustrates the findings with design fiction. Design research has been criticized as “solutionist”  i.e. solving problems that don’t exist or providing “quick fixes” for complex social, political and environmental problems. We respond to this critique by presenting a “solutionist” board game used to generate design concepts. Players are given data cards and technology dice, they move around the board by pitching concepts that would support positive aging. We argue that framing concept design as a solutionist game explicitly foregrounds play, irony and the limitations of technological intervention. Three of the game concepts are presented as design fictions in the form of advertisements for products and services that do not exist. The paper argues that design fiction can help create a space for design beyond solutionism.\",\"This paper reports a qualitative study of thriving older people and presents design fictions generated from the data through a solutionist game. It argues design fiction can help create a space for design beyond solutionism.\",12,\"Thu 12:10 - 12:30 PM\",1429827000,1429828200,\"Authors\",null],[747,743,\"pn1368\",\"Paper\",\"Design Considerations for Patient Portal Adoption by Low-Income, Older Adults\",\"This paper describes the results of an interview study investigating facilitators and barriers to adoption of patient portals among low-income, older adults in rural and urban populations in the southeastern United States. We describe attitudes of this population of older adults and their current level of technology use and patient portal use. From qualitative analysis of 36 patient interviews and 16 caregiver interviews within these communities, we derive themes related to benefits of portals, barriers to use, concerns and desired features. Based on our initial findings, we present a set of considerations for designing the patient portal user experience, aimed at helping healthcare clinics to meet U.S. federally-mandated `meaningful use' requirements.\",\"We present patient and caregiver interviews and resulting considerations for designing the patient portal user experience, aimed at helping healthcare clinics to meet meaningful use requirements.\",12,\"Thu 12:30 - 12:50 PM\",1429828200,1429829400,\"Authors\",null],[748,-1,\"s149\",\"Papers\",\"Interacting with Floors & Situated Displays\",null,null,13,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"Chair\",\"Papers\"],[749,748,\"pn638\",\"Paper\",\"BaseLase: An Interactive Focus+Context Laser Floor\",\"We present BaseLase, an interactive laser projected focus + context floor display. In order to provide a transportable system that works in areas where there are no ceilings, we provide an integrated unit (1.3m height) that stands on the floor. One unsolved challenge for laser projectors is to cover large projection areas while providing high resolution at the same time. Our focus + context laser projector solves this problem. BaseLase can cover a large context area in low resolution, while providing three movable high-resolution focus spots. We provide a convex mirror design that enables the laser to reach a large area (75m2) with low resolution while decreasing the beam divergence compared to spherical or parabolic mirrors. This hyperboloidal mirror shape approximately equalizes the point size on the floor independent from the projected location. We propose to add a number of planar mirrors on pan-tilt units to create dynamic zones of high resolution that can adjust to the user behavior. We provide example applications for BaseLase and report on user experience in preliminary trials.\",\"BaseLase is an interactive laser floor display. BaseLase covers a very large projection area (75m2) with a low resolution context projector, while it provides three movable high-resolution focus spots.  \",13,\"Thu 11:30 - 11:50 AM\",1429824600,1429825800,\"Authors\",null],[750,748,\"pn667\",\"Paper\",\"Ergonomic Interaction for Touch Floors\",\"The main appeal of touch floors is that they are the only direct touch form factor that scales to arbitrary size, therefore allowing direct touch to scale to very large numbers of display objects. In this paper, however, we argue that the price for this benefit is bad physical ergonomics: prolonged standing, especially in combination with looking down, quickly causes fatigue and repetitive strain. We propose addressing this issue by allowing users to operate touch floors in any pose they like, including sitting and lying. To allow users to transition between poses seamlessly, we present a simple pose-aware view manager that supports users by adjusting the entire view to the new pose. We support the main assumption behind the work with a simple study that shows that several poses are indeed more ergonomic for touch floor interaction than standing. We ground the design of our view manager by analyzing, which screen regions users can see and touch in each of the respective poses. \",\"Proposes improving the ergonomics of touch floor interaction by allowing users to interact in multiple poses. Presents PoseUI, a pose-aware view manager, whose design is based on two user studies.\",13,\"Thu 11:50 - 12:10 PM\",1429825800,1429827000,\"Authors\",null],[751,748,\"pn236\",\"Paper\",\"Display Blindness? Looking Again at the Visibility of Situated Displays using Eye-tracking\",\"Observational studies of situated displays have suggested that they are rarely looked at, and when they are it is typically only for a short period of time. Using a mobile eye tracker during a realistic shopping task in a shopping center, we show that people look at displays more than would be predicted from these observational studies, but still only short glances and often from quite far away. We characterize the patterns of eye-movements that precede looking at a display and discuss some of the design implications for the design of situated display technologies that are deployed in public space.\",\"Display blindness fact or myth? Using a mobile eye tracker we show that people do look at public digital displays far more than that predicted from previous observational studies.\",13,\"Thu 12:10 - 12:30 PM\",1429827000,1429828200,\"Authors\",null],[752,748,\"pn229\",\"Note\",\"Detecting User Intention at Public Displays from Foot Positions\",\"Foot positions are features of how humans express their intentions during conversations. This inspired us to investigate the usage of foot expressions during interactions with computers. We conducted an observational study to determine how foot positions correlate with the intentions of users at public displays. Using our findings, we performed a case study to demonstrate the usefulness of adapting content according to the intentions detected based on foot positions. Our results are valuable for researchers designing context-aware public displays.\",\"We explore foot position expressions at public displays to detect user intention. We present a user intention adaptive public display design measured by foot positions. The results are valuable for context-aware ubiquitous systems.\",13,\"Thu 12:30 - 12:40 PM\",1429828200,1429828800,\"Authors\",null],[753,-1,\"s120\",\"Papers\",\"Understanding Gamers\",null,null,10,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"Chair\",\"Papers\"],[754,753,\"pn1599\",\"Paper\",\"Masters of Control: Behavioral Patterns of Simultaneous Unit Group Manipulation in StarCraft 2\",\"Most user interfaces require the user to focus on one element at a time, but  StarCraft 2 is a game where players often control more than a hundred units simultaneously. The game interface provides an optional mechanism called \\\"control groups\\\" that allows players to select multiple units and assign them to a group in order to quickly recall previous selections of units. From an analysis of over 3,000 replays, we show that the usage of control groups is a key differentiator of individual players as well as players of different skill levels---novice users rarely use control groups while experts nearly always do. But players also behave differently in how they use their control groups, especially in time-pressured situations. While certain control group behaviors are common across all skill levels, expert players appear to be better at remaining composed and sustaining control group use in battle. We also qualitatively analyze discussions on web forums from players about how they use control groups to provide context about how such a simple interface mechanic has produced numerous ways of optimizing unit control.\",\"We investigate the keyboard usage habits of StarCraft 2 players of various skill levels and how seemingly meaningless actions can be relevant to HCI.\",10,\"Thu 11:30 - 11:50 AM\",1429824600,1429825800,\"Authors\",null],[755,753,\"pn1835\",\"Paper\",\"Cooperative Game Play with Avatars and Agents: Differences in Brain Activity and the Experience of Play\",\"The current study sought to identify the impact of whether teammates in a cooperative videogame were controlled by other humans (avatars) or by the game (agents). The impact on player experience was explored through both subjective questionnaire measures and brain wave activity measurement (electroencephalography). Play with human teammates was associated with a greater sense of relatedness, but less competence and flow than play with other computer-controlled teammates. In terms of brain activity, play with human teammates was associated with greater activity in the alpha, theta and beta power bands than play with computer-controlled teammates. Overall, the results suggest that play with human teammates involves greater cognitive activity in terms of ‘mentalising’ than play with computer-controlled teammates. Additionally, the associations between subjective measures of player experience and brain activity are described. Limitations of the current study are identified and key directions for future research are discussed.\",\"The paper discusses a study that explored the impact on player experience of whether teammates in a cooperative videogame were controlled by other humans (avatars) or by the game (agents). \",10,\"Thu 11:50 - 12:10 PM\",1429825800,1429827000,\"Authors\",null],[756,753,\"pn1874\",\"Note\",\"Examining Game World Topology Personalization\",\"We present an exploratory analysis of the effects of game world topologies on self-reported player experience in Computer Role Playing Games (CRPGs). We find that (a) players are more engaged in game worlds that better match their self-reported preferences; and (b) player preferences for game topology can be predicted based on their in-game behavior. We further describe how in-game behavioral features that correlate to preferences can be used to control procedural content generation algorithms.\",\"In an exploration of world topology personalization, we find that players are more engaged in worlds that match their topological preferences and that preferences for game topology can be predicted based on in-game behavior.\",10,\"Thu 12:10 - 12:20 PM\",1429827000,1429827600,\"Authors\",null],[757,753,\"pn820\",\"Note\",\"The Use of Games as Extrinisic Motivation in Education\",\"This paper presents results of a controlled trial using a clash-of-clans style game as an extrinsic motivator to encourage revision in 15-16 year olds preparing for a maths exam. The trial demonstrates a statistically significant improvement in performance among those using the game. We discuss differences between our work and a previous trial that showed no performance improvement from an extrinsically linked educational game, and present hypotheses as to why the game structure we used may be effective within our chosen deployment environment. \",\"We present a controlled trial using a clash-of-clans style game as an extrinsic motivator to encourage revision, and discuss why our game structure is effective within our chosen deployment environment. \",10,\"Thu 12:20 - 12:30 PM\",1429827600,1429828200,\"Authors\",null],[758,753,\"pn2213\",\"Paper\",\"Exploring Cyberbullying and Other Toxic Behavior in Team Competition Online Games\",\"In this work we explore cyberbullying and other toxic behavior in team competition online games. Using a dataset of over 10 million player reports on 1.46 million toxic players along with corresponding crowdsourced decisions, we test several hypotheses drawn from theories explaining toxic behavior. Besides providing large-scale, empirical based understanding of toxic behavior, our work can be used as a basis for building systems to detect, prevent, and counter-act toxic behavior.\",\"Drawing from sociology and psychology literature, we explore cyberbullying and other toxic behavior in the world's most popular online game, League of Legends, by using over 10 million player reports.\",10,\"Thu 12:30 - 12:50 PM\",1429828200,1429829400,\"Authors\",null],[759,-1,\"s-float-7\",\"Papers\",\"Mid-Air Gestures and Interaction\",null,null,4,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"Chair\",\"Papers\"],[760,759,\"pn362\",\"Paper\",\"Accurate, Robust, and Flexible Real-time Hand Tracking\",\"We present a new real-time hand tracking system based on a single depth camera.  The system can accurately reconstruct complex hand poses across a variety of subjects. It also allows for robust tracking, rapidly recovering from any temporary failures. Most uniquely, our tracker is highly flexible, dramatically improving upon previous approaches which have focused on front-facing close-range scenarios. This flexibility opens up new possibilities for human-computer interaction with examples including tracking at distances from tens of centimeters through to several meters (for controlling the TV at a distance), supporting tracking using a moving depth camera (for mobile scenarios), and arbitrary camera placements (for VR headsets). These features are achieved through a new pipeline that combines a multi-layered discriminative reinitialization strategy for per-frame pose estimation, followed by a generative model-fitting stage. We provide extensive technical details and a detailed qualitative and quantitative analysis.\",\"We present a new state of the art real-time articulated hand tracker. \",4,\"Thu 11:30 - 11:50 AM\",1429824600,1429825800,\"Authors\",null],[761,759,\"pn147\",\"Paper\",\"Investigating the Dexterity of Multi-Finger Input for Mid-Air Text Entry\",\"This paper investigates an emerging input method enabled by progress in hand tracking: input by free motion of fingers. The method is expressive, potentially fast, and usable across many settings as it does not insist on physical contact or visual feedback. Our goal is to inform the design of high-performance input methods by providing detailed analysis of the performance and anatomical characteristics of finger motion. We conducted an experiment using a commercially available sensor to report on the speed, accuracy, individuation, movement ranges, and individual differences of each finger. Findings show differences of up to 50% in movement times and provide indices quantifying the individuation of single fingers. We apply our findings to text entry by computational optimization of multi-finger gestures in mid-air. To this end, we define a novel objective function that considers performance, anatomical factors, and learnability. First investigations of one optimization case show entry rates of 22 words per minute (WPM). We conclude with a critical discussion of the limitations posed by human factors and performance characteristics of existing markerless hand trackers.\",\"We investigate the dexterity of using multiple fingers for mid-air input. Our data on performance and individuation can be used to design mid-air text entry methods.\",4,\"Thu 11:50 - 12:10 PM\",1429825800,1429827000,\"Authors\",null],[762,759,\"pn140\",\"Note\",\"Myopoint: Pointing and Clicking Using Forearm Mounted Electromyography and Inertial Motion Sensors\",\"We describe a mid-air, barehand pointing and clicking interaction technique using electromyographic (EMG) and inertial measurement unit (IMU) input from a consumer armband device. The technique uses enhanced pointer feedback to convey state, a custom pointer acceleration function tuned for angular inertial motion, and correction and filtering techniques to minimize side-effects when combining EMG and IMU input. By replicating a previous large display study using a motion capture pointing technique, we show the EMG and IMU technique is only 430 to 790 ms slower and has acceptable error rates for targets greater than 48 mm. Our work demonstrates that consumer-level EMG and IMU sensing is practical for distant pointing and clicking on large displays.\",\"We describe and evaluate a mid-air, barehand pointing and clicking technique using electromyographic and inertial input from a consumer armband device and demonstrate the practicality of such an approach.\",4,\"Thu 12:10 - 12:20 PM\",1429827000,1429827600,\"Authors\",null],[763,759,\"pn2607\",\"Note\",\"Joint Estimation of 3D Hand Position and Gestures from Monocular Video for Mobile Interaction\",\"We present a machine learning technique to recognize gestures and estimate metric depth of hands for 3D interaction, relying only on monocular RGB video input. We aim to enable spatial interaction with small, body-worn devices where rich 3D input is desired but the usage of conventional depth sensors is prohibitive due to their power consumption and size. We propose a hybrid classification-regression approach to learn and predict a mapping of RGB colors to absolute, metric depth in real time. We also classify distinct hand gestures, allowing for a variety of 3D interactions. We demonstrate our technique with three mobile interaction scenarios and evaluate the method quantitatively and qualitatively.\",\"We present a machine learning technique to jointly estimate 3D hand positions and gestures for rich, 3D interaction with mobile and wearable devices, only requiring monocular RGB video as input.\",4,\"Thu 12:20 - 12:30 PM\",1429827600,1429828200,\"Authors\",null],[764,759,\"pn1268\",\"Paper\",\"zSense: Enabling Shallow Depth Gesture Recognition for Greater Input Expressivity on Smart Wearables\",\"In this paper we present zSense, which provides greater input expressivity for spatially limited devices such as smart wearables through a shallow depth gesture recognition system using non-focused infrared sensors. To achieve this, we introduce a novel Non-linear Spatial Sampling (NSS) technique that significantly cuts down the number of required infrared sensors and emitters. These can be arranged in many different configurations; for example, number of sensor emitter units can be as minimal as one sensor and two emitters. We implemented different configurations of zSense on smart wearables such as smartwatches, smartglasses and smart rings. These configurations naturally fit into the flat or curved surfaces of such devices, providing a wide scope of zSense enabled application scenarios. Our evaluations reported over 94.8% gesture recognition accuracy across all configurations.\",\"In this paper we present zSense, which provides greater input expressivity for spatially limited devices such as smart wearables through a shallow depth gesture recognition system using non-focused infrared sensors.\",4,\"Thu 12:30 - 12:50 PM\",1429828200,1429829400,\"Authors\",null],[765,-1,\"s126\",\"Papers\",\"Bridging Communities\",null,null,15,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"Chair\",\"Papers\"],[766,765,\"pn824\",\"Paper\",\"Computer-Enabled Project Spaces: Connecting with Palestinian Refugees across Camp Boundaries\",\"Come_IN computer clubs are an established approach to support inter-cultural and inter-generational learning in German neighborhoods. We explore the adaptation of the come_IN concept to the Palestinian context as a means to bridge the social and economic divide that has plagued West Bank society for a period of more than six decades. Social exclusion, political conflicts and prolonged military occupation have kept the refugee camps in a perpetual state of marginalization. In this paper we report on our work in Al Amari– a Palestinian refugee camp adjacent to the city of Ramallah. We examine how the computer club enables the emergence of social ties among residents of the camp and university students acting as tutors. Even though the ties are small-scale and informal, they have the potential to generate new and wider opportunities for exchange that may eventually support more social integration between the camp's marginalized population and the wider Palestinian population.\",\"In this paper, we examine the establishment of a community-based learning space in the Al-Amari refugee camp. The paper contributes to an existing literature on community informatics and HCI4D.\",15,\"Thu 11:30 - 11:50 AM\",1429824600,1429825800,\"Authors\",null],[767,765,\"pn1915\",\"Paper\",\"Transnationalism, Indigenous Knowledge and Technology: Insights from the Kenyan Diaspora\",\"Our paper investigates how current digital technologies are sufficient, or insufficient, in supporting Kenyan transnationals in practising indigenous knowledge. We first outline a view of indigenous knowledge, and then apply it to a study of diaspora Kenyans living in Australia. The findings are framed as nine techniques for sustaining displaced practising of indigenous knowledge. These appropriations suggest directions for technology innovation, providing design considerations for technologies that translate, formulate and support indigenous knowledge in transnational contexts.\",\"We first propose a triad view of indigenous knowledge. Then apply this lens to generate findings and design recommendations from an ethnographic study conducted with Kenyan transnationals in Australia. \",15,\"Thu 11:50 - 12:10 PM\",1429825800,1429827000,\"Authors\",null],[768,765,\"pn687\",\"Paper\",\"Collective Intelligence in Computer-Mediated Collaboration Emerges in Different Contexts and Cultures\",\"Collective intelligence (CI) is a property of groups that emerges from the coordination and collaboration of members and predicts group performance on a wide range of tasks. Previous studies of CI have been conducted with lab-based groups in the United States. We introduce a new standardized online battery to measure CI and demonstrate consistent emergence of a CI factor across three different studies despite broad differences in (a) communication media (face-to-face vs online), (b) group contexts (short-term ad hoc groups vs long-term groups) and (c) cultural settings (US, Germany, and Japan). In two of the studies, we also show that CI is correlated with a group’s performance on more complex tasks. Consequently, the CI metric provides a generalizable performance measure for groups that is robust to broad changes in media, context, and culture, making it useful for testing the effects of general-purpose collaboration technologies intended to improve group performance.\",\"We propose a standardized battery for measuring collective intelligence in teams collaborating online, which we found robust to variation in communication modes, group context, and cultural settings. \",15,\"Thu 12:10 - 12:30 PM\",1429827000,1429828200,\"Authors\",null],[769,765,\"pn2606\",\"Paper\",\"Google+ Communities as Plazas and Topic Boards\",\"Researchers have recently been focusing on understanding online communities in social networks that offer easy access to new audiences. How do online communities function within these social networks? In this work, we conducted a mixed-method study of public Google+ Communities and found two major types evident in both how users talk about them and how they appear to use them: plazas to meet new people, and topic boards to discuss common interests. This reflects two common motivations users cite in describing Communities: \\\"meeting like minded people\\\" and \\\"finding great content\\\".  We characterize these two types of Communities within Google+ using mixed methods including surveys, interviews, and quantitative analytics, and expose differences in user behaviors between them.\",\"Explores why people use Communities in Google+ and how these motivations relate to the social network's follower graph.\",15,\"Thu 12:30 - 12:50 PM\",1429828200,1429829400,\"Authors\",null],[770,-1,\"s121\",\"Papers\",\"Gender & Technology\",null,null,11,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"Chair\",\"Papers\"],[771,770,\"pn2314\",\"Paper\",\"Gender and Tenure Diversity in GitHub Teams\",\"Software development is usually a collaborative venture. Open Source Software (OSS) projects are no exception; indeed, by design, the OSS approach can accommodate teams that are more open, geographically distributed, and dynamic than commercial teams. This, we find, leads to OSS teams that are quite diverse. Team diversity, predominantly in offline groups, is known to correlate with team output, mostly with positive effects. How about in OSS? Using GitHub, the largest publicly available collection of OSS projects, we studied how gender and tenure diversity relate to team productivity and turnover. Using regression modeling of GitHub data and the results of a survey, we show that both gender and tenure diversity are positive and significant predictors of productivity, together explaining a sizable fraction of the data variability. These results can inform decision making on all levels, leading to better outcomes in recruiting and performance.\",\"Given technical confounds of team size, project age, and others, having higher gender and tenure diversity is associated with higher productivity in GitHub teams.\",11,\"Thu 11:30 - 11:50 AM\",1429824600,1429825800,\"Authors\",null],[772,770,\"pn2234\",\"Paper\",\"Offline Strangers, Online Friends: Bridging Classroom Gender Segregation with WhatsApp\",\"Mobile Instant Messaging (MIM) apps such as WhatsApp are heralding new communication behaviors amongst students  in peri-urban India. From an ethnographic study of a co-ed engineering college, we describe and analyze the role of  WhatsApp in both engendering and balancing the ripples caused by cross gender communication. Through in-depth interviews and immersive participant observations in both physical as well as digital spaces, we show how WhatsApp emerges as the backbone of student interactions in a gender segregated academic environment. In analyzing social conditions and identifying structural features of WhatsApp that led to its bottoms up appropriation, our study presents possibilities for educators and designers aiming to create technology enabled collaborative spaces between people otherwise hemmed in by social norms from reaching out to one another.    \",\"MIMs like WhatsApp are heralding new communication behaviors among students in peri-urban India. From an ethnographic study of an engineering college, we describe the role of  WhatsApp in engendering and balancing ripples of cross-gender communication\",11,\"Thu 11:50 - 12:10 PM\",1429825800,1429827000,\"Authors\",null],[773,770,\"pn734\",\"Paper\",\"Online Inspiration and Exploration for Identity Reinvention\",\"Self-representation online can be difficult for those who are in life transitions that involve exploring new identity facets and changes in personal style. Many desire to tailor their online representations for different audiences. Social media site profiles and sharing settings offer varying levels of anonymity, privacy, and thus safety, but these settings are often opaque and poorly understood. To understand the complex relationship between identity, personal style and online self-representation, we examine how people explore and experiment with new styles in public and in private online settings during gender transition. We present the results of interviews with transgender people who have recently reinvented their personal style, or are planning to do so in the near future. We find that people explore new styles in online settings to craft possible or ideal future selves. When involving others, people engage intimate and unknown others, but often avoid weak ties. Our results indicate that to account for changing identities, social media sites must be designed to support finding inspiration and advice from strangers and style experimentation with close friends.\",\"We examine how people explore new styles online during gender transition. We find that people craft possible/ideal future selves, engaging intimate and unknown others but avoiding weak ties. \",11,\"Thu 12:10 - 12:30 PM\",1429827000,1429828200,\"Authors\",null],[774,770,\"pn2146\",\"Paper\",\"Unequal Representation and Gender Stereotypes in Image Search Results for Occupations\",\"Information environments have the power to affect people’s perceptions and behaviors. In this paper, we present the results of studies in which we characterize the gender bias present in image search results for a variety of occupations. We experimentally evaluate the effects of bias in image search results on the images people choose to represent those careers and on people’s perceptions of the prevalence of men and women in each occupation. We find evidence for both stereotype exaggeration and systematic underrepresentation of women in search results. We also find that people rate search results higher when they are consistent with stereotypes for a career, and shifting the representation of gender in image search results can shift people’s perceptions about real-world distributions. We also discuss tensions between desires for high-quality results and broader societal goals for equality of representation in this space.\",\"We explore the current state of gender portrayals in image search results, finding evidence for stereotyping and misrepresentation. We discuss several competing design goals for representation in search algorithm design.\",11,\"Thu 12:30 - 12:50 PM\",1429828200,1429829400,\"Authors\",null],[775,-1,\"s-float-31\",\"Papers\",\"MOOCS & e-Learning\",null,null,5,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"Chair\",\"Papers\"],[776,775,\"pn1574\",\"Paper\",\"Providing Adaptive Support in an Interactive Simulation for Learning: an Experimental Evaluation\",\"Recent rise of Massive Open Online Courses (MOOCs) with unlimited participants, makes employing learning tools such as interactive simulations all but inevitable. Interactive simulations give students the opportunity to experiment with concrete examples and develop better understanding of concepts they have learned. However, some students do not learn well from this relatively unstructured form of interaction, suggesting the provision of adaptive support as a way to address this issue.  This paper presents a formal evaluation of providing support to facilitate open exploration. We describe the process of designing an intervention delivery mechanism for adding adaptive support to an exploratory interactive simulation.  The experimental evaluation of the adaptive version of the simulation indicates that the adaptive support provided to students significantly improved their learning performance. Quantitative and qualitative evaluations of users’ acceptance of the system are generally positive but pinpoint areas for improvement.      \",\"This work presents a method for providing personalized support to facilitate open-ended exploration in interactive simulations for learning. The experimental results show that personalized support can increase the pedagogical effectiveness of these learning tools.\",5,\"Thu 11:30 - 11:50 AM\",1429824600,1429825800,\"Authors\",null],[777,775,\"pn1167\",\"Paper\",\"Interactive Cloud Experimentation for Biology: An Online Education Case Study\",\"Interacting with biological systems via experiments is important for academia, industry, and education, but access barriers exist due to training, costs, safety, logistics, and spatial separation. High-throughput equipment combined with web streaming could enable interactive biology experiments online, but no such platform currently exists. We present a cloud experimentation architecture (paralleling cloud computation), which is optimized for a class of domain-specific equipments (biotic processing units - BPU) to share and execute many experiments in parallel remotely and interactively at all time. We implemented an instance of this architecture that enables chemotactic experiments with a slime mold Physarum Polycephelum. A user study in the blended teaching and research setting of a graduate-level biophysics class demonstrated that this platform lowers the access barrier for non-biologists, enables discovery, and facilitates learning analytics. This architecture is flexible for integration with various biological specimens and equipments to facilitate scalable interactive online education, collaborations, research, and citizen science.\",\"We implemented and analyzed the first end-to-end use-case of a truly interactive biology cloud lab. This enables a true lab component for online education and facilitates interdisciplinary participation in biology.\",5,\"Thu 11:50 - 12:10 PM\",1429825800,1429827000,\"Authors\",null],[778,775,\"pn1335\",\"Paper\",\"Mining Memories: Designing a Platform to Support Social Media Based Writing\",\"Many teens struggle with school writing and particularly in identifying personally relevant topics, which motivate writing improvement. However, a wealth of potential topics is available through their social media data. We explore the design of Sparkfolio, a prewriting support tool that aims to help students successfully prepare meaningful writing topics from their own social media content. This web-delivered tool was evaluated with 46 teen users in the context of their high school English class. Findings demonstrate that the use of social media can enhance the quality of written outcomes, as Sparkfolio users had significantly greater gains than a control group.\",\"We present a social media based writing tool to enhance student writing quality and motivation. Evaluated with 46 students, we demonstrate improved engagement and learning through personally relevant social content.\",5,\"Thu 12:10 - 12:30 PM\",1429827000,1429828200,\"Authors\",null],[779,775,\"pn727\",\"Paper\",\"Wait-Learning: Leveraging Wait Time for Second Language Education\",\"Competing priorities in daily life make it difficult for those with a casual interest in learning to set aside time for regular practice. In this paper, we explore wait-learning: leveraging brief moments of waiting during a person’s existing conversations for second language vocabulary practice, even if the conversation happens in the native language. We present an augmented version of instant messaging, WaitChatter, that supports the notion of wait-learning by displaying contextually relevant foreign language vocabulary and micro-quizzes just-in-time while the user awaits a response from her conversant. Through a two week field study of WaitChatter with 20 people, we found that users were able to learn 57 new words on average during casual instant messaging. Furthermore, we found that users were most receptive to learning opportunities immediately after sending a chat message, and that this timing may be critical given user tendency to multi-task during waiting periods.\",\"We introduce a novel idea called “wait-learning,” and extend instant messaging to display interactive micro-quizzes while users await an IM response. In two weeks, users learned 57 words while chatting.\",5,\"Thu 12:30 - 12:50 PM\",1429828200,1429829400,\"Authors\",null],[780,-1,\"s-panel6\",\"Panel\",\"Why Google cannot be the # 1 in Korea?: In Search for Critical Success Factors from Local User Experience\",null,null,1,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"\",\"\"],[781,780,\"pan121\",\"Panel\",\"Why Google cannot be the # 1 in Korea?: In Search for Critical Success Factors from Local User Experience\",\"\",\"...\",1,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"\",\"\"],[782,-1,\"s-alt1\",\"alt.chi\",\"Mindfulness and Care\",null,null,2,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"Authors\",\"Papers\"],[783,782,\"alt107\",\"alt.chi\",\"Being Reasonable: A Manifesto for the Inclusion of Disabled People in SIGCHI Conferences\",\"\",\"...\",2,\"Thu 11:30 - 11:50 AM\",1429824600,1429825800,\"Authors\",\"Papers\"],[784,782,\"alt118\",\"alt.chi\",\"Crossing Cultural and Theoretical Borders: towards Mindfulness through a Cigarette and a Torii Gate\",\"\",\"...\",2,\"Thu 11:50 - 12:10 PM\",1429825800,1429827000,\"Authors\",\"Papers\"],[785,782,\"alt130\",\"alt.chi\",\"Communication in the Changing Dyadic Interaction of Diverse Players\",\"\",\"...\",2,\"Thu 12:10 - 12:30 PM\",1429827000,1429828200,\"Authors\",\"Papers\"],[786,782,\"alt164\",\"alt.chi\",\"Captchat: A Messaging Tool to Frustrate Ubiquitous Surveillance\",\"\",\"...\",2,\"Thu 12:30 - 12:50 PM\",1429828200,1429829400,\"Authors\",\"Papers\"],[787,-1,\"s-crs103\",\"Course\",\"Designing with the Mind in Mind\",null,null,7,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"Instructor\",null],[788,787,\"crs103\",\"Course\",\"Designing with the Mind in Mind: The Psychological Basis for UI Design Guidelines\",\"UI design rules and guidelines are not simple recipes.  Applying them effectively requires determining rule applicability and precedence and balancing trade-offs when rules compete.  By understanding the underlying psychology, designers and evaluators enhance their ability to apply design rules. This one-part (80-minute) course explains that psychology.\",\"By understanding the underlying psychology for the design rules, designers and evaluators enhance their ability to interpret and apply them.  Explaining that psychology is the focus of this course.\",7,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"Instructor\",null],[789,-1,\"s-crs124\",\"Course\",\"Benefit from Using ISO Standards\",null,null,14,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"Instructor\",null],[790,789,\"crs124\",\"Course\",\"How You Could Benefit from Using ISO Standards\",\"The course explains how international standards for HCI can provide a sound basis for education and training, can provide authority for design and development, and are a rich source of guidance and reference material.\",\"Learn how international standards can provide a sound basis for educational and training, can provide authority for design and development, and are a rich source of guidance and reference material.  \",14,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"Instructor\",null],[791,-1,\"s-sig7\",\"SIG\",\"Moving to a Virtual PC Meeting\",null,null,8,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"\",\"\"],[792,791,\"sig112\",\"SIG\",\"SIG for Moving to a Virtual PC Meeting\",\"CHI 2016 will pilot the process of having a virtual PC meeting for one of the subcommittees, instead of a face-to-face meeting. Although this pilot project is moving forward, there are still many decisions to be made about how the virtual PC meeting will be conducted. People interested in contributing ideas and concerns should attend this SIG - this is your chance to shape the future of the review process at CHI.\",\"CHI 2016 will pilot the process of having a virtual PC meeting for one of the subcommittees, instead of a face-to-face meeting. Although this pilot project is moving forward, there are still many decisions to be made about how the virtual PC meeting will be conducted. People interested in contributing ideas and concerns should attend this SIG - this is your chance to shape the future of the review process at CHI....\",8,\"Thu 11:30 - 12:50 PM\",1429824600,1429829400,\"\",\"\"],[793,-1,\"break-11\",\"Breaks\",\"Lunch Break (on your own) - Exhibit hall closes at 13:30\",null,null,15,\"Thu 12:50 - 2:30 PM\",1429829400,1429835400,\"\",\"\"],[794,-1,\"s-float-35\",\"Papers\",\"Social Media & Citizen Science\",null,null,15,\"Thu 2:30 - 3:50 PM\",1429835400,1429840200,\"Chair\",\"Papers\"],[795,794,\"pn1386\",\"Paper\",\"Piggyback Prototyping: Using Existing, Large-Scale Social Computing Systems To Prototype New Ones\",\"We propose a technique we call piggyback prototyping, a prototyping mechanism for designing new social computing systems on top of existing ones. Traditional HCI prototyping techniques do not translate well to large social computing systems. To address this gap, we describe a 6-stage process for prototyping new social computing systems using existing online systems, such as Twitter or Facebook. This allows researchers to focus on what people do on their system rather than how to attract people to it. We illustrate this technique with an instantiation on Twitter to pair people who are different from each other in airports. Even though there were many missed meetings, 53% of survey respondents would be interested in being matched again, and eight people even met in person. Through piggyback prototyping, we gained insight into the future design of this system. We conclude the paper with considerations for privacy, consent, volume of users, and evaluation metrics.\",\"We introduce piggyback prototyping, a prototyping mechanism for designing new large-scale social computing systems on top of existing ones such as Twitter or Facebook.   \",15,\"Thu 2:30 - 2:50 PM\",1429835400,1429836600,\"Authors\",null],[796,794,\"pn2224\",\"Note\",\"Situated Social Media Use: A Methodological Approach to Locating Social Media Practices and Trajectories\",\"In this paper we draw upon a number of explorations of social media activities, trying to capture and understand them as located, situated practices. This methodological endeavor spans over analyzing patterns in big data feeds (here Instagram) as well as small-scale video-based ethnographic studies of user activities. A situated social media perspective involves examining how social media production and consumption are intertwined. Drawing upon our studies of social media use in cultural institutions we show how visitors orient to their social media presence while attending to physical space during a visit, and how editing and sharing processes are formed by the trajectory through a space. We discuss the application and relevance of this approach for understanding social media and social photography in situ.\",\"This paper shows how social media users orient to their online presence while attending to co-participants and physical space, and how editing and sharing processes are formed by physical trajectories.\",15,\"Thu 2:50 - 3:00 PM\",1429836600,1429837200,\"Authors\",null],[797,794,\"pn207\",\"Note\",\"Break It Down: A Comparison of Macro- and Microtasks\",\"A large, seemingly overwhelming task can sometimes be transformed into a set of smaller, more manageable microtasks that can each be accomplished independently. For example, it may be hard to subjectively rank a large set of photographs, but easy to sort them in spare moments by making many pairwise comparisons. In crowdsourcing systems, microtasking enables unskilled workers with limited commitment to work together to complete tasks they would not be able to do individually. We explore the costs and benefits of decomposing macrotasks into microtasks for three task categories: arithmetic, sorting, and transcription. We find that breaking these tasks into microtasks results in longer overall task completion times, but higher quality outcomes and a better experience that may be more resilient to interruptions. These results suggest that microtasks can help people complete high quality work in interruption-driven environments.\",\"When should large macrotasks be broken down into smaller, more manageable microtasks (e.g., in crowdsourcing)? We study the benefits and drawbacks of breaking such tasks down, in terms of time taken, quality, interruptibility, and preference.\",15,\"Thu 3:00 - 3:10 PM\",1429837200,1429837800,\"Authors\",null],[798,794,\"pn586\",\"Note\",\"DIYbio Things: Open Source Biology Tools as Platforms for Hybrid Knowledge Production and Scientific Participation\",\"DIYbio (Do It Yourself Biology) is a growing movement of scientists, hobbyists, artists, and tinkerers who practice biology outside of professional settings. In this paper, we present our work with several open source DIYbio tools, including OpenPCR and Pearl Blue Transilluminator, which can be used to test DNA samples for specific sequences. We frame these platforms as things that gather heterogeneous materials and concerns, and enable new forms of knowledge transfer. Working with these hybrid systems in professional and DIY settings, we conducted a workshop where non-biologists tested food products for genetic modifications. Our findings suggest new design directions at the intersection of biology, technology, and DIY: i) DIYbio platforms as rich tools for hybrid knowledge production; and ii) open source biology as a site for public engagement with science.\",\"We worked with open-source biology tools (OpenPCR and PearlBiotech) in professional and DIY settings. We frame these platforms as \\\"things\\\" that gather heterogeneous materials and concerns, and enable new forms of knowledge transfer. \",15,\"Thu 3:10 - 3:20 PM\",1429837800,1429838400,\"Authors\",null],[799,794,\"pn1558\",\"Paper\",\"Designing for Citizen Data Analysis: A Cross-Sectional Case Study of a Multi-Domain Citizen Science Platform\",\"Designing an effective and sustainable citizen science (CS)project requires consideration of a great number of factors. This makes the overall process unpredictable,  even when a sound, user-centred design approach is followed by an experienced  team  of  UX  designers.   Moreover,  when  such  systems  are  deployed,  the  complexity  of  the  resulting  interactions challenges any attempt to generalisation from retrospective analysis.   In this paper,  we present a case study of the largest single platform of citizen driven data analysis projects to date, the Zooniverse.  By eliciting, through structured reflection, experiences of core members of its design team, our grounded analysis yielded four sets of themes,  focusing on Task Specificity, Community Development, Task Design and Public Relations and Engagement, supported by two-to-four specific design claims each. For each, we propose a set of design claims (DCs), drawing comparisons to the literature on crowdsourcing and online communities to contextualise our findings.\",\"Designing effective online citizen data analysis projects requires consideration of many factors. We present key insights from Zooniverse, spanning community integration, moderation and management, to public relations and task design.\",15,\"Thu 3:20 - 3:40 PM\",1429838400,1429839600,\"Authors\",null],[800,794,\"pn1257\",\"Note\",\"Is This How We (All) Do It?:  Butler Lies and Ambiguity Through a Broader Lens\",\"The ubiquity of mobile devices has resulted in more opportunities to interact with more people than ever before. Given a finite capacity for interaction with others, people commonly manage their availability by limiting others’ access to them. Prior work has demonstrated the importance of doing so in a relationally sensitive way and identified the butler lie, in which deception is used to manage availability, as a common linguistic strategy. Two key limitations of existing exploratory work, however, are limited samples of primarily students and a focus on media properties in understanding ambiguity that enables butler lies to be plausible. This paper aims to address these issues via a broad field study of deception and butler lies using a novel message-sampling method employed via a custom mobile app. Results show clear evidence of butler lies occurring in a broader population, with some gender differences; and urge adoption of a multi-level framework for understanding ambiguity that also includes private information and infrastructure-level attributes of interaction media.\",\"Extending research on deception as an availability management strategy to a broader population, this paper contributes to the taxonomy of ways ambiguity is used to deceive others in text messaging. \",15,\"Thu 3:40 - 3:50 PM\",1429839600,1429840200,\"Authors\",null],[801,-1,\"s-float-26\",\"Papers\",\"Home Physiotherapy & Rehabilitation\",null,null,12,\"Thu 2:30 - 3:50 PM\",1429835400,1429840200,\"Chair\",\"Papers\"],[802,801,\"pn1439\",\"Paper\",\"Physio@Home: Exploring Visual Guidance and Feedback Techniques for Physiotherapy Exercises\",\"Physiotherapy patients exercising at home alone are at risk of re-injury since they do not have corrective guidance from a therapist. To explore solutions to this problem, we designed Physio@Home, a prototype that guides people through pre-recorded physiotherapy exercises using real-time visual guides and multi-camera views. Our design ad-dresses several aspects of corrective guidance, including: plane and range of movement, joint positions and angles, and extent of movement. We evaluated our design, com-paring how closely people could follow exercise movements under various feedback conditions. Participants were most accurate when using our visual guide and multi-views. We provide suggestions for exercise guidance systems drawn from qualitative findings on visual feedback complexity.\",\"Articulates a set of design dimensions for systems used to guide/teach physical movement motivated from work with physiotherapists. Presents a study showing that a system with movement visualization and multi-view support promotes correct movement.\",12,\"Thu 2:30 - 2:50 PM\",1429835400,1429836600,\"Authors\",null],[803,801,\"pn2000\",\"Paper\",\"Lessons Learnt from Deploying an End-User Development Platform for Physical Rehabilitation\",\"Clinical researchers in rehabilitation technology have often called for exercise customization to address patient specific needs. Where such customization transcends simple parameter setting, the need for End-User Development (EUD) arises. EUD in this field can potentially tap on the expertise of highly skilled workers, but presents serious challenges regarding acceptance by end users and the feasibility of embedding EUD in their professional practice.  This paper describes the deployment and adoption process of TagTrainer, a physical rehabilitation technology that supports EUD. TagTrainer was deployed in four rehabilitation clinics and was used by 24 rehabilitation therapists. We analyze how they engaged in EUD activities and we discuss decisions that we took in the design and deployment of TagTrainer. Based on these case studies, we present guidelines for the deployment of EUD systems.\",\"Lessons from a multi-site case study on the deployment of an end-user extensible rehabilitation technology.\",12,\"Thu 2:50 - 3:10 PM\",1429836600,1429837800,\"Authors\",null],[804,801,\"pn2603\",\"Note\",\"Exergames for Physiotherapy and Rehabilitation: A Medium-term Situated Study of Motivational Aspects and Impact on Functional Reach\",\"Exergames are increasingly considered as an exercise instruction modality in health applications. Studies are typically conducted in non-situated contexts and capture short-term effects. We present first results from a medium-scale study conducted over the course of 5 weeks and integrated into a normal rehabilitation program. The study features three groups, comparing manually adjustable exergames with the identical games in adaptive versions and manual physiotherapy interventions without games. The results indicate that the exergames and traditional therapy are comparable regarding measures of competence and enjoyment, while exergames led to significantly higher scores for autonomy, presence, and in a functional reach test. With traditional therapy, scores for tension-pressure and effort-importance were significantly higher. The initial results of the broader study presented in this paper deliver insights regarding motivational aspects of exergames and traditional therapy and point out which motivational aspects could be strengthened in future implementations.\",\"The initial results of the study presented in this paper deliver insights regarding motivational aspects of exergames and traditional therapy and suggest motivational aspects to be strengthened in future implementations.\",12,\"Thu 3:10 - 3:20 PM\",1429837800,1429838400,\"Authors\",null],[805,801,\"pn1144\",\"Note\",\"Resilience Ex Machina: Learning a Complex Medical Device for Haemodialysis Self-Treatment\",\"Resilience, the ability to bounce back or manage sufficiently despite ongoing adversity, has received considerable interest from several domains over the last two decades. A concept that is easily and widely applicable, it has evolved a variety of nuanced interpretations. Recent work in the systems theory and resilience engineering domains has moved towards some sharper definitions. This paper discusses and develops these definitions, and by contrasting with robustness, applies them as an approach for HCI evaluation. Ethnographic data from a hospital training environment is used to examine how patients learn to operate home haemodialysis devices, and how patients’ safety is managed and maintained. This paper concludes that to improve recovery of adverse situations within the home, there is a necessity for design to support the acquirement of resilient reaction as a skill, in hand with temporal management. These ideas are developed in conjunction with the consideration of how technology can support, or nudge, the expression of resilient behaviours.\",\"This note evaluates observational data obtained from a case study of a home haemodialysis medical training environment. Resilient and Robust activities are identified in order to provide device design insights.\",12,\"Thu 3:20 - 3:30 PM\",1429838400,1429839000,\"Authors\",null],[806,801,\"pn2481\",\"Paper\",\"Understanding Design Tradeoffs for Health Technologies: A Mixed-Methods Approach\",\"We introduce a mixed-methods approach for determining how people weigh tradeoffs in values related to health and technologies for health self-management. Our approach combines interviews with Q-methodology, a method from psychology uniquely suited to quantifying opinions. We derive the framework for structured data collection and analysis for the Q-methodology from theories of self-management of chronic illness and technology adoption.  To illustrate the power of this new approach, we used it in a field study of nine older adults with type 2 diabetes, and nine mothers of children with asthma. Our mixed-methods approach provides three key advantages for health design science in HCI: (1) it provides a structured health sciences theoretical framework to guide data collection and analysis; (2) it enhances the coding of unstructured data with statistical patterns of polarizing and consensus views; and (3) it empowers participants to actively weigh competing values that are most personally significant to them. \",\"We contribute a mixed-methods approach to support designers to understand the polarizing and consensus views that influence stakeholders’ adoption and use of personal health technologies for chronic disease.\",12,\"Thu 3:30 - 3:50 PM\",1429839000,1429840200,\"Authors\",null],[807,-1,\"s-float-34\",\"Papers\",\"Interaction Techniques for Tables & Walls\",null,null,13,\"Thu 2:30 - 3:50 PM\",1429835400,1429840200,\"Chair\",\"Papers\"],[808,807,\"pn1673\",\"Note\",\"G-raff: An Elevating Tangible Block for Spatial Tabletop Interaction\",\"We present an elevating tangible block, G-raff that supports spatial interaction in a tabletop computing environment. The elevating head part of G-raff moves according to the given height and angle data. We adopted two rollable metal tape structures to create large movements with a small volume block. On the head part, a smartphone can be mounted either horizontally or vertically. G-raff becomes a device that can connect a mobile device with a tabletop computer, thus a new spatial representation and control interaction is made. This paper introduces the design details, key features and applications of G-raff. We report on the results of a preliminary user study and discuss future work to improve the elevating device. This work contributes to maximizing the availability of augmented reality space above the tabletop display.\",\"G-raff is a new type of active interface device for the tabletop computing environment that efficiently integrates three-dimensional information. This work contributes to maximizing the availability of augmented reality space above the tabletop display\",13,\"Thu 2:30 - 2:40 PM\",1429835400,1429836000,\"Authors\",null],[809,807,\"pn1069\",\"Note\",\"Modeling Distant Pointing for Compensating Systematic Displacements\",\"Distant pointing at objects and persons is a highly expressive gesture that is widely used in human communication. Pointing is also used to control a range of interactive systems. For determining where a user is pointing at, different ray casting methods have been proposed. In this paper we assess how accurately humans point over distance and how to improve it. Participants pointed at projected targets from 2m and 3m while standing and sitting. Testing three common ray casting methods, we found that even with the most accurate one the average error is 61.3cm. We found that all tested ray casting methods are affected by systematic displacements. Therefore, we trained a polynomial to compensate this displacement. We show that using a user-, pose-, and distant-independent quartic polynomial can reduce the average error by 37.3%\",\"Humans use pointing as part of their communication. Pointing can be interpreted by ray-cast techniques. By using a quadratic function we improve pointing accuracy. \",13,\"Thu 2:40 - 2:50 PM\",1429836000,1429836600,\"Authors\",null],[810,807,\"pn1016\",\"Paper\",\"Is Moving Improving? Some Effects of Locomotion in Wall-Display Interaction\",\"Physical movement plays an important role in interaction with wall-displays. Earlier work on its effect on performance has been inconclusive, however, because movement has not been experimentally controlled. In a first experiment, we controlled participants’ ability to physically move in front of a 3-meter wide 24-megapixel wall-display. Participants performed a classification task involving navigation using a zoom-and-pan interface. Results suggest that the ability to move does not increase performance, and that a majority of participants used virtual navigation (i.e., zooming and panning) and little or no physical navigation (i.e., moving their bodies). To isolate the effects of physical and virtual navigation, a second experiment compared conditions where participants could navigate using either only physical movement or only virtual navigation. The second experiment showed that physical movement does benefit performance. The results from the experiments suggest that moving may not be improving performance, depending on the use of virtual navigation. \",\"Two controlled experiments investigating the role of locomotion in wall-display interaction by isolating the effects of locomotion and comparing physical navigation to virtual navigation. \",13,\"Thu 2:50 - 3:10 PM\",1429836600,1429837800,\"Authors\",null],[811,807,\"pn1170\",\"Paper\",\"Gaze+RST: Integrating Gaze and Multitouch for Remote Rotate-Scale-Translate Tasks\",\"Our work investigates the use of gaze and multitouch to fluidly perform rotate-scale-translate (RST) tasks on large displays. The work specifically aims to understand if gaze can provide benefit in such a task, how task complexity affects performance, and how gaze and multitouch can be combined to create an integral input structure suited to the task of RST. We present four techniques that individually strike a different balance between gaze-based and touch-based translation while maintaining concurrent rotation and scaling operations. A 16 participant empirical evaluation revealed that three of our four techniques present viable options for this scenario, and that larger distances and rotation/scaling operations can significantly affect a gaze-based translation configuration. Furthermore we uncover new insights regarding multimodal integrality, finding that gaze and touch can be combined into configurations that pertain to integral or separable input structures.\",\"Does gaze provide benefit in compound tasks? We aim to understand how gaze can support integral rotate, scale, translate tasks with four techniques that pertain to integral and separable input structures.\",13,\"Thu 3:10 - 3:30 PM\",1429837800,1429839000,\"Authors\",null],[812,807,\"pn1927\",\"Paper\",\"Designing for Exploratory Search on Touch Devices\",\"Exploratory search confront users with challenges in expressing search intents as the current search interfaces require investigating result listings to identify search directions, iterative typing, and reformulating queries. We present the design of Exploration Wall, a touch-based search user interface that allows incremental exploration and sense-making of large information spaces by combining entity search, flexible use of result entities as query parameters, and spatial configuration of search streams that are visualized for interaction. Entities can be flexibly reused to modify and create new search streams, and manipulated to inspect their relationships with other entities. Data comprising of task-based experiments comparing Exploration Wall with conventional search user interface indicate that Exploration Wall achieves significantly improved recall for exploratory search tasks while preserving precision. Subjective feedback supports our design choices and indicates improved user satisfaction and engagement. Our findings can help to design user interfaces that can effectively support exploratory search on touch devices.\",\"Challenges in user interfaces supporting exploratory search are aggravated on touch devices. Exploration Wall is a novel user interface that addresses these challenges with a principled design.\",13,\"Thu 3:30 - 3:50 PM\",1429839000,1429840200,\"Authors\",null],[813,-1,\"s-float-19\",\"Papers\",\"Understanding & Protecting Kids Tech Use\",null,null,10,\"Thu 2:30 - 3:50 PM\",1429835400,1429840200,\"Chair\",\"Papers\"],[814,813,\"pn1742\",\"Paper\",\"Regulating Access to Adult Content (with Privacy Preservation)\",\"In the physical world we have well-established mechanisms for keeping children out of adult-only areas. In the virtual world this is generally replaced by self declaration. Some service providers resort to using heavy-weight identification mechanisms, judging adulthood as a side effect thereof. Collection of identification data arguably constitutes an unwarranted privacy invasion in this context, if carried out merely to perform adulthood estimation. This paper presents a mechanism that exploits the adult's more extensive exposure to public media, relying on the likelihood that they will be able to recall details if cued by a carefully chosen picture. We conducted an online study to gauge the viability of this scheme. With our prototype we were able to predict that the user was a child 99% of the time. Unfortunately the scheme also misclassified too many adults. We discuss our results and suggest directions for future research.\",\"We present the concept of knowledge-based regulation of access to adult content, and report on two studies, using empirically validated images to perform adulthood estimation. \",10,\"Thu 2:30 - 2:50 PM\",1429835400,1429836600,\"Authors\",null],[815,813,\"pn598\",\"Paper\",\"Resilience Mitigates the Negative Effects of Adolescent Internet Addiction and Online Risk Exposure\",\"We cannot fully protect adolescents from experiencing online risks; however, we can aim to better understand how online risk experiences impact teens, factors that contribute to or prevent teens from exposure to risk, as well as factors that can protect teens from psychological harm in spite of online risk exposure. Through a web-based survey study of 75 adolescents in the US, we develop and empirically validate a theoretical model of adolescent resilience in the presence of online risks. We show evidence that resilience is a key factor in protecting teens from experiencing online risks, even when teens exhibit high levels of Internet addiction. Resilience also neutralizes the negative psychological effects associated with Internet addiction and online risk exposure. Therefore, we emphasize the importance of design solutions that foster teen resilience and strength building, as opposed to solutions targeted toward parents that often focus on restriction and risk prevention.\",\"We develop and empirically validate a theoretical model of adolescent resilience in the presence of online risks and show that resilience is a key factor in protecting teens online.\",10,\"Thu 2:50 - 3:10 PM\",1429836600,1429837800,\"Authors\",null],[816,813,\"pn2340\",\"Note\",\"Generation Like: Comparative Characteristics in Instagram\",\"The emergence of social media has had a significant impact on how people communicate and socialize. Teens use social media to make and maintain social connections with friends and build their reputation. However, the way of analyzing the characteristics of teens in social media has mostly relied on ethnographic accounts or quantitative analyses with small datasets. This paper shows the possibility of detecting age information in user profiles by using a combination of textual and facial recognition methods and presents a comparative study of 27K teens and adults in Instagram. Our analysis highlights that (1) teens tend to post fewer photos but highly engage in adding more tags to their own photos and receiving more Likes and comments about their photos from others, and (2) to post more selfies and express themselves more than adults, showing a higher sense of self-representation. We demonstrate the application of our novel method that shows clear trends of age differences as well as substantiates previous insights in social media.\",\"This paper shows the possibility of detecting age information in user profiles by using a combination of textual and facial recognition methods and presents a large-data driven comparative study of teens and adults in Instagram\",10,\"Thu 3:10 - 3:20 PM\",1429837800,1429838400,\"Authors\",null],[817,813,\"pn1530\",\"Note\",\"Investigating High School Students' Perceptions of Digital Badges in Afterschool Learning\",\"This paper investigates high school students' perceptions of the opportunities and challenges of using digital badges to recognize and reward the skills and achievements they acquire in an afterschool science education program. Focus groups and usability tests were conducted with 10 students during the design of a badge system prototype for use in the program. We found that students recognized opportunities for personal empowerment in their use of badges, but also expressed concerns about sharing badges in various online contexts. The findings provide new insight into the values and goals that learners bring to discussions of digital badges in education. These insights hold relevance for designers of education-based badge systems as well as educators seeking to introduce badges into their practice. \",\"This paper assesses high school students' attitudes toward a digital badge system that recognizes students' achievements in an afterschool science education program. Findings are relevant for designing improved badge systems.\",10,\"Thu 3:20 - 3:30 PM\",1429838400,1429839000,\"Authors\",null],[818,-1,\"s158\",\"Papers\",\"Speech & Auditory Interfaces\",null,null,4,\"Thu 2:30 - 3:50 PM\",1429835400,1429840200,\"Chair\",\"Papers\"],[819,818,\"pn2111\",\"Paper\",\"Form Follows Sound: Designing Interactions from Sonic Memories\",\"Sonic interaction is the continuous relationship between user actions and sound, mediated by some technology. Because interaction with sound may be task oriented or experience-based it is important to understand the nature of action-sound relationships in order to design rich sonic interactions. We propose a participatory approach to sonic interaction design that first considers the affordances of sounds in order to imagine embodied interaction, and based on this, generates interaction models for interaction designers wishing to work with sound. We describe a series of workshops, called Form Follows Sound, where participants ideate imagined sonic interactions, and then realize working interactive sound prototypes.  We introduce the Sonic Incident technique, as a way to recall memorable sound experiences. We identified three interaction models for sonic interaction design: conducting; manipulating; substituting. These three interaction models offer interaction designers and developers a framework on which they can build richer sonic interactions.\",\"In this paper, we propose an approach for the design of sonic interaction where sound and the user’s sonic experience serve as the starting point for the imagination and realization of action–sound relationships. \",4,\"Thu 2:30 - 2:50 PM\",1429835400,1429836600,\"Authors\",null],[820,818,\"pn2228\",\"Paper\",\"Repurposing Conversation: Experiments with the Continuous Speech Stream\",\"Voice interaction with mobile devices has been focused on hands-free interaction or situations where visual interfaces are not applicable. In this paper we explore a subtler means of interaction – speech recognition from continual, in the background, audio recording of conversations. We call this the ‘continuous speech stream’ and explore how it could be repurposed as user input. We analyse ten days of recorded audio from our participants, alongside corresponding interviews, to explore how systems might make use of extracts from this stream. Rather than containing directly actionable items, our data suggests that the continuous speech stream is a rich resource for identifying users’ next actions, along with the interests and dispositions of those being recorded. Through design workshops we explored new interactions using the speech stream, and describe concepts for individual, shared and distributed use.\",\"We explore a subtle means of interaction – speech recognition from continual  background audio recording of conversations. The use of this ‘continuous speech stream’ is explored based on 10 days of recordings. \",4,\"Thu 2:50 - 3:10 PM\",1429836600,1429837800,\"Authors\",null],[821,818,\"pn1273\",\"Note\",\"The CADENCE Corpus: A New Resource for Inclusive Voice Interface Design\",\"Papers on voice interfaces for people with cognitive impairment or demenita only provide small snapshots of actual interactions, if at all. This is a major obstacle to the development of better interfaces. Transcripts of interactions between users and systems contain rich evidence of typical language patterns, indicate how users conceptualise their computer interlocutor, and highlight key design issues. In this paper, we introduce the CADENCE corpus and outline how it can be used to stimulate replicable research on inclusive voice interfaces. The CADENCE  corpus is first data set of its kind to include rich data from people with cognitive impairment and free for research use. The corpus consists of transcribed spoken interactions between older people with and without cognitive impairment and a simulated Intelligent Cognitive Assistant and includes comprehensive data on users' cognitive abilities. \",\"We introduce the CADENCE corpus, a unique data set of conversations between older adults with and without cognitive impairment and a simulated Intelligent Cognitive Assistant, distributed under a Creative Commons license.\",4,\"Thu 3:10 - 3:20 PM\",1429837800,1429838400,\"Authors\",null],[822,818,\"pn1302\",\"Note\",\"Empirical Evidence for a Diminished Sense of Agency in Speech Interfaces\",\"While the technology underlying speech interfaces has improved in recent years, our understanding of the human side of speech interactions remains limited. This paper provides new insight on one important human aspect of speech interactions: the sense of agency - defined as the experience of controlling one’s own actions and their outcomes. Two experiments are described. In each case a voice command is compared with keyboard input. Agency is measured using an implicit metric: intentional binding. In both experiments we find that participants’ sense of agency is significantly reduced for voice commands as compared to keyboard input. This finding presents a fundamental challenge for the design of effective speech interfaces. We reflect on this finding and, based on current theory in HCI and cognitive neuroscience, offer possible explanations for the reduced sense of agency observed in speech interfaces.\",\"We show that peoples' sense of agency is significantly reduced in speech interfaces as compared with other input techniques, e.g. a keyboard. \",4,\"Thu 3:20 - 3:30 PM\",1429838400,1429839000,\"Authors\",null],[823,818,\"pn306\",\"Paper\",\"To Beep or Not to Beep? Comparing Abstract versus Language-Based Multimodal Driver Displays\",\"Multimodal displays are increasingly being utilized as driver warnings. Abstract warnings, without any semantic association to the signified event, and language-based warnings are examples of such displays. This paper presents a first comparison between these two types, across all combinations of audio, visual and tactile modalities. Speech, text and Speech Tactons (a novel form of tactile warnings synchronous to speech) were compared to abstract pulses in two experiments. Results showed that recognition times of warning urgency during a non-critical driving situation were shorter for abstract warnings, highly urgent warnings and warnings including visual feedback. Response times during a critical situation were shorter for warnings including audio. We therefore suggest abstract visual feedback when informing drivers during a non-critical situation and audio in a highly critical one. Language-based warnings during a critical situation performed equally well as abstract ones, so they are suggested as less annoying vehicle alerts.\",\"Presents two experiments comparing responses to abstract versus language-based audio, visual and tactile warnings for drivers. Can assist car warning designers.\",4,\"Thu 3:30 - 3:50 PM\",1429839000,1429840200,\"Authors\",null],[824,-1,\"s-float-9\",\"Papers\",\"Multi-Device Interaction\",null,null,3,\"Thu 2:30 - 3:50 PM\",1429835400,1429840200,\"Chair\",\"Papers\"],[825,824,\"pn479\",\"Paper\",\"A Diary Study on Combining Multiple Information Devices in Everyday Activities and Tasks\",\"As people possess increasing numbers of information devices, situations where several devices are combined and used together have become more common. We present a user study on people’s current practices in combining multiple information devices in their everyday lives, ranging from pragmatic tasks to leisure activities. Based on diaries and interviews of 14 participants, we characterize the usage practices of the most common devices, including smartphones, computers, tablets, and home media centers. We analyze 123 real-life multi-device use cases and identify the main usage patterns, including Sequential Use, Resource Lending, Related Parallel Use, and Unrelated Parallel Use. We discuss the practical challenges of using several information devices together. Finally, we identify three levels of decisions that determine which devices are used in a particular situation, including acquiring, making available, and selecting the devices for use.\",\"We report people’s current practices in combining multiple information devices in their everyday lives. The findings provide insights into design of future interfaces, technologies, and applications supporting multi-device use.\",3,\"Thu 2:30 - 2:50 PM\",1429835400,1429836600,\"Authors\",null],[826,824,\"pn855\",\"Paper\",\"Spatially-aware or spatially-agnostic? Elicitation and Evaluation of User-Defined Cross-Device Interactions\",\"Cross-device interaction between multiple mobile devices is a popular field of research in HCI. However, the appropriate design of this interaction is still an open question, with competing approaches such as spatially-aware vs. spatially-agnostic techniques. In this paper, we present the results of a two-phase user study that explores this design space: In phase 1, we elicited gestures for typical mobile cross-device tasks from 4 focus groups (N=17). The results show that 71% of the elicited gestures were spatially-aware and that participants strongly associated cross-device tasks with interacting and thinking in space. In phase 2, we implemented one spatially-agnostic and two spatially-aware techniques from phase 1 and compared them in a controlled experiment (N=12). The results indicate that spatially-aware techniques are preferred by users and can decrease mental demand, effort, and frustration, but only when they are designed with great care. We conclude with a summary of findings to inform the design of future cross-device interactions.\",\"We contribute findings of a two-phased study. In phase 1, we elicited gestures for mobile cross-device tasks. In phase 2, we implemented three elicited techniques and compared them in a controlled experiment.\",3,\"Thu 2:50 - 3:10 PM\",1429836600,1429837800,\"Authors\",null],[827,824,\"pn1715\",\"Paper\",\"Weave: Scripting Cross-Device Wearable Interaction\",\"We present Weave, a framework for developers to create cross-device wearable interaction by scripting. Weave provides a set of high-level APIs, based on JavaScript, for developers to easily distribute UI output and combine sensing events and user input across mobile and wearable devices. Weave allows developers to focus on their target interaction behaviors and manipulate devices regarding their capabilities and affordances, rather than low-level specifications. Weave also contributes an integrated authoring environment for developers to program and test cross-device behaviors, and when ready, deploy these behaviors to its runtime environment on users’ ad-hoc network of devices. An evaluation of Weave with 12 participants on a range of tasks revealed that Weave significantly reduced the effort of developers for creating and iterating on cross-device interaction. \",\"Contributed a framework for developers to create cross-wearable interaction by scripting. Weave provides a set of high-level APIs to distribute UI and combine sensing events and user input across devices. \",3,\"Thu 3:10 - 3:30 PM\",1429837800,1429839000,\"Authors\",null],[828,824,\"pn1066\",\"Paper\",\"MultiFi: Multi Fidelity Interaction with Displays On and Around the Body\",\"Display devices on and around the body such as smartwatches, head-mounted displays or tablets enable users to interact on the go. However, diverging input and output fidelities of these devices can lead to interaction seams that can inhibit efficient mobile interaction, when users employ multiple devices at once. We present MultiFi, an interactive system that combines the strengths of multiple displays and overcomes the seams of mobile interaction with widgets distributed over multiple devices. A comparative user study indicates that combined head-mounted display and smartwatch interfaces can outperform interaction with single wearable devices.\",\"MultiFi is an interactive system that combines the strengths of multiple displays on and around the body and overcomes the seams of mobile interaction with widgets distributed over multiple devices. \",3,\"Thu 3:30 - 3:50 PM\",1429839000,1429840200,\"Authors\",null],[829,-1,\"s112\",\"Papers\",\"Disasters & Humanitarian Events\",null,null,11,\"Thu 2:30 - 3:50 PM\",1429835400,1429840200,\"Chair\",\"Papers\"],[830,829,\"pn710\",\"Paper\",\"CrowdMonitor: Mobile Crowd Sensing for Assessing  Physical and Digital Activities of Citizens during Emergencies\",\"Emergencies such as the 2013 Central European flood or the 2013 typhoon Haiyan in Philippines have shown how citizens can organize themselves and coordinate private relief activities. These activities can be found in (physical) groups of affected people, but also within (digital) social media communities. There is an evident need, however, for a clearer picture of what exactly is going on to be available for use by the official emergency services: to enlist them, to keep them safe, to support their efforts and to avoid needless duplications or conflicts. Aligning emergency services and volunteer activities is, then, crucial. In this paper we present a mobile crowd sensing based concept, which was designed as well as implemented as the application CrowdMonitor and facilitates the detection of physical and digital activities and the assignment of specific tasks to citizens. Finally we outline the findings of its evaluation.\",\"We have designed, implemented and evaluated the mobile crowd sensing based application ‘CrowdMonitor’, which allows emergency services the handling of social media content and advising on the ground civil activities.\",11,\"Thu 2:30 - 2:50 PM\",1429835400,1429836600,\"Authors\",null],[831,829,\"pn327\",\"Paper\",\"XHELP: Design of a Cross-Platform Social-Media Application  to Support Volunteer Moderators in Disasters\",\"Recent disasters have shown an increase in the significance of social media for both affected citizens and volunteers alike in the coordination of information and organization of relief activities, often independently of and in addition to the official emergency response. Existing research mainly focuses on the way in which individual platforms are used by volunteers in response to disasters. This paper examines the use of social media during the European Floods of 2013 and proposes a novel cross-social-media application for volunteers. Besides comprehensive analysis of volunteer communities, interviews were conducted with “digital volunteers” such as Facebook moderators of disaster-related groups. Based on the challenges identified, we designed and implemented the cross-social-media application “XHELP”, which allows information to be both, acquired and distributed cross-media and cross-channel. The evaluation with 20 users leads to further design requirements for applications aiming to support volunteer moderators during disasters. \",\"We designed, implemented and evaluated the cross-platform social-media application XHELP, which allows the acquisition and distribution of information cross-media and cross-channel to support volunteer moderators during disasters.\",11,\"Thu 2:50 - 3:10 PM\",1429836600,1429837800,\"Authors\",null],[832,829,\"pn1018\",\"Paper\",\"Building a Birds Eye View: Collaborative Work in Disaster Response\",\"Command and control environments ranging from transport control rooms to disaster response have long been of interest to HCI and CSCW as rich sites of interactive technology use embedded in work practice. Drawing on our engagement with disaster response teams, including ethnography of their training work, we unpack the ways in which situational uncertainty is managed while a shared operational ‘picture’ is constituted through various practices around tabletop work. Our analysis reveals how this picture is collaboratively assembled as a socially shared object and displayed by drawing on digital and physical resources. Accordingly, we provide a range of principles implicated by our study that guide the design of systems augmenting and enriching disaster response work practices. In turn, we propose the Augmented Bird Table to illustrate how our principles can be implemented to support tabletop work. \",\"Presents ethnographic findings from embedding with a disaster response organisation that show teams co-constructing the socially shared 'operational picture', drawing on a variety of digital and physical resources, and rendering it to the bird table.\",11,\"Thu 3:10 - 3:30 PM\",1429837800,1429839000,\"Authors\",null],[833,829,\"pn898\",\"Paper\",\"Success & Scale in a Data-Producing Organization: The Socio-Technical Evolution of OpenStreetMap in Response to Humanitarian Events\",\"OpenStreetMap (OSM) is a volunteer-driven, globally distributed organization whose members work to create a common digital map of the world. OSM embraces ideals of open data, and to that end innovates both socially and technically to develop practices and processes for coordinated operation. This paper provides a brief history of OSM and then, through quantitative and qualitative examination of the OSM database and other sites of articulation work, examines organizational growth through the lens of two catastrophes that spurred enormous humanitarian relief responses—the 2010 Haiti Earthquake and the 2013 Typhoon Yolanda. The temporally- and geographically- constrained events scope analysis for what is a rapidly maturing, whole-planet operation. The first disaster identified how OSM could support other organizations responding to the event. However, to achieve this, OSM has had to refine mechanisms of collaboration around map creation, which were tested again in Typhoon Yolanda. The transformation of work between these two events yields insights into the organizational development of large, data-producing online organizations.\",\"OpenStreetMap is an organization of over 1 million volunteers who create a digital global map. Two catastrophes ~4 years apart illustrate socio-technical shifts in the organization that differ from Wikipedia’s.\",11,\"Thu 3:30 - 3:50 PM\",1429839000,1429840200,\"Authors\",null],[834,-1,\"s-float-4\",\"Papers\",\"Email & Social Media at Work\",null,null,5,\"Thu 2:30 - 3:50 PM\",1429835400,1429840200,\"Chair\",\"Papers\"],[835,834,\"pn1151\",\"Note\",\"Lost in Email: Pulling Users Down a Path of Interaction\",\"In this paper we describe a study exploring why users spend more time in email than originally intended, which we call getting lost in email.  To study this phenomenon, we implemented an IMAP logger that also dispatched diary entries to collect data for twenty participants over a two week period. Most participants reported getting lost in email during both short and long sessions. Our analysis suggests two primary factors in getting lost: the number of emails awaiting a reply and whether or not the session caused an interruption. We conclude that much of the problem around getting lost in email is in managing the tension between promptly responding to messages while limiting engagement with email.\",\"In this paper we describe a study exploring why users spend more time in email than originally intended, which we call getting lost in email.\",5,\"Thu 2:30 - 2:40 PM\",1429835400,1429836000,\"Authors\",null],[836,834,\"pn1350\",\"Note\",\"Balancing Boundaries: Using Multiple Devices to Manage Work-Life Balance\",\"Information and communication technologies (ICTs) continue to give us increased flexibility about when and where we choose to work and the freedom to deal with home tasks whilst at work. However more use of ICT for work during non-work time has been linked with negative outcomes including lower work and life satisfaction and increased stress. Previous work has suggested that in order to reduce some of these negative effects, people should adopt technology use strategies that aid separation of their home and work lives. In this paper we report the results of a questionnaire study investigating work-life balance boundary behaviours and technology use. We find that people use multiple devices as a way of creating boundaries between home and work, and the extent to which they do this relates to their boundary behaviour style. These findings have particular relevance given the increasing trend for Bring Your Own Device (BYOD) policies.\",\"A study of how people use multiple devices to create and maintain boundaries between home and work and how this relates to their boundary style preferences. \",5,\"Thu 2:40 - 2:50 PM\",1429836000,1429836600,\"Authors\",null],[837,834,\"pn2247\",\"Paper\",\"Working 9-5? Professional Differences in Email and Boundary Management Practices\",\"Technology not only brings benefits such as flexible working practices but can also have negative stressful consequences such as increasing email overload and the blurring of work-home boundaries. We report on an exploratory study that extends the current understanding of email usage by investigating how different professions at a university manage work and personal emails using different devices and how this impacts their work-home boundary management. Our findings lead us to identify two user groups: those with permeable boundaries (primarily academics) and those who have more rigid ones (primarily professional services employees) and that there are differences in when, where and how they manage their work and personal emails. In particular we find that some participants use micro-boundary strategies to manage transitions between work and personal life. Based on these novel findings we propose improvements of email software design to facilitate effective email, work-home boundary management, and support micro-boundary practices.\",\"We present an exploratory study on email usage by investigating how different professions at a university manage their inboxes using different devices and how this impacts their work-home boundary management.\",5,\"Thu 2:50 - 3:10 PM\",1429836600,1429837800,\"Authors\",null],[838,834,\"pn1682\",\"Paper\",\"Inferring Employee Engagement from Social Media\",\"Employees increasingly are expressing ideas and feelings through enterprise social media. Recent work in CHI and CSCW has applied linguistic analysis towards understanding employee experiences. In this paper, we apply dictionary based linguistic analysis to measure ‘Employee Engagement’. Employee engagement is a measure of employee willingness to apply discretionary effort towards organizational goals, and plays an important role in organizational outcomes such as financial or operational results. Organizations typically use surveys to measure engagement. This paper describes an approach to model employee engagement based on word choice in social media. This method can potentially complement surveys, thus providing more real-time insights into engagement and allowing organizations to address engagement issues faster. Our results predicting engagement scores on a survey by combining demographics with social media text demonstrate that social media text has significant predictive power compared to demographic data alone. We also find that engagement may be a state than a stable trait since social media posts closer to the administration of the survey had the most predictive power. We further identify the minimum number of social media posts required per employee for the best prediction. \",\"Is the first paper to describe an approach to use internal social media to infer employee engagement, allowing an organization to address engagement issues faster compared to a traditional survey.\",5,\"Thu 3:10 - 3:30 PM\",1429837800,1429839000,\"Authors\",null],[839,834,\"pn410\",\"Paper\",\"Mailing Lists: Why Are They Still Here, What's Wrong With Them, and How Can We Fix Them?\",\"Mailing lists have existed since the early days of email and are still widely used today, even as more sophisticated online forums and social media websites proliferate. The simplicity of mailing lists can be seen as a reason for their endurance, a source of dissatisfaction, and an opportunity for improvement. Using a mixed-method approach, we studied two community mailing lists in depth with interviews and surveys, and surveyed a broader spectrum of 28 lists. We report how members of the different communities use their lists and their goals and desires for them. We explore why members prefer mailing lists to other group communication tools. But we also identify several tensions around mailing list usage that appear to contribute to dissatisfaction with them. We conclude with design implications, discussing ways to alleviate these tensions while preserving mailing lists’ appeal.\",\"We study several mailing list communities and find that members prefer them over social media for group communication but still many tensions arise over differences, suggesting new directions for innovation.\",5,\"Thu 3:30 - 3:50 PM\",1429839000,1429840200,\"Authors\",null],[840,-1,\"s163\",\"Papers\",\"Interacting with GUIs\",null,null,1,\"Thu 2:30 - 3:50 PM\",1429835400,1429840200,\"Chair\",\"Papers\"],[841,840,\"pn142\",\"Note\",\"Clutching Is Not (Necessarily) the Enemy\",\"Clutching is usually assumed to be triggered by a lack of physical space and detrimental to pointing performance. We conduct a controlled experiment using a laptop trackpad where the effect of clutching on pointing performance is dissociated from the effects of control-to-display transfer functions. Participants performed a series of target acquisition tasks using typical cursor acceleration functions with and without clutching. All pointing tasks were feasible without clutching, but clutch-less movements were harder to perform, caused more errors, required more preparation time, and were not faster than clutch-enabled movements.\",\"Clutching supposedly decreases pointing performance. Using a trackpad, we find that clutch-less pointing is harder, causes more errors, requires more preparation time, and is not faster than clutch-enabled pointing.\",1,\"Thu 2:30 - 2:40 PM\",1429835400,1429836000,\"Authors\",null],[842,840,\"pn359\",\"Note\",\"Visual Grouping in Menu Interfaces\",\"Menu interfaces often arrange options into semantic groups. This semantic structure is then usually conveyed to the user by supplementary visual grouping cues. We investigate whether these visual grouping cues actually help users locate items in menus faster, and whether there is potential for these powerful grouping cues to impede search when used inappropriately. Thirty-six participants performed known-item searches of word menus. These menus differed along three dimensions: (1) whether visual grouping cues were used, (2) whether items were semantically organized, and (3) the number of items belonging to each semantic group. Results show that the usefulness of visual grouping entirely depends on the underlying semantic structure of the menu. When menus were semantically organized, having visual grouping cues delineate the boundaries between large semantic groups resulted in the fastest search times. But when semantically unrelated items were visually grouped together, participants took far longer to locate targets. Menu designers should therefore take great care to avoid visually grouping semantically unrelated items as this has the potential to hinder menu interactions.\",\"Investigates whether visual grouping helps users locate items in menus. Results show that care should be taken to avoid visually grouping semantically unrelated items, as this will hinder performance.\",1,\"Thu 2:40 - 2:50 PM\",1429836000,1429836600,\"Authors\",null],[843,840,\"pn332\",\"Paper\",\"Color Portraits : From Color Picking to Interacting with Color\",\"Although ubiquitous, color pickers have remained largely unchanged for 25 years. Based on contextual interviews with artists and designers, we created the Color Portraits design space to characterize five key color manipulation activities: sampling and tweaking individual colors, manipulating color relationships, combining colors with other elements, revisiting previous color choices, and revealing a design process through color. We found similar color manipulation requirements with scientists and engineers. We designed novel color interaction tools inspired by the design space, and used them as probes to identify specific design requirements, including: interactive palettes for sampling colors and exploring relationships; color composites for blending and decomposing colors with other elements; interactive histories to enable reuse of previous color choices; and providing color as a way to reveal underlying processes. We argue that color tools should allow users to interact with colors, not just pick or sample them.\",\"This paper presents a design space  and a set of tools for interacting with color. Color Portraits is extracted from interviews with artists and designers and reveals their need to manipulate color beyond selection.\",1,\"Thu 2:50 - 3:10 PM\",1429836600,1429837800,\"Authors\",null],[844,840,\"pn1895\",\"Paper\",\"The Emergence of Interactive Behavior: A Model of Rational Menu Search\",\"One reason that human interaction with technology is difficult to understand is because the way in which people perform interactive tasks is highly adaptive. One such interactive task is menu search. In the current article we test the hypothesis that menu search is rationally adapted to (1) the ecological structure of interaction, (2) cognitive and perceptual limits, and (3) the goal to maximise the trade-off between speed and accuracy. Unlike in previous models, no assumptions are made about the strategies available to or adopted by users, rather the menu search problem is specified as a reinforcement learning problem and behaviour emerges by finding the optimal Markov Decision Process (MDP). The model is tested against existing empirical findings concerning the effect of menu organisation and menu length. The model predicts the effect of these variables on task completion time and eye movements. The discussion considers the pros and cons of the modelling approach relative to other well-known mod- elling approaches.\",\"A novel computational model of menu search showing how behaviour is an emergent consequence of environment, cognition, and utility; Explaining how existing empirical findings concerning menu search as rational adaptation to constraints.\",1,\"Thu 3:10 - 3:30 PM\",1429837800,1429839000,\"Authors\",null],[845,840,\"pn2296\",\"Paper\",\"Selective Undo Support for Painting Applications\",\"Today’s widely deployed painting applications use a linear undo model that allows users to backtrack previous operations in reverse chronological order. This undo model is not useful if the user has performed desired operations after undesired ones. Selective undo, in contrast, allows users to select specific operations in the past and only undo those, while keeping the remaining operations intact. Although selective undo has been widely explored in the context of text editing and object-oriented drawing, we explore selective undo for painting (bitmap) editing, which has received less attention and introduces many interesting user interface design challenges. Our system, called Aquamarine, explores the script model for selective undo, where selectively undone operations are skipped in the history, rather than the more explored inverse model, which puts an inverse of the selected operations at the end of the history. We discuss the design implications and show through two informal user studies that selective undo is usable and desirable\",\"Aquamarine shows that selective undo using the script model in a paint program can be usable and solves problems identified by professional users of paint programs like Photoshop. \",1,\"Thu 3:30 - 3:50 PM\",1429839000,1429840200,\"Authors\",null],[846,-1,\"s-case5\",\"Case Studies\",\"Special Environments\",null,null,2,\"Thu 2:30 - 3:50 PM\",1429835400,1429840200,\"Chair\",\"Papers\"],[847,846,\"case134\",\"Case Study\",\"Voice or Gesture in the Operating Room\",\"This case study represents our efforts to investigate the uses of voice control versus gestural control in the OR.  We present a system we expressly built to allow for both gestural or voice control at the choice of the surgeon. We explain our deployment of this system in the context of cardiothoracic surgery and present a vignette on how the system was used in the moment by the attending surgeon. We learn that, in terms of design, its not just a question of saying voice is better for one type of functionality and gesture is better for another; rather, the benefits are circumstantial. Thus, there is a case for building in redundancy in control with both voice and gesture.\",\"We investigated the uses of voice vs. gestural control in the OR. We show that there is a case for building in redundancy in control with both voice and gesture.\",2,\"Thu 2:30 - 2:50 PM\",1429835400,1429836600,\"Authors\",null],[848,846,\"case139\",\"Case Study\",\"Can Androids Be Salespeople in the Real World?\",\"The roles of robots in the real world have become more diverse depending on their bodily properties. In this study, we aim to determine the roles that androids, whose bodily properties resemble humans, could serve in the real world.  Selling and purchasing are common human activities. Therefore, we proposed the use of an android as a salesperson with cognitive and affective strategies utilizing the advantages of online- and counter- selling methods. We conducted a field study to investigate whether androids could sell goods in a department store. As a result, our sales strategies worked well and the android could sell 43 sweaters that cost approximately 100 dollars each for 10 days. These results are important knowledge for determining how androids may serve new roles and communicate with humans in the real world.\",\"Development of androids, human-like appearance robots, that sell clothes in a department store.\",2,\"Thu 2:50 - 3:10 PM\",1429836600,1429837800,\"Authors\",null],[849,846,\"case140\",\"Case Study\",\"An Outlook for Content UX in TV: The Emergence of Augmented Content\",\"This case study describes the findings from our exploration on content user experience for next- generation live TV and VOD (Video-on-Demand) services. First, we introduce our background study on new trends in the TV industry. Based on this study, we list several keywords that characterize the content experience for next-generation TV. We then describe our interviews with six professionals working in content production. These interviews were conducted to verify our derived characteristics, and to collect the thoughts of these experts on the contribution of UX to future content production. Our study led us to a new research topic we call “Augmented Content,” which we believe has significant potential to provide content UX for next- generation television services.\",\"Our case study introduces a new research topic of “Augmented Content,” which we believe has significant potential to provide content UX for next- generation television services.\",2,\"Thu 3:10 - 3:30 PM\",1429837800,1429839000,\"Authors\",null],[850,846,\"case155\",\"Case Study\",\"A consensual and non-ambiguous set of gestures to interact with UAV in infantrymen\",\"In the context of using an Unmanned Aerial Vehicle (UAV) in hostile environments, gestures allow to free the operator of bulky control interfaces. Since a navigation plan is defined before the mission, only a few commands have to be activated during the mission. This allows a gestural symbolic interaction that maps commands to a set of gestures. Nevertheless, as gestures are not universal, this asks the question of choosing the proper gestures that are easy to learn memorize and perform. We propose a four step methodology for eliciting a gestural vocabulary, and apply it to this use case. The methodology consists of 4 steps: (1) collecting gestures through user creativity sessions, (2) extracting candidate gestures to build a catalogue, (3) electing the gesture vocabulary and (3) evaluating the non-ambiguity of it. We then discuss the relevance of the GV.\",\"A four steps methodology for eliciting a gestural vocabulary is presented. This method is applied to the specific use case of choosing gestures to command a UAV for infantrimen.\",2,\"Thu 3:30 - 3:50 PM\",1429839000,1429840200,\"Authors\",null],[851,-1,\"break-12\",\"Breaks\",\"Coffee Break\",null,null,15,\"Thu 3:50 - 4:30 PM\",1429840200,1429842600,\"\",\"\"],[852,-1,\"keynote-5\",\"Keynote\",\"Plenary Session - Cultural Crossing from Local to Global through Music: Technology, Media, and Future\",null,null,15,\"Thu 4:30 - 5:50 PM\",1429842600,1429847400,\"Speaker\",null],[853,852,\"key5\",\"Keynote\",\"Cultural Crossing from Local to Global through Music: Technology, Media, and Future\",\"Many people think that the global success of the song Gangnam Style has contributed to the tremendous success of the Korean Wave. Being in front of experts in technology and human interactions, I’d like to share my thinking and story about questions like the following: What was the effect of global social media such as YouTube on the global crossing of local culture? How do I plan and utilize the new way of interacting with audience across national and cultural boundaries? Reflecting on the great success of Gangnam Style, what was the main trigger to the big bang of the spread of the Korean wave? As both a musician and an entrepreneur, what do I think is the new process from the ideation of a new song to a global distribution, publicity, and performance of that song? For the creativity that can be appreciated by global audience, how do I think about the technology and media of the future, in terms of creative works? I am looking forward to sharing my experience and opinion here at CHI 2015.\",\"Many people think that the global success of the song Gangnam Style has contributed to the tremendous success of the Korean Wave. Being in front of experts in technology and human interactions, I’d like to share my thinking and story about questions like the following: What was the effect of global social media such as YouTube on the global crossing of local culture? How do I plan and utilize the new way of interacting with audience across national and cultural boundaries? Reflecting on the grea...\",15,\"Thu 4:30 - 5:50 PM\",1429842600,1429847400,\"Speaker\",null]]},\"event_people\":{\"headers\":[\"_id\",\"event_fk\",\"person_fk\",\"sequence\"],\"rows\":[[1,6,1,1],[2,7,2,1],[3,7,3,2],[4,8,4,1],[5,8,5,2],[6,8,6,3],[7,8,3,4],[8,9,7,1],[9,9,3,2],[10,9,8,3],[11,9,9,4],[12,9,10,5],[13,9,11,6],[14,9,12,7],[15,9,13,8],[16,10,14,1],[17,10,15,2],[18,10,16,3],[19,11,17,1],[20,11,18,2],[21,11,19,3],[22,11,20,4],[23,12,21,1],[24,13,22,1],[25,13,23,2],[26,13,24,3],[27,13,25,4],[28,13,26,5],[29,14,27,1],[30,14,28,2],[31,15,29,1],[32,15,30,2],[33,15,31,3],[34,15,32,4],[35,16,33,1],[36,16,29,2],[37,16,22,3],[38,16,30,4],[39,17,34,1],[40,18,35,1],[41,18,36,2],[42,18,37,3],[43,18,38,4],[44,18,39,5],[45,18,40,6],[46,19,41,1],[47,19,42,2],[48,20,43,1],[49,20,44,2],[50,21,45,1],[51,21,46,2],[52,21,47,3],[53,22,48,1],[54,22,49,2],[55,22,50,3],[56,22,51,4],[57,22,52,5],[58,22,53,6],[59,22,54,7],[60,22,55,8],[61,23,56,1],[62,24,57,1],[63,24,58,2],[64,24,59,3],[65,24,60,4],[66,24,61,5],[67,24,62,6],[68,24,63,7],[69,24,64,8],[70,25,65,1],[71,25,66,2],[72,25,67,3],[73,25,68,4],[74,26,69,1],[75,26,70,2],[76,27,71,1],[77,27,72,2],[78,27,73,3],[79,27,74,4],[80,27,75,5],[81,28,76,1],[82,29,77,1],[83,30,78,1],[84,30,79,2],[85,30,80,3],[86,30,81,4],[87,30,82,5],[88,30,83,6],[89,30,84,7],[90,30,85,8],[91,30,86,9],[92,31,87,1],[93,31,88,2],[94,32,89,1],[95,32,90,2],[96,32,91,3],[97,32,92,4],[98,32,93,5],[99,32,94,6],[100,33,95,1],[101,33,96,2],[102,33,97,3],[103,33,98,4],[104,34,99,1],[105,35,100,1],[106,35,101,2],[107,36,102,1],[108,36,103,2],[109,36,104,3],[110,36,105,4],[111,37,106,1],[112,37,107,2],[113,37,108,3],[114,37,109,4],[115,37,110,5],[116,37,111,6],[117,38,112,1],[118,38,113,2],[119,39,114,1],[120,39,115,2],[121,39,116,3],[122,39,117,4],[123,39,118,5],[124,39,119,6],[125,41,120,1],[126,41,121,2],[127,41,122,3],[128,41,123,4],[129,41,124,5],[130,41,125,6],[131,41,126,7],[132,42,127,1],[133,43,128,1],[134,43,129,2],[135,44,130,1],[136,44,131,2],[137,45,132,1],[138,45,133,2],[139,46,134,1],[140,46,135,2],[141,46,136,3],[142,46,137,4],[143,46,138,5],[144,48,139,1],[145,50,140,1],[146,52,141,1],[147,52,142,2],[148,53,143,1],[149,54,144,1],[150,54,145,2],[151,54,146,3],[152,54,147,4],[153,54,148,5],[154,54,149,6],[155,54,150,7],[156,55,151,1],[157,55,152,2],[158,55,153,3],[159,56,154,1],[160,56,155,2],[161,56,156,3],[162,56,157,4],[163,57,158,1],[164,57,159,2],[165,57,160,3],[166,57,161,4],[167,57,162,5],[168,58,163,1],[169,58,164,2],[170,59,165,1],[171,60,166,1],[172,60,167,2],[173,60,168,3],[174,60,169,4],[175,61,170,1],[176,61,171,2],[177,62,172,1],[178,62,173,2],[179,62,174,3],[180,62,175,4],[181,63,176,1],[182,63,177,2],[183,64,178,1],[184,64,179,2],[185,64,180,3],[186,64,181,4],[187,66,182,1],[188,67,183,1],[189,67,184,2],[190,67,185,3],[191,67,186,4],[192,67,187,5],[193,68,188,1],[194,68,189,2],[195,68,190,3],[196,68,191,4],[197,68,192,5],[198,68,193,6],[199,68,194,7],[200,68,195,8],[201,68,196,9],[202,68,197,10],[203,68,55,11],[204,69,188,1],[205,69,198,2],[206,69,119,3],[207,69,189,4],[208,69,199,5],[209,69,55,6],[210,70,200,1],[211,70,201,2],[212,70,202,3],[213,70,203,4],[214,70,204,5],[215,71,205,1],[216,71,206,2],[217,71,207,3],[218,71,208,4],[219,71,209,5],[220,71,210,6],[221,71,211,7],[222,72,212,1],[223,73,213,1],[224,73,214,2],[225,73,215,3],[226,74,216,1],[227,74,217,2],[228,74,218,3],[229,75,219,1],[230,75,220,2],[231,75,221,3],[232,75,222,4],[233,76,223,1],[234,76,224,2],[235,76,225,3],[236,76,217,4],[237,76,226,5],[238,76,227,6],[239,76,228,7],[240,76,229,8],[241,76,230,9],[242,77,231,1],[243,78,232,1],[244,78,233,2],[245,78,234,3],[246,78,235,4],[247,78,236,5],[248,79,237,1],[249,79,238,2],[250,79,239,3],[251,79,153,4],[252,80,240,1],[253,80,241,2],[254,80,242,3],[255,80,243,4],[256,81,244,1],[257,81,245,2],[258,81,246,3],[259,81,247,4],[260,82,248,1],[261,82,249,2],[262,82,250,3],[263,82,251,4],[264,82,252,5],[265,82,253,6],[266,83,254,1],[267,84,255,1],[268,84,256,2],[269,84,257,3],[270,84,258,4],[271,85,259,1],[272,85,260,2],[273,86,261,1],[274,86,262,2],[275,86,263,3],[276,87,264,1],[277,87,265,2],[278,87,266,3],[279,88,267,1],[280,89,268,1],[281,89,269,2],[282,89,270,3],[283,89,271,4],[284,90,272,1],[285,90,273,2],[286,90,274,3],[287,90,275,4],[288,91,276,1],[289,92,277,1],[290,92,278,2],[291,92,279,3],[292,93,280,1],[293,94,281,1],[294,94,282,2],[295,94,283,3],[296,94,284,4],[297,94,285,5],[298,94,286,6],[299,95,287,1],[300,95,20,2],[301,95,288,3],[302,96,289,1],[303,96,290,2],[304,96,174,3],[305,97,291,1],[306,97,292,2],[307,97,293,3],[308,98,294,1],[309,99,295,1],[310,100,296,1],[311,101,297,1],[312,101,298,2],[313,102,299,1],[314,102,300,2],[315,102,301,3],[316,102,302,4],[317,102,303,5],[318,102,304,6],[319,102,305,7],[320,103,306,1],[321,104,307,1],[322,104,308,2],[323,105,309,1],[324,105,310,2],[325,106,311,1],[326,106,312,2],[327,106,313,3],[328,106,314,4],[329,106,315,5],[330,106,316,6],[331,106,317,7],[332,107,318,1],[333,107,319,2],[334,107,320,3],[335,109,321,1],[336,109,322,2],[337,110,323,1],[338,111,324,1],[339,113,325,1],[340,113,326,2],[341,113,327,3],[342,115,328,1],[343,115,329,2],[344,117,330,1],[345,117,331,2],[346,117,332,3],[347,117,333,4],[348,117,334,5],[349,117,335,6],[350,119,336,1],[351,119,337,2],[352,119,338,3],[353,119,339,4],[354,119,340,5],[355,120,341,1],[356,121,342,1],[357,121,343,2],[358,122,344,1],[359,122,345,2],[360,122,346,3],[361,123,347,1],[362,123,348,2],[363,123,349,3],[364,123,350,4],[365,124,351,1],[366,124,352,2],[367,124,353,3],[368,124,354,4],[369,124,355,5],[370,124,356,6],[371,126,357,1],[372,127,358,1],[373,127,359,2],[374,127,360,3],[375,127,361,4],[376,127,362,5],[377,127,363,6],[378,127,364,7],[379,127,365,8],[380,127,366,9],[381,127,320,10],[382,128,122,1],[383,128,367,2],[384,128,368,3],[385,129,369,1],[386,129,370,2],[387,129,371,3],[388,130,372,1],[389,130,373,2],[390,131,374,1],[391,132,375,1],[392,132,376,2],[393,133,377,1],[394,133,378,2],[395,133,379,3],[396,133,380,4],[397,134,381,1],[398,134,382,2],[399,134,383,3],[400,134,384,4],[401,135,385,1],[402,135,386,2],[403,135,387,3],[404,135,388,4],[405,135,389,5],[406,135,288,6],[407,136,390,1],[408,136,391,2],[409,136,392,3],[410,137,393,1],[411,138,394,1],[412,138,395,2],[413,138,396,3],[414,138,397,4],[415,138,398,5],[416,138,126,6],[417,139,399,1],[418,139,400,2],[419,139,401,3],[420,139,402,4],[421,139,403,5],[422,140,404,1],[423,140,405,2],[424,140,406,3],[425,140,156,4],[426,140,157,5],[427,141,402,1],[428,141,126,2],[429,141,403,3],[430,142,407,1],[431,143,408,1],[432,143,409,2],[433,143,410,3],[434,143,411,4],[435,143,217,5],[436,143,412,6],[437,143,413,7],[438,143,227,8],[439,143,414,9],[440,144,415,1],[441,144,416,2],[442,144,417,3],[443,144,418,4],[444,145,191,1],[445,145,419,2],[446,145,54,3],[447,146,420,1],[448,146,276,2],[449,146,421,3],[450,146,422,4],[451,147,423,1],[452,148,424,1],[453,148,425,2],[454,148,426,3],[455,148,427,4],[456,148,428,5],[457,148,429,6],[458,148,430,7],[459,148,431,8],[460,149,432,1],[461,149,433,2],[462,149,434,3],[463,149,435,4],[464,149,436,5],[465,149,437,6],[466,150,438,1],[467,150,439,2],[468,150,440,3],[469,151,441,1],[470,151,442,2],[471,151,443,3],[472,151,444,4],[473,151,445,5],[474,151,446,6],[475,152,447,1],[476,153,448,1],[477,153,449,2],[478,153,450,3],[479,153,451,4],[480,153,452,5],[481,153,453,6],[482,154,454,1],[483,154,455,2],[484,154,456,3],[485,155,457,1],[486,155,458,2],[487,156,459,1],[488,156,460,2],[489,156,461,3],[490,156,462,4],[491,156,463,5],[492,156,464,6],[493,157,465,1],[494,158,466,1],[495,158,467,2],[496,158,468,3],[497,158,217,4],[498,158,469,5],[499,158,470,6],[500,159,471,1],[501,159,472,2],[502,159,473,3],[503,159,474,4],[504,160,475,1],[505,160,119,2],[506,160,55,3],[507,161,476,1],[508,161,477,2],[509,162,478,1],[510,163,479,1],[511,163,480,2],[512,163,481,3],[513,163,482,4],[514,163,483,5],[515,163,484,6],[516,163,485,7],[517,163,486,8],[518,163,487,9],[519,164,488,1],[520,164,215,2],[521,165,489,1],[522,165,490,2],[523,165,491,3],[524,165,492,4],[525,166,493,1],[526,166,494,2],[527,166,495,3],[528,166,496,4],[529,166,497,5],[530,168,321,1],[531,168,322,2],[532,170,336,1],[533,170,337,2],[534,170,338,3],[535,170,339,4],[536,170,340,5],[537,172,325,1],[538,172,326,2],[539,172,327,3],[540,174,328,1],[541,174,329,2],[542,175,498,1],[543,176,499,1],[544,176,500,2],[545,176,501,3],[546,176,502,4],[547,176,503,5],[548,176,504,6],[549,176,505,7],[550,177,506,1],[551,177,507,2],[552,178,508,1],[553,178,509,2],[554,178,510,3],[555,179,511,1],[556,179,512,2],[557,179,513,3],[558,180,514,1],[559,181,515,1],[560,181,516,2],[561,181,517,3],[562,181,518,4],[563,182,519,1],[564,182,520,2],[565,182,521,3],[566,182,522,4],[567,182,523,5],[568,183,524,1],[569,183,525,2],[570,183,526,3],[571,183,527,4],[572,183,528,5],[573,184,529,1],[574,184,530,2],[575,184,531,3],[576,184,532,4],[577,184,533,5],[578,184,534,6],[579,184,535,7],[580,184,536,8],[581,188,537,1],[582,189,538,1],[583,189,539,2],[584,189,540,3],[585,189,541,4],[586,190,542,1],[587,190,543,2],[588,190,544,3],[589,190,545,4],[590,190,546,5],[591,191,547,1],[592,191,548,2],[593,191,549,3],[594,191,550,4],[595,191,551,5],[596,192,552,1],[597,192,553,2],[598,193,554,1],[599,193,555,2],[600,193,556,3],[601,193,557,4],[602,193,558,5],[603,193,421,6],[604,193,559,7],[605,194,560,1],[606,195,561,1],[607,195,562,2],[608,196,563,1],[609,196,564,2],[610,196,565,3],[611,197,566,1],[612,197,567,2],[613,197,568,3],[614,197,569,4],[615,197,570,5],[616,198,571,1],[617,198,572,2],[618,198,573,3],[619,199,574,1],[620,199,575,2],[621,199,576,3],[622,200,577,1],[623,201,578,1],[624,201,579,2],[625,201,580,3],[626,202,581,1],[627,202,582,2],[628,202,583,3],[629,202,584,4],[630,203,585,1],[631,203,586,2],[632,203,587,3],[633,203,588,4],[634,204,589,1],[635,204,590,2],[636,204,591,3],[637,204,592,4],[638,204,593,5],[639,204,594,6],[640,205,595,1],[641,206,596,1],[642,206,597,2],[643,207,598,1],[644,207,599,2],[645,207,600,3],[646,207,601,4],[647,208,602,1],[648,208,603,2],[649,208,604,3],[650,208,384,4],[651,208,496,5],[652,209,605,1],[653,209,606,2],[654,209,279,3],[655,209,607,4],[656,210,608,1],[657,210,609,2],[658,210,610,3],[659,211,611,1],[660,211,612,2],[661,211,354,3],[662,211,613,4],[663,211,94,5],[664,212,614,1],[665,213,615,1],[666,213,338,2],[667,213,616,3],[668,214,617,1],[669,214,618,2],[670,215,619,1],[671,215,620,2],[672,215,621,3],[673,215,622,4],[674,216,620,1],[675,216,623,2],[676,216,624,3],[677,216,625,4],[678,216,626,5],[679,216,622,6],[680,217,627,1],[681,218,628,1],[682,218,629,2],[683,218,630,3],[684,219,631,1],[685,219,632,2],[686,219,633,3],[687,220,634,1],[688,220,635,2],[689,220,636,3],[690,220,637,4],[691,220,638,5],[692,220,639,6],[693,220,640,7],[694,221,641,1],[695,221,642,2],[696,221,643,3],[697,221,644,4],[698,221,645,5],[699,222,646,1],[700,223,647,1],[701,223,648,2],[702,223,649,3],[703,224,650,1],[704,224,651,2],[705,224,652,3],[706,224,653,4],[707,224,654,5],[708,225,655,1],[709,225,656,2],[710,225,657,3],[711,225,658,4],[712,225,659,5],[713,226,660,1],[714,226,661,2],[715,226,662,3],[716,227,663,1],[717,228,664,1],[718,228,665,2],[719,228,666,3],[720,228,667,4],[721,228,668,5],[722,228,669,6],[723,228,670,7],[724,228,671,8],[725,229,672,1],[726,229,673,2],[727,229,674,3],[728,229,675,4],[729,229,676,5],[730,229,677,6],[731,229,678,7],[732,230,679,1],[733,230,24,2],[734,230,680,3],[735,230,681,4],[736,230,682,5],[737,231,683,1],[738,231,684,2],[739,231,25,3],[740,232,104,1],[741,232,685,2],[742,232,686,3],[743,232,687,4],[744,233,688,1],[745,234,689,1],[746,234,690,2],[747,234,691,3],[748,235,150,1],[749,235,692,2],[750,235,693,3],[751,235,507,4],[752,235,694,5],[753,235,695,6],[754,236,696,1],[755,236,697,2],[756,236,698,3],[757,237,699,1],[758,237,700,2],[759,237,701,3],[760,237,702,4],[761,237,703,5],[762,237,704,6],[763,239,705,1],[764,239,706,2],[765,241,707,1],[766,243,330,1],[767,243,708,2],[768,245,709,1],[769,246,710,1],[770,247,711,1],[771,247,712,2],[772,247,713,3],[773,247,714,4],[774,248,715,1],[775,248,716,2],[776,248,717,3],[777,248,718,4],[778,248,719,5],[779,249,720,1],[780,249,721,2],[781,249,722,3],[782,250,711,1],[783,250,723,2],[784,250,724,3],[785,254,725,1],[786,255,721,1],[787,256,726,1],[788,257,727,1],[789,257,728,2],[790,257,729,3],[791,258,730,1],[792,258,731,2],[793,259,732,1],[794,260,733,1],[795,260,734,2],[796,260,735,3],[797,260,736,4],[798,260,737,5],[799,261,738,1],[800,261,739,2],[801,261,740,3],[802,262,741,1],[803,262,742,2],[804,262,743,3],[805,262,744,4],[806,262,745,5],[807,262,746,6],[808,262,747,7],[809,263,748,1],[810,263,749,2],[811,263,750,3],[812,264,751,1],[813,265,686,1],[814,265,328,2],[815,266,752,1],[816,266,753,2],[817,266,754,3],[818,266,755,4],[819,266,756,5],[820,266,680,6],[821,267,757,1],[822,267,758,2],[823,267,759,3],[824,267,760,4],[825,267,761,5],[826,267,762,6],[827,267,763,7],[828,267,764,8],[829,268,765,1],[830,268,766,2],[831,268,217,3],[832,268,239,4],[833,268,767,5],[834,268,768,6],[835,268,769,7],[836,269,770,1],[837,269,771,2],[838,269,772,3],[839,269,123,4],[840,269,724,5],[841,270,773,1],[842,271,774,1],[843,271,775,2],[844,271,276,3],[845,272,776,1],[846,272,777,2],[847,272,778,3],[848,272,779,4],[849,273,780,1],[850,273,337,2],[851,273,681,3],[852,274,781,1],[853,274,782,2],[854,274,783,3],[855,274,616,4],[856,275,784,1],[857,275,785,2],[858,276,786,1],[859,277,787,1],[860,277,788,2],[861,277,789,3],[862,278,790,1],[863,278,788,2],[864,278,791,3],[865,279,792,1],[866,279,788,2],[867,279,793,3],[868,279,789,4],[869,280,794,1],[870,280,795,2],[871,280,788,3],[872,280,796,4],[873,280,797,5],[874,280,798,6],[875,280,799,7],[876,281,788,1],[877,281,787,2],[878,281,792,3],[879,281,789,4],[880,282,800,1],[881,282,801,2],[882,282,802,3],[883,282,274,4],[884,282,803,5],[885,283,804,1],[886,284,805,1],[887,284,806,2],[888,284,113,3],[889,285,807,1],[890,285,808,2],[891,286,809,1],[892,286,810,2],[893,287,811,1],[894,287,812,2],[895,287,813,3],[896,289,814,1],[897,289,815,2],[898,290,816,1],[899,291,817,1],[900,291,818,2],[901,291,819,3],[902,292,817,1],[903,292,820,2],[904,292,821,3],[905,292,822,4],[906,294,705,1],[907,294,706,2],[908,296,707,1],[909,298,330,1],[910,298,708,2],[911,300,709,1],[912,302,823,1],[913,302,474,2],[914,302,824,3],[915,303,825,1],[916,304,826,1],[917,304,827,2],[918,304,828,3],[919,305,829,1],[920,305,830,2],[921,305,831,3],[922,305,828,4],[923,306,456,1],[924,306,832,2],[925,306,833,3],[926,306,834,4],[927,307,835,1],[928,307,836,2],[929,308,837,1],[930,308,838,2],[931,308,839,3],[932,309,840,1],[933,310,841,1],[934,310,842,2],[935,310,843,3],[936,311,844,1],[937,311,845,2],[938,311,846,3],[939,311,284,4],[940,311,847,5],[941,312,848,1],[942,312,849,2],[943,312,850,3],[944,312,477,4],[945,312,851,5],[946,313,852,1],[947,313,853,2],[948,313,854,3],[949,313,855,4],[950,313,496,5],[951,313,67,6],[952,315,856,1],[953,316,857,1],[954,316,858,2],[955,317,859,1],[956,317,860,2],[957,317,861,3],[958,317,862,4],[959,318,863,1],[960,318,864,2],[961,318,865,3],[962,318,866,4],[963,318,867,5],[964,319,868,1],[965,319,869,2],[966,319,870,3],[967,319,871,4],[968,319,872,5],[969,319,873,6],[970,320,874,1],[971,321,875,1],[972,322,876,1],[973,323,119,1],[974,323,475,2],[975,323,877,3],[976,323,55,4],[977,323,878,5],[978,324,879,1],[979,324,880,2],[980,324,881,3],[981,325,882,1],[982,325,883,2],[983,325,884,3],[984,325,235,4],[985,326,885,1],[986,326,886,2],[987,326,887,3],[988,326,114,4],[989,326,888,5],[990,327,889,1],[991,328,890,1],[992,328,122,2],[993,328,891,3],[994,328,892,4],[995,329,893,1],[996,329,894,2],[997,329,895,3],[998,329,896,4],[999,330,897,1],[1000,330,898,2],[1001,330,899,3],[1002,330,900,4],[1003,330,901,5],[1004,330,902,6],[1005,331,903,1],[1006,331,904,2],[1007,332,905,1],[1008,332,906,2],[1009,332,907,3],[1010,332,908,4],[1011,333,909,1],[1012,334,910,1],[1013,334,911,2],[1014,334,912,3],[1015,334,913,4],[1016,335,914,1],[1017,335,915,2],[1018,335,916,3],[1019,335,917,4],[1020,336,918,1],[1021,336,919,2],[1022,336,920,3],[1023,337,921,1],[1024,337,922,2],[1025,337,681,3],[1026,337,923,4],[1027,337,924,5],[1028,337,925,6],[1029,337,926,7],[1030,338,927,1],[1031,338,928,2],[1032,338,929,3],[1033,338,930,4],[1034,339,931,1],[1035,340,932,1],[1036,340,933,2],[1037,340,934,3],[1038,340,935,4],[1039,341,801,1],[1040,341,936,2],[1041,341,937,3],[1042,341,938,4],[1043,341,274,5],[1044,342,939,1],[1045,342,940,2],[1046,342,941,3],[1047,342,942,4],[1048,342,943,5],[1049,342,944,6],[1050,343,945,1],[1051,343,946,2],[1052,344,941,1],[1053,344,947,2],[1054,344,948,3],[1055,345,949,1],[1056,346,950,1],[1057,346,951,2],[1058,346,952,3],[1059,346,338,4],[1060,347,461,1],[1061,347,953,2],[1062,347,954,3],[1063,347,955,4],[1064,348,951,1],[1065,348,950,2],[1066,348,952,3],[1067,348,338,4],[1068,349,956,1],[1069,349,957,2],[1070,350,958,1],[1071,350,959,2],[1072,350,960,3],[1073,350,961,4],[1074,350,279,5],[1075,351,962,1],[1076,352,120,1],[1077,352,963,2],[1078,352,964,3],[1079,353,965,1],[1080,353,966,2],[1081,353,389,3],[1082,354,263,1],[1083,354,967,2],[1084,355,968,1],[1085,355,969,2],[1086,355,970,3],[1087,355,971,4],[1088,356,972,1],[1089,357,973,1],[1090,357,974,2],[1091,357,975,3],[1092,357,976,4],[1093,358,977,1],[1094,358,491,2],[1095,358,978,3],[1096,359,979,1],[1097,359,980,2],[1098,359,981,3],[1099,360,183,1],[1100,360,982,2],[1101,360,983,3],[1102,362,156,1],[1103,362,799,2],[1104,364,984,1],[1105,364,985,2],[1106,364,986,3],[1107,364,632,4],[1108,364,987,5],[1109,364,988,6],[1110,364,989,7],[1111,366,990,1],[1112,366,991,2],[1113,366,992,3],[1114,368,836,1],[1115,368,68,2],[1116,369,993,1],[1117,370,994,1],[1118,370,995,2],[1119,370,996,3],[1120,371,997,1],[1121,371,998,2],[1122,371,999,3],[1123,372,1000,1],[1124,372,1001,2],[1125,372,515,3],[1126,372,1002,4],[1127,372,1003,5],[1128,373,189,1],[1129,373,1004,2],[1130,373,1005,3],[1131,373,1006,4],[1132,373,1007,5],[1133,377,1008,1],[1134,378,1009,1],[1135,378,122,2],[1136,378,892,3],[1137,379,1010,1],[1138,379,1011,2],[1139,379,724,3],[1140,379,1012,4],[1141,380,1013,1],[1142,380,1014,2],[1143,380,1015,3],[1144,380,1016,4],[1145,380,594,5],[1146,381,1010,1],[1147,381,507,2],[1148,381,1017,3],[1149,382,1018,1],[1150,383,1019,1],[1151,383,1020,2],[1152,383,418,3],[1153,383,1021,4],[1154,384,1022,1],[1155,384,1023,2],[1156,384,320,3],[1157,384,1024,4],[1158,385,418,1],[1159,385,1025,2],[1160,386,1026,1],[1161,386,1027,2],[1162,386,630,3],[1163,387,1028,1],[1164,388,1029,1],[1165,388,1030,2],[1166,388,1031,3],[1167,388,1032,4],[1168,388,1033,5],[1169,389,1034,1],[1170,389,153,2],[1171,389,1035,3],[1172,389,1036,4],[1173,389,1037,5],[1174,390,1038,1],[1175,390,1039,2],[1176,390,1040,3],[1177,391,1041,1],[1178,391,1042,2],[1179,392,1043,1],[1180,393,1044,1],[1181,393,1045,2],[1182,393,1046,3],[1183,393,1047,4],[1184,394,1044,1],[1185,394,1047,2],[1186,395,1048,1],[1187,395,1049,2],[1188,396,331,1],[1189,396,1050,2],[1190,396,1051,3],[1191,396,1052,4],[1192,397,1053,1],[1193,398,581,1],[1194,398,582,2],[1195,398,583,3],[1196,398,1054,4],[1197,398,584,5],[1198,399,1055,1],[1199,399,1056,2],[1200,399,1057,3],[1201,399,891,4],[1202,400,1058,1],[1203,401,1059,1],[1204,401,1060,2],[1205,401,1061,3],[1206,401,1062,4],[1207,401,763,5],[1208,402,1063,1],[1209,402,1064,2],[1210,403,1065,1],[1211,404,781,1],[1212,404,950,2],[1213,404,1066,3],[1214,404,1067,4],[1215,404,616,5],[1216,404,681,6],[1217,405,1068,1],[1218,405,781,2],[1219,405,1069,3],[1220,405,1070,4],[1221,405,616,5],[1222,405,123,6],[1223,406,781,1],[1224,406,1071,2],[1225,406,1072,3],[1226,406,1073,4],[1227,406,616,5],[1228,406,1074,6],[1229,407,1075,1],[1230,408,1076,1],[1231,409,1077,1],[1232,409,416,2],[1233,409,1078,3],[1234,409,1079,4],[1235,409,1080,5],[1236,409,1081,6],[1237,409,1082,7],[1238,410,1083,1],[1239,410,1084,2],[1240,411,1001,1],[1241,411,515,2],[1242,411,1000,3],[1243,411,1085,4],[1244,411,1086,5],[1245,411,1087,6],[1246,412,1088,1],[1247,412,1089,2],[1248,412,1090,3],[1249,412,1091,4],[1250,412,1092,5],[1251,412,1093,6],[1252,413,716,1],[1253,413,715,2],[1254,413,719,3],[1255,414,1094,1],[1256,415,1095,1],[1257,415,1096,2],[1258,415,1097,3],[1259,415,1098,4],[1260,416,1099,1],[1261,416,1100,2],[1262,416,1101,3],[1263,416,1102,4],[1264,416,1103,5],[1265,417,1104,1],[1266,417,1105,2],[1267,417,1106,3],[1268,418,1107,1],[1269,418,1108,2],[1270,418,119,3],[1271,418,55,4],[1272,419,1109,1],[1273,420,1110,1],[1274,420,1111,2],[1275,420,1112,3],[1276,420,1113,4],[1277,420,1114,5],[1278,420,1115,6],[1279,421,510,1],[1280,421,509,2],[1281,421,1116,3],[1282,422,1110,1],[1283,422,1117,2],[1284,423,1118,1],[1285,423,1119,2],[1286,423,1120,3],[1287,423,1121,4],[1288,424,1122,1],[1289,425,116,1],[1290,425,1123,2],[1291,425,1124,3],[1292,425,1125,4],[1293,425,1126,5],[1294,426,1127,1],[1295,426,1128,2],[1296,426,1129,3],[1297,426,1130,4],[1298,426,1131,5],[1299,427,397,1],[1300,427,1132,2],[1301,427,1133,3],[1302,429,156,1],[1303,429,799,2],[1304,431,984,1],[1305,431,985,2],[1306,431,986,3],[1307,431,632,4],[1308,431,987,5],[1309,431,988,6],[1310,431,989,7],[1311,433,990,1],[1312,433,991,2],[1313,433,992,3],[1314,435,836,1],[1315,435,68,2],[1316,437,1134,1],[1317,442,1135,1],[1318,442,1136,2],[1319,443,1137,1],[1320,444,1138,1],[1321,444,781,2],[1322,444,1139,3],[1323,444,616,4],[1324,445,770,1],[1325,445,1140,2],[1326,446,1141,1],[1327,446,1142,2],[1328,446,1143,3],[1329,446,1144,4],[1330,446,1145,5],[1331,447,1146,1],[1332,447,211,2],[1333,448,1147,1],[1334,449,1068,1],[1335,449,771,2],[1336,449,724,3],[1337,449,123,4],[1338,450,1148,1],[1339,450,1149,2],[1340,450,1150,3],[1341,450,597,4],[1342,451,1151,1],[1343,451,1152,2],[1344,451,565,3],[1345,452,1153,1],[1346,452,1154,2],[1347,452,1155,3],[1348,452,1156,4],[1349,452,1157,5],[1350,452,1158,6],[1351,452,1159,7],[1352,452,1160,8],[1353,453,1161,1],[1354,454,1162,1],[1355,454,1004,2],[1356,454,189,3],[1357,455,1163,1],[1358,455,1164,2],[1359,456,1165,1],[1360,456,1166,2],[1361,456,1167,3],[1362,456,1168,4],[1363,457,1169,1],[1364,457,1170,2],[1365,457,1171,3],[1366,458,1172,1],[1367,459,1173,1],[1368,459,1174,2],[1369,459,1175,3],[1370,460,1176,1],[1371,460,1177,2],[1372,460,1178,3],[1373,460,1179,4],[1374,460,1180,5],[1375,461,1181,1],[1376,461,1182,2],[1377,461,1183,3],[1378,462,792,1],[1379,462,788,2],[1380,462,1184,3],[1381,462,789,4],[1382,463,1185,1],[1383,463,1186,2],[1384,463,1187,3],[1385,463,1188,4],[1386,463,1189,5],[1387,464,1190,1],[1388,465,1191,1],[1389,465,1192,2],[1390,465,1193,3],[1391,465,1194,4],[1392,466,1195,1],[1393,466,1196,2],[1394,466,1197,3],[1395,467,1198,1],[1396,467,1199,2],[1397,467,1200,3],[1398,467,1201,4],[1399,468,375,1],[1400,469,1202,1],[1401,470,462,1],[1402,470,953,2],[1403,470,1203,3],[1404,470,954,4],[1405,470,955,5],[1406,471,1204,1],[1407,471,1205,2],[1408,471,1206,3],[1409,471,1207,4],[1410,472,1208,1],[1411,472,1209,2],[1412,472,1210,3],[1413,472,217,4],[1414,473,1211,1],[1415,473,1212,2],[1416,473,1210,3],[1417,473,1213,4],[1418,473,270,5],[1419,473,1214,6],[1420,474,1215,1],[1421,475,1216,1],[1422,475,219,2],[1423,476,1217,1],[1424,476,217,2],[1425,476,1218,3],[1426,477,1219,1],[1427,477,1220,2],[1428,478,881,1],[1429,478,1221,2],[1430,478,1222,3],[1431,478,1223,4],[1432,478,1224,5],[1433,479,1225,1],[1434,480,1226,1],[1435,480,1227,2],[1436,481,1228,1],[1437,481,986,2],[1438,482,1229,1],[1439,482,880,2],[1440,482,174,3],[1441,483,1230,1],[1442,483,325,2],[1443,483,1231,3],[1444,485,114,1],[1445,485,1232,2],[1446,487,1233,1],[1447,487,1234,2],[1448,488,1235,1],[1449,489,1236,1],[1450,489,1237,2],[1451,489,1238,3],[1452,489,1239,4],[1453,489,1240,5],[1454,489,1241,6],[1455,490,798,1],[1456,490,1242,2],[1457,490,799,3],[1458,491,1243,1],[1459,491,1244,2],[1460,491,1245,3],[1461,492,1246,1],[1462,492,1247,2],[1463,492,1248,3],[1464,492,1249,4],[1465,493,1250,1],[1466,493,1251,2],[1467,493,1252,3],[1468,494,1253,1],[1469,494,1254,2],[1470,494,1255,3],[1471,494,1256,4],[1472,494,1257,5],[1473,494,1258,6],[1474,494,594,7],[1475,495,1259,1],[1476,496,1260,1],[1477,496,1261,2],[1478,496,1262,3],[1479,496,1263,4],[1480,496,1264,5],[1481,497,1265,1],[1482,497,1266,2],[1483,497,1267,3],[1484,498,1268,1],[1485,498,1269,2],[1486,498,1270,3],[1487,498,1271,4],[1488,499,384,1],[1489,499,1272,2],[1490,499,1273,3],[1491,499,383,4],[1492,499,1274,5],[1493,499,1275,6],[1494,499,1276,7],[1495,499,68,8],[1496,503,1277,1],[1497,504,1278,1],[1498,504,1279,2],[1499,504,434,3],[1500,505,1280,1],[1501,505,986,2],[1502,505,1281,3],[1503,506,1282,1],[1504,506,1283,2],[1505,506,881,3],[1506,506,1284,4],[1507,506,1285,5],[1508,507,1286,1],[1509,507,1287,2],[1510,507,1288,3],[1511,507,1289,4],[1512,508,1290,1],[1513,509,1291,1],[1514,509,283,2],[1515,509,1292,3],[1516,509,1293,4],[1517,510,1294,1],[1518,510,1295,2],[1519,510,1296,3],[1520,510,597,4],[1521,511,1297,1],[1522,511,1298,2],[1523,512,1299,1],[1524,512,890,2],[1525,512,892,3],[1526,513,1300,1],[1527,513,1301,2],[1528,513,1302,3],[1529,514,1303,1],[1530,515,1304,1],[1531,515,1305,2],[1532,516,1306,1],[1533,516,1307,2],[1534,516,1308,3],[1535,516,1309,4],[1536,516,1310,5],[1537,517,466,1],[1538,517,1311,2],[1539,517,1210,3],[1540,517,217,4],[1541,517,1312,5],[1542,517,1313,6],[1543,517,1314,7],[1544,518,51,1],[1545,518,1315,2],[1546,518,1316,3],[1547,518,1317,4],[1548,518,1318,5],[1549,518,54,6],[1550,519,1319,1],[1551,519,1320,2],[1552,519,1321,3],[1553,519,1322,4],[1554,519,1323,5],[1555,519,1324,6],[1556,519,1325,7],[1557,519,1326,8],[1558,519,1327,9],[1559,520,1328,1],[1560,521,1329,1],[1561,521,232,2],[1562,521,1330,3],[1563,521,235,4],[1564,521,1331,5],[1565,521,320,6],[1566,522,1330,1],[1567,522,232,2],[1568,522,235,3],[1569,523,590,1],[1570,523,1332,2],[1571,523,594,3],[1572,524,1333,1],[1573,524,1334,2],[1574,524,1335,3],[1575,524,791,4],[1576,524,1336,5],[1577,525,589,1],[1578,525,593,2],[1579,525,594,3],[1580,526,1337,1],[1581,527,1338,1],[1582,527,1339,2],[1583,528,1340,1],[1584,528,1341,2],[1585,528,1342,3],[1586,529,1343,1],[1587,529,1344,2],[1588,529,1345,3],[1589,529,1346,4],[1590,529,1347,5],[1591,529,1348,6],[1592,530,1349,1],[1593,530,1350,2],[1594,530,1351,3],[1595,531,1352,1],[1596,532,1353,1],[1597,532,1354,2],[1598,532,1355,3],[1599,532,1356,4],[1600,532,1357,5],[1601,532,1358,6],[1602,532,572,7],[1603,533,1359,1],[1604,533,1360,2],[1605,533,1361,3],[1606,533,1362,4],[1607,534,1363,1],[1608,535,1364,1],[1609,535,1365,2],[1610,535,1366,3],[1611,535,1367,4],[1612,535,1368,5],[1613,536,1227,1],[1614,536,1226,2],[1615,536,1369,3],[1616,537,1370,1],[1617,537,1011,2],[1618,537,724,3],[1619,538,1371,1],[1620,538,1372,2],[1621,538,1373,3],[1622,540,1374,1],[1623,540,1375,2],[1624,540,1376,3],[1625,540,1377,4],[1626,540,1378,5],[1627,540,1119,6],[1628,540,1379,7],[1629,540,499,8],[1630,541,874,1],[1631,542,1380,1],[1632,542,1381,2],[1633,542,288,3],[1634,543,1382,1],[1635,543,1383,2],[1636,543,1384,3],[1637,543,1385,4],[1638,544,1386,1],[1639,544,1387,2],[1640,545,1388,1],[1641,545,843,2],[1642,545,1389,3],[1643,546,1390,1],[1644,547,1391,1],[1645,547,1392,2],[1646,548,1393,1],[1647,548,1394,2],[1648,548,355,3],[1649,549,50,1],[1650,549,53,2],[1651,550,1216,1],[1652,550,689,2],[1653,552,1395,1],[1654,552,880,2],[1655,552,334,3],[1656,552,1396,4],[1657,552,1397,5],[1658,554,114,1],[1659,554,1232,2],[1660,556,1233,1],[1661,556,1234,2],[1662,558,1398,1],[1663,558,1399,2],[1664,558,1400,3],[1665,558,1401,4],[1666,558,1402,5],[1667,558,1403,6],[1668,558,1404,7],[1669,560,1135,1],[1670,560,1136,2],[1671,563,1405,1],[1672,563,1406,2],[1673,563,1407,3],[1674,564,1408,1],[1675,565,1409,1],[1676,565,1410,2],[1677,566,1411,1],[1678,566,997,2],[1679,567,1412,1],[1680,567,1413,2],[1681,567,1414,3],[1682,567,1415,4],[1683,567,1416,5],[1684,568,1417,1],[1685,568,1418,2],[1686,568,1419,3],[1687,568,1420,4],[1688,568,836,5],[1689,568,1421,6],[1690,569,1422,1],[1691,570,1423,1],[1692,570,1424,2],[1693,570,632,3],[1694,571,974,1],[1695,571,973,2],[1696,572,1044,1],[1697,572,1047,2],[1698,573,1425,1],[1699,573,1426,2],[1700,574,1427,1],[1701,574,1428,2],[1702,574,104,3],[1703,575,1427,1],[1704,575,1429,2],[1705,575,686,3],[1706,575,328,4],[1707,575,1430,5],[1708,576,1431,1],[1709,577,1432,1],[1710,577,1081,2],[1711,577,1433,3],[1712,577,1434,4],[1713,577,1435,5],[1714,577,1436,6],[1715,577,1078,7],[1716,578,1437,1],[1717,578,1438,2],[1718,579,608,1],[1719,579,609,2],[1720,580,1437,1],[1721,580,1439,2],[1722,580,1440,3],[1723,581,1441,1],[1724,582,1442,1],[1725,582,1443,2],[1726,582,1444,3],[1727,582,1445,4],[1728,583,950,1],[1729,583,1446,2],[1730,583,1447,3],[1731,583,1448,4],[1732,583,1449,5],[1733,583,1450,6],[1734,584,1451,1],[1735,584,1004,2],[1736,584,1452,3],[1737,584,49,4],[1738,584,54,5],[1739,584,55,6],[1740,585,1453,1],[1741,585,1454,2],[1742,585,1455,3],[1743,585,1456,4],[1744,585,1457,5],[1745,585,1458,6],[1746,585,1459,7],[1747,586,1460,1],[1748,587,941,1],[1749,587,1461,2],[1750,588,1462,1],[1751,588,1463,2],[1752,588,1464,3],[1753,588,1465,4],[1754,588,1466,5],[1755,588,1467,6],[1756,589,1468,1],[1757,589,1469,2],[1758,589,1470,3],[1759,589,1359,4],[1760,589,1471,5],[1761,589,1472,6],[1762,589,1473,7],[1763,589,1474,8],[1764,590,1475,1],[1765,590,1476,2],[1766,590,1477,3],[1767,590,1478,4],[1768,590,1479,5],[1769,590,1480,6],[1770,590,1481,7],[1771,590,1482,8],[1772,590,1483,9],[1773,590,1484,10],[1774,591,1485,1],[1775,592,1486,1],[1776,592,1487,2],[1777,592,1488,3],[1778,592,1489,4],[1779,593,1490,1],[1780,593,1491,2],[1781,593,1492,3],[1782,593,405,4],[1783,593,156,5],[1784,594,1493,1],[1785,594,1494,2],[1786,594,290,3],[1787,594,245,4],[1788,594,289,5],[1789,594,1495,6],[1790,595,1496,1],[1791,595,1497,2],[1792,595,1498,3],[1793,596,1499,1],[1794,596,1500,2],[1795,596,1501,3],[1796,596,47,4],[1797,598,1502,1],[1798,598,1383,2],[1799,598,1503,3],[1800,598,219,4],[1801,598,1136,5],[1802,598,1504,6],[1803,599,1505,1],[1804,600,1506,1],[1805,601,1507,1],[1806,602,1508,1],[1807,602,17,2],[1808,602,1509,3],[1809,602,20,4],[1810,602,810,5],[1811,603,1510,1],[1812,603,1511,2],[1813,603,896,3],[1814,604,1512,1],[1815,604,1513,2],[1816,604,1514,3],[1817,604,1515,4],[1818,604,1516,5],[1819,604,1517,6],[1820,604,1518,7],[1821,605,1519,1],[1822,605,1520,2],[1823,605,1521,3],[1824,606,1522,1],[1825,606,1523,2],[1826,608,1391,1],[1827,608,1524,2],[1828,608,1525,3],[1829,608,1526,4],[1830,610,1527,1],[1831,610,1528,2],[1832,612,139,1],[1833,616,817,1],[1834,616,1529,2],[1835,620,1530,1],[1836,621,1531,1],[1837,621,1532,2],[1838,621,1533,3],[1839,621,583,4],[1840,621,1534,5],[1841,621,1054,6],[1842,622,761,1],[1843,622,1535,2],[1844,622,1536,3],[1845,622,1537,4],[1846,622,1538,5],[1847,622,757,6],[1848,622,764,7],[1849,623,610,1],[1850,623,1539,2],[1851,623,1540,3],[1852,624,1541,1],[1853,624,1542,2],[1854,624,1543,3],[1855,624,1544,4],[1856,625,1545,1],[1857,625,46,2],[1858,625,47,3],[1859,626,1546,1],[1860,627,1547,1],[1861,627,1548,2],[1862,627,1549,3],[1863,627,1550,4],[1864,627,1551,5],[1865,627,1552,6],[1866,628,1553,1],[1867,628,1349,2],[1868,628,1351,3],[1869,629,554,1],[1870,629,557,2],[1871,629,1554,3],[1872,629,559,4],[1873,630,1555,1],[1874,630,1556,2],[1875,630,1557,3],[1876,631,1558,1],[1877,632,1559,1],[1878,632,1560,2],[1879,632,1561,3],[1880,632,162,4],[1881,632,1562,5],[1882,632,1563,6],[1883,632,153,7],[1884,632,215,8],[1885,633,160,1],[1886,633,158,2],[1887,633,1562,3],[1888,633,159,4],[1889,633,1559,5],[1890,633,215,6],[1891,633,162,7],[1892,634,1564,1],[1893,634,1565,2],[1894,634,1245,3],[1895,635,1566,1],[1896,635,445,2],[1897,635,573,3],[1898,636,1567,1],[1899,636,1568,2],[1900,636,1569,3],[1901,637,1570,1],[1902,638,503,1],[1903,638,499,2],[1904,638,295,3],[1905,639,1571,1],[1906,639,1572,2],[1907,639,1573,3],[1908,639,1574,4],[1909,639,1575,5],[1910,640,1576,1],[1911,640,1577,2],[1912,640,1578,3],[1913,640,1579,4],[1914,640,1580,5],[1915,640,343,6],[1916,641,1581,1],[1917,641,839,2],[1918,641,369,3],[1919,642,1505,1],[1920,643,1582,1],[1921,643,1583,2],[1922,643,1584,3],[1923,644,1585,1],[1924,644,1586,2],[1925,644,1587,3],[1926,644,441,4],[1927,644,1588,5],[1928,644,1589,6],[1929,644,1590,7],[1930,645,1591,1],[1931,645,1592,2],[1932,645,1593,3],[1933,645,1594,4],[1934,645,1595,5],[1935,646,1596,1],[1936,646,1597,2],[1937,646,1598,3],[1938,646,410,4],[1939,647,1599,1],[1940,648,1600,1],[1941,648,1046,2],[1942,649,1601,1],[1943,649,1011,2],[1944,649,1117,3],[1945,650,1602,1],[1946,650,1603,2],[1947,650,998,3],[1948,651,1604,1],[1949,651,968,2],[1950,652,1605,1],[1951,653,1606,1],[1952,653,1607,2],[1953,654,1608,1],[1954,654,49,2],[1955,654,1609,3],[1956,654,191,4],[1957,654,419,5],[1958,654,1451,6],[1959,654,1610,7],[1960,654,877,8],[1961,654,55,9],[1962,655,1611,1],[1963,655,1612,2],[1964,655,1613,3],[1965,655,1614,4],[1966,655,1615,5],[1967,656,1616,1],[1968,656,119,2],[1969,656,1005,3],[1970,656,1617,4],[1971,656,1284,5],[1972,656,1282,6],[1973,657,1618,1],[1974,658,1619,1],[1975,658,1620,2],[1976,658,1621,3],[1977,659,951,1],[1978,659,1622,2],[1979,659,1623,3],[1980,659,1624,4],[1981,659,523,5],[1982,660,1625,1],[1983,660,1626,2],[1984,660,1627,3],[1985,661,1628,1],[1986,661,1629,2],[1987,661,1630,3],[1988,662,1631,1],[1989,663,1632,1],[1990,663,1633,2],[1991,664,1634,1],[1992,665,1635,1],[1993,665,508,2],[1994,665,1636,3],[1995,666,296,1],[1996,668,817,1],[1997,668,1529,2],[1998,670,1405,1],[1999,670,1406,2],[2000,670,1407,3],[2001,672,1226,1],[2002,672,1637,2],[2003,672,1638,3],[2004,674,1527,1],[2005,674,1528,2],[2006,676,139,1],[2007,678,418,1],[2008,678,469,2],[2009,678,1412,3],[2010,678,1410,4],[2011,678,1409,5],[2012,681,1639,1],[2013,682,1640,1],[2014,682,1641,2],[2015,682,169,3],[2016,683,1642,1],[2017,683,1643,2],[2018,683,1644,3],[2019,683,1645,4],[2020,683,1646,5],[2021,683,1647,6],[2022,683,1648,7],[2023,683,1649,8],[2024,683,822,9],[2025,683,1650,10],[2026,684,1059,1],[2027,684,1651,2],[2028,684,1652,3],[2029,684,1653,4],[2030,684,1654,5],[2031,684,1655,6],[2032,684,1656,7],[2033,684,763,8],[2034,685,1657,1],[2035,685,1658,2],[2036,685,1659,3],[2037,685,1660,4],[2038,685,1661,5],[2039,686,1662,1],[2040,687,1663,1],[2041,687,1664,2],[2042,687,1665,3],[2043,687,1666,4],[2044,688,512,1],[2045,688,1667,2],[2046,688,1668,3],[2047,688,1560,4],[2048,689,1669,1],[2049,689,1670,2],[2050,689,1671,3],[2051,690,1672,1],[2052,690,1673,2],[2053,690,1674,3],[2054,691,1675,1],[2055,692,1676,1],[2056,692,1677,2],[2057,692,1454,3],[2058,693,1678,1],[2059,693,1679,2],[2060,693,1680,3],[2061,694,1681,1],[2062,694,1682,2],[2063,694,333,3],[2064,695,1683,1],[2065,695,1684,2],[2066,695,1685,3],[2067,695,920,4],[2068,696,1686,1],[2069,697,1687,1],[2070,697,1688,2],[2071,698,1689,1],[2072,698,1690,2],[2073,699,1691,1],[2074,699,1692,2],[2075,700,1693,1],[2076,700,397,2],[2077,700,126,3],[2078,701,1694,1],[2079,701,585,2],[2080,701,588,3],[2081,702,1695,1],[2082,703,1696,1],[2083,703,490,2],[2084,703,1697,3],[2085,703,1698,4],[2086,704,1699,1],[2087,704,349,2],[2088,705,1700,1],[2089,705,1701,2],[2090,706,1702,1],[2091,706,1703,2],[2092,706,1704,3],[2093,706,1705,4],[2094,706,1706,5],[2095,706,1707,6],[2096,706,1708,7],[2097,706,1709,8],[2098,707,1710,1],[2099,708,1554,1],[2100,708,1711,2],[2101,709,1712,1],[2102,709,954,2],[2103,709,1713,3],[2104,709,1714,4],[2105,709,1715,5],[2106,709,1716,6],[2107,709,1717,7],[2108,710,1718,1],[2109,710,1719,2],[2110,710,1720,3],[2111,710,337,4],[2112,710,1721,5],[2113,710,1722,6],[2114,710,1723,7],[2115,711,1724,1],[2116,711,1725,2],[2117,711,1726,3],[2118,712,1727,1],[2119,713,1728,1],[2120,713,371,2],[2121,713,1729,3],[2122,714,1730,1],[2123,714,1731,2],[2124,714,1732,3],[2125,714,1733,4],[2126,715,1734,1],[2127,715,1735,2],[2128,716,1736,1],[2129,716,1737,2],[2130,716,1738,3],[2131,717,1739,1],[2132,717,1740,2],[2133,718,1741,1],[2134,719,273,1],[2135,719,801,2],[2136,719,545,3],[2137,719,938,4],[2138,719,274,5],[2139,720,1742,1],[2140,720,881,2],[2141,720,1743,3],[2142,720,1744,4],[2143,720,1745,5],[2144,721,1746,1],[2145,721,1747,2],[2146,721,1748,3],[2147,721,1749,4],[2148,721,1750,5],[2149,722,1751,1],[2150,722,1752,2],[2151,722,1753,3],[2152,722,235,4],[2153,722,1754,5],[2154,722,1755,6],[2155,723,1756,1],[2156,724,1757,1],[2157,724,1758,2],[2158,724,1759,3],[2159,724,1760,4],[2160,724,1761,5],[2161,724,1762,6],[2162,725,1763,1],[2163,725,1764,2],[2164,725,1765,3],[2165,726,1766,1],[2166,726,1767,2],[2167,726,1768,3],[2168,726,1769,4],[2169,727,1770,1],[2170,727,1771,2],[2171,727,1772,3],[2172,727,1000,4],[2173,727,1773,5],[2174,727,1001,6],[2175,729,150,1],[2176,729,692,2],[2177,729,693,3],[2178,729,144,4],[2179,729,145,5],[2180,731,837,1],[2181,731,838,2],[2182,733,1774,1],[2183,733,1775,2],[2184,735,1776,1],[2185,735,1777,2],[2186,735,1778,3],[2187,735,1779,4],[2188,735,1780,5],[2189,738,1781,1],[2190,739,1782,1],[2191,739,1783,2],[2192,739,1784,3],[2193,739,1785,4],[2194,739,1786,5],[2195,740,1787,1],[2196,740,1270,2],[2197,740,1788,3],[2198,741,1789,1],[2199,741,1270,2],[2200,742,1790,1],[2201,742,1791,2],[2202,742,1792,3],[2203,742,1793,4],[2204,742,1794,5],[2205,742,1795,6],[2206,743,1796,1],[2207,744,1279,1],[2208,744,620,2],[2209,744,1797,3],[2210,744,1798,4],[2211,744,1799,5],[2212,744,1800,6],[2213,744,1801,7],[2214,744,434,8],[2215,745,1802,1],[2216,745,1803,2],[2217,745,1804,3],[2218,745,1805,4],[2219,745,1806,5],[2220,745,1807,6],[2221,745,451,7],[2222,745,1808,8],[2223,745,1809,9],[2224,746,1810,1],[2225,746,1811,2],[2226,746,1812,3],[2227,746,1813,4],[2228,747,1711,1],[2229,747,1814,2],[2230,747,1815,3],[2231,747,1816,4],[2232,747,1817,5],[2233,747,1818,6],[2234,747,1819,7],[2235,747,1820,8],[2236,748,1821,1],[2237,749,1822,1],[2238,749,1823,2],[2239,749,1824,3],[2240,750,1253,1],[2241,750,1825,2],[2242,750,1826,3],[2243,750,1827,4],[2244,750,1828,5],[2245,750,1829,6],[2246,750,1830,7],[2247,750,1831,8],[2248,750,594,9],[2249,751,1832,1],[2250,751,1833,2],[2251,751,266,3],[2252,752,1834,1],[2253,752,1835,2],[2254,752,1836,3],[2255,753,1837,1],[2256,754,1838,1],[2257,754,1839,2],[2258,754,1840,3],[2259,755,1230,1],[2260,755,1841,2],[2261,755,1842,3],[2262,755,1843,4],[2263,756,1844,1],[2264,756,1845,2],[2265,756,1846,3],[2266,757,1847,1],[2267,757,1848,2],[2268,758,1849,1],[2269,758,1850,2],[2270,758,1851,3],[2271,759,1852,1],[2272,760,1853,1],[2273,760,1854,2],[2274,760,1855,3],[2275,760,1856,4],[2276,760,1857,5],[2277,760,1858,6],[2278,760,1859,7],[2279,760,1860,8],[2280,760,1861,9],[2281,760,1862,10],[2282,760,1863,11],[2283,760,1864,12],[2284,760,1865,13],[2285,760,1866,14],[2286,760,822,15],[2287,761,1867,1],[2288,761,1868,2],[2289,761,1869,3],[2290,761,583,4],[2291,762,1870,1],[2292,762,1871,2],[2293,762,1688,3],[2294,763,1872,1],[2295,763,1873,2],[2296,763,1874,3],[2297,763,1875,4],[2298,763,1627,5],[2299,764,1876,1],[2300,764,1877,2],[2301,764,1878,3],[2302,764,1879,4],[2303,765,1880,1],[2304,766,1881,1],[2305,766,1882,2],[2306,766,1883,3],[2307,766,1884,4],[2308,766,1885,5],[2309,766,1168,6],[2310,767,1886,1],[2311,767,1887,2],[2312,767,1888,3],[2313,768,1889,1],[2314,768,1890,2],[2315,768,1891,3],[2316,768,1892,4],[2317,768,1893,5],[2318,768,1894,6],[2319,768,1895,7],[2320,768,1896,8],[2321,768,1897,9],[2322,769,1898,1],[2323,769,1899,2],[2324,769,340,3],[2325,770,1900,1],[2326,771,1901,1],[2327,771,1902,2],[2328,771,1903,3],[2329,771,1904,4],[2330,771,1905,5],[2331,771,1906,6],[2332,771,1907,7],[2333,772,1908,1],[2334,772,1909,2],[2335,773,472,1],[2336,773,471,2],[2337,773,473,3],[2338,773,474,4],[2339,774,287,1],[2340,774,1910,2],[2341,774,538,3],[2342,775,1911,1],[2343,776,1912,1],[2344,776,1913,2],[2345,777,1914,1],[2346,777,1915,2],[2347,777,1916,3],[2348,777,1321,4],[2349,777,1917,5],[2350,777,1918,6],[2351,777,1919,7],[2352,777,1920,8],[2353,777,1921,9],[2354,777,1326,10],[2355,777,1327,11],[2356,778,1922,1],[2357,778,1923,2],[2358,778,1924,3],[2359,779,1925,1],[2360,779,1624,2],[2361,779,1926,3],[2362,779,523,4],[2363,781,1927,1],[2364,781,1928,2],[2365,781,1929,3],[2366,781,1930,4],[2367,782,1931,1],[2368,783,1932,1],[2369,783,119,2],[2370,783,55,3],[2371,784,727,1],[2372,784,1049,2],[2373,785,1933,1],[2374,785,1934,2],[2375,785,1935,3],[2376,785,1936,4],[2377,786,1937,1],[2378,786,354,2],[2379,786,1938,3],[2380,786,55,4],[2381,788,139,1],[2382,790,1939,1],[2383,794,1940,1],[2384,795,1941,1],[2385,795,276,2],[2386,796,1942,1],[2387,796,1943,2],[2388,797,780,1],[2389,797,337,2],[2390,797,349,3],[2391,797,681,4],[2392,798,1944,1],[2393,798,1945,2],[2394,798,1946,3],[2395,798,1947,4],[2396,798,724,5],[2397,798,1117,6],[2398,799,1948,1],[2399,799,1949,2],[2400,799,1950,3],[2401,799,1951,4],[2402,799,1952,5],[2403,799,1953,6],[2404,800,1954,1],[2405,800,1955,2],[2406,800,1340,3],[2407,800,1956,4],[2408,801,1957,1],[2409,802,1958,1],[2410,802,1959,2],[2411,802,604,3],[2412,802,1960,4],[2413,802,496,5],[2414,803,1961,1],[2415,803,1962,2],[2416,803,1963,3],[2417,803,1964,4],[2418,803,1965,5],[2419,803,1966,6],[2420,803,333,7],[2421,804,1791,1],[2422,804,1967,2],[2423,804,1795,3],[2424,805,1968,1],[2425,806,1969,1],[2426,806,1970,2],[2427,806,994,3],[2428,806,1971,4],[2429,806,1972,5],[2430,806,551,6],[2431,807,1973,1],[2432,808,1974,1],[2433,808,565,2],[2434,809,1491,1],[2435,809,1492,2],[2436,809,1335,3],[2437,809,156,4],[2438,810,488,1],[2439,810,215,2],[2440,811,1975,1],[2441,811,162,2],[2442,811,168,3],[2443,811,169,4],[2444,812,1976,1],[2445,812,1977,2],[2446,812,1978,3],[2447,812,1979,4],[2448,812,1980,5],[2449,812,1981,6],[2450,813,1982,1],[2451,814,1983,1],[2452,814,1984,2],[2453,815,1985,1],[2454,815,1131,2],[2455,815,1986,3],[2456,815,1987,4],[2457,815,1988,5],[2458,815,1989,6],[2459,815,622,7],[2460,816,1990,1],[2461,816,621,2],[2462,816,619,3],[2463,816,1991,4],[2464,817,1992,1],[2465,817,1993,2],[2466,818,1994,1],[2467,819,578,1],[2468,819,1995,2],[2469,819,1996,3],[2470,819,580,4],[2471,820,1997,1],[2472,820,1998,2],[2473,820,1503,3],[2474,821,1999,1],[2475,821,2000,2],[2476,821,2001,3],[2477,821,2002,4],[2478,821,2003,5],[2479,822,2004,1],[2480,822,2005,2],[2481,822,2006,3],[2482,823,2007,1],[2483,823,1249,2],[2484,823,2008,3],[2485,824,2009,1],[2486,825,2010,1],[2487,825,2011,2],[2488,825,2012,3],[2489,826,906,1],[2490,826,907,2],[2491,826,2013,3],[2492,826,2014,4],[2493,826,908,5],[2494,826,998,6],[2495,827,2015,1],[2496,827,1692,2],[2497,828,2016,1],[2498,828,2017,2],[2499,828,133,3],[2500,828,1660,4],[2501,829,2018,1],[2502,830,2019,1],[2503,830,2020,2],[2504,830,2021,3],[2505,830,2022,4],[2506,831,2020,1],[2507,831,2019,2],[2508,831,2023,3],[2509,831,2022,4],[2510,832,2024,1],[2511,832,466,2],[2512,832,270,3],[2513,832,2025,4],[2514,832,2026,5],[2515,832,2027,6],[2516,833,324,1],[2517,833,2028,2],[2518,833,2029,3],[2519,833,2030,4],[2520,834,2031,1],[2521,835,914,1],[2522,835,2032,2],[2523,836,2033,1],[2524,836,986,2],[2525,836,2034,3],[2526,837,2035,1],[2527,837,986,2],[2528,837,265,3],[2529,838,2036,1],[2530,838,2037,2],[2531,838,2038,3],[2532,838,2039,4],[2533,838,2040,5],[2534,839,1338,1],[2535,839,2041,2],[2536,839,2042,3],[2537,840,2043,1],[2538,841,1871,1],[2539,841,1688,2],[2540,841,1084,3],[2541,842,985,1],[2542,842,2044,2],[2543,843,2045,1],[2544,843,2046,2],[2545,843,513,3],[2546,844,2047,1],[2547,844,1533,2],[2548,844,985,3],[2549,844,583,4],[2550,844,2048,5],[2551,845,1735,1],[2552,845,2049,2],[2553,845,2050,3],[2554,845,2051,4],[2555,845,2052,5],[2556,845,2053,6],[2557,846,2054,1],[2558,847,183,1],[2559,847,2055,2],[2560,847,2056,3],[2561,847,1677,4],[2562,847,2057,5],[2563,847,2058,6],[2564,847,2059,7],[2565,847,2060,8],[2566,848,2061,1],[2567,848,2062,2],[2568,848,2063,3],[2569,849,2064,1],[2570,849,2065,2],[2571,849,2066,3],[2572,849,2067,4],[2573,849,2068,5],[2574,849,2069,6],[2575,850,2070,1],[2576,850,2071,2],[2577,850,2072,3],[2578,850,2073,4],[2579,850,2074,5]]},\"event_events\":{\"headers\":[\"_id\",\"parent_fk\",\"child_fk\",\"sequence\"],\"rows\":[[1,1,2,0],[2,6,7,0],[3,6,8,1],[4,6,9,2],[5,6,10,3],[6,6,11,4],[7,12,13,0],[8,12,14,1],[9,12,15,2],[10,12,16,3],[11,17,18,0],[12,17,19,1],[13,17,20,2],[14,17,21,3],[15,17,22,4],[16,23,24,0],[17,23,25,1],[18,23,26,2],[19,23,27,3],[20,28,29,0],[21,28,30,1],[22,28,31,2],[23,28,32,3],[24,28,33,4],[25,34,35,0],[26,34,36,1],[27,34,37,2],[28,34,38,3],[29,34,39,4],[30,40,41,0],[31,42,43,0],[32,42,44,1],[33,42,45,2],[34,42,46,3],[35,47,48,0],[36,49,50,0],[37,51,52,0],[38,53,54,0],[39,53,55,1],[40,53,56,2],[41,53,57,3],[42,53,58,4],[43,59,60,0],[44,59,61,1],[45,59,62,2],[46,59,63,3],[47,59,64,4],[48,66,67,0],[49,66,68,1],[50,66,69,2],[51,66,70,3],[52,66,71,4],[53,72,73,0],[54,72,74,1],[55,72,75,2],[56,72,76,3],[57,77,78,0],[58,77,79,1],[59,77,80,2],[60,77,81,3],[61,77,82,4],[62,83,84,0],[63,83,85,1],[64,83,86,2],[65,83,87,3],[66,88,89,0],[67,88,90,1],[68,88,91,2],[69,88,92,3],[70,93,94,0],[71,93,95,1],[72,93,96,2],[73,93,97,3],[74,98,99,0],[75,98,100,1],[76,98,101,2],[77,98,102,3],[78,103,104,0],[79,103,105,1],[80,103,106,2],[81,103,107,3],[82,108,109,0],[83,110,111,0],[84,112,113,0],[85,114,115,0],[86,116,117,0],[87,118,119,0],[88,120,121,0],[89,120,122,1],[90,120,123,2],[91,120,124,3],[92,126,127,0],[93,126,128,1],[94,126,129,2],[95,126,130,3],[96,131,132,0],[97,131,133,1],[98,131,134,2],[99,131,135,3],[100,131,136,4],[101,137,138,0],[102,137,139,1],[103,137,140,2],[104,137,141,3],[105,142,143,0],[106,142,144,1],[107,142,145,2],[108,142,146,3],[109,147,148,0],[110,147,149,1],[111,147,150,2],[112,147,151,3],[113,152,153,0],[114,152,154,1],[115,152,155,2],[116,152,156,3],[117,157,158,0],[118,157,159,1],[119,157,160,2],[120,157,161,3],[121,162,163,0],[122,162,164,1],[123,162,165,2],[124,162,166,3],[125,167,168,0],[126,169,170,0],[127,171,172,0],[128,173,174,0],[129,175,176,0],[130,175,177,1],[131,175,178,2],[132,175,179,3],[133,180,181,0],[134,180,182,1],[135,180,183,2],[136,180,184,3],[137,186,187,0],[138,188,189,0],[139,188,190,1],[140,188,191,2],[141,188,192,3],[142,188,193,4],[143,194,195,0],[144,194,196,1],[145,194,197,2],[146,194,198,3],[147,194,199,4],[148,200,201,0],[149,200,202,1],[150,200,203,2],[151,200,204,3],[152,205,206,0],[153,205,207,1],[154,205,208,2],[155,205,209,3],[156,205,210,4],[157,205,211,5],[158,212,213,0],[159,212,214,1],[160,212,215,2],[161,212,216,3],[162,217,218,0],[163,217,219,1],[164,217,220,2],[165,217,221,3],[166,222,223,0],[167,222,224,1],[168,222,225,2],[169,222,226,3],[170,227,228,0],[171,227,229,1],[172,227,230,2],[173,227,231,3],[174,227,232,4],[175,233,234,0],[176,233,235,1],[177,233,236,2],[178,233,237,3],[179,238,239,0],[180,240,241,0],[181,242,243,0],[182,244,245,0],[183,246,247,0],[184,246,248,1],[185,246,249,2],[186,246,250,3],[187,254,255,0],[188,254,256,1],[189,254,257,2],[190,254,258,3],[191,259,260,0],[192,259,261,1],[193,259,262,2],[194,259,263,3],[195,264,265,0],[196,264,266,1],[197,264,267,2],[198,264,268,3],[199,264,269,4],[200,270,271,0],[201,270,272,1],[202,270,273,2],[203,270,274,3],[204,270,275,4],[205,276,277,0],[206,276,278,1],[207,276,279,2],[208,276,280,3],[209,276,281,4],[210,276,282,5],[211,283,284,0],[212,283,285,1],[213,283,286,2],[214,283,287,3],[215,288,289,0],[216,290,291,0],[217,290,292,1],[218,293,294,0],[219,295,296,0],[220,297,298,0],[221,299,300,0],[222,301,302,0],[223,303,304,0],[224,303,305,1],[225,303,306,2],[226,303,307,3],[227,303,308,4],[228,309,310,0],[229,309,311,1],[230,309,312,2],[231,309,313,3],[232,315,316,0],[233,315,317,1],[234,315,318,2],[235,315,319,3],[236,320,321,0],[237,322,323,0],[238,322,324,1],[239,322,325,2],[240,322,326,3],[241,327,328,0],[242,327,329,1],[243,327,330,2],[244,327,331,3],[245,327,332,4],[246,333,334,0],[247,333,335,1],[248,333,336,2],[249,333,337,3],[250,333,338,4],[251,339,340,0],[252,339,341,1],[253,339,342,2],[254,339,343,3],[255,339,344,4],[256,345,346,0],[257,345,347,1],[258,345,348,2],[259,345,349,3],[260,345,350,4],[261,351,352,0],[262,351,353,1],[263,351,354,2],[264,351,355,3],[265,356,357,0],[266,356,358,1],[267,356,359,2],[268,356,360,3],[269,361,362,0],[270,363,364,0],[271,365,366,0],[272,367,368,0],[273,369,370,0],[274,369,371,1],[275,369,372,2],[276,369,373,3],[277,377,378,0],[278,377,379,1],[279,377,380,2],[280,377,381,3],[281,382,383,0],[282,382,384,1],[283,382,385,2],[284,382,386,3],[285,387,388,0],[286,387,389,1],[287,387,390,2],[288,387,391,3],[289,392,393,0],[290,392,394,1],[291,392,395,2],[292,392,396,3],[293,397,398,0],[294,397,399,1],[295,397,400,2],[296,397,401,3],[297,397,402,4],[298,403,404,0],[299,403,405,1],[300,403,406,2],[301,403,407,3],[302,408,409,0],[303,408,410,1],[304,408,411,2],[305,408,412,3],[306,408,413,4],[307,414,415,0],[308,414,416,1],[309,414,417,2],[310,414,418,3],[311,419,420,0],[312,419,421,1],[313,419,422,2],[314,419,423,3],[315,424,425,0],[316,424,426,1],[317,424,427,2],[318,428,429,0],[319,430,431,0],[320,432,433,0],[321,434,435,0],[322,436,437,0],[323,439,440,0],[324,441,442,0],[325,443,444,0],[326,443,445,1],[327,443,446,2],[328,443,447,3],[329,448,449,0],[330,448,450,1],[331,448,451,2],[332,448,452,3],[333,453,454,0],[334,453,455,1],[335,453,456,2],[336,453,457,3],[337,458,459,0],[338,458,460,1],[339,458,461,2],[340,458,462,3],[341,458,463,4],[342,464,465,0],[343,464,466,1],[344,464,467,2],[345,464,468,3],[346,469,470,0],[347,469,471,1],[348,469,472,2],[349,469,473,3],[350,474,475,0],[351,474,476,1],[352,474,477,2],[353,474,478,3],[354,479,480,0],[355,479,481,1],[356,479,482,2],[357,479,483,3],[358,484,485,0],[359,486,487,0],[360,488,489,0],[361,488,490,1],[362,488,491,2],[363,488,492,3],[364,488,493,4],[365,488,494,5],[366,495,496,0],[367,495,497,1],[368,495,498,2],[369,495,499,3],[370,503,504,0],[371,503,505,1],[372,503,506,2],[373,503,507,3],[374,508,509,0],[375,508,510,1],[376,508,511,2],[377,508,512,3],[378,508,513,4],[379,514,515,0],[380,514,516,1],[381,514,517,2],[382,514,518,3],[383,514,519,4],[384,520,521,0],[385,520,522,1],[386,520,523,2],[387,520,524,3],[388,520,525,4],[389,526,527,0],[390,526,528,1],[391,526,529,2],[392,526,530,3],[393,531,532,0],[394,531,533,1],[395,534,535,0],[396,534,536,1],[397,534,537,2],[398,534,538,3],[399,539,540,0],[400,541,542,0],[401,541,543,1],[402,541,544,2],[403,541,545,3],[404,546,547,0],[405,546,548,1],[406,546,549,2],[407,546,550,3],[408,551,552,0],[409,553,554,0],[410,555,556,0],[411,557,558,0],[412,559,560,0],[413,562,563,0],[414,564,565,0],[415,564,566,1],[416,564,567,2],[417,564,568,3],[418,569,570,0],[419,569,571,1],[420,569,572,2],[421,569,573,3],[422,569,574,4],[423,569,575,5],[424,576,577,0],[425,576,578,1],[426,576,579,2],[427,576,580,3],[428,581,582,0],[429,581,583,1],[430,581,584,2],[431,581,585,3],[432,586,587,0],[433,586,588,1],[434,586,589,2],[435,586,590,3],[436,591,592,0],[437,591,593,1],[438,591,594,2],[439,591,595,3],[440,591,596,4],[441,597,598,0],[442,599,600,0],[443,601,602,0],[444,601,603,1],[445,601,604,2],[446,601,605,3],[447,601,606,4],[448,607,608,0],[449,609,610,0],[450,611,612,0],[451,613,614,0],[452,615,616,0],[453,620,621,0],[454,620,622,1],[455,620,623,2],[456,620,624,3],[457,620,625,4],[458,626,627,0],[459,626,628,1],[460,626,629,2],[461,626,630,3],[462,631,632,0],[463,631,633,1],[464,631,634,2],[465,631,635,3],[466,631,636,4],[467,637,638,0],[468,637,639,1],[469,637,640,2],[470,637,641,3],[471,642,643,0],[472,642,644,1],[473,642,645,2],[474,642,646,3],[475,647,648,0],[476,647,649,1],[477,647,650,2],[478,647,651,3],[479,652,653,0],[480,652,654,1],[481,652,655,2],[482,652,656,3],[483,657,658,0],[484,657,659,1],[485,657,660,2],[486,657,661,3],[487,662,663,0],[488,662,664,1],[489,662,665,2],[490,662,666,3],[491,667,668,0],[492,669,670,0],[493,671,672,0],[494,673,674,0],[495,675,676,0],[496,677,678,0],[497,679,680,0],[498,681,682,0],[499,681,683,1],[500,681,684,2],[501,681,685,3],[502,686,687,0],[503,686,688,1],[504,686,689,2],[505,686,690,3],[506,691,692,0],[507,691,693,1],[508,691,694,2],[509,691,695,3],[510,696,697,0],[511,696,698,1],[512,696,699,2],[513,696,700,3],[514,696,701,4],[515,702,703,0],[516,702,704,1],[517,702,705,2],[518,702,706,3],[519,707,708,0],[520,707,709,1],[521,707,710,2],[522,707,711,3],[523,712,713,0],[524,712,714,1],[525,712,715,2],[526,712,716,3],[527,712,717,4],[528,718,719,0],[529,718,720,1],[530,718,721,2],[531,718,722,3],[532,723,724,0],[533,723,725,1],[534,723,726,2],[535,723,727,3],[536,728,729,0],[537,730,731,0],[538,732,733,0],[539,734,735,0],[540,738,739,0],[541,738,740,1],[542,738,741,2],[543,738,742,3],[544,743,744,0],[545,743,745,1],[546,743,746,2],[547,743,747,3],[548,748,749,0],[549,748,750,1],[550,748,751,2],[551,748,752,3],[552,753,754,0],[553,753,755,1],[554,753,756,2],[555,753,757,3],[556,753,758,4],[557,759,760,0],[558,759,761,1],[559,759,762,2],[560,759,763,3],[561,759,764,4],[562,765,766,0],[563,765,767,1],[564,765,768,2],[565,765,769,3],[566,770,771,0],[567,770,772,1],[568,770,773,2],[569,770,774,3],[570,775,776,0],[571,775,777,1],[572,775,778,2],[573,775,779,3],[574,780,781,0],[575,782,783,0],[576,782,784,1],[577,782,785,2],[578,782,786,3],[579,787,788,0],[580,789,790,0],[581,791,792,0],[582,794,795,0],[583,794,796,1],[584,794,797,2],[585,794,798,3],[586,794,799,4],[587,794,800,5],[588,801,802,0],[589,801,803,1],[590,801,804,2],[591,801,805,3],[592,801,806,4],[593,807,808,0],[594,807,809,1],[595,807,810,2],[596,807,811,3],[597,807,812,4],[598,813,814,0],[599,813,815,1],[600,813,816,2],[601,813,817,3],[602,818,819,0],[603,818,820,1],[604,818,821,2],[605,818,822,3],[606,818,823,4],[607,824,825,0],[608,824,826,1],[609,824,827,2],[610,824,828,3],[611,829,830,0],[612,829,831,1],[613,829,832,2],[614,829,833,3],[615,834,835,0],[616,834,836,1],[617,834,837,2],[618,834,838,3],[619,834,839,4],[620,840,841,0],[621,840,842,1],[622,840,843,2],[623,840,844,3],[624,840,845,4],[625,846,847,0],[626,846,848,1],[627,846,849,2],[628,846,850,3],[629,852,853,0]]},\"event_annotations\":{\"headers\":[\"_id\",\"event_fk\",\"annotation_fk\",\"sequence\"],\"rows\":[[1,11,2,1],[2,13,2,1],[3,19,2,1],[4,21,2,1],[5,24,1,1],[6,31,1,1],[7,32,2,1],[8,39,2,1],[9,54,2,1],[10,58,2,1],[11,69,2,1],[12,71,1,1],[13,76,2,1],[14,79,2,1],[15,84,1,1],[16,91,2,1],[17,101,2,1],[18,136,2,1],[19,138,2,1],[20,139,1,1],[21,160,2,1],[22,163,1,1],[23,165,2,1],[24,178,2,1],[25,182,2,1],[26,184,2,1],[27,190,2,1],[28,193,2,1],[29,195,2,1],[30,196,1,1],[31,210,2,1],[32,213,2,1],[33,215,2,1],[34,216,2,1],[35,218,2,1],[36,220,2,1],[37,226,2,1],[38,230,2,1],[39,248,2,1],[40,250,2,1],[41,260,2,1],[42,271,2,1],[43,273,2,1],[44,277,2,1],[45,281,2,1],[46,286,2,1],[47,328,2,1],[48,337,2,1],[49,348,2,1],[50,349,2,1],[51,352,1,1],[52,354,2,1],[53,370,2,1],[54,372,2,1],[55,378,2,1],[56,379,2,1],[57,380,2,1],[58,389,2,1],[59,394,1,1],[60,398,2,1],[61,399,2,1],[62,404,2,1],[63,409,1,1],[64,413,2,1],[65,415,2,1],[66,420,2,1],[67,421,2,1],[68,449,1,1],[69,456,2,1],[70,468,2,1],[71,481,2,1],[72,482,2,1],[73,506,2,1],[74,511,2,1],[75,512,2,1],[76,517,2,1],[77,524,2,1],[78,525,1,1],[79,527,2,1],[80,537,2,1],[81,550,2,1],[82,567,2,1],[83,568,2,1],[84,583,2,1],[85,585,2,1],[86,587,2,1],[87,604,2,1],[88,605,1,1],[89,621,1,1],[90,624,2,1],[91,635,2,1],[92,636,2,1],[93,641,2,1],[94,650,2,1],[95,653,2,1],[96,655,1,1],[97,665,2,1],[98,688,1,1],[99,689,2,1],[100,703,2,1],[101,706,2,1],[102,716,2,1],[103,721,1,1],[104,740,2,1],[105,741,1,1],[106,745,2,1],[107,746,2,1],[108,749,1,1],[109,760,2,1],[110,774,1,1],[111,777,2,1],[112,795,2,1],[113,797,2,1],[114,799,2,1],[115,800,2,1],[116,805,2,1],[117,815,1,1],[118,838,2,1],[119,843,2,1]]},\"event_attachments\":{\"headers\":[\"_id\",\"type\",\"event_fk\",\"filename\",\"directory\",\"url\"],\"rows\":[[1,\"Paper\",7,\"p221.pdf\",\"proceedings/p221.pdf\",\"\"],[2,\"Paper\",8,\"p231.pdf\",\"proceedings/p231.pdf\",\"\"],[3,\"YoutubeVP\",9,\"\",\"\",\"DCPtCNREZjY\"],[4,\"VPreview\",9,\"pn1373.mp4\",\"preview/pn1373.mp4\",\"\"],[5,\"Paper\",9,\"p241.pdf\",\"proceedings/p241.pdf\",\"http://dx.doi.org/10.1145/2702123.2702393\"],[6,\"Paper\",10,\"p251.pdf\",\"proceedings/p251.pdf\",\"\"],[7,\"Paper\",11,\"p255.pdf\",\"proceedings/p255.pdf\",\"\"],[8,\"YoutubeVP\",13,\"\",\"\",\"mNzodpnke2M\"],[9,\"VPreview\",13,\"pn1552.mp4\",\"preview/pn1552.mp4\",\"\"],[10,\"Paper\",13,\"p259.pdf\",\"proceedings/p259.pdf\",\"http://dx.doi.org/10.1145/2702123.2702419\"],[11,\"Paper\",14,\"p269.pdf\",\"proceedings/p269.pdf\",\"\"],[12,\"YoutubeVP\",15,\"\",\"\",\"4NrNckjFsr8\"],[13,\"VPreview\",15,\"pn1684.mp4\",\"preview/pn1684.mp4\",\"\"],[14,\"Paper\",15,\"p279.pdf\",\"proceedings/p279.pdf\",\"http://dx.doi.org/10.1145/2702123.2702446\"],[15,\"YoutubeVP\",16,\"\",\"\",\"cd7FN8ZuTbY\"],[16,\"VPreview\",16,\"pn1886.mp4\",\"preview/pn1886.mp4\",\"\"],[17,\"Paper\",16,\"p289.pdf\",\"proceedings/p289.pdf\",\"http://dx.doi.org/10.1145/2702123.2702476\"],[18,\"YoutubeVP\",18,\"\",\"\",\"q2AfjMdCnoc\"],[19,\"VPreview\",18,\"pn1275.mp4\",\"preview/pn1275.mp4\",\"\"],[20,\"Paper\",18,\"p39.pdf\",\"proceedings/p39.pdf\",\"http://dx.doi.org/10.1145/2702123.2702373\"],[21,\"Paper\",19,\"p43.pdf\",\"proceedings/p43.pdf\",\"\"],[22,\"Paper\",20,\"p47.pdf\",\"proceedings/p47.pdf\",\"\"],[23,\"YoutubeVP\",21,\"\",\"\",\"FmOcNE8Ir6s\"],[24,\"VPreview\",21,\"pn1187.mp4\",\"preview/pn1187.mp4\",\"\"],[25,\"Paper\",21,\"p57.pdf\",\"proceedings/p57.pdf\",\"http://dx.doi.org/10.1145/2702123.2702358\"],[26,\"YoutubeVP\",22,\"\",\"\",\"lfj5ruis5jk\"],[27,\"VPreview\",22,\"pn1966.mp4\",\"preview/pn1966.mp4\",\"\"],[28,\"Paper\",22,\"p67.pdf\",\"proceedings/p67.pdf\",\"http://dx.doi.org/10.1145/2702123.2702497\"],[29,\"YoutubeVP\",24,\"\",\"\",\"XQRJI5BcLMM\"],[30,\"VPreview\",24,\"pn2341.mp4\",\"preview/pn2341.mp4\",\"\"],[31,\"Paper\",24,\"p153.pdf\",\"proceedings/p153.pdf\",\"http://dx.doi.org/10.1145/2702123.2702556\"],[32,\"Paper\",25,\"p163.pdf\",\"proceedings/p163.pdf\",\"\"],[33,\"Paper\",26,\"p173.pdf\",\"proceedings/p173.pdf\",\"\"],[34,\"Paper\",29,\"p183.pdf\",\"proceedings/p183.pdf\",\"\"],[35,\"YoutubeVP\",30,\"\",\"\",\"38sxgD1PK60\"],[36,\"VPreview\",30,\"pn1626.mp4\",\"preview/pn1626.mp4\",\"\"],[37,\"Paper\",30,\"p193.pdf\",\"proceedings/p193.pdf\",\"http://dx.doi.org/10.1145/2702123.2702436\"],[38,\"Paper\",31,\"p207.pdf\",\"proceedings/p207.pdf\",\"\"],[39,\"Paper\",32,\"p197.pdf\",\"proceedings/p197.pdf\",\"\"],[40,\"YoutubeVP\",33,\"\",\"\",\"QZrx0Wn_nLM\"],[41,\"VPreview\",33,\"pn2370.mp4\",\"preview/pn2370.mp4\",\"\"],[42,\"Paper\",33,\"p211.pdf\",\"proceedings/p211.pdf\",\"http://dx.doi.org/10.1145/2702123.2702559\"],[43,\"YoutubeVP\",35,\"\",\"\",\"faxuHmdP3gU\"],[44,\"VPreview\",35,\"pn1573.mp4\",\"preview/pn1573.mp4\",\"\"],[45,\"Paper\",35,\"p77.pdf\",\"proceedings/p77.pdf\",\"http://dx.doi.org/10.1145/2702123.2702423\"],[46,\"Paper\",36,\"p81.pdf\",\"proceedings/p81.pdf\",\"\"],[47,\"Paper\",37,\"p85.pdf\",\"proceedings/p85.pdf\",\"\"],[48,\"Paper\",38,\"p95.pdf\",\"proceedings/p95.pdf\",\"\"],[49,\"Paper\",39,\"p105.pdf\",\"proceedings/p105.pdf\",\"\"],[50,\"YoutubeVP\",43,\"\",\"\",\"lz6-OaCk35w\"],[51,\"VPreview\",43,\"alt140.mp4\",\"preview/alt140.mp4\",\"\"],[52,\"Paper\",43,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2732506\"],[53,\"YoutubeVP\",44,\"\",\"\",\"uZDukdqd0go\"],[54,\"VPreview\",44,\"alt136.mp4\",\"preview/alt136.mp4\",\"\"],[55,\"Paper\",44,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2732504\"],[56,\"YoutubeVP\",45,\"\",\"\",\"YIzJ1Q9e2NA\"],[57,\"VPreview\",45,\"alt149.mp4\",\"preview/alt149.mp4\",\"\"],[58,\"Paper\",45,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2732508\"],[59,\"YoutubeVP\",46,\"\",\"\",\"K3MAv-rdrM0\"],[60,\"VPreview\",46,\"alt153.mp4\",\"preview/alt153.mp4\",\"\"],[61,\"Paper\",46,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2732511\"],[62,\"YoutubeVP\",50,\"\",\"\",\"NN7LSHVFwIg\"],[63,\"VPreview\",50,\"crs128.mp4\",\"preview/crs128.mp4\",\"\"],[64,\"Paper\",50,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2706686\"],[65,\"YoutubeVP\",54,\"\",\"\",\"VZQYn_uh9GM\"],[66,\"VPreview\",54,\"pn2680.mp4\",\"preview/pn2680.mp4\",\"\"],[67,\"Paper\",54,\"p1.pdf\",\"proceedings/p1.pdf\",\"http://dx.doi.org/10.1145/2702123.2702611\"],[68,\"YoutubeVP\",55,\"\",\"\",\"VlQILrifzPs\"],[69,\"VPreview\",55,\"pn1217.mp4\",\"preview/pn1217.mp4\",\"\"],[70,\"Paper\",55,\"p11.pdf\",\"proceedings/p11.pdf\",\"http://dx.doi.org/10.1145/2702123.2702363\"],[71,\"YoutubeVP\",56,\"\",\"\",\"s87lbqdv6gM\"],[72,\"VPreview\",56,\"pn875.mp4\",\"preview/pn875.mp4\",\"\"],[73,\"Paper\",56,\"p15.pdf\",\"proceedings/p15.pdf\",\"http://dx.doi.org/10.1145/2702123.2702290\"],[74,\"YoutubeVP\",57,\"\",\"\",\"FhnSkhxR2uw\"],[75,\"VPreview\",57,\"pn2604.mp4\",\"preview/pn2604.mp4\",\"\"],[76,\"Paper\",57,\"p19.pdf\",\"proceedings/p19.pdf\",\"http://dx.doi.org/10.1145/2702123.2702599\"],[77,\"YoutubeVP\",58,\"\",\"\",\"4L_ulzhhnE0\"],[78,\"VPreview\",58,\"pn2122.mp4\",\"preview/pn2122.mp4\",\"\"],[79,\"Paper\",58,\"p29.pdf\",\"proceedings/p29.pdf\",\"http://dx.doi.org/10.1145/2702123.2702516\"],[80,\"Paper\",60,\"p115.pdf\",\"proceedings/p115.pdf\",\"\"],[81,\"YoutubeVP\",61,\"\",\"\",\"dcM765zR2VY\"],[82,\"VPreview\",61,\"pn153.mp4\",\"preview/pn153.mp4\",\"\"],[83,\"Paper\",61,\"p125.pdf\",\"proceedings/p125.pdf\",\"http://dx.doi.org/10.1145/2702123.2702138\"],[84,\"Paper\",62,\"p135.pdf\",\"proceedings/p135.pdf\",\"\"],[85,\"YoutubeVP\",63,\"\",\"\",\"8ApARSat2wI\"],[86,\"VPreview\",63,\"pn681.mp4\",\"preview/pn681.mp4\",\"\"],[87,\"Paper\",63,\"p145.pdf\",\"proceedings/p145.pdf\",\"http://dx.doi.org/10.1145/2702123.2702256\"],[88,\"Paper\",64,\"p149.pdf\",\"proceedings/p149.pdf\",\"\"],[89,\"Paper\",67,\"p511.pdf\",\"proceedings/p511.pdf\",\"\"],[90,\"Paper\",68,\"p501.pdf\",\"proceedings/p501.pdf\",\"\"],[91,\"Paper\",69,\"p497.pdf\",\"proceedings/p497.pdf\",\"\"],[92,\"Paper\",70,\"p521.pdf\",\"proceedings/p521.pdf\",\"\"],[93,\"YoutubeVP\",71,\"\",\"\",\"oAOt33Q7Skk\"],[94,\"VPreview\",71,\"pn2191.mp4\",\"preview/pn2191.mp4\",\"\"],[95,\"Paper\",71,\"p525.pdf\",\"proceedings/p525.pdf\",\"http://dx.doi.org/10.1145/2702123.2702525\"],[96,\"YoutubeVP\",73,\"\",\"\",\"ZCLNu9IKpZw\"],[97,\"VPreview\",73,\"pn1942.mp4\",\"preview/pn1942.mp4\",\"\"],[98,\"Paper\",73,\"p377.pdf\",\"proceedings/p377.pdf\",\"http://dx.doi.org/10.1145/2702123.2702492\"],[99,\"YoutubeVP\",74,\"\",\"\",\"Sbb1EBbNf0c\"],[100,\"VPreview\",74,\"pn587.mp4\",\"preview/pn587.mp4\",\"\"],[101,\"Paper\",74,\"p387.pdf\",\"proceedings/p387.pdf\",\"http://dx.doi.org/10.1145/2702123.2702236\"],[102,\"YoutubeVP\",75,\"\",\"\",\"xO1m5p3auCI\"],[103,\"VPreview\",75,\"pn1834.mp4\",\"preview/pn1834.mp4\",\"\"],[104,\"Paper\",75,\"p397.pdf\",\"proceedings/p397.pdf\",\"http://dx.doi.org/10.1145/2702123.2702467\"],[105,\"YoutubeVP\",76,\"\",\"\",\"8TOeQoiYVhY\"],[106,\"VPreview\",76,\"pn815.mp4\",\"preview/pn815.mp4\",\"\"],[107,\"Paper\",76,\"p407.pdf\",\"proceedings/p407.pdf\",\"http://dx.doi.org/10.1145/2702123.2702281\"],[108,\"YoutubeVP\",78,\"\",\"\",\"Xl2eqEMKDgg\"],[109,\"VPreview\",78,\"pn112.mp4\",\"preview/pn112.mp4\",\"\"],[110,\"Paper\",78,\"p299.pdf\",\"proceedings/p299.pdf\",\"http://dx.doi.org/10.1145/2702123.2702126\"],[111,\"YoutubeVP\",79,\"\",\"\",\"fsBt6YfkFWI\"],[112,\"VPreview\",79,\"pn1073.mp4\",\"preview/pn1073.mp4\",\"\"],[113,\"Paper\",79,\"p309.pdf\",\"proceedings/p309.pdf\",\"http://dx.doi.org/10.1145/2702123.2702333\"],[114,\"Paper\",80,\"p313.pdf\",\"proceedings/p313.pdf\",\"\"],[115,\"YoutubeVP\",81,\"\",\"\",\"D9lXDyh5U9I\"],[116,\"VPreview\",81,\"pn263.mp4\",\"preview/pn263.mp4\",\"\"],[117,\"Paper\",81,\"p317.pdf\",\"proceedings/p317.pdf\",\"http://dx.doi.org/10.1145/2702123.2702158\"],[118,\"Paper\",82,\"p327.pdf\",\"proceedings/p327.pdf\",\"\"],[119,\"Paper\",84,\"p417.pdf\",\"proceedings/p417.pdf\",\"\"],[120,\"Paper\",85,\"p427.pdf\",\"proceedings/p427.pdf\",\"\"],[121,\"YoutubeVP\",86,\"\",\"\",\"EeXBB0Yx8gA\"],[122,\"VPreview\",86,\"pn2476.mp4\",\"preview/pn2476.mp4\",\"\"],[123,\"Paper\",86,\"p437.pdf\",\"proceedings/p437.pdf\",\"http://dx.doi.org/10.1145/2702123.2702573\"],[124,\"Paper\",87,\"p447.pdf\",\"proceedings/p447.pdf\",\"\"],[125,\"YoutubeVP\",89,\"\",\"\",\"vbAKhW46NcI\"],[126,\"VPreview\",89,\"pn169.mp4\",\"preview/pn169.mp4\",\"\"],[127,\"Paper\",89,\"p457.pdf\",\"proceedings/p457.pdf\",\"http://dx.doi.org/10.1145/2702123.2702142\"],[128,\"Paper\",90,\"p467.pdf\",\"proceedings/p467.pdf\",\"\"],[129,\"Paper\",91,\"p477.pdf\",\"proceedings/p477.pdf\",\"\"],[130,\"Paper\",92,\"p487.pdf\",\"proceedings/p487.pdf\",\"\"],[131,\"YoutubeVP\",94,\"\",\"\",\"ZDyErvFmT-Y\"],[132,\"VPreview\",94,\"pn2048.mp4\",\"preview/pn2048.mp4\",\"\"],[133,\"Paper\",94,\"p337.pdf\",\"proceedings/p337.pdf\",\"http://dx.doi.org/10.1145/2702123.2702509\"],[134,\"YoutubeVP\",95,\"\",\"\",\"CD6_YkXh-8Q\"],[135,\"VPreview\",95,\"pn2620.mp4\",\"preview/pn2620.mp4\",\"\"],[136,\"Paper\",95,\"p347.pdf\",\"proceedings/p347.pdf\",\"http://dx.doi.org/10.1145/2702123.2702603\"],[137,\"Paper\",96,\"p357.pdf\",\"proceedings/p357.pdf\",\"\"],[138,\"YoutubeVP\",97,\"\",\"\",\"G_t9yMaElxw\"],[139,\"VPreview\",97,\"pn1596.mp4\",\"preview/pn1596.mp4\",\"\"],[140,\"Paper\",97,\"p367.pdf\",\"proceedings/p367.pdf\",\"http://dx.doi.org/10.1145/2702123.2702428\"],[141,\"Paper\",99,\"p575.pdf\",\"proceedings/p575.pdf\",\"\"],[142,\"Paper\",100,\"p585.pdf\",\"proceedings/p585.pdf\",\"\"],[143,\"Paper\",101,\"p595.pdf\",\"proceedings/p595.pdf\",\"\"],[144,\"Paper\",102,\"p605.pdf\",\"proceedings/p605.pdf\",\"\"],[145,\"YoutubeVP\",104,\"\",\"\",\"XU1Id4faleg\"],[146,\"VPreview\",104,\"case115.mp4\",\"preview/case115.mp4\",\"\"],[147,\"Paper\",104,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2702955\"],[148,\"Paper\",121,\"p535.pdf\",\"proceedings/p535.pdf\",\"\"],[149,\"YoutubeVP\",122,\"\",\"\",\"AF6WQdyAtaw\"],[150,\"VPreview\",122,\"pn1122.mp4\",\"preview/pn1122.mp4\",\"\"],[151,\"Paper\",122,\"p545.pdf\",\"proceedings/p545.pdf\",\"http://dx.doi.org/10.1145/2702123.2702343\"],[152,\"Paper\",123,\"p555.pdf\",\"proceedings/p555.pdf\",\"\"],[153,\"YoutubeVP\",124,\"\",\"\",\"TXLkqMypces\"],[154,\"VPreview\",124,\"pn1023.mp4\",\"preview/pn1023.mp4\",\"\"],[155,\"Paper\",124,\"p565.pdf\",\"proceedings/p565.pdf\",\"http://dx.doi.org/10.1145/2702123.2702314\"],[156,\"YoutubeVP\",127,\"\",\"\",\"OpHJVqhTmhg\"],[157,\"VPreview\",127,\"alt151.mp4\",\"preview/alt151.mp4\",\"\"],[158,\"Paper\",127,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2732509\"],[159,\"YoutubeVP\",128,\"\",\"\",\"2fu-FNcHMUM\"],[160,\"VPreview\",128,\"alt129.mp4\",\"preview/alt129.mp4\",\"\"],[161,\"Paper\",128,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2732501\"],[162,\"YoutubeVP\",129,\"\",\"\",\"Rj6l7MqyjNA\"],[163,\"VPreview\",129,\"alt100.mp4\",\"preview/alt100.mp4\",\"\"],[164,\"Paper\",129,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2732496\"],[165,\"YoutubeVP\",130,\"\",\"\",\"x6QjToYc-gQ\"],[166,\"VPreview\",130,\"alt154.mp4\",\"preview/alt154.mp4\",\"\"],[167,\"Paper\",130,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2732512\"],[168,\"Paper\",132,\"p709.pdf\",\"proceedings/p709.pdf\",\"\"],[169,\"Paper\",133,\"p713.pdf\",\"proceedings/p713.pdf\",\"\"],[170,\"YoutubeVP\",134,\"\",\"\",\"HT5RNr1RNmU\"],[171,\"VPreview\",134,\"pn930.mp4\",\"preview/pn930.mp4\",\"\"],[172,\"Paper\",134,\"p717.pdf\",\"proceedings/p717.pdf\",\"http://dx.doi.org/10.1145/2702123.2702301\"],[173,\"YoutubeVP\",135,\"\",\"\",\"7i4FVfWdJxg\"],[174,\"VPreview\",135,\"pn420.mp4\",\"preview/pn420.mp4\",\"\"],[175,\"Paper\",135,\"p727.pdf\",\"proceedings/p727.pdf\",\"http://dx.doi.org/10.1145/2702123.2702199\"],[176,\"YoutubeVP\",136,\"\",\"\",\"HEzZLJPyzGE\"],[177,\"VPreview\",136,\"pn1583.mp4\",\"preview/pn1583.mp4\",\"\"],[178,\"Paper\",136,\"p737.pdf\",\"proceedings/p737.pdf\",\"http://dx.doi.org/10.1145/2702123.2702427\"],[179,\"YoutubeVP\",138,\"\",\"\",\"ZFQrQo3ejU0\"],[180,\"VPreview\",138,\"pn1991.mp4\",\"preview/pn1991.mp4\",\"\"],[181,\"Paper\",138,\"p649.pdf\",\"proceedings/p649.pdf\",\"http://dx.doi.org/10.1145/2702123.2702503\"],[182,\"Paper\",139,\"p659.pdf\",\"proceedings/p659.pdf\",\"\"],[183,\"YoutubeVP\",140,\"\",\"\",\"10njaEv-Pi0\"],[184,\"VPreview\",140,\"pn1356.mp4\",\"preview/pn1356.mp4\",\"\"],[185,\"Paper\",140,\"p669.pdf\",\"proceedings/p669.pdf\",\"http://dx.doi.org/10.1145/2702123.2702388\"],[186,\"Paper\",141,\"p679.pdf\",\"proceedings/p679.pdf\",\"\"],[187,\"Paper\",143,\"p747.pdf\",\"proceedings/p747.pdf\",\"\"],[188,\"Paper\",144,\"p757.pdf\",\"proceedings/p757.pdf\",\"\"],[189,\"YoutubeVP\",145,\"\",\"\",\"QnssXRTBE9k\"],[190,\"VPreview\",145,\"pn555.mp4\",\"preview/pn555.mp4\",\"\"],[191,\"Paper\",145,\"p767.pdf\",\"proceedings/p767.pdf\",\"http://dx.doi.org/10.1145/2702123.2702229\"],[192,\"Paper\",146,\"p777.pdf\",\"proceedings/p777.pdf\",\"\"],[193,\"YoutubeVP\",148,\"\",\"\",\"Taa5ADLsToM\"],[194,\"VPreview\",148,\"pn466.mp4\",\"preview/pn466.mp4\",\"\"],[195,\"Paper\",148,\"p787.pdf\",\"proceedings/p787.pdf\",\"http://dx.doi.org/10.1145/2702123.2702210\"],[196,\"YoutubeVP\",149,\"\",\"\",\"ch-6TPqk9Rg\"],[197,\"VPreview\",149,\"pn763.mp4\",\"preview/pn763.mp4\",\"\"],[198,\"Paper\",149,\"p797.pdf\",\"proceedings/p797.pdf\",\"http://dx.doi.org/10.1145/2702123.2702274\"],[199,\"Paper\",150,\"p807.pdf\",\"proceedings/p807.pdf\",\"\"],[200,\"YoutubeVP\",151,\"\",\"\",\"FzuKiP4B1Tg\"],[201,\"VPreview\",151,\"pn895.mp4\",\"preview/pn895.mp4\",\"\"],[202,\"Paper\",151,\"p817.pdf\",\"proceedings/p817.pdf\",\"http://dx.doi.org/10.1145/2702123.2702293\"],[203,\"YoutubeVP\",153,\"\",\"\",\"X34Xp8NY7dM\"],[204,\"VPreview\",153,\"pn1147.mp4\",\"preview/pn1147.mp4\",\"\"],[205,\"Paper\",153,\"p689.pdf\",\"proceedings/p689.pdf\",\"http://dx.doi.org/10.1145/2702123.2702349\"],[206,\"YoutubeVP\",154,\"\",\"\",\"3WrW_7lz31s\"],[207,\"VPreview\",154,\"pn933.mp4\",\"preview/pn933.mp4\",\"\"],[208,\"Paper\",154,\"p699.pdf\",\"proceedings/p699.pdf\",\"http://dx.doi.org/10.1145/2702123.2702303\"],[209,\"Paper\",159,\"p897.pdf\",\"proceedings/p897.pdf\",\"\"],[210,\"Paper\",160,\"p907.pdf\",\"proceedings/p907.pdf\",\"\"],[211,\"Paper\",161,\"p917.pdf\",\"proceedings/p917.pdf\",\"\"],[212,\"YoutubeVP\",163,\"\",\"\",\"OSKJWUukxCs\"],[213,\"VPreview\",163,\"pn564.mp4\",\"preview/pn564.mp4\",\"\"],[214,\"Paper\",163,\"p867.pdf\",\"proceedings/p867.pdf\",\"http://dx.doi.org/10.1145/2702123.2702231\"],[215,\"YoutubeVP\",165,\"\",\"\",\"YXx_5E4CPho\"],[216,\"VPreview\",165,\"pn851.mp4\",\"preview/pn851.mp4\",\"\"],[217,\"Paper\",165,\"p877.pdf\",\"proceedings/p877.pdf\",\"http://dx.doi.org/10.1145/2702123.2702286\"],[218,\"Paper\",166,\"p887.pdf\",\"proceedings/p887.pdf\",\"\"],[219,\"Paper\",176,\"p609.pdf\",\"proceedings/p609.pdf\",\"\"],[220,\"Paper\",177,\"p619.pdf\",\"proceedings/p619.pdf\",\"\"],[221,\"Paper\",178,\"p629.pdf\",\"proceedings/p629.pdf\",\"\"],[222,\"Paper\",179,\"p639.pdf\",\"proceedings/p639.pdf\",\"\"],[223,\"Paper\",181,\"p827.pdf\",\"proceedings/p827.pdf\",\"\"],[224,\"Paper\",182,\"p837.pdf\",\"proceedings/p837.pdf\",\"\"],[225,\"YoutubeVP\",183,\"\",\"\",\"tK57eMmj_3o\"],[226,\"VPreview\",183,\"pn1990.mp4\",\"preview/pn1990.mp4\",\"\"],[227,\"Paper\",183,\"p847.pdf\",\"proceedings/p847.pdf\",\"http://dx.doi.org/10.1145/2702123.2702502\"],[228,\"Paper\",184,\"p857.pdf\",\"proceedings/p857.pdf\",\"\"],[229,\"YoutubeVP\",189,\"\",\"\",\"-XJ0yYhNuI8\"],[230,\"VPreview\",189,\"pn2185.mp4\",\"preview/pn2185.mp4\",\"\"],[231,\"Paper\",189,\"p1135.pdf\",\"proceedings/p1135.pdf\",\"http://dx.doi.org/10.1145/2702123.2702524\"],[232,\"Paper\",190,\"p1145.pdf\",\"proceedings/p1145.pdf\",\"\"],[233,\"Paper\",192,\"p1155.pdf\",\"proceedings/p1155.pdf\",\"\"],[234,\"Paper\",193,\"p1159.pdf\",\"proceedings/p1159.pdf\",\"\"],[235,\"YoutubeVP\",195,\"\",\"\",\"Mt5ZO16FPpo\"],[236,\"VPreview\",195,\"pn2480.mp4\",\"preview/pn2480.mp4\",\"\"],[237,\"Paper\",195,\"p1163.pdf\",\"proceedings/p1163.pdf\",\"http://dx.doi.org/10.1145/2702123.2702575\"],[238,\"YoutubeVP\",196,\"\",\"\",\"tYg_xJdAjls\"],[239,\"VPreview\",196,\"pn481.mp4\",\"preview/pn481.mp4\",\"\"],[240,\"Paper\",196,\"p1173.pdf\",\"proceedings/p1173.pdf\",\"http://dx.doi.org/10.1145/2702123.2702213\"],[241,\"Paper\",197,\"p1183.pdf\",\"proceedings/p1183.pdf\",\"\"],[242,\"Paper\",198,\"p1187.pdf\",\"proceedings/p1187.pdf\",\"\"],[243,\"Paper\",199,\"p1191.pdf\",\"proceedings/p1191.pdf\",\"\"],[244,\"Paper\",203,\"p929.pdf\",\"proceedings/p929.pdf\",\"\"],[245,\"YoutubeVP\",204,\"\",\"\",\"BUemx3lXJjU\"],[246,\"VPreview\",204,\"pn1766.mp4\",\"preview/pn1766.mp4\",\"\"],[247,\"Paper\",204,\"p939.pdf\",\"proceedings/p939.pdf\",\"http://dx.doi.org/10.1145/2702123.2702461\"],[248,\"Paper\",206,\"p949.pdf\",\"proceedings/p949.pdf\",\"\"],[249,\"YoutubeVP\",207,\"\",\"\",\"_nB2AdnlAoc\"],[250,\"VPreview\",207,\"pn1647.mp4\",\"preview/pn1647.mp4\",\"\"],[251,\"Paper\",207,\"p953.pdf\",\"proceedings/p953.pdf\",\"http://dx.doi.org/10.1145/2702123.2702440\"],[252,\"YoutubeVP\",208,\"\",\"\",\"YPq6xdA_vRk\"],[253,\"VPreview\",208,\"pn1129.mp4\",\"preview/pn1129.mp4\",\"\"],[254,\"Paper\",208,\"p957.pdf\",\"proceedings/p957.pdf\",\"http://dx.doi.org/10.1145/2702123.2702345\"],[255,\"Paper\",210,\"p967.pdf\",\"proceedings/p967.pdf\",\"\"],[256,\"Paper\",211,\"p971.pdf\",\"proceedings/p971.pdf\",\"\"],[257,\"Paper\",213,\"p1055.pdf\",\"proceedings/p1055.pdf\",\"\"],[258,\"YoutubeVP\",214,\"\",\"\",\"t098GS9G3xQ\"],[259,\"VPreview\",214,\"pn906.mp4\",\"preview/pn906.mp4\",\"\"],[260,\"Paper\",214,\"p1065.pdf\",\"proceedings/p1065.pdf\",\"http://dx.doi.org/10.1145/2702123.2702296\"],[261,\"Paper\",215,\"p1075.pdf\",\"proceedings/p1075.pdf\",\"\"],[262,\"Paper\",216,\"p1085.pdf\",\"proceedings/p1085.pdf\",\"\"],[263,\"YoutubeVP\",218,\"\",\"\",\"0iK7cwYKLgY\"],[264,\"VPreview\",218,\"pn982.mp4\",\"preview/pn982.mp4\",\"\"],[265,\"Paper\",218,\"p1095.pdf\",\"proceedings/p1095.pdf\",\"http://dx.doi.org/10.1145/2702123.2702309\"],[266,\"YoutubeVP\",219,\"\",\"\",\"5aC6coEAZjA\"],[267,\"VPreview\",219,\"pn833.mp4\",\"preview/pn833.mp4\",\"\"],[268,\"Paper\",219,\"p1105.pdf\",\"proceedings/p1105.pdf\",\"http://dx.doi.org/10.1145/2702123.2702284\"],[269,\"Paper\",220,\"p1115.pdf\",\"proceedings/p1115.pdf\",\"\"],[270,\"YoutubeVP\",221,\"\",\"\",\"M-rM8Quhjac\"],[271,\"VPreview\",221,\"pn569.mp4\",\"preview/pn569.mp4\",\"\"],[272,\"Paper\",221,\"p1125.pdf\",\"proceedings/p1125.pdf\",\"http://dx.doi.org/10.1145/2702123.2702232\"],[273,\"YoutubeVP\",223,\"\",\"\",\"Fr-o3a3XgRs\"],[274,\"VPreview\",223,\"pn1958.mp4\",\"preview/pn1958.mp4\",\"\"],[275,\"Paper\",223,\"p975.pdf\",\"proceedings/p975.pdf\",\"http://dx.doi.org/10.1145/2702123.2702496\"],[276,\"Paper\",224,\"p985.pdf\",\"proceedings/p985.pdf\",\"\"],[277,\"YoutubeVP\",225,\"\",\"\",\"V8mF4nqXbMo\"],[278,\"VPreview\",225,\"pn532.mp4\",\"preview/pn532.mp4\",\"\"],[279,\"Paper\",225,\"p995.pdf\",\"proceedings/p995.pdf\",\"http://dx.doi.org/10.1145/2702123.2702224\"],[280,\"Paper\",226,\"p1005.pdf\",\"proceedings/p1005.pdf\",\"\"],[281,\"YoutubeVP\",229,\"\",\"\",\"88vJlCWp-4k\"],[282,\"VPreview\",229,\"pn1419.mp4\",\"preview/pn1419.mp4\",\"\"],[283,\"Paper\",229,\"p1201.pdf\",\"proceedings/p1201.pdf\",\"http://dx.doi.org/10.1145/2702123.2702398\"],[284,\"Paper\",230,\"p1211.pdf\",\"proceedings/p1211.pdf\",\"\"],[285,\"YoutubeVP\",231,\"\",\"\",\"PvovIEHaHTA\"],[286,\"VPreview\",231,\"pn234.mp4\",\"preview/pn234.mp4\",\"\"],[287,\"Paper\",231,\"p1221.pdf\",\"proceedings/p1221.pdf\",\"http://dx.doi.org/10.1145/2702123.2702149\"],[288,\"YoutubeVP\",232,\"\",\"\",\"-Pen2H2IsAM\"],[289,\"VPreview\",232,\"pn302.mp4\",\"preview/pn302.mp4\",\"\"],[290,\"Paper\",232,\"p1225.pdf\",\"proceedings/p1225.pdf\",\"http://dx.doi.org/10.1145/2702123.2702166\"],[291,\"YoutubeVP\",235,\"\",\"\",\"RlLfrW9PmVo\"],[292,\"VPreview\",235,\"case147.mp4\",\"preview/case147.mp4\",\"\"],[293,\"Paper\",235,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2702969\"],[294,\"YoutubeVP\",237,\"\",\"\",\"pMcj6TVeNDM\"],[295,\"VPreview\",237,\"case183.mp4\",\"preview/case183.mp4\",\"\"],[296,\"Paper\",237,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2702975\"],[297,\"YoutubeVP\",241,\"\",\"\",\"ogC1xa41Ayw\"],[298,\"VPreview\",241,\"crs100.mp4\",\"preview/crs100.mp4\",\"\"],[299,\"Paper\",241,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2706665\"],[300,\"YoutubeVP\",247,\"\",\"\",\"ec-cNlmMPxM\"],[301,\"VPreview\",247,\"pn1390.mp4\",\"preview/pn1390.mp4\",\"\"],[302,\"Paper\",247,\"p1015.pdf\",\"proceedings/p1015.pdf\",\"http://dx.doi.org/10.1145/2702123.2702396\"],[303,\"YoutubeVP\",248,\"\",\"\",\"dLTvezrHLLQ\"],[304,\"VPreview\",248,\"pn919.mp4\",\"preview/pn919.mp4\",\"\"],[305,\"Paper\",248,\"p1025.pdf\",\"proceedings/p1025.pdf\",\"http://dx.doi.org/10.1145/2702123.2702299\"],[306,\"YoutubeVP\",249,\"\",\"\",\"NsPuu5ck0k0\"],[307,\"VPreview\",249,\"pn654.mp4\",\"preview/pn654.mp4\",\"\"],[308,\"Paper\",249,\"p1035.pdf\",\"proceedings/p1035.pdf\",\"http://dx.doi.org/10.1145/2702123.2702250\"],[309,\"YoutubeVP\",250,\"\",\"\",\"4M31Zh7t9eA\"],[310,\"VPreview\",250,\"pn1391.mp4\",\"preview/pn1391.mp4\",\"\"],[311,\"Paper\",250,\"p1045.pdf\",\"proceedings/p1045.pdf\",\"http://dx.doi.org/10.1145/2702123.2702397\"],[312,\"Paper\",260,\"p1419.pdf\",\"proceedings/p1419.pdf\",\"\"],[313,\"Paper\",262,\"p1429.pdf\",\"proceedings/p1429.pdf\",\"\"],[314,\"Paper\",263,\"p1439.pdf\",\"proceedings/p1439.pdf\",\"\"],[315,\"Paper\",265,\"p1267.pdf\",\"proceedings/p1267.pdf\",\"\"],[316,\"YoutubeVP\",266,\"\",\"\",\"DZn0LVZsBUo\"],[317,\"VPreview\",266,\"pn453.mp4\",\"preview/pn453.mp4\",\"\"],[318,\"Paper\",266,\"p1277.pdf\",\"proceedings/p1277.pdf\",\"http://dx.doi.org/10.1145/2702123.2702207\"],[319,\"YoutubeVP\",267,\"\",\"\",\"VoDn8mqukdE\"],[320,\"VPreview\",267,\"pn1620.mp4\",\"preview/pn1620.mp4\",\"\"],[321,\"Paper\",267,\"p1281.pdf\",\"proceedings/p1281.pdf\",\"http://dx.doi.org/10.1145/2702123.2702434\"],[322,\"YoutubeVP\",268,\"\",\"\",\"8U5yLcGBQ0M\"],[323,\"VPreview\",268,\"pn451.mp4\",\"preview/pn451.mp4\",\"\"],[324,\"Paper\",268,\"p1285.pdf\",\"proceedings/p1285.pdf\",\"http://dx.doi.org/10.1145/2702123.2702206\"],[325,\"YoutubeVP\",269,\"\",\"\",\"-4gFYvhkz0Y\"],[326,\"VPreview\",269,\"pn2464.mp4\",\"preview/pn2464.mp4\",\"\"],[327,\"Paper\",269,\"p1295.pdf\",\"proceedings/p1295.pdf\",\"http://dx.doi.org/10.1145/2702123.2702569\"],[328,\"Paper\",271,\"p1345.pdf\",\"proceedings/p1345.pdf\",\"\"],[329,\"YoutubeVP\",272,\"\",\"\",\"8PIfMwpx2Qc\"],[330,\"VPreview\",272,\"pn1840.mp4\",\"preview/pn1840.mp4\",\"\"],[331,\"Paper\",272,\"p1355.pdf\",\"proceedings/p1355.pdf\",\"http://dx.doi.org/10.1145/2702123.2702470\"],[332,\"Paper\",273,\"p1365.pdf\",\"proceedings/p1365.pdf\",\"\"],[333,\"Paper\",274,\"p1375.pdf\",\"proceedings/p1375.pdf\",\"\"],[334,\"Paper\",275,\"p1379.pdf\",\"proceedings/p1379.pdf\",\"\"],[335,\"Paper\",277,\"p1383.pdf\",\"proceedings/p1383.pdf\",\"\"],[336,\"Paper\",278,\"p1393.pdf\",\"proceedings/p1393.pdf\",\"\"],[337,\"YoutubeVP\",279,\"\",\"\",\"5gKjcFwb55c\"],[338,\"VPreview\",279,\"pn480.mp4\",\"preview/pn480.mp4\",\"\"],[339,\"Paper\",279,\"p1403.pdf\",\"proceedings/p1403.pdf\",\"http://dx.doi.org/10.1145/2702123.2702212\"],[340,\"YoutubeVP\",280,\"\",\"\",\"oaIkmS0nP64\"],[341,\"VPreview\",280,\"pn1031.mp4\",\"preview/pn1031.mp4\",\"\"],[342,\"Paper\",280,\"p1407.pdf\",\"proceedings/p1407.pdf\",\"http://dx.doi.org/10.1145/2702123.2702316\"],[343,\"Paper\",281,\"p1411.pdf\",\"proceedings/p1411.pdf\",\"\"],[344,\"Paper\",282,\"p1415.pdf\",\"proceedings/p1415.pdf\",\"\"],[345,\"Paper\",284,\"p1305.pdf\",\"proceedings/p1305.pdf\",\"\"],[346,\"YoutubeVP\",285,\"\",\"\",\"ub6MMwpJyi8\"],[347,\"VPreview\",285,\"pn1188.mp4\",\"preview/pn1188.mp4\",\"\"],[348,\"Paper\",285,\"p1315.pdf\",\"proceedings/p1315.pdf\",\"http://dx.doi.org/10.1145/2702123.2702359\"],[349,\"Paper\",286,\"p1325.pdf\",\"proceedings/p1325.pdf\",\"\"],[350,\"Paper\",287,\"p1335.pdf\",\"proceedings/p1335.pdf\",\"\"],[351,\"YoutubeVP\",296,\"\",\"\",\"ogC1xa41Ayw\"],[352,\"VPreview\",296,\"crs100.mp4\",\"preview/crs100.mp4\",\"\"],[353,\"Paper\",296,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2706665\"],[354,\"YoutubeVP\",304,\"\",\"\",\"BNt1xC9wwLs\"],[355,\"VPreview\",304,\"pn2218.mp4\",\"preview/pn2218.mp4\",\"\"],[356,\"Paper\",304,\"p1229.pdf\",\"proceedings/p1229.pdf\",\"http://dx.doi.org/10.1145/2702123.2702530\"],[357,\"YoutubeVP\",305,\"\",\"\",\"_RbI_FxreH4\"],[358,\"VPreview\",305,\"pn762.mp4\",\"preview/pn762.mp4\",\"\"],[359,\"Paper\",305,\"p1233.pdf\",\"proceedings/p1233.pdf\",\"http://dx.doi.org/10.1145/2702123.2702273\"],[360,\"YoutubeVP\",306,\"\",\"\",\"7Dkbfv_JQD0\"],[361,\"VPreview\",306,\"pn546.mp4\",\"preview/pn546.mp4\",\"\"],[362,\"Paper\",306,\"p1237.pdf\",\"proceedings/p1237.pdf\",\"http://dx.doi.org/10.1145/2702123.2702226\"],[363,\"YoutubeVP\",307,\"\",\"\",\"u4js7V0-Uq0\"],[364,\"VPreview\",307,\"pn488.mp4\",\"preview/pn488.mp4\",\"\"],[365,\"Paper\",307,\"p1247.pdf\",\"proceedings/p1247.pdf\",\"http://dx.doi.org/10.1145/2702123.2702215\"],[366,\"YoutubeVP\",308,\"\",\"\",\"Ytv32TfuLyQ\"],[367,\"VPreview\",308,\"pn643.mp4\",\"preview/pn643.mp4\",\"\"],[368,\"Paper\",308,\"p1257.pdf\",\"proceedings/p1257.pdf\",\"http://dx.doi.org/10.1145/2702123.2702247\"],[369,\"YoutubeVP\",310,\"\",\"\",\"zDJwOdR8d3Q\"],[370,\"VPreview\",310,\"pn1717.mp4\",\"preview/pn1717.mp4\",\"\"],[371,\"Paper\",310,\"p1449.pdf\",\"proceedings/p1449.pdf\",\"http://dx.doi.org/10.1145/2702123.2702452\"],[372,\"YoutubeVP\",311,\"\",\"\",\"ddEB5Ck_16A\"],[373,\"VPreview\",311,\"pn1606.mp4\",\"preview/pn1606.mp4\",\"\"],[374,\"Paper\",311,\"p1459.pdf\",\"proceedings/p1459.pdf\",\"http://dx.doi.org/10.1145/2702123.2702431\"],[375,\"YoutubeVP\",312,\"\",\"\",\"GKCrrdnIVvM\"],[376,\"VPreview\",312,\"pn2637.mp4\",\"preview/pn2637.mp4\",\"\"],[377,\"Paper\",312,\"p1469.pdf\",\"proceedings/p1469.pdf\",\"http://dx.doi.org/10.1145/2702123.2702608\"],[378,\"YoutubeVP\",313,\"\",\"\",\"CKwwwIh5y_I\"],[379,\"VPreview\",313,\"pn1580.mp4\",\"preview/pn1580.mp4\",\"\"],[380,\"Paper\",313,\"p1479.pdf\",\"proceedings/p1479.pdf\",\"http://dx.doi.org/10.1145/2702123.2702426\"],[381,\"YoutubeVP\",316,\"\",\"\",\"RbXAxghid0w\"],[382,\"VPreview\",316,\"case128.mp4\",\"preview/case128.mp4\",\"\"],[383,\"Paper\",316,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2702959\"],[384,\"Paper\",324,\"p1573.pdf\",\"proceedings/p1573.pdf\",\"\"],[385,\"Paper\",325,\"p1583.pdf\",\"proceedings/p1583.pdf\",\"\"],[386,\"Paper\",326,\"p1593.pdf\",\"proceedings/p1593.pdf\",\"\"],[387,\"YoutubeVP\",328,\"\",\"\",\"x02Rq7_0Lhg\"],[388,\"VPreview\",328,\"pn1086.mp4\",\"preview/pn1086.mp4\",\"\"],[389,\"Paper\",328,\"p1489.pdf\",\"proceedings/p1489.pdf\",\"http://dx.doi.org/10.1145/2702123.2702336\"],[390,\"YoutubeVP\",329,\"\",\"\",\"IAkKTGIkPiU\"],[391,\"VPreview\",329,\"pn1577.mp4\",\"preview/pn1577.mp4\",\"\"],[392,\"Paper\",329,\"p1499.pdf\",\"proceedings/p1499.pdf\",\"http://dx.doi.org/10.1145/2702123.2702425\"],[393,\"YoutubeVP\",330,\"\",\"\",\"pStLrlkLZhE\"],[394,\"VPreview\",330,\"pn2102.mp4\",\"preview/pn2102.mp4\",\"\"],[395,\"Paper\",330,\"p1509.pdf\",\"proceedings/p1509.pdf\",\"http://dx.doi.org/10.1145/2702123.2702513\"],[396,\"Paper\",331,\"p1519.pdf\",\"proceedings/p1519.pdf\",\"\"],[397,\"YoutubeVP\",332,\"\",\"\",\"6d8AExgELPo\"],[398,\"VPreview\",332,\"pn548.mp4\",\"preview/pn548.mp4\",\"\"],[399,\"Paper\",332,\"p1523.pdf\",\"proceedings/p1523.pdf\",\"http://dx.doi.org/10.1145/2702123.2702227\"],[400,\"YoutubeVP\",334,\"\",\"\",\"haCclIai86w\"],[401,\"VPreview\",334,\"pn2313.mp4\",\"preview/pn2313.mp4\",\"\"],[402,\"Paper\",334,\"p1603.pdf\",\"proceedings/p1603.pdf\",\"http://dx.doi.org/10.1145/2702123.2702548\"],[403,\"Paper\",335,\"p1613.pdf\",\"proceedings/p1613.pdf\",\"\"],[404,\"Paper\",336,\"p1617.pdf\",\"proceedings/p1617.pdf\",\"\"],[405,\"Paper\",337,\"p1621.pdf\",\"proceedings/p1621.pdf\",\"\"],[406,\"Paper\",338,\"p1631.pdf\",\"proceedings/p1631.pdf\",\"\"],[407,\"YoutubeVP\",340,\"\",\"\",\"ngA0UmIJIro\"],[408,\"VPreview\",340,\"pn2244.mp4\",\"preview/pn2244.mp4\",\"\"],[409,\"Paper\",340,\"p1641.pdf\",\"proceedings/p1641.pdf\",\"http://dx.doi.org/10.1145/2702123.2702535\"],[410,\"Paper\",341,\"p1645.pdf\",\"proceedings/p1645.pdf\",\"\"],[411,\"Paper\",342,\"p1649.pdf\",\"proceedings/p1649.pdf\",\"\"],[412,\"YoutubeVP\",343,\"\",\"\",\"m9-vTvfRil4\"],[413,\"VPreview\",343,\"pn2478.mp4\",\"preview/pn2478.mp4\",\"\"],[414,\"Paper\",343,\"p1659.pdf\",\"proceedings/p1659.pdf\",\"http://dx.doi.org/10.1145/2702123.2702574\"],[415,\"Paper\",344,\"p1669.pdf\",\"proceedings/p1669.pdf\",\"\"],[416,\"YoutubeVP\",346,\"\",\"\",\"e2SDLVNG8Jc\"],[417,\"VPreview\",346,\"pn382.mp4\",\"preview/pn382.mp4\",\"\"],[418,\"Paper\",346,\"p1535.pdf\",\"proceedings/p1535.pdf\",\"http://dx.doi.org/10.1145/2702123.2702186\"],[419,\"YoutubeVP\",347,\"\",\"\",\"GhFLKsy5uqM\"],[420,\"VPreview\",347,\"pn2492.mp4\",\"preview/pn2492.mp4\",\"\"],[421,\"Paper\",347,\"p1545.pdf\",\"proceedings/p1545.pdf\",\"http://dx.doi.org/10.1145/2702123.2702580\"],[422,\"YoutubeVP\",348,\"\",\"\",\"WX8SM28bfnk\"],[423,\"VPreview\",348,\"pn936.mp4\",\"preview/pn936.mp4\",\"\"],[424,\"Paper\",348,\"p1555.pdf\",\"proceedings/p1555.pdf\",\"http://dx.doi.org/10.1145/2702123.2702304\"],[425,\"YoutubeVP\",349,\"\",\"\",\"oeAGe5lEewM\"],[426,\"VPreview\",349,\"pn464.mp4\",\"preview/pn464.mp4\",\"\"],[427,\"Paper\",349,\"p1565.pdf\",\"proceedings/p1565.pdf\",\"http://dx.doi.org/10.1145/2702123.2702209\"],[428,\"Paper\",350,\"p1569.pdf\",\"proceedings/p1569.pdf\",\"\"],[429,\"YoutubeVP\",352,\"\",\"\",\"WWOUI6CTEIE\"],[430,\"VPreview\",352,\"pn1528.mp4\",\"preview/pn1528.mp4\",\"\"],[431,\"Paper\",352,\"p1749.pdf\",\"proceedings/p1749.pdf\",\"http://dx.doi.org/10.1145/2702123.2702412\"],[432,\"Paper\",353,\"p1759.pdf\",\"proceedings/p1759.pdf\",\"\"],[433,\"Paper\",354,\"p1769.pdf\",\"proceedings/p1769.pdf\",\"\"],[434,\"YoutubeVP\",357,\"\",\"\",\"yjddOjLrZ5s\"],[435,\"VPreview\",357,\"pn1828.mp4\",\"preview/pn1828.mp4\",\"\"],[436,\"Paper\",357,\"p1719.pdf\",\"proceedings/p1719.pdf\",\"http://dx.doi.org/10.1145/2702123.2702465\"],[437,\"YoutubeVP\",358,\"\",\"\",\"oHcVndXQt5o\"],[438,\"VPreview\",358,\"pn1258.mp4\",\"preview/pn1258.mp4\",\"\"],[439,\"Paper\",358,\"p1729.pdf\",\"proceedings/p1729.pdf\",\"http://dx.doi.org/10.1145/2702123.2702369\"],[440,\"YoutubeVP\",359,\"\",\"\",\"Hxjz3PqcvdE\"],[441,\"VPreview\",359,\"pn2536.mp4\",\"preview/pn2536.mp4\",\"\"],[442,\"Paper\",359,\"p1739.pdf\",\"proceedings/p1739.pdf\",\"http://dx.doi.org/10.1145/2702123.2702584\"],[443,\"YoutubeVP\",366,\"\",\"\",\"3_oqADvaBfc\"],[444,\"VPreview\",366,\"crs109.mp4\",\"preview/crs109.mp4\",\"\"],[445,\"Paper\",366,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2706673\"],[446,\"Paper\",370,\"p1679.pdf\",\"proceedings/p1679.pdf\",\"\"],[447,\"YoutubeVP\",371,\"\",\"\",\"cMu_Yg1H2gY\"],[448,\"VPreview\",371,\"pn1722.mp4\",\"preview/pn1722.mp4\",\"\"],[449,\"Paper\",371,\"p1689.pdf\",\"proceedings/p1689.pdf\",\"http://dx.doi.org/10.1145/2702123.2702453\"],[450,\"Paper\",372,\"p1699.pdf\",\"proceedings/p1699.pdf\",\"\"],[451,\"Paper\",373,\"p1709.pdf\",\"proceedings/p1709.pdf\",\"\"],[452,\"YoutubeVP\",378,\"\",\"\",\"2_U4oaZ850I\"],[453,\"VPreview\",378,\"pn2494.mp4\",\"preview/pn2494.mp4\",\"\"],[454,\"Paper\",378,\"p1779.pdf\",\"proceedings/p1779.pdf\",\"http://dx.doi.org/10.1145/2702123.2702581\"],[455,\"Paper\",379,\"p1789.pdf\",\"proceedings/p1789.pdf\",\"\"],[456,\"YoutubeVP\",380,\"\",\"\",\"Sn2R8ElOxoo\"],[457,\"VPreview\",380,\"pn545.mp4\",\"preview/pn545.mp4\",\"\"],[458,\"Paper\",380,\"p1799.pdf\",\"proceedings/p1799.pdf\",\"http://dx.doi.org/10.1145/2702123.2702225\"],[459,\"Paper\",381,\"p1807.pdf\",\"proceedings/p1807.pdf\",\"\"],[460,\"YoutubeVP\",383,\"\",\"\",\"kFFmUn0mKQc\"],[461,\"VPreview\",383,\"pn611.mp4\",\"preview/pn611.mp4\",\"\"],[462,\"Paper\",383,\"p2003.pdf\",\"proceedings/p2003.pdf\",\"http://dx.doi.org/10.1145/2702123.2702243\"],[463,\"Paper\",384,\"p2013.pdf\",\"proceedings/p2013.pdf\",\"\"],[464,\"YoutubeVP\",385,\"\",\"\",\"u6HVwOCq3as\"],[465,\"VPreview\",385,\"pn1856.mp4\",\"preview/pn1856.mp4\",\"\"],[466,\"Paper\",385,\"p2023.pdf\",\"proceedings/p2023.pdf\",\"http://dx.doi.org/10.1145/2702123.2702472\"],[467,\"YoutubeVP\",386,\"\",\"\",\"qn0CVhy8bE8\"],[468,\"VPreview\",386,\"pn1010.mp4\",\"preview/pn1010.mp4\",\"\"],[469,\"Paper\",386,\"p2033.pdf\",\"proceedings/p2033.pdf\",\"http://dx.doi.org/10.1145/2702123.2702311\"],[470,\"YoutubeVP\",388,\"\",\"\",\"Cw5AqSmHkMk\"],[471,\"VPreview\",388,\"pn859.mp4\",\"preview/pn859.mp4\",\"\"],[472,\"Paper\",388,\"p2043.pdf\",\"proceedings/p2043.pdf\",\"http://dx.doi.org/10.1145/2702123.2702288\"],[473,\"YoutubeVP\",389,\"\",\"\",\"54qBUH0ktxU\"],[474,\"VPreview\",389,\"pn1195.mp4\",\"preview/pn1195.mp4\",\"\"],[475,\"Paper\",389,\"p2053.pdf\",\"proceedings/p2053.pdf\",\"http://dx.doi.org/10.1145/2702123.2702361\"],[476,\"YoutubeVP\",390,\"\",\"\",\"HFmJRbaML_E\"],[477,\"VPreview\",390,\"pn507.mp4\",\"preview/pn507.mp4\",\"\"],[478,\"Paper\",390,\"p2063.pdf\",\"proceedings/p2063.pdf\",\"http://dx.doi.org/10.1145/2702123.2702219\"],[479,\"YoutubeVP\",391,\"\",\"\",\"HgiwXWmU-u8\"],[480,\"VPreview\",391,\"pn2050.mp4\",\"preview/pn2050.mp4\",\"\"],[481,\"Paper\",391,\"p2073.pdf\",\"proceedings/p2073.pdf\",\"http://dx.doi.org/10.1145/2702123.2702510\"],[482,\"Paper\",393,\"p1895.pdf\",\"proceedings/p1895.pdf\",\"\"],[483,\"Paper\",394,\"p1905.pdf\",\"proceedings/p1905.pdf\",\"\"],[484,\"Paper\",396,\"p1915.pdf\",\"proceedings/p1915.pdf\",\"\"],[485,\"YoutubeVP\",398,\"\",\"\",\"TIDoc1nkbSo\"],[486,\"VPreview\",398,\"pn2629.mp4\",\"preview/pn2629.mp4\",\"\"],[487,\"Paper\",398,\"p1817.pdf\",\"proceedings/p1817.pdf\",\"http://dx.doi.org/10.1145/2702123.2702607\"],[488,\"YoutubeVP\",399,\"\",\"\",\"1dKlMZrM_sw\"],[489,\"VPreview\",399,\"pn922.mp4\",\"preview/pn922.mp4\",\"\"],[490,\"Paper\",399,\"p1827.pdf\",\"proceedings/p1827.pdf\",\"http://dx.doi.org/10.1145/2702123.2702300\"],[491,\"Paper\",400,\"p1837.pdf\",\"proceedings/p1837.pdf\",\"\"],[492,\"YoutubeVP\",401,\"\",\"\",\"kGpnxgDT2M4\"],[493,\"VPreview\",401,\"pn2495.mp4\",\"preview/pn2495.mp4\",\"\"],[494,\"Paper\",401,\"p1847.pdf\",\"proceedings/p1847.pdf\",\"http://dx.doi.org/10.1145/2702123.2702582\"],[495,\"YoutubeVP\",402,\"\",\"\",\"x3RcAKr_z-s\"],[496,\"VPreview\",402,\"pn1979.mp4\",\"preview/pn1979.mp4\",\"\"],[497,\"Paper\",402,\"p1851.pdf\",\"proceedings/p1851.pdf\",\"http://dx.doi.org/10.1145/2702123.2702500\"],[498,\"Paper\",404,\"p1925.pdf\",\"proceedings/p1925.pdf\",\"\"],[499,\"YoutubeVP\",405,\"\",\"\",\"aYHzG9uXQ6k\"],[500,\"VPreview\",405,\"pn1539.mp4\",\"preview/pn1539.mp4\",\"\"],[501,\"Paper\",405,\"p1935.pdf\",\"proceedings/p1935.pdf\",\"http://dx.doi.org/10.1145/2702123.2702416\"],[502,\"Paper\",406,\"p1945.pdf\",\"proceedings/p1945.pdf\",\"\"],[503,\"YoutubeVP\",407,\"\",\"\",\"U_Mwo1VNiFI\"],[504,\"VPreview\",407,\"pn239.mp4\",\"preview/pn239.mp4\",\"\"],[505,\"Paper\",407,\"p1955.pdf\",\"proceedings/p1955.pdf\",\"http://dx.doi.org/10.1145/2702123.2702151\"],[506,\"YoutubeVP\",409,\"\",\"\",\"9PNvu0J4BDk\"],[507,\"VPreview\",409,\"pn849.mp4\",\"preview/pn849.mp4\",\"\"],[508,\"Paper\",409,\"p1965.pdf\",\"proceedings/p1965.pdf\",\"http://dx.doi.org/10.1145/2702123.2702285\"],[509,\"Paper\",410,\"p1975.pdf\",\"proceedings/p1975.pdf\",\"\"],[510,\"Paper\",411,\"p1985.pdf\",\"proceedings/p1985.pdf\",\"\"],[511,\"Paper\",412,\"p1989.pdf\",\"proceedings/p1989.pdf\",\"\"],[512,\"YoutubeVP\",413,\"\",\"\",\"_99FLD8xxnM\"],[513,\"VPreview\",413,\"pn2212.mp4\",\"preview/pn2212.mp4\",\"\"],[514,\"Paper\",413,\"p1993.pdf\",\"proceedings/p1993.pdf\",\"http://dx.doi.org/10.1145/2702123.2702528\"],[515,\"Paper\",415,\"p1855.pdf\",\"proceedings/p1855.pdf\",\"\"],[516,\"YoutubeVP\",416,\"\",\"\",\"TwXm9oS4CgY\"],[517,\"VPreview\",416,\"pn2126.mp4\",\"preview/pn2126.mp4\",\"\"],[518,\"Paper\",416,\"p1865.pdf\",\"proceedings/p1865.pdf\",\"http://dx.doi.org/10.1145/2702123.2702517\"],[519,\"Paper\",417,\"p1875.pdf\",\"proceedings/p1875.pdf\",\"\"],[520,\"Paper\",418,\"p1885.pdf\",\"proceedings/p1885.pdf\",\"\"],[521,\"Paper\",420,\"p2083.pdf\",\"proceedings/p2083.pdf\",\"\"],[522,\"Paper\",421,\"p2093.pdf\",\"proceedings/p2093.pdf\",\"\"],[523,\"Paper\",422,\"p2103.pdf\",\"proceedings/p2103.pdf\",\"\"],[524,\"Paper\",423,\"p2113.pdf\",\"proceedings/p2113.pdf\",\"\"],[525,\"YoutubeVP\",433,\"\",\"\",\"3_oqADvaBfc\"],[526,\"VPreview\",433,\"crs109.mp4\",\"preview/crs109.mp4\",\"\"],[527,\"Paper\",433,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2706673\"],[528,\"Paper\",444,\"p2353.pdf\",\"proceedings/p2353.pdf\",\"\"],[529,\"YoutubeVP\",446,\"\",\"\",\"25uPK2POLwc\"],[530,\"VPreview\",446,\"pn1559.mp4\",\"preview/pn1559.mp4\",\"\"],[531,\"Paper\",446,\"p2363.pdf\",\"proceedings/p2363.pdf\",\"http://dx.doi.org/10.1145/2702123.2702421\"],[532,\"Paper\",447,\"p2373.pdf\",\"proceedings/p2373.pdf\",\"\"],[533,\"YoutubeVP\",449,\"\",\"\",\"C2d1pB1qlvA\"],[534,\"VPreview\",449,\"pn1533.mp4\",\"preview/pn1533.mp4\",\"\"],[535,\"Paper\",449,\"p2161.pdf\",\"proceedings/p2161.pdf\",\"http://dx.doi.org/10.1145/2702123.2702414\"],[536,\"YoutubeVP\",450,\"\",\"\",\"1uv07nd5iD0\"],[537,\"VPreview\",450,\"pn783.mp4\",\"preview/pn783.mp4\",\"\"],[538,\"Paper\",450,\"p2171.pdf\",\"proceedings/p2171.pdf\",\"http://dx.doi.org/10.1145/2702123.2702277\"],[539,\"YoutubeVP\",451,\"\",\"\",\"XobWS3ccxWg\"],[540,\"VPreview\",451,\"pn1054.mp4\",\"preview/pn1054.mp4\",\"\"],[541,\"Paper\",451,\"p2181.pdf\",\"proceedings/p2181.pdf\",\"http://dx.doi.org/10.1145/2702123.2702326\"],[542,\"YoutubeVP\",452,\"\",\"\",\"wUgFwCqH5eo\"],[543,\"VPreview\",452,\"pn312.mp4\",\"preview/pn312.mp4\",\"\"],[544,\"Paper\",452,\"p2191.pdf\",\"proceedings/p2191.pdf\",\"http://dx.doi.org/10.1145/2702123.2702169\"],[545,\"Paper\",454,\"p2275.pdf\",\"proceedings/p2275.pdf\",\"\"],[546,\"Paper\",455,\"p2285.pdf\",\"proceedings/p2285.pdf\",\"\"],[547,\"YoutubeVP\",456,\"\",\"\",\"j1LFJeMkM0I\"],[548,\"VPreview\",456,\"pn1689.mp4\",\"preview/pn1689.mp4\",\"\"],[549,\"Paper\",456,\"p2295.pdf\",\"proceedings/p2295.pdf\",\"http://dx.doi.org/10.1145/2702123.2702449\"],[550,\"Paper\",457,\"p2305.pdf\",\"proceedings/p2305.pdf\",\"\"],[551,\"YoutubeVP\",459,\"\",\"\",\"MgaEPkIYQa8\"],[552,\"VPreview\",459,\"pn602.mp4\",\"preview/pn602.mp4\",\"\"],[553,\"Paper\",459,\"p2315.pdf\",\"proceedings/p2315.pdf\",\"http://dx.doi.org/10.1145/2702123.2702241\"],[554,\"YoutubeVP\",460,\"\",\"\",\"hssYkAKIZpE\"],[555,\"VPreview\",460,\"pn1743.mp4\",\"preview/pn1743.mp4\",\"\"],[556,\"Paper\",460,\"p2325.pdf\",\"proceedings/p2325.pdf\",\"http://dx.doi.org/10.1145/2702123.2702457\"],[557,\"Paper\",461,\"p2335.pdf\",\"proceedings/p2335.pdf\",\"\"],[558,\"Paper\",462,\"p2339.pdf\",\"proceedings/p2339.pdf\",\"\"],[559,\"YoutubeVP\",463,\"\",\"\",\"M2HGE3Se3t4\"],[560,\"VPreview\",463,\"pn1221.mp4\",\"preview/pn1221.mp4\",\"\"],[561,\"Paper\",463,\"p2343.pdf\",\"proceedings/p2343.pdf\",\"http://dx.doi.org/10.1145/2702123.2702365\"],[562,\"Paper\",465,\"p2201.pdf\",\"proceedings/p2201.pdf\",\"\"],[563,\"Paper\",466,\"p2211.pdf\",\"proceedings/p2211.pdf\",\"\"],[564,\"Paper\",467,\"p2221.pdf\",\"proceedings/p2221.pdf\",\"\"],[565,\"Paper\",468,\"p2231.pdf\",\"proceedings/p2231.pdf\",\"\"],[566,\"Paper\",470,\"p2407.pdf\",\"proceedings/p2407.pdf\",\"\"],[567,\"YoutubeVP\",471,\"\",\"\",\"YPXfkwJo4Ns\"],[568,\"VPreview\",471,\"pn2483.mp4\",\"preview/pn2483.mp4\",\"\"],[569,\"Paper\",471,\"p2417.pdf\",\"proceedings/p2417.pdf\",\"http://dx.doi.org/10.1145/2702123.2702577\"],[570,\"YoutubeVP\",472,\"\",\"\",\"_E7vx0BCRiA\"],[571,\"VPreview\",472,\"pn1296.mp4\",\"preview/pn1296.mp4\",\"\"],[572,\"Paper\",472,\"p2427.pdf\",\"proceedings/p2427.pdf\",\"http://dx.doi.org/10.1145/2702123.2702377\"],[573,\"YoutubeVP\",473,\"\",\"\",\"3evfboFgZ5M\"],[574,\"VPreview\",473,\"pn1727.mp4\",\"preview/pn1727.mp4\",\"\"],[575,\"Paper\",473,\"p2437.pdf\",\"proceedings/p2437.pdf\",\"http://dx.doi.org/10.1145/2702123.2702455\"],[576,\"YoutubeVP\",475,\"\",\"\",\"_Y8MVfoiFQw\"],[577,\"VPreview\",475,\"alt142.mp4\",\"preview/alt142.mp4\",\"\"],[578,\"Paper\",475,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2732507\"],[579,\"Paper\",480,\"p2235.pdf\",\"proceedings/p2235.pdf\",\"\"],[580,\"YoutubeVP\",481,\"\",\"\",\"dKAN_71aorY\"],[581,\"VPreview\",481,\"pn448.mp4\",\"preview/pn448.mp4\",\"\"],[582,\"Paper\",481,\"p2245.pdf\",\"proceedings/p2245.pdf\",\"http://dx.doi.org/10.1145/2702123.2702204\"],[583,\"YoutubeVP\",482,\"\",\"\",\"k4CFGMBvhBQ\"],[584,\"VPreview\",482,\"pn605.mp4\",\"preview/pn605.mp4\",\"\"],[585,\"Paper\",482,\"p2255.pdf\",\"proceedings/p2255.pdf\",\"http://dx.doi.org/10.1145/2702123.2702242\"],[586,\"Paper\",483,\"p2265.pdf\",\"proceedings/p2265.pdf\",\"\"],[587,\"YoutubeVP\",489,\"\",\"\",\"02mSH2lh1lg\"],[588,\"VPreview\",489,\"pn954.mp4\",\"preview/pn954.mp4\",\"\"],[589,\"Paper\",489,\"p2125.pdf\",\"proceedings/p2125.pdf\",\"http://dx.doi.org/10.1145/2702123.2702305\"],[590,\"YoutubeVP\",490,\"\",\"\",\"y8Ub3u2IhsA\"],[591,\"VPreview\",490,\"pn1709.mp4\",\"preview/pn1709.mp4\",\"\"],[592,\"Paper\",490,\"p2135.pdf\",\"proceedings/p2135.pdf\",\"http://dx.doi.org/10.1145/2702123.2702450\"],[593,\"YoutubeVP\",491,\"\",\"\",\"UcDSrjqJ0VU\"],[594,\"VPreview\",491,\"pn273.mp4\",\"preview/pn273.mp4\",\"\"],[595,\"Paper\",491,\"p2139.pdf\",\"proceedings/p2139.pdf\",\"http://dx.doi.org/10.1145/2702123.2702161\"],[596,\"YoutubeVP\",492,\"\",\"\",\"_PESkwbCwgc\"],[597,\"VPreview\",492,\"pn1323.mp4\",\"preview/pn1323.mp4\",\"\"],[598,\"Paper\",492,\"p2143.pdf\",\"proceedings/p2143.pdf\",\"http://dx.doi.org/10.1145/2702123.2702382\"],[599,\"Paper\",493,\"p2153.pdf\",\"proceedings/p2153.pdf\",\"\"],[600,\"YoutubeVP\",494,\"\",\"\",\"UhqYIMG6nWE\"],[601,\"VPreview\",494,\"pn665.mp4\",\"preview/pn665.mp4\",\"\"],[602,\"Paper\",494,\"p2157.pdf\",\"proceedings/p2157.pdf\",\"http://dx.doi.org/10.1145/2702123.2702253\"],[603,\"YoutubeVP\",496,\"\",\"\",\"TCU1Ifr5VUc\"],[604,\"VPreview\",496,\"pn271.mp4\",\"preview/pn271.mp4\",\"\"],[605,\"Paper\",496,\"p2383.pdf\",\"proceedings/p2383.pdf\",\"http://dx.doi.org/10.1145/2702123.2702160\"],[606,\"YoutubeVP\",497,\"\",\"\",\"EcFFP2bQSW0\"],[607,\"VPreview\",497,\"pn1688.mp4\",\"preview/pn1688.mp4\",\"\"],[608,\"Paper\",497,\"p2393.pdf\",\"proceedings/p2393.pdf\",\"http://dx.doi.org/10.1145/2702123.2702448\"],[609,\"YoutubeVP\",498,\"\",\"\",\"mh2QnFopvqw\"],[610,\"VPreview\",498,\"pn2196.mp4\",\"preview/pn2196.mp4\",\"\"],[611,\"Paper\",498,\"p2397.pdf\",\"proceedings/p2397.pdf\",\"http://dx.doi.org/10.1145/2702123.2702526\"],[612,\"Paper\",504,\"p2643.pdf\",\"proceedings/p2643.pdf\",\"\"],[613,\"Paper\",505,\"p2653.pdf\",\"proceedings/p2653.pdf\",\"\"],[614,\"Paper\",506,\"p2663.pdf\",\"proceedings/p2663.pdf\",\"\"],[615,\"YoutubeVP\",507,\"\",\"\",\"t12gXUzlCJU\"],[616,\"VPreview\",507,\"pn2412.mp4\",\"preview/pn2412.mp4\",\"\"],[617,\"Paper\",507,\"p2673.pdf\",\"proceedings/p2673.pdf\",\"http://dx.doi.org/10.1145/2702123.2702562\"],[618,\"YoutubeVP\",509,\"\",\"\",\"aesPApLe8YI\"],[619,\"VPreview\",509,\"pn697.mp4\",\"preview/pn697.mp4\",\"\"],[620,\"Paper\",509,\"p2683.pdf\",\"proceedings/p2683.pdf\",\"http://dx.doi.org/10.1145/2702123.2702262\"],[621,\"YoutubeVP\",510,\"\",\"\",\"IiWG3u1p3-s\"],[622,\"VPreview\",510,\"pn1142.mp4\",\"preview/pn1142.mp4\",\"\"],[623,\"Paper\",510,\"p2693.pdf\",\"proceedings/p2693.pdf\",\"http://dx.doi.org/10.1145/2702123.2702347\"],[624,\"YoutubeVP\",511,\"\",\"\",\"ZuLbEWXAIlI\"],[625,\"VPreview\",511,\"pn592.mp4\",\"preview/pn592.mp4\",\"\"],[626,\"Paper\",511,\"p2703.pdf\",\"proceedings/p2703.pdf\",\"http://dx.doi.org/10.1145/2702123.2702237\"],[627,\"YoutubeVP\",512,\"\",\"\",\"JP80ajFX9o4\"],[628,\"VPreview\",512,\"pn2539.mp4\",\"preview/pn2539.mp4\",\"\"],[629,\"Paper\",512,\"p2707.pdf\",\"proceedings/p2707.pdf\",\"http://dx.doi.org/10.1145/2702123.2702585\"],[630,\"Paper\",513,\"p2711.pdf\",\"proceedings/p2711.pdf\",\"\"],[631,\"Paper\",515,\"p2565.pdf\",\"proceedings/p2565.pdf\",\"\"],[632,\"YoutubeVP\",516,\"\",\"\",\"UpUXYf_Bzek\"],[633,\"VPreview\",516,\"pn2272.mp4\",\"preview/pn2272.mp4\",\"\"],[634,\"Paper\",516,\"p2569.pdf\",\"proceedings/p2569.pdf\",\"http://dx.doi.org/10.1145/2702123.2702538\"],[635,\"YoutubeVP\",517,\"\",\"\",\"kpQU7uytAvc\"],[636,\"VPreview\",517,\"pn682.mp4\",\"preview/pn682.mp4\",\"\"],[637,\"Paper\",517,\"p2573.pdf\",\"proceedings/p2573.pdf\",\"http://dx.doi.org/10.1145/2702123.2702257\"],[638,\"Paper\",518,\"p2583.pdf\",\"proceedings/p2583.pdf\",\"\"],[639,\"YoutubeVP\",519,\"\",\"\",\"eixmJqiRVMw\"],[640,\"VPreview\",519,\"pn517.mp4\",\"preview/pn517.mp4\",\"\"],[641,\"Paper\",519,\"p2593.pdf\",\"proceedings/p2593.pdf\",\"http://dx.doi.org/10.1145/2702123.2702220\"],[642,\"YoutubeVP\",521,\"\",\"\",\"u7VzV93AGFw\"],[643,\"VPreview\",521,\"pn1114.mp4\",\"preview/pn1114.mp4\",\"\"],[644,\"Paper\",521,\"p2487.pdf\",\"proceedings/p2487.pdf\",\"http://dx.doi.org/10.1145/2702123.2702341\"],[645,\"YoutubeVP\",522,\"\",\"\",\"kOaphlSryf4\"],[646,\"VPreview\",522,\"pn1149.mp4\",\"preview/pn1149.mp4\",\"\"],[647,\"Paper\",522,\"p2497.pdf\",\"proceedings/p2497.pdf\",\"http://dx.doi.org/10.1145/2702123.2702350\"],[648,\"YoutubeVP\",523,\"\",\"\",\"H-megrNfqDo\"],[649,\"VPreview\",523,\"pn1763.mp4\",\"preview/pn1763.mp4\",\"\"],[650,\"Paper\",523,\"p2501.pdf\",\"proceedings/p2501.pdf\",\"http://dx.doi.org/10.1145/2702123.2702459\"],[651,\"YoutubeVP\",524,\"\",\"\",\"JSfnm_HoUv4\"],[652,\"VPreview\",524,\"pn399.mp4\",\"preview/pn399.mp4\",\"\"],[653,\"Paper\",524,\"p2505.pdf\",\"proceedings/p2505.pdf\",\"http://dx.doi.org/10.1145/2702123.2702190\"],[654,\"YoutubeVP\",525,\"\",\"\",\"d0J7V37zQjY\"],[655,\"VPreview\",525,\"pn115.mp4\",\"preview/pn115.mp4\",\"\"],[656,\"Paper\",525,\"p2515.pdf\",\"proceedings/p2515.pdf\",\"http://dx.doi.org/10.1145/2702123.2702128\"],[657,\"YoutubeVP\",527,\"\",\"\",\"k5EQTeuIkTQ\"],[658,\"VPreview\",527,\"pn409.mp4\",\"preview/pn409.mp4\",\"\"],[659,\"Paper\",527,\"p2603.pdf\",\"proceedings/p2603.pdf\",\"http://dx.doi.org/10.1145/2702123.2702193\"],[660,\"Paper\",528,\"p2613.pdf\",\"proceedings/p2613.pdf\",\"\"],[661,\"Paper\",529,\"p2623.pdf\",\"proceedings/p2623.pdf\",\"\"],[662,\"Paper\",530,\"p2633.pdf\",\"proceedings/p2633.pdf\",\"\"],[663,\"Paper\",535,\"p2525.pdf\",\"proceedings/p2525.pdf\",\"\"],[664,\"Paper\",536,\"p2535.pdf\",\"proceedings/p2535.pdf\",\"\"],[665,\"Paper\",537,\"p2545.pdf\",\"proceedings/p2545.pdf\",\"\"],[666,\"YoutubeVP\",538,\"\",\"\",\"Z4kXs5trp_c\"],[667,\"VPreview\",538,\"pn361.mp4\",\"preview/pn361.mp4\",\"\"],[668,\"Paper\",538,\"p2555.pdf\",\"proceedings/p2555.pdf\",\"http://dx.doi.org/10.1145/2702123.2702178\"],[669,\"YoutubeVP\",547,\"\",\"\",\"RVEzAYkByFI\"],[670,\"VPreview\",547,\"pn1088.mp4\",\"preview/pn1088.mp4\",\"\"],[671,\"Paper\",547,\"p2447.pdf\",\"proceedings/p2447.pdf\",\"http://dx.doi.org/10.1145/2702123.2702337\"],[672,\"YoutubeVP\",548,\"\",\"\",\"sTuc4joTDPI\"],[673,\"VPreview\",548,\"pn1911.mp4\",\"preview/pn1911.mp4\",\"\"],[674,\"Paper\",548,\"p2457.pdf\",\"proceedings/p2457.pdf\",\"http://dx.doi.org/10.1145/2702123.2702487\"],[675,\"YoutubeVP\",549,\"\",\"\",\"1bMWAS9Fp-o\"],[676,\"VPreview\",549,\"pn631.mp4\",\"preview/pn631.mp4\",\"\"],[677,\"Paper\",549,\"p2467.pdf\",\"proceedings/p2467.pdf\",\"http://dx.doi.org/10.1145/2702123.2702245\"],[678,\"YoutubeVP\",550,\"\",\"\",\"ilRIKCR405g\"],[679,\"VPreview\",550,\"pn2312.mp4\",\"preview/pn2312.mp4\",\"\"],[680,\"Paper\",550,\"p2477.pdf\",\"proceedings/p2477.pdf\",\"http://dx.doi.org/10.1145/2702123.2702547\"],[681,\"Paper\",565,\"p2913.pdf\",\"proceedings/p2913.pdf\",\"\"],[682,\"YoutubeVP\",566,\"\",\"\",\"OZwW4Cj9Eiw\"],[683,\"VPreview\",566,\"pn1336.mp4\",\"preview/pn1336.mp4\",\"\"],[684,\"Paper\",566,\"p2923.pdf\",\"proceedings/p2923.pdf\",\"http://dx.doi.org/10.1145/2702123.2702384\"],[685,\"YoutubeVP\",567,\"\",\"\",\"RRKR0dekPxo\"],[686,\"VPreview\",567,\"pn414.mp4\",\"preview/pn414.mp4\",\"\"],[687,\"Paper\",567,\"p2933.pdf\",\"proceedings/p2933.pdf\",\"http://dx.doi.org/10.1145/2702123.2702197\"],[688,\"YoutubeVP\",568,\"\",\"\",\"6Tcx6F5y6Rw\"],[689,\"VPreview\",568,\"pn1280.mp4\",\"preview/pn1280.mp4\",\"\"],[690,\"Paper\",568,\"p2943.pdf\",\"proceedings/p2943.pdf\",\"http://dx.doi.org/10.1145/2702123.2702374\"],[691,\"YoutubeVP\",570,\"\",\"\",\"xjRUASJ7xP4\"],[692,\"VPreview\",570,\"pn1337.mp4\",\"preview/pn1337.mp4\",\"\"],[693,\"Paper\",570,\"p2797.pdf\",\"proceedings/p2797.pdf\",\"http://dx.doi.org/10.1145/2702123.2702385\"],[694,\"Paper\",571,\"p2801.pdf\",\"proceedings/p2801.pdf\",\"\"],[695,\"Paper\",572,\"p2805.pdf\",\"proceedings/p2805.pdf\",\"\"],[696,\"Paper\",573,\"p2815.pdf\",\"proceedings/p2815.pdf\",\"\"],[697,\"Paper\",574,\"p2825.pdf\",\"proceedings/p2825.pdf\",\"\"],[698,\"Paper\",575,\"p2829.pdf\",\"proceedings/p2829.pdf\",\"\"],[699,\"Paper\",577,\"p2729.pdf\",\"proceedings/p2729.pdf\",\"\"],[700,\"Paper\",578,\"p2739.pdf\",\"proceedings/p2739.pdf\",\"\"],[701,\"Paper\",579,\"p2749.pdf\",\"proceedings/p2749.pdf\",\"\"],[702,\"Paper\",582,\"p2833.pdf\",\"proceedings/p2833.pdf\",\"\"],[703,\"YoutubeVP\",583,\"\",\"\",\"l8FcYQoBb4I\"],[704,\"VPreview\",583,\"pn1156.mp4\",\"preview/pn1156.mp4\",\"\"],[705,\"Paper\",583,\"p2843.pdf\",\"proceedings/p2843.pdf\",\"http://dx.doi.org/10.1145/2702123.2702352\"],[706,\"Paper\",584,\"p2853.pdf\",\"proceedings/p2853.pdf\",\"\"],[707,\"Paper\",585,\"p2863.pdf\",\"proceedings/p2863.pdf\",\"\"],[708,\"Paper\",587,\"p2873.pdf\",\"proceedings/p2873.pdf\",\"\"],[709,\"YoutubeVP\",588,\"\",\"\",\"XzR6SYGEAEI\"],[710,\"VPreview\",588,\"pn1047.mp4\",\"preview/pn1047.mp4\",\"\"],[711,\"Paper\",588,\"p2883.pdf\",\"proceedings/p2883.pdf\",\"http://dx.doi.org/10.1145/2702123.2702322\"],[712,\"Paper\",589,\"p2893.pdf\",\"proceedings/p2893.pdf\",\"\"],[713,\"YoutubeVP\",590,\"\",\"\",\"uBSEx51-ecM\"],[714,\"VPreview\",590,\"pn2548.mp4\",\"preview/pn2548.mp4\",\"\"],[715,\"Paper\",590,\"p2903.pdf\",\"proceedings/p2903.pdf\",\"http://dx.doi.org/10.1145/2702123.2702586\"],[716,\"YoutubeVP\",592,\"\",\"\",\"H5mQIhdi_z4\"],[717,\"VPreview\",592,\"pn1492.mp4\",\"preview/pn1492.mp4\",\"\"],[718,\"Paper\",592,\"p2759.pdf\",\"proceedings/p2759.pdf\",\"http://dx.doi.org/10.1145/2702123.2702406\"],[719,\"YoutubeVP\",593,\"\",\"\",\"EH0iKvXFKdE\"],[720,\"VPreview\",593,\"pn1361.mp4\",\"preview/pn1361.mp4\",\"\"],[721,\"Paper\",593,\"p2769.pdf\",\"proceedings/p2769.pdf\",\"http://dx.doi.org/10.1145/2702123.2702390\"],[722,\"YoutubeVP\",594,\"\",\"\",\"zVoqyDXduCg\"],[723,\"VPreview\",594,\"pn139.mp4\",\"preview/pn139.mp4\",\"\"],[724,\"Paper\",594,\"p2773.pdf\",\"proceedings/p2773.pdf\",\"http://dx.doi.org/10.1145/2702123.2702132\"],[725,\"YoutubeVP\",595,\"\",\"\",\"jV3VkukDM9U\"],[726,\"VPreview\",595,\"pn1284.mp4\",\"preview/pn1284.mp4\",\"\"],[727,\"Paper\",595,\"p2777.pdf\",\"proceedings/p2777.pdf\",\"http://dx.doi.org/10.1145/2702123.2702375\"],[728,\"YoutubeVP\",596,\"\",\"\",\"8qLmWETHkwM\"],[729,\"VPreview\",596,\"pn416.mp4\",\"preview/pn416.mp4\",\"\"],[730,\"Paper\",596,\"p2787.pdf\",\"proceedings/p2787.pdf\",\"http://dx.doi.org/10.1145/2702123.2702198\"],[731,\"Paper\",602,\"p2953.pdf\",\"proceedings/p2953.pdf\",\"\"],[732,\"YoutubeVP\",603,\"\",\"\",\"HVJYLiyxmmI\"],[733,\"VPreview\",603,\"pn1103.mp4\",\"preview/pn1103.mp4\",\"\"],[734,\"Paper\",603,\"p2963.pdf\",\"proceedings/p2963.pdf\",\"http://dx.doi.org/10.1145/2702123.2702340\"],[735,\"YoutubeVP\",604,\"\",\"\",\"R2CEE89EN14\"],[736,\"VPreview\",604,\"pn1256.mp4\",\"preview/pn1256.mp4\",\"\"],[737,\"Paper\",604,\"p2967.pdf\",\"proceedings/p2967.pdf\",\"http://dx.doi.org/10.1145/2702123.2702367\"],[738,\"Paper\",605,\"p2971.pdf\",\"proceedings/p2971.pdf\",\"\"],[739,\"Paper\",606,\"p2981.pdf\",\"proceedings/p2981.pdf\",\"\"],[740,\"YoutubeVP\",612,\"\",\"\",\"WWadkBFAZAc\"],[741,\"VPreview\",612,\"crs107.mp4\",\"preview/crs107.mp4\",\"\"],[742,\"Paper\",612,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2706671\"],[743,\"YoutubeVP\",621,\"\",\"\",\"-muK9kJKgfQ\"],[744,\"VPreview\",621,\"pn1367.mp4\",\"preview/pn1367.mp4\",\"\"],[745,\"Paper\",621,\"p2991.pdf\",\"proceedings/p2991.pdf\",\"http://dx.doi.org/10.1145/2702123.2702391\"],[746,\"YoutubeVP\",622,\"\",\"\",\"_aefLE7K0qY\"],[747,\"VPreview\",622,\"pn1809.mp4\",\"preview/pn1809.mp4\",\"\"],[748,\"Paper\",622,\"p3001.pdf\",\"proceedings/p3001.pdf\",\"http://dx.doi.org/10.1145/2702123.2702464\"],[749,\"Paper\",623,\"p3011.pdf\",\"proceedings/p3011.pdf\",\"\"],[750,\"YoutubeVP\",624,\"\",\"\",\"jzEUxUzWPqc\"],[751,\"VPreview\",624,\"pn2473.mp4\",\"preview/pn2473.mp4\",\"\"],[752,\"Paper\",624,\"p3015.pdf\",\"proceedings/p3015.pdf\",\"http://dx.doi.org/10.1145/2702123.2702572\"],[753,\"YoutubeVP\",625,\"\",\"\",\"CMPD-eZYOO0\"],[754,\"VPreview\",625,\"pn979.mp4\",\"preview/pn979.mp4\",\"\"],[755,\"Paper\",625,\"p3019.pdf\",\"proceedings/p3019.pdf\",\"http://dx.doi.org/10.1145/2702123.2702308\"],[756,\"Paper\",627,\"p3187.pdf\",\"proceedings/p3187.pdf\",\"\"],[757,\"YoutubeVP\",628,\"\",\"\",\"BLun9CyCLAg\"],[758,\"VPreview\",628,\"pn243.mp4\",\"preview/pn243.mp4\",\"\"],[759,\"Paper\",628,\"p3197.pdf\",\"proceedings/p3197.pdf\",\"http://dx.doi.org/10.1145/2702123.2702153\"],[760,\"Paper\",629,\"p3207.pdf\",\"proceedings/p3207.pdf\",\"\"],[761,\"Paper\",630,\"p3217.pdf\",\"proceedings/p3217.pdf\",\"\"],[762,\"YoutubeVP\",632,\"\",\"\",\"-ITadxbL8Wk\"],[763,\"VPreview\",632,\"pn365.mp4\",\"preview/pn365.mp4\",\"\"],[764,\"Paper\",632,\"p3227.pdf\",\"proceedings/p3227.pdf\",\"http://dx.doi.org/10.1145/2702123.2702180\"],[765,\"YoutubeVP\",633,\"\",\"\",\"TIKuE6GT_P4\"],[766,\"VPreview\",633,\"pn2625.mp4\",\"preview/pn2625.mp4\",\"\"],[767,\"Paper\",633,\"p3237.pdf\",\"proceedings/p3237.pdf\",\"http://dx.doi.org/10.1145/2702123.2702604\"],[768,\"YoutubeVP\",634,\"\",\"\",\"i_-Q3uhiob8\"],[769,\"VPreview\",634,\"pn650.mp4\",\"preview/pn650.mp4\",\"\"],[770,\"Paper\",634,\"p3247.pdf\",\"proceedings/p3247.pdf\",\"http://dx.doi.org/10.1145/2702123.2702248\"],[771,\"Paper\",635,\"p3251.pdf\",\"proceedings/p3251.pdf\",\"\"],[772,\"YoutubeVP\",636,\"\",\"\",\"ldy15WAwKqA\"],[773,\"VPreview\",636,\"pn123.mp4\",\"preview/pn123.mp4\",\"\"],[774,\"Paper\",636,\"p3255.pdf\",\"proceedings/p3255.pdf\",\"http://dx.doi.org/10.1145/2702123.2702129\"],[775,\"YoutubeVP\",638,\"\",\"\",\"REYLPOVKd6o\"],[776,\"VPreview\",638,\"pn2282.mp4\",\"preview/pn2282.mp4\",\"\"],[777,\"Paper\",638,\"p3073.pdf\",\"proceedings/p3073.pdf\",\"http://dx.doi.org/10.1145/2702123.2702540\"],[778,\"Paper\",639,\"p3083.pdf\",\"proceedings/p3083.pdf\",\"\"],[779,\"YoutubeVP\",640,\"\",\"\",\"KWn5mJL14Hs\"],[780,\"VPreview\",640,\"pn504.mp4\",\"preview/pn504.mp4\",\"\"],[781,\"Paper\",640,\"p3093.pdf\",\"proceedings/p3093.pdf\",\"http://dx.doi.org/10.1145/2702123.2702218\"],[782,\"YoutubeVP\",641,\"\",\"\",\"uXxo75QxOw0\"],[783,\"VPreview\",641,\"pn787.mp4\",\"preview/pn787.mp4\",\"\"],[784,\"Paper\",641,\"p3103.pdf\",\"proceedings/p3103.pdf\",\"http://dx.doi.org/10.1145/2702123.2702278\"],[785,\"Paper\",643,\"p3029.pdf\",\"proceedings/p3029.pdf\",\"\"],[786,\"Paper\",646,\"p3039.pdf\",\"proceedings/p3039.pdf\",\"\"],[787,\"Paper\",648,\"p3107.pdf\",\"proceedings/p3107.pdf\",\"\"],[788,\"Paper\",649,\"p3117.pdf\",\"proceedings/p3117.pdf\",\"\"],[789,\"YoutubeVP\",650,\"\",\"\",\"Ypk10Rb65no\"],[790,\"VPreview\",650,\"pn699.mp4\",\"preview/pn699.mp4\",\"\"],[791,\"Paper\",650,\"p3127.pdf\",\"proceedings/p3127.pdf\",\"http://dx.doi.org/10.1145/2702123.2702263\"],[792,\"Paper\",651,\"p3137.pdf\",\"proceedings/p3137.pdf\",\"\"],[793,\"Paper\",653,\"p3147.pdf\",\"proceedings/p3147.pdf\",\"\"],[794,\"YoutubeVP\",654,\"\",\"\",\"xC3-oZ0YEoo\"],[795,\"VPreview\",654,\"pn439.mp4\",\"preview/pn439.mp4\",\"\"],[796,\"Paper\",654,\"p3157.pdf\",\"proceedings/p3157.pdf\",\"http://dx.doi.org/10.1145/2702123.2702203\"],[797,\"Paper\",655,\"p3167.pdf\",\"proceedings/p3167.pdf\",\"\"],[798,\"Paper\",656,\"p3177.pdf\",\"proceedings/p3177.pdf\",\"\"],[799,\"YoutubeVP\",658,\"\",\"\",\"D2yvrMtOqWc\"],[800,\"VPreview\",658,\"pn2575.mp4\",\"preview/pn2575.mp4\",\"\"],[801,\"Paper\",658,\"p3043.pdf\",\"proceedings/p3043.pdf\",\"http://dx.doi.org/10.1145/2702123.2702589\"],[802,\"YoutubeVP\",660,\"\",\"\",\"x_QdgBQ43OI\"],[803,\"VPreview\",660,\"pn1038.mp4\",\"preview/pn1038.mp4\",\"\"],[804,\"Paper\",660,\"p3053.pdf\",\"proceedings/p3053.pdf\",\"http://dx.doi.org/10.1145/2702123.2702319\"],[805,\"YoutubeVP\",661,\"\",\"\",\"eoilYq-jtBM\"],[806,\"VPreview\",661,\"pn932.mp4\",\"preview/pn932.mp4\",\"\"],[807,\"Paper\",661,\"p3063.pdf\",\"proceedings/p3063.pdf\",\"http://dx.doi.org/10.1145/2702123.2702302\"],[808,\"Paper\",663,\"p3265.pdf\",\"proceedings/p3265.pdf\",\"\"],[809,\"Paper\",664,\"p3275.pdf\",\"proceedings/p3275.pdf\",\"\"],[810,\"Paper\",665,\"p3285.pdf\",\"proceedings/p3285.pdf\",\"\"],[811,\"Paper\",666,\"p3295.pdf\",\"proceedings/p3295.pdf\",\"\"],[812,\"YoutubeVP\",676,\"\",\"\",\"WWadkBFAZAc\"],[813,\"VPreview\",676,\"crs107.mp4\",\"preview/crs107.mp4\",\"\"],[814,\"Paper\",676,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2706671\"],[815,\"YoutubeVP\",678,\"\",\"\",\"bc6tQeUKKNE\"],[816,\"VPreview\",678,\"sig105.mp4\",\"preview/sig105.mp4\",\"\"],[817,\"Paper\",678,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2727688\"],[818,\"YoutubeVP\",682,\"\",\"\",\"SuIgD2Iaaiw\"],[819,\"VPreview\",682,\"pn1357.mp4\",\"preview/pn1357.mp4\",\"\"],[820,\"Paper\",682,\"p3307.pdf\",\"proceedings/p3307.pdf\",\"http://dx.doi.org/10.1145/2702123.2702389\"],[821,\"YoutubeVP\",683,\"\",\"\",\"3x9qtJjXkuY\"],[822,\"VPreview\",683,\"pn525.mp4\",\"preview/pn525.mp4\",\"\"],[823,\"Paper\",683,\"p3317.pdf\",\"proceedings/p3317.pdf\",\"http://dx.doi.org/10.1145/2702123.2702222\"],[824,\"Paper\",684,\"p3327.pdf\",\"proceedings/p3327.pdf\",\"\"],[825,\"YoutubeVP\",685,\"\",\"\",\"UnMbK-gY_kM\"],[826,\"VPreview\",685,\"pn1936.mp4\",\"preview/pn1936.mp4\",\"\"],[827,\"Paper\",685,\"p3337.pdf\",\"proceedings/p3337.pdf\",\"http://dx.doi.org/10.1145/2702123.2702490\"],[828,\"YoutubeVP\",687,\"\",\"\",\"iKrPvpeWi_Y\"],[829,\"VPreview\",687,\"pn1892.mp4\",\"preview/pn1892.mp4\",\"\"],[830,\"Paper\",687,\"p3553.pdf\",\"proceedings/p3553.pdf\",\"http://dx.doi.org/10.1145/2702123.2702480\"],[831,\"YoutubeVP\",688,\"\",\"\",\"YW31lmzQzpc\"],[832,\"VPreview\",688,\"pn328.mp4\",\"preview/pn328.mp4\",\"\"],[833,\"Paper\",688,\"p3563.pdf\",\"proceedings/p3563.pdf\",\"http://dx.doi.org/10.1145/2702123.2702172\"],[834,\"YoutubeVP\",689,\"\",\"\",\"-q702OTBpT8\"],[835,\"VPreview\",689,\"pn134.mp4\",\"preview/pn134.mp4\",\"\"],[836,\"Paper\",689,\"p3573.pdf\",\"proceedings/p3573.pdf\",\"http://dx.doi.org/10.1145/2702123.2702130\"],[837,\"Paper\",690,\"p3583.pdf\",\"proceedings/p3583.pdf\",\"\"],[838,\"Paper\",692,\"p3423.pdf\",\"proceedings/p3423.pdf\",\"\"],[839,\"Paper\",693,\"p3433.pdf\",\"proceedings/p3433.pdf\",\"\"],[840,\"YoutubeVP\",694,\"\",\"\",\"KRZnPcyg-oE\"],[841,\"VPreview\",694,\"pn1764.mp4\",\"preview/pn1764.mp4\",\"\"],[842,\"Paper\",694,\"p3443.pdf\",\"proceedings/p3443.pdf\",\"http://dx.doi.org/10.1145/2702123.2702460\"],[843,\"Paper\",695,\"p3453.pdf\",\"proceedings/p3453.pdf\",\"\"],[844,\"YoutubeVP\",697,\"\",\"\",\"_-fmT4N2yK0\"],[845,\"VPreview\",697,\"pn2504.mp4\",\"preview/pn2504.mp4\",\"\"],[846,\"Paper\",697,\"p3347.pdf\",\"proceedings/p3347.pdf\",\"http://dx.doi.org/10.1145/2702123.2702583\"],[847,\"Paper\",698,\"p3351.pdf\",\"proceedings/p3351.pdf\",\"\"],[848,\"Paper\",699,\"p3355.pdf\",\"proceedings/p3355.pdf\",\"\"],[849,\"Paper\",700,\"p3365.pdf\",\"proceedings/p3365.pdf\",\"\"],[850,\"Paper\",701,\"p3375.pdf\",\"proceedings/p3375.pdf\",\"\"],[851,\"Paper\",703,\"p3463.pdf\",\"proceedings/p3463.pdf\",\"\"],[852,\"Paper\",704,\"p3473.pdf\",\"proceedings/p3473.pdf\",\"\"],[853,\"Paper\",705,\"p3483.pdf\",\"proceedings/p3483.pdf\",\"\"],[854,\"YoutubeVP\",706,\"\",\"\",\"4wHQqeRUupo\"],[855,\"VPreview\",706,\"pn1095.mp4\",\"preview/pn1095.mp4\",\"\"],[856,\"Paper\",706,\"p3493.pdf\",\"proceedings/p3493.pdf\",\"http://dx.doi.org/10.1145/2702123.2702339\"],[857,\"YoutubeVP\",709,\"\",\"\",\"3XL9ZzfTvK8\"],[858,\"VPreview\",709,\"pn2327.mp4\",\"preview/pn2327.mp4\",\"\"],[859,\"Paper\",709,\"p3503.pdf\",\"proceedings/p3503.pdf\",\"http://dx.doi.org/10.1145/2702123.2702551\"],[860,\"Paper\",710,\"p3513.pdf\",\"proceedings/p3513.pdf\",\"\"],[861,\"Paper\",713,\"p3385.pdf\",\"proceedings/p3385.pdf\",\"\"],[862,\"YoutubeVP\",714,\"\",\"\",\"VXlMYyL3g20\"],[863,\"VPreview\",714,\"pn1618.mp4\",\"preview/pn1618.mp4\",\"\"],[864,\"Paper\",714,\"p3395.pdf\",\"proceedings/p3395.pdf\",\"http://dx.doi.org/10.1145/2702123.2702433\"],[865,\"YoutubeVP\",715,\"\",\"\",\"js5T6NSnLjw\"],[866,\"VPreview\",715,\"pn2560.mp4\",\"preview/pn2560.mp4\",\"\"],[867,\"Paper\",715,\"p3399.pdf\",\"proceedings/p3399.pdf\",\"http://dx.doi.org/10.1145/2702123.2702587\"],[868,\"YoutubeVP\",716,\"\",\"\",\"lOdt-pf5U8Q\"],[869,\"VPreview\",716,\"pn160.mp4\",\"preview/pn160.mp4\",\"\"],[870,\"Paper\",716,\"p3403.pdf\",\"proceedings/p3403.pdf\",\"http://dx.doi.org/10.1145/2702123.2702140\"],[871,\"Paper\",717,\"p3413.pdf\",\"proceedings/p3413.pdf\",\"\"],[872,\"Paper\",719,\"p3523.pdf\",\"proceedings/p3523.pdf\",\"\"],[873,\"Paper\",720,\"p3533.pdf\",\"proceedings/p3533.pdf\",\"\"],[874,\"Paper\",721,\"p3543.pdf\",\"proceedings/p3543.pdf\",\"\"],[875,\"YoutubeVP\",725,\"\",\"\",\"YsKNyteWsqc\"],[876,\"VPreview\",725,\"case136.mp4\",\"preview/case136.mp4\",\"\"],[877,\"Paper\",725,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2702964\"],[878,\"YoutubeVP\",726,\"\",\"\",\"DxcLfYWKe8Y\"],[879,\"VPreview\",726,\"case138.mp4\",\"preview/case138.mp4\",\"\"],[880,\"Paper\",726,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2702966\"],[881,\"Paper\",739,\"p3593.pdf\",\"proceedings/p3593.pdf\",\"\"],[882,\"YoutubeVP\",740,\"\",\"\",\"zHCmz4hNoR0\"],[883,\"VPreview\",740,\"pn2586.mp4\",\"preview/pn2586.mp4\",\"\"],[884,\"Paper\",740,\"p3603.pdf\",\"proceedings/p3603.pdf\",\"http://dx.doi.org/10.1145/2702123.2702592\"],[885,\"YoutubeVP\",741,\"\",\"\",\"X4qk5AX5dQc\"],[886,\"VPreview\",741,\"pn366.mp4\",\"preview/pn366.mp4\",\"\"],[887,\"Paper\",741,\"p3613.pdf\",\"proceedings/p3613.pdf\",\"http://dx.doi.org/10.1145/2702123.2702181\"],[888,\"YoutubeVP\",742,\"\",\"\",\"REEgBzvcjMQ\"],[889,\"VPreview\",742,\"pn2328.mp4\",\"preview/pn2328.mp4\",\"\"],[890,\"Paper\",742,\"p3623.pdf\",\"proceedings/p3623.pdf\",\"http://dx.doi.org/10.1145/2702123.2702552\"],[891,\"YoutubeVP\",744,\"\",\"\",\"pvcbsDp_jms\"],[892,\"VPreview\",744,\"pn2085.mp4\",\"preview/pn2085.mp4\",\"\"],[893,\"Paper\",744,\"p3829.pdf\",\"proceedings/p3829.pdf\",\"http://dx.doi.org/10.1145/2702123.2702512\"],[894,\"Paper\",745,\"p3839.pdf\",\"proceedings/p3839.pdf\",\"\"],[895,\"Paper\",746,\"p3849.pdf\",\"proceedings/p3849.pdf\",\"\"],[896,\"Paper\",747,\"p3859.pdf\",\"proceedings/p3859.pdf\",\"\"],[897,\"YoutubeVP\",749,\"\",\"\",\"xXl3F5AoeQU\"],[898,\"VPreview\",749,\"pn638.mp4\",\"preview/pn638.mp4\",\"\"],[899,\"Paper\",749,\"p3869.pdf\",\"proceedings/p3869.pdf\",\"http://dx.doi.org/10.1145/2702123.2702246\"],[900,\"YoutubeVP\",750,\"\",\"\",\"jC4BbqfovGc\"],[901,\"VPreview\",750,\"pn667.mp4\",\"preview/pn667.mp4\",\"\"],[902,\"Paper\",750,\"p3879.pdf\",\"proceedings/p3879.pdf\",\"http://dx.doi.org/10.1145/2702123.2702254\"],[903,\"YoutubeVP\",751,\"\",\"\",\"1rCsFzcXP2c\"],[904,\"VPreview\",751,\"pn236.mp4\",\"preview/pn236.mp4\",\"\"],[905,\"Paper\",751,\"p3889.pdf\",\"proceedings/p3889.pdf\",\"http://dx.doi.org/10.1145/2702123.2702150\"],[906,\"Paper\",752,\"p3899.pdf\",\"proceedings/p3899.pdf\",\"\"],[907,\"YoutubeVP\",754,\"\",\"\",\"WPN0g7M8E9c\"],[908,\"VPreview\",754,\"pn1599.mp4\",\"preview/pn1599.mp4\",\"\"],[909,\"Paper\",754,\"p3711.pdf\",\"proceedings/p3711.pdf\",\"http://dx.doi.org/10.1145/2702123.2702429\"],[910,\"Paper\",755,\"p3721.pdf\",\"proceedings/p3721.pdf\",\"\"],[911,\"Paper\",756,\"p3731.pdf\",\"proceedings/p3731.pdf\",\"\"],[912,\"Paper\",757,\"p3735.pdf\",\"proceedings/p3735.pdf\",\"\"],[913,\"Paper\",758,\"p3739.pdf\",\"proceedings/p3739.pdf\",\"\"],[914,\"Paper\",760,\"p3633.pdf\",\"proceedings/p3633.pdf\",\"\"],[915,\"YoutubeVP\",761,\"\",\"\",\"tKEjkyIeszs\"],[916,\"VPreview\",761,\"pn147.mp4\",\"preview/pn147.mp4\",\"\"],[917,\"Paper\",761,\"p3643.pdf\",\"proceedings/p3643.pdf\",\"http://dx.doi.org/10.1145/2702123.2702136\"],[918,\"YoutubeVP\",762,\"\",\"\",\"_q-3bS0SvKs\"],[919,\"VPreview\",762,\"pn140.mp4\",\"preview/pn140.mp4\",\"\"],[920,\"Paper\",762,\"p3653.pdf\",\"proceedings/p3653.pdf\",\"http://dx.doi.org/10.1145/2702123.2702133\"],[921,\"YoutubeVP\",763,\"\",\"\",\"JuwGLnCHvag\"],[922,\"VPreview\",763,\"pn2607.mp4\",\"preview/pn2607.mp4\",\"\"],[923,\"Paper\",763,\"p3657.pdf\",\"proceedings/p3657.pdf\",\"http://dx.doi.org/10.1145/2702123.2702601\"],[924,\"YoutubeVP\",764,\"\",\"\",\"fQobwL8eSU4\"],[925,\"VPreview\",764,\"pn1268.mp4\",\"preview/pn1268.mp4\",\"\"],[926,\"Paper\",764,\"p3661.pdf\",\"proceedings/p3661.pdf\",\"http://dx.doi.org/10.1145/2702123.2702371\"],[927,\"Paper\",766,\"p3749.pdf\",\"proceedings/p3749.pdf\",\"\"],[928,\"Paper\",767,\"p3759.pdf\",\"proceedings/p3759.pdf\",\"\"],[929,\"Paper\",768,\"p3769.pdf\",\"proceedings/p3769.pdf\",\"\"],[930,\"Paper\",769,\"p3779.pdf\",\"proceedings/p3779.pdf\",\"\"],[931,\"Paper\",771,\"p3789.pdf\",\"proceedings/p3789.pdf\",\"\"],[932,\"Paper\",772,\"p3799.pdf\",\"proceedings/p3799.pdf\",\"\"],[933,\"Paper\",773,\"p3809.pdf\",\"proceedings/p3809.pdf\",\"\"],[934,\"YoutubeVP\",774,\"\",\"\",\"xeZherjrfSE\"],[935,\"VPreview\",774,\"pn2146.mp4\",\"preview/pn2146.mp4\",\"\"],[936,\"Paper\",774,\"p3819.pdf\",\"proceedings/p3819.pdf\",\"http://dx.doi.org/10.1145/2702123.2702520\"],[937,\"YoutubeVP\",776,\"\",\"\",\"gyzVerduLLk\"],[938,\"VPreview\",776,\"pn1574.mp4\",\"preview/pn1574.mp4\",\"\"],[939,\"Paper\",776,\"p3671.pdf\",\"proceedings/p3671.pdf\",\"http://dx.doi.org/10.1145/2702123.2702424\"],[940,\"YoutubeVP\",777,\"\",\"\",\"UV9Es86xT5k\"],[941,\"VPreview\",777,\"pn1167.mp4\",\"preview/pn1167.mp4\",\"\"],[942,\"Paper\",777,\"p3681.pdf\",\"proceedings/p3681.pdf\",\"http://dx.doi.org/10.1145/2702123.2702354\"],[943,\"Paper\",778,\"p3691.pdf\",\"proceedings/p3691.pdf\",\"\"],[944,\"YoutubeVP\",779,\"\",\"\",\"pntF2Diu3G8\"],[945,\"VPreview\",779,\"pn727.mp4\",\"preview/pn727.mp4\",\"\"],[946,\"Paper\",779,\"p3701.pdf\",\"proceedings/p3701.pdf\",\"http://dx.doi.org/10.1145/2702123.2702267\"],[947,\"YoutubeVP\",783,\"\",\"\",\"y-RMpTCMps8\"],[948,\"VPreview\",783,\"alt107.mp4\",\"preview/alt107.mp4\",\"\"],[949,\"Paper\",783,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2732497\"],[950,\"YoutubeVP\",785,\"\",\"\",\"gR1klXKbpQQ\"],[951,\"VPreview\",785,\"alt130.mp4\",\"preview/alt130.mp4\",\"\"],[952,\"Paper\",785,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2732502\"],[953,\"YoutubeVP\",788,\"\",\"\",\"X8X4O70CCZ0\"],[954,\"VPreview\",788,\"crs103.mp4\",\"preview/crs103.mp4\",\"\"],[955,\"Paper\",788,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2706667\"],[956,\"Paper\",795,\"p4047.pdf\",\"proceedings/p4047.pdf\",\"\"],[957,\"Paper\",796,\"p4057.pdf\",\"proceedings/p4057.pdf\",\"\"],[958,\"Paper\",797,\"p4061.pdf\",\"proceedings/p4061.pdf\",\"\"],[959,\"Paper\",798,\"p4065.pdf\",\"proceedings/p4065.pdf\",\"\"],[960,\"YoutubeVP\",799,\"\",\"\",\"LmmcEHUhErA\"],[961,\"VPreview\",799,\"pn1558.mp4\",\"preview/pn1558.mp4\",\"\"],[962,\"Paper\",799,\"p4069.pdf\",\"proceedings/p4069.pdf\",\"http://dx.doi.org/10.1145/2702123.2702420\"],[963,\"Paper\",800,\"p4079.pdf\",\"proceedings/p4079.pdf\",\"\"],[964,\"YoutubeVP\",802,\"\",\"\",\"V91HzzQZZRA\"],[965,\"VPreview\",802,\"pn1439.mp4\",\"preview/pn1439.mp4\",\"\"],[966,\"Paper\",802,\"p4123.pdf\",\"proceedings/p4123.pdf\",\"http://dx.doi.org/10.1145/2702123.2702401\"],[967,\"Paper\",803,\"p4133.pdf\",\"proceedings/p4133.pdf\",\"\"],[968,\"YoutubeVP\",804,\"\",\"\",\"Y6Ku6elg2Yg\"],[969,\"VPreview\",804,\"pn2603.mp4\",\"preview/pn2603.mp4\",\"\"],[970,\"Paper\",804,\"p4143.pdf\",\"proceedings/p4143.pdf\",\"http://dx.doi.org/10.1145/2702123.2702598\"],[971,\"Paper\",805,\"p4147.pdf\",\"proceedings/p4147.pdf\",\"\"],[972,\"Paper\",806,\"p4151.pdf\",\"proceedings/p4151.pdf\",\"\"],[973,\"Paper\",808,\"p4161.pdf\",\"proceedings/p4161.pdf\",\"\"],[974,\"YoutubeVP\",809,\"\",\"\",\"f8NOERrhWfA\"],[975,\"VPreview\",809,\"pn1069.mp4\",\"preview/pn1069.mp4\",\"\"],[976,\"Paper\",809,\"p4165.pdf\",\"proceedings/p4165.pdf\",\"http://dx.doi.org/10.1145/2702123.2702332\"],[977,\"Paper\",810,\"p4169.pdf\",\"proceedings/p4169.pdf\",\"\"],[978,\"YoutubeVP\",811,\"\",\"\",\"FZa29K7BKsQ\"],[979,\"VPreview\",811,\"pn1170.mp4\",\"preview/pn1170.mp4\",\"\"],[980,\"Paper\",811,\"p4179.pdf\",\"proceedings/p4179.pdf\",\"http://dx.doi.org/10.1145/2702123.2702355\"],[981,\"YoutubeVP\",812,\"\",\"\",\"zRJEhb0y050\"],[982,\"VPreview\",812,\"pn1927.mp4\",\"preview/pn1927.mp4\",\"\"],[983,\"Paper\",812,\"p4189.pdf\",\"proceedings/p4189.pdf\",\"http://dx.doi.org/10.1145/2702123.2702489\"],[984,\"YoutubeVP\",814,\"\",\"\",\"1PVtHuDUXXY\"],[985,\"VPreview\",814,\"pn1742.mp4\",\"preview/pn1742.mp4\",\"\"],[986,\"Paper\",814,\"p4019.pdf\",\"proceedings/p4019.pdf\",\"http://dx.doi.org/10.1145/2702123.2702456\"],[987,\"YoutubeVP\",815,\"\",\"\",\"fDJ_gEgGxqQ\"],[988,\"VPreview\",815,\"pn598.mp4\",\"preview/pn598.mp4\",\"\"],[989,\"Paper\",815,\"p4029.pdf\",\"proceedings/p4029.pdf\",\"http://dx.doi.org/10.1145/2702123.2702240\"],[990,\"Paper\",816,\"p4039.pdf\",\"proceedings/p4039.pdf\",\"\"],[991,\"Paper\",817,\"p4043.pdf\",\"proceedings/p4043.pdf\",\"\"],[992,\"YoutubeVP\",819,\"\",\"\",\"yHEB7arGOQs\"],[993,\"VPreview\",819,\"pn2111.mp4\",\"preview/pn2111.mp4\",\"\"],[994,\"Paper\",819,\"p3943.pdf\",\"proceedings/p3943.pdf\",\"http://dx.doi.org/10.1145/2702123.2702515\"],[995,\"Paper\",820,\"p3953.pdf\",\"proceedings/p3953.pdf\",\"\"],[996,\"YoutubeVP\",821,\"\",\"\",\"tLDNDGMnxek\"],[997,\"VPreview\",821,\"pn1273.mp4\",\"preview/pn1273.mp4\",\"\"],[998,\"Paper\",821,\"p3963.pdf\",\"proceedings/p3963.pdf\",\"http://dx.doi.org/10.1145/2702123.2702372\"],[999,\"Paper\",822,\"p3967.pdf\",\"proceedings/p3967.pdf\",\"\"],[1000,\"YoutubeVP\",823,\"\",\"\",\"me5j5OIHVGk\"],[1001,\"VPreview\",823,\"pn306.mp4\",\"preview/pn306.mp4\",\"\"],[1002,\"Paper\",823,\"p3971.pdf\",\"proceedings/p3971.pdf\",\"http://dx.doi.org/10.1145/2702123.2702167\"],[1003,\"YoutubeVP\",825,\"\",\"\",\"VEgNxj2JgaU\"],[1004,\"VPreview\",825,\"pn479.mp4\",\"preview/pn479.mp4\",\"\"],[1005,\"Paper\",825,\"p3903.pdf\",\"proceedings/p3903.pdf\",\"http://dx.doi.org/10.1145/2702123.2702211\"],[1006,\"YoutubeVP\",826,\"\",\"\",\"y_XQjD8Uar4\"],[1007,\"VPreview\",826,\"pn855.mp4\",\"preview/pn855.mp4\",\"\"],[1008,\"Paper\",826,\"p3913.pdf\",\"proceedings/p3913.pdf\",\"http://dx.doi.org/10.1145/2702123.2702287\"],[1009,\"YoutubeVP\",827,\"\",\"\",\"xGqn1FQRQPQ\"],[1010,\"VPreview\",827,\"pn1715.mp4\",\"preview/pn1715.mp4\",\"\"],[1011,\"Paper\",827,\"p3923.pdf\",\"proceedings/p3923.pdf\",\"http://dx.doi.org/10.1145/2702123.2702451\"],[1012,\"YoutubeVP\",828,\"\",\"\",\"QsfQWZpiR18\"],[1013,\"VPreview\",828,\"pn1066.mp4\",\"preview/pn1066.mp4\",\"\"],[1014,\"Paper\",828,\"p3933.pdf\",\"proceedings/p3933.pdf\",\"http://dx.doi.org/10.1145/2702123.2702331\"],[1015,\"YoutubeVP\",830,\"\",\"\",\"dJmy-pFwxKA\"],[1016,\"VPreview\",830,\"pn710.mp4\",\"preview/pn710.mp4\",\"\"],[1017,\"Paper\",830,\"p4083.pdf\",\"proceedings/p4083.pdf\",\"http://dx.doi.org/10.1145/2702123.2702265\"],[1018,\"YoutubeVP\",831,\"\",\"\",\"UJjonJRa3Lg\"],[1019,\"VPreview\",831,\"pn327.mp4\",\"preview/pn327.mp4\",\"\"],[1020,\"Paper\",831,\"p4093.pdf\",\"proceedings/p4093.pdf\",\"http://dx.doi.org/10.1145/2702123.2702171\"],[1021,\"YoutubeVP\",832,\"\",\"\",\"FSIgiUhn9m8\"],[1022,\"VPreview\",832,\"pn1018.mp4\",\"preview/pn1018.mp4\",\"\"],[1023,\"Paper\",832,\"p4103.pdf\",\"proceedings/p4103.pdf\",\"http://dx.doi.org/10.1145/2702123.2702313\"],[1024,\"YoutubeVP\",833,\"\",\"\",\"hhIs6VpHOG4\"],[1025,\"VPreview\",833,\"pn898.mp4\",\"preview/pn898.mp4\",\"\"],[1026,\"Paper\",833,\"p4113.pdf\",\"proceedings/p4113.pdf\",\"http://dx.doi.org/10.1145/2702123.2702294\"],[1027,\"Paper\",835,\"p3981.pdf\",\"proceedings/p3981.pdf\",\"\"],[1028,\"Paper\",836,\"p3985.pdf\",\"proceedings/p3985.pdf\",\"\"],[1029,\"YoutubeVP\",837,\"\",\"\",\"SXuxCFQUlyo\"],[1030,\"VPreview\",837,\"pn2247.mp4\",\"preview/pn2247.mp4\",\"\"],[1031,\"Paper\",837,\"p3989.pdf\",\"proceedings/p3989.pdf\",\"http://dx.doi.org/10.1145/2702123.2702537\"],[1032,\"YoutubeVP\",838,\"\",\"\",\"zxr5_-sgFYc\"],[1033,\"VPreview\",838,\"pn1682.mp4\",\"preview/pn1682.mp4\",\"\"],[1034,\"Paper\",838,\"p3999.pdf\",\"proceedings/p3999.pdf\",\"http://dx.doi.org/10.1145/2702123.2702445\"],[1035,\"YoutubeVP\",839,\"\",\"\",\"-t0U7-BiWHw\"],[1036,\"VPreview\",839,\"pn410.mp4\",\"preview/pn410.mp4\",\"\"],[1037,\"Paper\",839,\"p4009.pdf\",\"proceedings/p4009.pdf\",\"http://dx.doi.org/10.1145/2702123.2702194\"],[1038,\"YoutubeVP\",841,\"\",\"\",\"yMfR_alzPh4\"],[1039,\"VPreview\",841,\"pn142.mp4\",\"preview/pn142.mp4\",\"\"],[1040,\"Paper\",841,\"p4199.pdf\",\"proceedings/p4199.pdf\",\"http://dx.doi.org/10.1145/2702123.2702134\"],[1041,\"YoutubeVP\",842,\"\",\"\",\"-yU3H3kEwrk\"],[1042,\"VPreview\",842,\"pn359.mp4\",\"preview/pn359.mp4\",\"\"],[1043,\"Paper\",842,\"p4203.pdf\",\"proceedings/p4203.pdf\",\"http://dx.doi.org/10.1145/2702123.2702177\"],[1044,\"YoutubeVP\",843,\"\",\"\",\"TiuUuoVlKhg\"],[1045,\"VPreview\",843,\"pn332.mp4\",\"preview/pn332.mp4\",\"\"],[1046,\"Paper\",843,\"p4207.pdf\",\"proceedings/p4207.pdf\",\"http://dx.doi.org/10.1145/2702123.2702173\"],[1047,\"Paper\",844,\"p4217.pdf\",\"proceedings/p4217.pdf\",\"\"],[1048,\"YoutubeVP\",845,\"\",\"\",\"qUHnZudq7ws\"],[1049,\"VPreview\",845,\"pn2296.mp4\",\"preview/pn2296.mp4\",\"\"],[1050,\"Paper\",845,\"p4227.pdf\",\"proceedings/p4227.pdf\",\"http://dx.doi.org/10.1145/2702123.2702543\"],[1051,\"YoutubeVP\",848,\"\",\"\",\"BYC02jnlhKY\"],[1052,\"VPreview\",848,\"case139.mp4\",\"preview/case139.mp4\",\"\"],[1053,\"Paper\",848,\"\",\"\",\"http://dx.doi.org/10.1145/2702613.2702967\"]]}}\n\n7 matches across 4 files\n",
			"settings":
			{
				"buffer_size": 1084374,
				"line_ending": "Unix",
				"name": "Find Results",
				"scratch": true
			}
		},
		{
			"file": "program/full-schedule.php",
			"settings":
			{
				"buffer_size": 13322,
				"line_ending": "Unix"
			}
		},
		{
			"file": "js/data/sessions.json",
			"settings":
			{
				"buffer_size": 109326,
				"line_ending": "Unix"
			}
		},
		{
			"file": "js/data/schedule.json",
			"settings":
			{
				"buffer_size": 36629,
				"line_ending": "Unix"
			}
		},
		{
			"file": "attending/mobileapps.php",
			"settings":
			{
				"buffer_size": 4684,
				"line_ending": "Unix"
			}
		},
		{
			"file": "news.php",
			"settings":
			{
				"buffer_size": 7292,
				"line_ending": "Unix"
			}
		},
		{
			"file": "js/main.js",
			"settings":
			{
				"buffer_size": 2737,
				"line_ending": "Unix"
			}
		},
		{
			"file": "js/data/papers.json",
			"settings":
			{
				"buffer_size": 2844117,
				"line_ending": "Unix"
			}
		},
		{
			"file": "program/papers-notes.php",
			"settings":
			{
				"buffer_size": 1261,
				"line_ending": "Unix"
			}
		},
		{
			"file": "js/data/link.php",
			"settings":
			{
				"buffer_size": 3266,
				"line_ending": "Unix"
			}
		},
		{
			"file": "js/data/filters.json",
			"settings":
			{
				"buffer_size": 6277,
				"line_ending": "Unix"
			}
		}
	],
	"build_system": "",
	"build_system_choices":
	[
	],
	"build_varint": "",
	"command_palette":
	{
		"height": 392.0,
		"last_filter": "",
		"selected_items":
		[
			[
				"Snippet: cl",
				"Snippet: console.log"
			],
			[
				"Package Control: instal",
				"Package Control: Install Package"
			],
			[
				"ins",
				"Package Control: Install Package"
			],
			[
				"inst",
				"Package Control: Install Package"
			],
			[
				"instl",
				"Package Control: Install Package"
			],
			[
				"pack",
				"Package Control: Install Package"
			],
			[
				"pac",
				"Package Control: Install Package"
			],
			[
				"packa",
				"Package Control: Install Package"
			],
			[
				"package",
				"Package Control: Enable Package"
			]
		],
		"width": 602.0
	},
	"console":
	{
		"height": 125.0,
		"history":
		[
			"import urllib.request,os,hashlib; h = '7183a2d3e96f11eeadd761d777e62404' + 'e330c659d4bb41d3bdf022e94cab3cd0'; pf = 'Package Control.sublime-package'; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( 'http://sublime.wbond.net/' + pf.replace(' ', '%20')).read(); dh = hashlib.sha256(by).hexdigest(); print('Error validating download (got %s instead of %s), please try manual install' % (dh, h)) if dh != h else open(os.path.join( ipp, pf), 'wb' ).write(by)"
		]
	},
	"distraction_free":
	{
		"menu_visible": true,
		"show_minimap": false,
		"show_open_files": false,
		"show_tabs": false,
		"side_bar_visible": false,
		"status_bar_visible": false
	},
	"expanded_folders":
	[
		"/Applications/MAMP/htdocs/chi2015",
		"/Applications/MAMP/htdocs/chi2015/attending",
		"/Applications/MAMP/htdocs/chi2015/chibingo",
		"/Applications/MAMP/htdocs/chi2015/css",
		"/Applications/MAMP/htdocs/chi2015/js",
		"/Applications/MAMP/htdocs/chi2015/js/data",
		"/Applications/MAMP/htdocs/chi2015/program"
	],
	"file_history":
	[
		"/Applications/MAMP/htdocs/chi2015/attending/mobileapps.php",
		"/Applications/MAMP/htdocs/chi2015/css/main.css",
		"/Applications/MAMP/htdocs/chi2015/chibingo.php",
		"/Applications/MAMP/htdocs/chi2015/js/data/sessions.json",
		"/Applications/MAMP/htdocs/chi2015/program/schedule-glance.php",
		"/Applications/MAMP/htdocs/chi2015/program/schedule_glance.php",
		"/Applications/MAMP/htdocs/chi2015/js/data/schedule_glance.php",
		"/Applications/MAMP/htdocs/chi2015/js/data/schedule_glance.csv",
		"/Applications/MAMP/htdocs/chi2015/js/data/papers.json",
		"/Applications/MAMP/htdocs/chi2015/index.php",
		"/Applications/MAMP/htdocs/chi2015/program/special-events.php",
		"/Applications/MAMP/htdocs/chi2015/js/data/schedule.json",
		"/Applications/MAMP/htdocs/chi2015/js/angular/modules/full_program_2.js",
		"/Applications/MAMP/htdocs/chi2015/js/data/video_previews.php",
		"/Applications/MAMP/htdocs/chi2015/js/data/link.php",
		"/Applications/MAMP/htdocs/chi2015/attending/how-to-go-from-incheon-airport-to-coex.php",
		"/Applications/MAMP/htdocs/chi2015/js/data/video_previews_win.csv",
		"/Applications/MAMP/htdocs/chi2015/header.php",
		"/Applications/MAMP/htdocs/chi2015/js/main.js",
		"/Applications/MAMP/htdocs/chi2015/program/keynotes.php",
		"/Applications/MAMP/htdocs/chi2015/modified_footer.php",
		"/Applications/MAMP/htdocs/chi2015/program/full-schedule.php",
		"/Applications/MAMP/htdocs/chi2015/attending.php",
		"/Applications/MAMP/htdocs/chi2015/js/angular/modules/courses.js",
		"/Applications/MAMP/htdocs/chi2015/organizers.php",
		"/Users/juhokim/Downloads/fancyapps-fancyBox-18d1712/README.md",
		"/Applications/MAMP/htdocs/chi2015/js/angular/modules/main_app.js",
		"/Applications/MAMP/htdocs/chi2015/leftbar.php",
		"/Applications/MAMP/htdocs/chi2015/program/interactivity.php",
		"/Applications/MAMP/htdocs/chi2015/js/data/interactivity.php",
		"/Applications/MAMP/htdocs/chi2015/js/data/video_previews.csv",
		"/Applications/MAMP/htdocs/chi2015/js/data/video-previews.php",
		"/Applications/MAMP/htdocs/chi2015/js/angular/modules/full_program.js",
		"/Applications/MAMP/htdocs/chi2015/attending/womens-breakfast.php",
		"/Applications/MAMP/htdocs/chi2015/recruiting/list-of-recruiters.php",
		"/Users/juhokim/Desktop/chi2015-schedule-dump-simplified.txt",
		"/Users/juhokim/Desktop/chi2015-schedule-dump.txt",
		"/Applications/MAMP/htdocs/chi2015/authors/student-research-competition.php",
		"/Applications/MAMP/htdocs/chi2015/program/courses.php",
		"/Applications/MAMP/htdocs/chi2015/js/data/papers-no-award.json",
		"/Users/juhokim/Desktop/schedule-dump.txt",
		"/Applications/MAMP/htdocs/chi2015/js/data/sessions-no-award.json",
		"/Users/juhokim/Downloads/ps2/src/index.html",
		"/Users/juhokim/Downloads/ps2/src/board.js",
		"/Applications/MAMP/htdocs/chi2015/program/best-of-chi.php",
		"/Applications/MAMP/htdocs/chi2015/news.php",
		"/Applications/MAMP/htdocs/chi2015/js/angular/modules/interactivity.js",
		"/Applications/MAMP/htdocs/chi2015/js/angular/modules/best_of_chi.js",
		"/Applications/MAMP/htdocs/chi2015/attending/how-to-go-from-gimpo-airport-to-coex.php",
		"/Applications/MAMP/htdocs/chi2015/sponsoring/sponsors-of-chi2015.php",
		"/Applications/MAMP/htdocs/chi2015/attending/press.php",
		"/Applications/MAMP/htdocs/chi2015/js/data/papers.php",
		"/Applications/MAMP/htdocs/chi2015/program/full_schedule.php",
		"/Applications/MAMP/htdocs/chi2015/program.php",
		"/Applications/MAMP/htdocs/chi2015/authors/interactivity.php",
		"/Applications/MAMP/htdocs/chi2015/exhibiting.php",
		"/Applications/MAMP/htdocs/chi2015/exhibiting/list-of-exhibitors.php",
		"/Applications/MAMP/htdocs/chi2015/production.php",
		"/Applications/MAMP/htdocs/chi2015/.htaccess",
		"/Applications/MAMP/htdocs/chi2015/authors/video-previews.php",
		"/Applications/MAMP/htdocs/chi2015/authors/video-showcase.php",
		"/Applications/MAMP/htdocs/chi2015/authors/works-in-progress.php",
		"/Applications/MAMP/htdocs/chi2015/authors/workshops-cfp.php",
		"/Applications/MAMP/htdocs/chi2015/authors/workshops.php",
		"/Applications/MAMP/htdocs/chi2015/authors/guide-to-preparing-posters.php",
		"/Applications/MAMP/htdocs/chi2015/authors.php",
		"/Applications/MAMP/htdocs/chi2015/authors/pub-ready-instructions.php",
		"/Applications/MAMP/htdocs/chi2015/authors/selecting-a-subcommittee.php",
		"/Applications/MAMP/htdocs/chi2015/authors/selection-processes.php",
		"/Applications/MAMP/htdocs/chi2015/authors/set-the-tab-order.php",
		"/Applications/MAMP/htdocs/chi2015/authors/shall-i-offer-a-course-or-a-workshop.php",
		"/Applications/MAMP/htdocs/chi2015/authors/sig-meetings.php",
		"/Applications/MAMP/htdocs/chi2015/authors/sigchi-submitter-agreement.php",
		"/Applications/MAMP/htdocs/chi2015/authors/student-design-competition.php",
		"/Applications/MAMP/htdocs/chi2015/authors/student-game-competition.php",
		"/Applications/MAMP/htdocs/chi2015/authors/verify-the-default-language.php",
		"/Applications/MAMP/htdocs/chi2015/authors/video-previews-details.php",
		"/Applications/MAMP/htdocs/chi2015/authors/format.php",
		"/Applications/MAMP/htdocs/chi2015/authors/generate-a-tagged-pdf.php",
		"/Applications/MAMP/htdocs/chi2015/authors/guide-to-a-successful-archival-submission.php",
		"/Applications/MAMP/htdocs/chi2015/authors/guide-to-a-successful-presentation.php",
		"/Applications/MAMP/htdocs/chi2015/authors/guide-to-an-accessible-submission.php",
		"/Applications/MAMP/htdocs/chi2015/authors/guide-to-reviewing-chi-papers-and-notes.php",
		"/Applications/MAMP/htdocs/chi2015/authors/guide-to-submitting-a-video-as-supplementary-material.php",
		"/Applications/MAMP/htdocs/chi2015/authors/mark-table-headers.php",
		"/Applications/MAMP/htdocs/chi2015/authors/panels.php",
		"/Applications/MAMP/htdocs/chi2015/authors/papers-notes.php",
		"/Applications/MAMP/htdocs/chi2015/authors/papers-versus-notes.php",
		"/Applications/MAMP/htdocs/chi2015/authors/add-alternative-text-to-all-figures.php",
		"/Applications/MAMP/htdocs/chi2015/authors/alt-chi.php",
		"/Applications/MAMP/htdocs/chi2015/authors/case-studies.php",
		"/Applications/MAMP/htdocs/chi2015/authors/chi-anonymization-policy.php",
		"/Applications/MAMP/htdocs/chi2015/authors/chi-papers-and-notes-review-process.php",
		"/Applications/MAMP/htdocs/chi2015/authors/contributions-to-hci.php",
		"/Applications/MAMP/htdocs/chi2015/authors/courses.php",
		"/Applications/MAMP/htdocs/chi2015/authors/doctoral-consortium.php",
		"/Applications/MAMP/htdocs/chi2015/authors/doctoral-consortium-proposal-content.php",
		"/Applications/MAMP/htdocs/chi2015/attending/housing.php",
		"/Applications/MAMP/htdocs/chi2015/program/papers-notes.php",
		"/Applications/MAMP/htdocs/chi2015/js/data/sessions.php",
		"/Applications/MAMP/htdocs/chi2015/diffht",
		"/Applications/MAMP/htdocs/chi2015/js/data/link.js",
		"/Applications/MAMP/htdocs/chi2015/attending/visa.php",
		"/Applications/MAMP/htdocs/chi2015/program/workshops.php",
		"/Applications/MAMP/htdocs/chi2015/recruiting.php",
		"/Applications/MAMP/htdocs/chi2015/program/asianchisymposia.php",
		"/Applications/MAMP/htdocs/chi2015/sponsoring.php",
		"/Applications/MAMP/htdocs/chi2015/rightbar.php",
		"/Applications/MAMP/htdocs/chi2015/footer.php",
		"/Applications/MAMP/htdocs/chi2015/chi2015.sublime-project",
		"/Applications/MAMP/htdocs/chi2015/authors/guide-to-submitting-a-video.php",
		"/Applications/MAMP/htdocs/chi2015/css/responsive.css",
		"/Users/juhokim/Dropbox/crowdcamphcomp/index.html",
		"/Applications/MAMP/htdocs/chi2015/impact.php",
		"/Users/juhokim/Downloads/chi2015Org (1).html",
		"/Users/juhokim/Downloads/chi2015Org.html",
		"/Applications/MAMP/htdocs/selfmix-study/study.html",
		"/Applications/MAMP/htdocs/chi2015/authors/information-for-poster-presenters.php",
		"/Applications/MAMP/htdocs/chi2015/css/ie.css",
		"/Applications/MAMP/htdocs/chi2015/css/bootstrap.css",
		"/Applications/MAMP/htdocs/chi2015/js/vendor/bootstrap.js",
		"/Applications/MAMP/htdocs/chi2015/css/bootstrap-theme.css",
		"/Users/juhokim/Downloads/page/Page 1.css",
		"/Users/juhokim/Desktop/2014.02.06/CHI2015_2/index.html",
		"/Applications/MAMP/htdocs/chi2015/main.js",
		"/Users/juhokim/Desktop/2014.02.06/CHI2015_2/index_files/main.css",
		"/Users/juhokim/Desktop/2014.02.06/CHI2015_2/index_files/main.js",
		"/Applications/MAMP/htdocs/chi2015/.gitignore"
	],
	"find":
	{
		"height": 37.0
	},
	"find_in_files":
	{
		"height": 93.0,
		"where_history":
		[
			"<open folders>",
			"/Applications/MAMP/htdocs/juhokim.com",
			"/Applications/MAMP/htdocs/cobi/js",
			"js",
			""
		]
	},
	"find_state":
	{
		"case_sensitive": false,
		"find_history":
		[
			"sungwon",
			"Kori",
			"ABC",
			"early",
			"video_previews",
			"Or-bach",
			"Oh-bach",
			"days-left",
			"samsung.com",
			"Oh-bach",
			"Confer,",
			"first-block",
			"files/",
			"daumkakao.png",
			"daumkakao",
			"Mirza",
			"Video",
			"case",
			"p_venue",
			"sdc",
			"competition",
			"#NAME",
			"jrn1",
			"jour",
			"vp-paper",
			"h4",
			"bg.png",
			"modified_footer",
			"h4",
			"h4_a",
			"text-decoration",
			"underline",
			"full_schedule_submission_h4",
			"str_getcsv",
			"video_previews",
			"papers",
			"papers_factory",
			"data_link",
			"papers.json",
			"interactivity.php",
			"sessions.php",
			"ssessions.php",
			"csv",
			"paper_only",
			"csv",
			"tochi.csv",
			"Show ",
			"full_schedule_abstract",
			"Go back up",
			"Abstract:",
			"full_schedule_authors",
			"<b>Authors",
			"<i>",
			"Keywords",
			"author",
			"industrial-and-city-tours",
			"how-to-go-from-incheon-airport-to-coex",
			"Tangible",
			"Cisco Systems",
			"pn1688",
			"Video Preview",
			"id=",
			"VM[0-9]",
			"full_",
			"VM[0-9]",
			"pn965",
			"Rm:",
			"\"Rm:",
			"daejeon",
			"South Korea",
			"checkerCell",
			"indexToPixel",
			"checkerImg",
			"placeChecker",
			"c03",
			"c05",
			" search ",
			"search ",
			"search",
			"morning1",
			"Arts &",
			"crs113",
			"crs112",
			"crs133",
			"virtual",
			"going jogging",
			"sig1",
			"2014",
			"first-block",
			"abstract_toggle",
			"papers[submissions]",
			"bp_papers",
			"data_link",
			"papers_factory",
			"interactivity_box",
			"papers",
			"full_schedule_query",
			"search",
			"full_schedule_query",
			"papers.json",
			"scheduling",
			"glance",
			"before",
			"when",
			"angular.module",
			"routeprovider",
			"link.php",
			"juhokim.com",
			"early bird",
			"main_app.js",
			"courses.js",
			"js/data",
			"link.js",
			"link.php",
			"biogra",
			"C100",
			"C1",
			"VM1274",
			"http",
			"<div class=\"course-entry\">",
			"div class=\"title\"",
			"workshop",
			"<div class=\"course-entry\">",
			"candb",
			"C1",
			"<div class=\"course-entry\">",
			"C1",
			"Program Description"
		],
		"highlight": true,
		"in_selection": false,
		"preserve_case": false,
		"regex": true,
		"replace_history":
		[
			"Korea",
			"&amp;",
			"hist",
			"\"none\"",
			"getSessionCell",
			"unscheduled-papers",
			"removeSessionFromSlot",
			"swap"
		],
		"reverse": false,
		"show_context": true,
		"use_buffer2": true,
		"whole_word": false,
		"wrap": true
	},
	"groups":
	[
		{
			"selected": 11,
			"sheets":
			[
				{
					"buffer": 0,
					"file": "sponsoring/sponsors-of-chi2015.php",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 5395,
						"regions":
						{
						},
						"selection":
						[
							[
								570,
								570
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountShouldRun": false,
							"WordCountSyntax": "php",
							"auto_complete": false,
							"bh_regions":
							[
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content"
							],
							"syntax": "Packages/PHP/PHP.tmLanguage",
							"tab_size": 2,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 2,
					"type": "text"
				},
				{
					"buffer": 1,
					"file": "attending/press.php",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 2333,
						"regions":
						{
						},
						"selection":
						[
							[
								388,
								388
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountSyntax": "php",
							"auto_complete": false,
							"bh_regions":
							[
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content"
							],
							"syntax": "Packages/PHP/PHP.tmLanguage",
							"tab_size": 2,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 66.0,
						"zoom_level": 1.0
					},
					"stack_index": 14,
					"type": "text"
				},
				{
					"buffer": 2,
					"file": "program.php",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 3292,
						"regions":
						{
						},
						"selection":
						[
							[
								2332,
								2332
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountSyntax": "php",
							"auto_complete": false,
							"bh_regions":
							[
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content"
							],
							"syntax": "Packages/PHP/PHP.tmLanguage",
							"tab_size": 2,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 700.0,
						"zoom_level": 1.0
					},
					"stack_index": 11,
					"type": "text"
				},
				{
					"buffer": 3,
					"file": "leftbar.php",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 9911,
						"regions":
						{
						},
						"selection":
						[
							[
								686,
								686
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountSyntax": "php",
							"auto_complete": false,
							"bh_regions":
							[
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content"
							],
							"syntax": "Packages/PHP/PHP.tmLanguage",
							"translate_tabs_to_spaces": false
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 9,
					"type": "text"
				},
				{
					"buffer": 4,
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 1084374,
						"regions":
						{
							"match":
							{
								"flags": 112,
								"regions":
								[
									[
										282,
										296
									],
									[
										426,
										440
									],
									[
										596,
										610
									],
									[
										706,
										720
									],
									[
										779,
										793
									],
									[
										847,
										861
									],
									[
										1036,
										1050
									],
									[
										1311,
										1325
									],
									[
										1455,
										1469
									],
									[
										1644,
										1658
									],
									[
										1769,
										1783
									],
									[
										1979,
										1993
									],
									[
										2075,
										2089
									],
									[
										2099,
										2113
									],
									[
										2273,
										2287
									],
									[
										2374,
										2388
									],
									[
										2564,
										2578
									],
									[
										2855,
										2869
									],
									[
										2941,
										2955
									],
									[
										2997,
										3011
									],
									[
										8175,
										8182
									],
									[
										8518,
										8525
									],
									[
										9342,
										9349
									],
									[
										9395,
										9402
									],
									[
										9635,
										9642
									],
									[
										9679,
										9686
									],
									[
										121368,
										121375
									]
								],
								"scope": ""
							}
						},
						"selection":
						[
							[
								9683,
								9683
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountShouldRun": true,
							"WordCountSyntax": "find results.hidden-tmlanguage",
							"bh_regions":
							[
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content"
							],
							"detect_indentation": false,
							"line_numbers": false,
							"output_tag": 2,
							"result_base_dir": "",
							"result_file_regex": "^([A-Za-z\\\\/<].*):$",
							"result_line_regex": "^ +([0-9]+):",
							"scroll_past_end": true,
							"syntax": "Packages/Default/Find Results.hidden-tmLanguage",
							"translate_tabs_to_spaces": false
						},
						"translation.x": 0.0,
						"translation.y": 2820.0,
						"zoom_level": 1.0
					},
					"stack_index": 1,
					"type": "text"
				},
				{
					"buffer": 5,
					"file": "program/full-schedule.php",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 13322,
						"regions":
						{
						},
						"selection":
						[
							[
								7162,
								7162
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountSyntax": "php",
							"auto_complete": false,
							"bh_regions":
							[
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content"
							],
							"syntax": "Packages/PHP/PHP.tmLanguage",
							"translate_tabs_to_spaces": false
						},
						"translation.x": 0.0,
						"translation.y": 3161.0,
						"zoom_level": 1.0
					},
					"stack_index": 6,
					"type": "text"
				},
				{
					"buffer": 6,
					"file": "js/data/sessions.json",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 109326,
						"regions":
						{
						},
						"selection":
						[
							[
								45786,
								45786
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountShouldRun": false,
							"WordCountSyntax": "json",
							"auto_complete": true,
							"bh_regions":
							[
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content"
							],
							"syntax": "Packages/JavaScript/JSON.tmLanguage",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 33749.0,
						"zoom_level": 1.0
					},
					"stack_index": 3,
					"type": "text"
				},
				{
					"buffer": 7,
					"file": "js/data/schedule.json",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 36629,
						"regions":
						{
						},
						"selection":
						[
							[
								1110,
								1110
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountSyntax": "json",
							"auto_complete": true,
							"bh_regions":
							[
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content"
							],
							"syntax": "Packages/JavaScript/JSON.tmLanguage",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 128.0,
						"zoom_level": 1.0
					},
					"stack_index": 5,
					"type": "text"
				},
				{
					"buffer": 8,
					"file": "attending/mobileapps.php",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 4684,
						"regions":
						{
						},
						"selection":
						[
							[
								858,
								858
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountSyntax": "php",
							"auto_complete": false,
							"bh_regions":
							[
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content"
							],
							"syntax": "Packages/PHP/PHP.tmLanguage",
							"tab_size": 2,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 249.0,
						"zoom_level": 1.0
					},
					"stack_index": 8,
					"type": "text"
				},
				{
					"buffer": 9,
					"file": "news.php",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 7292,
						"regions":
						{
						},
						"selection":
						[
							[
								441,
								441
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountSyntax": "php",
							"auto_complete": false,
							"bh_regions":
							[
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content"
							],
							"syntax": "Packages/PHP/PHP.tmLanguage",
							"tab_size": 2,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 7,
					"type": "text"
				},
				{
					"buffer": 10,
					"file": "js/main.js",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 2737,
						"regions":
						{
						},
						"selection":
						[
							[
								2123,
								2123
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountSyntax": "javascript",
							"auto_complete": false,
							"bh_regions":
							[
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content"
							],
							"syntax": "Packages/JavaScript/JavaScript.tmLanguage",
							"translate_tabs_to_spaces": false
						},
						"translation.x": 0.0,
						"translation.y": 760.0,
						"zoom_level": 1.0
					},
					"stack_index": 10,
					"type": "text"
				},
				{
					"buffer": 11,
					"file": "js/data/papers.json",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 2844117,
						"regions":
						{
						},
						"selection":
						[
							[
								1449064,
								1449064
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountShouldRun": false,
							"WordCountSyntax": "json",
							"auto_complete": true,
							"bh_regions":
							[
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content"
							],
							"syntax": "Packages/JavaScript/JSON.tmLanguage",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 532538.0,
						"zoom_level": 1.0
					},
					"stack_index": 0,
					"type": "text"
				},
				{
					"buffer": 12,
					"file": "program/papers-notes.php",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 1261,
						"regions":
						{
						},
						"selection":
						[
							[
								166,
								166
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountSyntax": "php",
							"bh_regions":
							[
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content"
							],
							"syntax": "Packages/PHP/PHP.tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 12,
					"type": "text"
				},
				{
					"buffer": 13,
					"file": "js/data/link.php",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 3266,
						"regions":
						{
						},
						"selection":
						[
							[
								1732,
								1732
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountSyntax": "php",
							"auto_complete": false,
							"bh_regions":
							[
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content"
							],
							"syntax": "Packages/PHP/PHP.tmLanguage",
							"translate_tabs_to_spaces": false
						},
						"translation.x": 0.0,
						"translation.y": 1462.0,
						"zoom_level": 1.0
					},
					"stack_index": 13,
					"type": "text"
				},
				{
					"buffer": 14,
					"file": "js/data/filters.json",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 6277,
						"regions":
						{
						},
						"selection":
						[
							[
								3206,
								3206
							]
						],
						"settings":
						{
							"BracketHighlighterBusy": false,
							"WordCountSyntax": "json",
							"auto_complete": true,
							"bh_regions":
							[
								"bh_angle",
								"bh_angle_center",
								"bh_angle_open",
								"bh_angle_close",
								"bh_angle_content",
								"bh_double_quote",
								"bh_double_quote_center",
								"bh_double_quote_open",
								"bh_double_quote_close",
								"bh_double_quote_content",
								"bh_round",
								"bh_round_center",
								"bh_round_open",
								"bh_round_close",
								"bh_round_content",
								"bh_tag",
								"bh_tag_center",
								"bh_tag_open",
								"bh_tag_close",
								"bh_tag_content",
								"bh_unmatched",
								"bh_unmatched_center",
								"bh_unmatched_open",
								"bh_unmatched_close",
								"bh_unmatched_content",
								"bh_curly",
								"bh_curly_center",
								"bh_curly_open",
								"bh_curly_close",
								"bh_curly_content",
								"bh_regex",
								"bh_regex_center",
								"bh_regex_open",
								"bh_regex_close",
								"bh_regex_content",
								"bh_square",
								"bh_square_center",
								"bh_square_open",
								"bh_square_close",
								"bh_square_content",
								"bh_single_quote",
								"bh_single_quote_center",
								"bh_single_quote_open",
								"bh_single_quote_close",
								"bh_single_quote_content",
								"bh_c_define",
								"bh_c_define_center",
								"bh_c_define_open",
								"bh_c_define_close",
								"bh_c_define_content",
								"bh_default",
								"bh_default_center",
								"bh_default_open",
								"bh_default_close",
								"bh_default_content"
							],
							"syntax": "Packages/JavaScript/JSON.tmLanguage",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 1601.0,
						"zoom_level": 1.0
					},
					"stack_index": 4,
					"type": "text"
				}
			]
		}
	],
	"incremental_find":
	{
		"height": 27.0
	},
	"input":
	{
		"height": 31.0
	},
	"layout":
	{
		"cells":
		[
			[
				0,
				0,
				1,
				1
			]
		],
		"cols":
		[
			0.0,
			1.0
		],
		"rows":
		[
			0.0,
			1.0
		]
	},
	"menu_visible": true,
	"output.find_results":
	{
		"height": 0.0
	},
	"output.git":
	{
		"height": 100.0
	},
	"pinned_build_system": "",
	"project": "chi2015.sublime-project",
	"replace":
	{
		"height": 66.0
	},
	"save_all_on_build": true,
	"select_file":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
			[
				"conn",
				"conn.php"
			]
		],
		"width": 0.0
	},
	"select_project":
	{
		"height": 500.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 380.0
	},
	"select_symbol":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"selected_group": 0,
	"settings":
	{
	},
	"show_minimap": true,
	"show_open_files": false,
	"show_tabs": true,
	"side_bar_visible": true,
	"side_bar_width": 297.0,
	"status_bar_visible": true,
	"template_settings":
	{
	}
}
