PCS ID,ACM ID,DOI,ACM DL URL,YT ID,YT URL,YT tags,YT playlists,YT privacy,YT embed code,Title,Authors,Abstract,Early Release
alt100,2732496,http://dx.doi.org/10.1145/2702613.2732496,http://dl.acm.org/citation.cfm?id=2732496,Rj6l7MqyjNA,www.youtube.com/watch?v=Rj6l7MqyjNA,CHI 2015;CHI 2015 alt.CHI,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/Rj6l7MqyjNA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,"""I Woke Up as a Newspaper"": Designing-in Interaction Analytics","Michael Evans, Lianne Kerlin, Caroline Jay","Spending the day as a newspaper, with your faculties and HCI curiosity intact, would allow rich observation of the interaction process: the reader’s touch, gaze, expression... all relating valuable information about the user experience. Digital devices – unlike newspapers – have the capacity to log interaction data. We are still some way from fully exploiting it however, due to the data’s size and complexity. Rather than simply logging data and trying to make sense of it, we suggest designing-in detailed UX-analytics. We report our experience challenging interaction designers to consider what they would like to know about the user, and how they could capture this data – from the starting point of a sentient newspaper.",TRUE
alt107,2732497,http://dx.doi.org/10.1145/2702613.2732497,http://dl.acm.org/citation.cfm?id=2732497,y-RMpTCMps8,www.youtube.com/watch?v=y-RMpTCMps8,CHI 2015;CHI 2015 alt.CHI,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/y-RMpTCMps8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Being Reasonable: A Manifesto for Improving the Inclusion of Disabled People in SIGCHI Conferences,"Reuben Kirkham, John Vines, Patrick Olivier","Participation levels of people with disabilities in the SIGCHI community reflect a general inadequacy in how they are supported, and their interests promoted, within the ACM, the wider computing industry and academia itself. In response, we propose a manifesto for overhauling existing SIGCHI practices to increase the opportunities for including a wide range of disabled people in our research community through dissemination venues such as CHI. We set out the moral case for change, before providing a summary of UK disability discrimination law which we use identify sources of direct and indirect discrimination. Our goal has been to go beyond just accessibility: instead we emphasize disability inclusion in a much broader sense, and articulate a range of steps that can be conducted in order to meet this. ",TRUE
alt129,2732501,http://dx.doi.org/10.1145/2702613.2732501,http://dl.acm.org/citation.cfm?id=2732501,2fu-FNcHMUM,www.youtube.com/watch?v=2fu-FNcHMUM,CHI 2015;CHI 2015 alt.CHI,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/2fu-FNcHMUM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Your Paper is Dead! Bringing Life to Research Articles with Animated Figures,"Tovi Grossman, Fanny Chevalier, Rubaiat Habib Kazi","The dissemination of scientific knowledge has evolved over the centuries from handwritten manuscripts transcribed and published as physical black and white prints-on-paper, to digital documents in full color available for consultation online. Even if it now primarily relies on digital media, academic publishing still generally adheres to its historical rigid paper-based style—where static content is presented at the ready-to-print letter format. In this paper, we reflect on our experience of authoring a published academic article that embeds an animated figure and discuss the opportunities and caveats of transitioning to such practice at the wider academic literature scale.",TRUE
alt130,2732502,http://dx.doi.org/10.1145/2702613.2732502,http://dl.acm.org/citation.cfm?id=2732502,gR1klXKbpQQ,www.youtube.com/watch?v=gR1klXKbpQQ,CHI 2015;CHI 2015 alt.CHI,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/gR1klXKbpQQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Communication in the Changing Dyadic Interaction of Diverse Players,"Mark Rice, Hong Huei Tay, Jamie Ng, Ranieri Koh","In this paper, we present the findings of a two month exploratory game study in which we compared the verbal and non-verbal communication practices of two independent groups of older adults. Among other factors, these groups differed in their education, technology literacy and physical functioning. Through observational measurements, we outline significant differences and trends in players’ paired interaction, which progressively changed through prolonged exposure to the game. By comparing player performance both within and between groups, we raise questions and provide some insights as to how differences in the backgrounds of older players can influence dyadic interaction in collocated play.",TRUE
alt136,2732504,http://dx.doi.org/10.1145/2702613.2732504,http://dl.acm.org/citation.cfm?id=2732504,uZDukdqd0go,www.youtube.com/watch?v=uZDukdqd0go,CHI 2015;CHI 2015 alt.CHI,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/uZDukdqd0go' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Consider the Moon. Human-Computer Bricolage of Extended Objects,"Cosima Rughinis, Razvan Rughinis","Our minds are extended through tools – from pencils on paper to clocks and computers. 'Extended minds' have gained acclaim in digital times, but have also stirred fear: do objects become smarter at our expense? We propose a new approach to help cultivate auspicious cognitive relationships with things: the 'extended object'. If our thoughts are extended through things, things can be symmetrically and methodically extended through our thoughts – in conversation, and in time. Let us consider the Moon: Can it colonize us?",TRUE
alt140,2732506,http://dx.doi.org/10.1145/2702613.2732506,http://dl.acm.org/citation.cfm?id=2732506,lz6-OaCk35w,www.youtube.com/watch?v=lz6-OaCk35w,CHI 2015;CHI 2015 alt.CHI,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/lz6-OaCk35w' width='640' height='360' frameborder='0' allowfullscreen='true'/>,ChameleonMask: Embodied Physical and Social Telepresence using human surrogates,"Kana Misawa, Jun Rekimoto","Chameleonmask is a telepresence system that shows a remote user’s face on the other user’s face. While most telepresence systems have been designed to provide a remote user’s existence with a teleoperated robot, the system uses a real human as a surrogate for another remote user. To do this, a surrogate user wears a mask-shaped display that shows a remote user’s live face, and a voice channel transmits a remote user’s voice. A surrogate user mimics a remote user by following the remote user’s directions. This design is based on our hypothesis assuming physical and social telepresence can be embodied by such a surrogate human who imitates the remote user. It also eliminates many difficulties of teleoperated robots wandering in the environment. Our pilot study confirmed that people could regard the masked person as a right person.",TRUE
alt142,2732507,http://dx.doi.org/10.1145/2702613.2732507,http://dl.acm.org/citation.cfm?id=2732507,_Y8MVfoiFQw,www.youtube.com/watch?v=_Y8MVfoiFQw,CHI 2015;CHI 2015 alt.CHI,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/_Y8MVfoiFQw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Reimagining Digital Fabrication as Performance Art,"Laura Devendorf, Daniela K Rosner","Within the HCI literature to date, digital fabrication systems are often oriented towards pre-determined goals and discussed in terms of the meaning of objects produced rather than the meanings of actions from which those object emerged. This paper draws from contemporary performance art to inform fabrication system designs that frame meaningful actions as the primary product of fabrication activity. In doing so, we open up new generative ideas for HCI theory and practice, specifically in relation to posthumanist and research through design agendas.",TRUE
alt149,2732508,http://dx.doi.org/10.1145/2702613.2732508,http://dl.acm.org/citation.cfm?id=2732508,YIzJ1Q9e2NA,www.youtube.com/watch?v=YIzJ1Q9e2NA,CHI 2015;CHI 2015 alt.CHI,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/YIzJ1Q9e2NA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,The Broken Dream of Pervasive Sentient Ambient Calm Invisible Ubiquitous Computing,"Matthew P. Aylett, Aaron Quigley","We dreamt of technology becoming invisible, for our wants and needs to be primary and the tools we use for making them a reality to become like a genie, a snap of the fingers and ta daa, everything is realised. What went wrong? Was this always an impossible dream? How did we end up with this fetishised obsession with mobile phones? How did we end up with technology tearing apart our sense of experience and replacing it with 'Likes'. No one meant this to happen, not even US Corporates, they just wanted to own us, not diminish our sense of existing and interacting within the real world. In this paper we consider how tools took over, and how the dream of ubiquitous (or whatever its called) computing was destroyed. We rally rebellious forces and consider how we might fight back, and whether we should even bother trying.",TRUE
alt151,2732509,http://dx.doi.org/10.1145/2702613.2732509,http://dl.acm.org/citation.cfm?id=2732509,OpHJVqhTmhg,www.youtube.com/watch?v=OpHJVqhTmhg,CHI 2015;CHI 2015 alt.CHI,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/OpHJVqhTmhg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Emergent Interfaces: Constructive Assembly of Identical Units,"Alexandru Dancu, Stig Anton Nielsen, Kening Zhu, Ayça Ünlüer, Max Witt, Catherine Hedler, Hanna Frank, Axel Pelling, Christian Carlsson, Morten Fjeld","In this paper, we present five types of constructive assemblies that emerge through a form-finding process resembling growth. The synthetic growth is obtained through the assembly of identical blocks performed by two competing users. \ Each block type gives rise to different morphologies during each assembly session depending on the user and the environment that is augmented through projection on the synthetic structure and around it.  \ The digitally augmented tangible interface is evaluated by professionals and students in interaction design.  \ We introduce the concept of Emergent Interfaces (EI), which proposes harnessing non-determinism, temporal design, and self-organization. \ This work could contribute to organic user interfaces and morphogenetic engineering.",TRUE
alt153,2732511,http://dx.doi.org/10.1145/2702613.2732511,http://dl.acm.org/citation.cfm?id=2732511,K3MAv-rdrM0,www.youtube.com/watch?v=K3MAv-rdrM0,CHI 2015;CHI 2015 alt.CHI,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/K3MAv-rdrM0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,A Formal Analysis of the ISO 9241-210 Definition of User Experience,"Alexander G Mirnig, Alexander Meschtscherjakov, Daniela Wurhofer, Thomas Meneweger, Manfred Tscheligi","User Experience (UX) is a major concept in HCI and a variety of different UX definitions have been suggested within the scientific community. An ISO UX definition has been presented to standardize the term from an industry perspective. We introduce methods from formal logic in order to formalize and analyze the ISO UX definition with regard to consistency and ambiguities and present recommendations for an improved version. Although this kind of formalization is not common within the CHI community, we show that quasi-formal methods provide an alternative way of analyzing widely discussed HCI terms, such as UX, to deepen its understanding.",TRUE
alt154,2732512,http://dx.doi.org/10.1145/2702613.2732512,http://dl.acm.org/citation.cfm?id=2732512,x6QjToYc-gQ,www.youtube.com/watch?v=x6QjToYc-gQ,CHI 2015;CHI 2015 alt.CHI,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/x6QjToYc-gQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Not all Days are Equal: Investigating the Meaning in the Digital Calendar,"Daniel Buzzo, Nicolo Merendino","The electronic calendar is a common tool used by large numbers of people to reflect and shape their daily activities. It's function and structure is rooted in legacy representations dating back thousands of years. Collaborating with designers and engineers our project seeks to re-consider what the calendar does for us and how we may perceive and represent our time, personally and collectively.  \  \ This paper investigates the background to 'the calendar problem' and documents design-led research. Seeking to identify some of the key problems with the current representation and to establish criteria for new interpretations of the meaning of calendar.",TRUE
case115,2702955,http://dx.doi.org/10.1145/2702613.2702955,http://dl.acm.org/citation.cfm?id=2702955,XU1Id4faleg,www.youtube.com/watch?v=XU1Id4faleg,CHI 2015;CHI 2015 Case Studies,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/XU1Id4faleg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,12 Way Mirror –  Reflecting on Window Displays.,"Lida Theodorou, Patrick G. T. Healey","Shop windows are the paradigmatic design environment for attracting and holding people’s attention. They also provide a handy mirror in which people can check their appearance. The 12-way mirror project plays with this duality by building and testing an interactive installation that tracks people’s reflections as they look into a shop window. Three versions of the installation are compared, one with static mirrors, one with moving mirrors and one with face-tracking mirrors. These were tested over a 5 day period in the window display of an Eyewear shop on a busy commercial road in East London. Data were collected on how many people looked in the window, for how long and what they did while looking. The results show that while movement attracts people’s attention and stops them, their own reflection is most effective in keeping their interest.",TRUE
case128,2702959,http://dx.doi.org/10.1145/2702613.2702959,http://dl.acm.org/citation.cfm?id=2702959,RbXAxghid0w,www.youtube.com/watch?v=RbXAxghid0w,CHI 2015;CHI 2015 Case Studies,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/RbXAxghid0w' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Connective MOOC for K-12 Teacher Professional Development in Native American Pueblo Schools,"Josephine Kilde, Lorenzo Gonzales","This case study describes preliminary work toward developing a teacher training project that is intended to increase STEM proficiency among elementary and high school teachers in Native American Pueblo schools in New Mexico. This project builds upon prior work that trained K-12 teachers to use investigative teaching, which in turn had a significant positive impact on the math and science proficiency of Native American and Hispanic students. The current project seeks to use Connectivist Massive Open Course (cMOOC) technology to capture and scale this professional development through the use of video, imagery, and community building in order to integrate Native American learning processes.  The overall objective is to enable Pueblo teachers to more effectively teach STEM subject matter, as measured by an increase in both teacher and student content knowledge scores.  If successful, the use of these technologies should facilitate rapid expansion of the program in all Native American reservation schools in United States, Canada, and Mexico.",TRUE
case136,2702964,http://dx.doi.org/10.1145/2702613.2702964,http://dl.acm.org/citation.cfm?id=2702964,YsKNyteWsqc,www.youtube.com/watch?v=YsKNyteWsqc,CHI 2015;CHI 2015 Case Studies,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/YsKNyteWsqc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Photo Based Observation Method: How to quickly observe the behavior of the user,"HeeJeong Son, Hyunsoo Kim, Hyojung Kim","Although users are still important in ever-changing mobile market, the time for understanding needs of the users is limited. In this context, we have utilized photos in observing the users in PBO method (Photo Based Observation Method) with which the behavioral pattern of the users can be easily and quickly discovered. PBO method has a 5-step research process – prediction, collection, classification, deduction and verification. Our 10 examiners, respectively, have taken photos of easily-witnessed user behaviors around each of them with their own smartphones for 7 days and we have collected and analyzed the photos. As a result, we found out 7 different patterns on how the users utilize their mobile devices. We expect such methodology to be useful in easily and quickly observing and collecting a common behavioral pattern of multiple users, providing us an opportunity to discover the users’ needs through their natural actions. ",TRUE
case138,2702966,http://dx.doi.org/10.1145/2702613.2702966,http://dl.acm.org/citation.cfm?id=2702966,DxcLfYWKe8Y,www.youtube.com/watch?v=DxcLfYWKe8Y,CHI 2015;CHI 2015 Case Studies,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/DxcLfYWKe8Y' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Representation Strategies Adopted by Participants in a Population Stereotype Hunt: A Case Study for Icon Design,"Avijit Sengupta, Klarissa T.T. Chang, Maffee Peng-Hui Wan, Wen Yong Chua","Population Stereotype tells interaction designers just one-half of the complete story. It informs them only about the level of general consensus regarding each representation generated by different participants. It does not provide answers to those questions, which ask how the representation is to be achieved. Identification of different representation strategies adopted by different participants can reveal the rest of the story. In the presence of more than one or no strong contenders (population stereotype), adoption of the right representation strategy can be really beneficial. As most of the representational strategies are complementary to each other, the combination of different representational strategies can lead towards a more representative icon development.",TRUE
case139,2702967,http://dx.doi.org/10.1145/2702613.2702967,http://dl.acm.org/citation.cfm?id=2702967,BYC02jnlhKY,www.youtube.com/watch?v=BYC02jnlhKY,CHI 2015;CHI 2015 Case Studies,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/BYC02jnlhKY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Can Androids Be Salespeople in the Real World?,"Miki Watanabe, Kohei Ogawa, Hiroshi Ishiguro","The roles of robots in the real world have become more diverse depending on their bodily properties. In this study, we aim to determine the roles that androids, whose bodily properties resemble humans, could serve in the real world.  \ Selling and purchasing are common human activities. Therefore, we proposed the use of an android as a salesperson with cognitive and affective strategies utilizing the advantages of online- and counter- selling methods. We conducted a field study to investigate whether androids could sell goods in a department store. As a result, our sales strategies worked well and the android could sell 43 sweaters that cost approximately 100 dollars each for 10 days. These results are important knowledge for determining how androids may serve new roles and communicate with humans in the real world.",TRUE
case147,2702969,http://dx.doi.org/10.1145/2702613.2702969,http://dl.acm.org/citation.cfm?id=2702969,RlLfrW9PmVo,www.youtube.com/watch?v=RlLfrW9PmVo,CHI 2015;CHI 2015 Case Studies,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/RlLfrW9PmVo' width='640' height='360' frameborder='0' allowfullscreen='true'/>,TRANSFORM: Embodiment of “Radical Atoms” at Milano Design Week,"Hiroshi Ishii, Daniel Leithinger, Sean Follmer, Amit Zoran, Philipp Schoessler, Jared Counts","RANSFORM fuses technology and design to celebrate the transformation from a piece of static furniture to a dynamic machine driven by streams of data and energy. TRANSFORM aims to inspire viewers with unexpected transformations, as well as the aesthetics of a complex machine in motion. This paper describes the concept, engine, product, and motion design of TRANSFORM, which was first exhibited at LEXUS DESIGN AMAZING 2014 MILAN in April 2014.",TRUE
case183,2702975,http://dx.doi.org/10.1145/2702613.2702975,http://dl.acm.org/citation.cfm?id=2702975,pMcj6TVeNDM,www.youtube.com/watch?v=pMcj6TVeNDM,CHI 2015;CHI 2015 Case Studies,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/pMcj6TVeNDM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Colormaps that Improve Perception of High-Resolution Ocean Data,"Francesca Samsel, Mark Petersen, Terece Geld, Greg Abram, Joanne Wendelberger, James Ahrens","Scientists from the Climate, Ocean and Sea Ice Modeling Team (COSIM) at the Los Alamos National Laboratory (LANL) are interested in gaining a deeper understanding of three primary ocean currents: the Gulf Stream, the Kuroshio Current, and the Agulhas Current & Retroflection. To address these needs, visual artist Francesca Samsel teamed up with experts from the areas of computer science, climate science, statistics, and perceptual science.  By engaging an artist specializing in color, we created colormaps that provide the ability to see greater detail in these high-resolution datasets.  The new colormaps applied to the POP dataset enabled scientists to see areas of interest unclear using standard colormaps.  Improvements in the perceptual range of color allowed scientists to highlight structures within specific ocean currents. Work with the COSIM team members drove development of nested colormaps which provide further detail to the scientists.",TRUE
crs100,2706665,http://dx.doi.org/10.1145/2702613.2706665,http://dl.acm.org/citation.cfm?id=2706665,ogC1xa41Ayw,www.youtube.com/watch?v=ogC1xa41Ayw,CHI 2015;CHI 2015 Courses,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/ogC1xa41Ayw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Learn to Sketch (Even if You Can’t Draw): Hands-on Sketching Course,Stephanie Foehrenbach,Sketching as a technique to quickly draw something on a piece of paper can be used to explore and communicate ideas. Practitioners can make use of their ability to draw sketches from an early phase of a project on. It can be valuable not only for the exploration of ideas but also for gathering feedback from stakeholders and to foster a common understanding of requirements and concepts. This course introduces basic sketching techniques and a visual language which participants can immediately apply. It is a hands-on course which allows participants to do a lot of sketching during the session.,TRUE
crs103,2706667,http://dx.doi.org/10.1145/2702613.2706667,http://dl.acm.org/citation.cfm?id=2706667,X8X4O70CCZ0,www.youtube.com/watch?v=X8X4O70CCZ0,CHI 2015;CHI 2015 Courses,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/X8X4O70CCZ0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Designing with the Mind in Mind: The Psychological Basis for UI Design Guidelines,Jeff A Johnson,"UI design rules and guidelines are not simple recipes.  Applying them effectively requires determining rule applicability and precedence and balancing trade-offs when rules compete.  By understanding the underlying psychology, designers and evaluators enhance their ability to apply design rules. This one-part (80-minute) course explains that psychology.",TRUE
crs107,2706671,http://dx.doi.org/10.1145/2702613.2706671,http://dl.acm.org/citation.cfm?id=2706671,WWadkBFAZAc,www.youtube.com/watch?v=WWadkBFAZAc,CHI 2015;CHI 2015 Courses,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/WWadkBFAZAc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Conceptual Models: Core to Good Design,Jeff A Johnson,"A crucial step in designing a user interface for a software application is to design a coherent, task-focused conceptual model (CM).  With a CM, designers design better, developers develop better, and users learn and use better.  Unfortunately, this step is often skipped, resulting in incoherent, arbitrary, inconsistent, overly-complex applications that impede design, development, learning, understanding, and use.  This course covers what CMs are, how they help, how to develop them, and provides hands-on experience.",TRUE
crs109,2706673,http://dx.doi.org/10.1145/2702613.2706673,http://dl.acm.org/citation.cfm?id=2706673,3_oqADvaBfc,www.youtube.com/watch?v=3_oqADvaBfc,CHI 2015;CHI 2015 Courses,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/3_oqADvaBfc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,HCI Lessons: From Earth to Outer Space... and Back,"Guy André Boy, Jeffrey M Bradshaw, Soyeon Yi","This storytelling course will bring, in meaningful terms, insightful concepts, methods and tools that are used in the air and space domains. HCI for complex engineered systems challenges conventional HCI solutions to propose new kinds of approaches that turn out to be very useful for solving HCI complex problems. Participants will design devices usable on Earth using accumulated knowledge and tips from aerospace experience. Creativity, in the sense of synthesis and integration, and design thinking will be at the center of this course, where participants will learn how to state and solve a complex design problem, and deliver the resulting product.",TRUE
crs128,2706686,http://dx.doi.org/10.1145/2702613.2706686,http://dl.acm.org/citation.cfm?id=2706686,NN7LSHVFwIg,www.youtube.com/watch?v=NN7LSHVFwIg,CHI 2015;CHI 2015 Courses,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/NN7LSHVFwIg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,"Design and Adaptation for Cross-Device, Context-dependent User Interfaces",Fabio Paternò,"This tutorial aims to help user interface designers and developers to understand the issues involved in multi-device, context-dependent interactive applications, which can be accessed through wearable, mobile and stationary devices even exploiting different interaction modalities. It will provide a discussion of the possible solutions in terms of concepts, techniques, languages, and tools, with particular attention to Web environments. The tutorial will deal with the various strategies in order to adapt, distribute, and migrate the user interface according to the context of use. ",TRUE
int105,2725428,http://dx.doi.org/10.1145/2702613.2725428,http://dl.acm.org/citation.cfm?id=2725428,2jw8eTSJb_I,www.youtube.com/watch?v=2jw8eTSJb_I,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/2jw8eTSJb_I' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Harmonious Haptics: Enhanced Tactile Feedback Using a Mobile and a Wearable Device,"Sungjae Hwang, John Song, Junghyeon Gim","Smartwatches now allow information to be conveniently accessed directly from the user’s wrist. However, the smartwatches currently available in the market offer a limited number of applications. In this paper, we propose a new interaction technique named Harmonious Haptics, which provides users with enhanced tactile sensations by utilizing smartwatches as additional tactile displays for smartphones. When combined with typical mobile devices, our technique enables the design of a wide variety of tactile stimuli. To illustrate the potential of our approach, we developed a set of example applications that provide users with rich tactile feedback such as feeling textures in a graphical user interface, transferring a file between the tablet and the smartwatch device, and controlling UI components.",TRUE
int108,2725429,http://dx.doi.org/10.1145/2702613.2725429,http://dl.acm.org/citation.cfm?id=2725429,tNE8bMFDdn8,www.youtube.com/watch?v=tNE8bMFDdn8,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/tNE8bMFDdn8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Low-Fidelity Fabrication: Speeding up Design Iteration of 3D Objects,"Stefanie Mueller, Dustin Beyer, Tobias Mohr, Serafima Gurevich, Alexander Teibrich, Lisa Pfisterer, Kerstin Guenther, Johannes Frohnhofen, Hsiang-Ting Chen, Patrick Baudisch, Sangha Im, François V Guimbretière","Low-fidelity fabrication systems speed up rapid prototyping by printing intermediate versions of a prototype as fast, low-fidelity previews. Only the final version is fabricated as a full high-fidelity 3D print. This allows designers to iterate more quickly—achieving a better design in less time.  \  \ Depending on what is currently being tested, low-fidelity fabrication is implemented in different ways: (1) faBrickator allows for a modular approach by substituting sub-volumes of the 3D model with building blocks. (2) WirePrint allows for quickly testing the shape of an object, such as the ergonomic fit, by printing wireframe structures. (3) Platener preserves the technical function by substituting 3D print with laser-cut plates of the same size and thickness.  \  \ At our CHI’15 interactivity booth, we give a combined live demo of all three low-fidelity fabrication systems—putting special focus on our new low-fidelity fabrication system Platener (paper at CHI’15).  \ ",TRUE
int109,2725430,http://dx.doi.org/10.1145/2702613.2725430,http://dl.acm.org/citation.cfm?id=2725430,rSjE0NGhUKY,www.youtube.com/watch?v=rSjE0NGhUKY,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/rSjE0NGhUKY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,PaperPulse: An Integrated Approach to Fabricating Interactive Paper,"Raf Ramakers, Kashyap Todi, Kris Luyten","We present PaperPulse, a design and fabrication approach that enables designers to produce standalone interactive paper artifacts by augmenting them with electronics. With PaperPulse, users overlay visual designs with widgets provided in the design tool. PaperPulse provides three families of widgets, designed for smooth integration with paper, for a total of 20 different interactive components. We also contribute a demonstration and recording approach, Pulsation, that allows specifying interaction logic. Using the final design and the recorded Pulsation logic, PaperPulse generates layered electronic circuit designs, and code that can be deployed on a microcontroller. By following automatically generated assembly instructions, designers can seamlessly integrate the microcontroller and widgets in the final paper artifact.",TRUE
int110,2725431,http://dx.doi.org/10.1145/2702613.2725431,http://dl.acm.org/citation.cfm?id=2725431,b7HrW6-rouQ,www.youtube.com/watch?v=b7HrW6-rouQ,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/b7HrW6-rouQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Level-Ups: Motorized Stilts that Simulate Stair Steps in Virtual Reality,"Dominik Schmidt, Robert Kovacs, Vikram Mehta, Udayan Umapathi, Sven Köhler, Lung-Pan Cheng, Patrick Baudisch","We present “Level-Ups”, computer-controlled stilts that allow virtual reality users to experience walking up and down steps. Each Level-Up unit is a self-contained device worn like a boot. Its main functional element is a vertical actuation mechanism mounted to the bottom of the boot that extends vertically. Unlike traditional solutions that are integrated with locomotion devices, Level-Ups allow users to walk around freely (“real-walking”). We present Level-Ups in a demo environment based on a head-mounted display, optical motion capture, and integrated with a game engine.",TRUE
int115,2725432,http://dx.doi.org/10.1145/2702613.2725432,http://dl.acm.org/citation.cfm?id=2725432,b1Mlfqwxa-I,www.youtube.com/watch?v=b1Mlfqwxa-I,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/b1Mlfqwxa-I' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Designing Engaging Data in Communities,"Tim Regan, David Sweeney, John Helmes, Vasillis Vlachokyriakos, Siân Lindley, Alex Taylor","We present two sets of ‘data technologies’ that we have designed to collect and display local data, both derived from our engagement with a community. The first, Bull-frog, is a bespoke voting device. The second, a series of physical charts, respond to the increasing sophistica-tion of data visualisations by making playful use of pie charts and bar graphs, reimagining them in mechanical forms that are compelling but easily readable.",TRUE
int116,2725433,http://dx.doi.org/10.1145/2702613.2725433,http://dl.acm.org/citation.cfm?id=2725433,uWbQkTrBQaQ,www.youtube.com/watch?v=uWbQkTrBQaQ,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/uWbQkTrBQaQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,The EmotiveModeler: An Emotive Form Design CAD Tool,"Philippa Mothersill, V. Michael Bove Jr.","Whether or not we are experts in the design language of objects, we have an unconscious understanding of the emotional character of their forms.  The EmotiveModeler integrates knowledge about our emotive perception of shapes into a CAD tool that uses descriptive adjectives as an input to aid designers in creating objects that can communicate emotive character.  Through inputting words into the EmotiveModeler UI in the Rhinoceros 3D modeling software, both expert and novice designers can manipulate the design of a bottle to express emotive character through its form.",TRUE
int117,2725434,http://dx.doi.org/10.1145/2702613.2725434,http://dl.acm.org/citation.cfm?id=2725434,9ctpGp1Kuio,www.youtube.com/watch?v=9ctpGp1Kuio,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/9ctpGp1Kuio' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Remnance of Form: Interactive Narratives through Unexpected Behaviors of a Shadow,"Sang-won Leigh, Asta Roseway, Ann Paradiso, Pattie Maes","Remnance of Form is an interactive installation that explores the dynamic tension between an object and its shadow. By fusing light, projection, and motion technologies, the shadow can now detach itself from its former role. This creates a new narrative that challenges our perception of reality, what’s real and what’s not. Through several playful vignettes, the shadow interacts with viewers’ presence, body posture, and their manipulation of the light source creating the shadow.",TRUE
int124,2725436,http://dx.doi.org/10.1145/2702613.2725436,http://dl.acm.org/citation.cfm?id=2725436,Fwl0Mf41GzE,www.youtube.com/watch?v=Fwl0Mf41GzE,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/Fwl0Mf41GzE' width='640' height='360' frameborder='0' allowfullscreen='true'/>,EdiPulse: Turning Physical Activity Into Chocolates,"Rohit Ashok Khot, Ryan Pennings, Florian 'Floyd' Mueller","We present EdiPulse that creates 3D printed chocolates displaying cheerful messages using the heart rate data of physical activity. Our work expands the view on representing physical activity data through the use of edible materials such as chocolates, which additionally serves as a hedonic reward for doing the physical activity. Ultimately, with this work, we aim to inspire and guide design thinking on food printing, which we believe opens up new interaction possibilities to support the physical activity experience.",TRUE
int132,2725439,http://dx.doi.org/10.1145/2702613.2725439,http://dl.acm.org/citation.cfm?id=2725439,9yg8xoZQFBM,www.youtube.com/watch?v=9yg8xoZQFBM,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/9yg8xoZQFBM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Researcher: A Reading Application Helping the Flow of Research in Tablet and Mobile Phone,"Minjeong Kang, Juhyun Eune","With a growing digital environment, a huge quantity of digital content is being created and distributed quickly. Therefore, people from academia are under pressure to create and study such content. In addition, there are a number of reading applications supporting different functions and diverse platforms, which distract the flow of research. To solve this problem, we created a prototype reading app, Researcher, for the tablet PC and mobile phone, which helps the flow of research by providing cooperation among platforms, seamlessly circulating between consumption and creation of contents, prioritizing contents by context, and holding attention by multimodal input. We conducted an in-depth interview and survey to verify the effectiveness of the features and to find out the appropriate modality of input for the flow of research.",TRUE
int138,2725441,http://dx.doi.org/10.1145/2702613.2725441,http://dl.acm.org/citation.cfm?id=2725441,IBrdQ5DngSY,www.youtube.com/watch?v=IBrdQ5DngSY,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/IBrdQ5DngSY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,BandSense: Pressure-sensitive Multi-touch Interaction on a Wristband,"Youngseok Ahn, Sungjae Hwang, Hyungook Yoon, Jung-hee Ryu","In this paper, we propose a new interaction technique, called BandSense, which allows pressure-sensitive multi-touch interaction on a wristband. The proposed method provides users with a broader interaction area and higher input expressiveness, enabling a precision interaction with a less occlusion. To illustrate the potential of our approach, we present a series of example applications with several input vocabularies. We also describe the overall architecture of our system. We believe that our technique would greatly help users control a smartwatch easily and conveniently.",TRUE
int139,2725442,http://dx.doi.org/10.1145/2702613.2725442,http://dl.acm.org/citation.cfm?id=2725442,wAAyKGH_Pk4,www.youtube.com/watch?v=wAAyKGH_Pk4,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/wAAyKGH_Pk4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Wearable Solution for Industrial Maintenance,"Sam Zheng, Patrik Matos, Cedric Foucault, Siddharth Dasari, Meng Yuan, Stuart Goose","Wearable technology, such as Google Glass, offers potential benefits to engineers in industrial settings. We designed and developed a wearable solution for industrial maintenance, which 1) provides workflow guidance to the user, 2) supports hands-free operation, 3) allows the users to focus on their work, and 4) enables an efficient way for collaborating with a remote expert. The prototype, which was demonstrated at InnoTrans 2014, the largest international trade show for train technology, received positive feedback from many potential users and customers.",TRUE
int143,2725443,http://dx.doi.org/10.1145/2702613.2725443,http://dl.acm.org/citation.cfm?id=2725443,GdQ7GcU217o,www.youtube.com/watch?v=GdQ7GcU217o,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/GdQ7GcU217o' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Development of Realistic Digital Expression of Human Avatars through Pupillary Responses based on Heart Rate,"Myoung Ju Won, Sangin Park, SungTeac Hwang, Mincheol Whang","The eyes of a virtual human avatar are the fundamental means for communicating language and affective feelings in a virtual environment. For this purpose, this study evaluates user's visual feeling according to the changes pupillary responses based on the heart rate for a representing a human avatar; this is considered as a new factor for representing a realistic avatar. We construct a human avatar in which the pupillary response is delivered real-time based on the heart rate. The results can be regarded as the basis for designing a realistic human avatar system by supporting a new visual realistic representing factor.",TRUE
int144,2725444,http://dx.doi.org/10.1145/2702613.2725444,http://dl.acm.org/citation.cfm?id=2725444,8OKSZlWIFp8,www.youtube.com/watch?v=8OKSZlWIFp8,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/8OKSZlWIFp8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Waving Authentication: Your Smartphone Authenticate You on Motion Gesture,"Feng Hong, Meiyu Wei, Shujuan You, Yuan Feng, Zhongwen Guo","User authentication is important to protect sensitive and private information for smartphone users. \ We propose Waving Authentication (WA) which is a motion gesture authentication system based on accelerometer. WA utilizes eight distinguishing features hiding in the acceleration traces of motion gestures and exploits one-class Support Vector Machine for classification. It is insusceptible to shoulder surfing attacks. In the interactivity, we first \ provide two exhibitors' phones for audiences to try intruding WA by all kinds of waving. And we present our WA app to the audience smartphones, letting the phone to recognize their owners on audiences motion gesture.",TRUE
int145,2725445,http://dx.doi.org/10.1145/2702613.2725445,http://dl.acm.org/citation.cfm?id=2725445,68tlooOilto,www.youtube.com/watch?v=68tlooOilto,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/68tlooOilto' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Data Transmission Method for Mobile Phone Using Groove Scan Code,"Junbong Song, Hyunwoo Bang","A new mobile phone data-transmit method, groove scan code, is suggested for transmitting low-size data. As groove scan code uses audible collision sound generated by scanning on pre-encoded groove pattern as a data source, it can be implemented at minimum cost. By decoding the scanning sound, the original data can be transferred to mobile phone. Through the feasibility tests, we achieved an acceptable data decoding success rate and transmitting speed. The usability and intuitiveness are scored through user interviews.",TRUE
int147,2725446,http://dx.doi.org/10.1145/2702613.2725446,http://dl.acm.org/citation.cfm?id=2725446,G2l06c0eHVQ,www.youtube.com/watch?v=G2l06c0eHVQ,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/G2l06c0eHVQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,NOISA: A Novel Intelligent System Facilitating Smart Interaction,"Koray Tahiro_lu, Thomas Svedström, Valtteri Wikström","In this paper, we describe NOISA (Network of Intelligent Sonic Agents). NOISA is an intelligent system that acts to maintain and deepen the user’s engagement with digital artefacts by learning from the user’s actions and behavioural patterns in the moment of interaction. It facilitates a smart interaction by monitoring user’s bodily movements, facial expressions and control inputs. We present our model and system in a musical context, interfaced with our digital musical instrument (DMI). Our concept can be further extended to possible application areas in Human Computer Interaction (HCI) research field.",TRUE
int149,2725448,http://dx.doi.org/10.1145/2702613.2725448,http://dl.acm.org/citation.cfm?id=2725448,C2AP_f2DNnc,www.youtube.com/watch?v=C2AP_f2DNnc,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/C2AP_f2DNnc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Sustainable Transport System: A Wheel Based Interactive Information Installation,"Geon Dong Kim, Juhyun Eune","Sustainable Transport System is an interactive wheel based information installation where users can watch the information projected on the wheel with a narration. Its information consists of 9 questions that are related with road transport systems ranging from 'The history of road traffic' to 'How will the sustainable traffic system evolve in the future?’ The circular interface was used to show information in a pie chart, diagram and history of wheel. This interface contains the meaning of sustainable circulation. The modalities of the project are Vision, Sonic, and Touch. A potentiometer sensor is mounted onto the center of wheel, which is linked with Flash action script through Arduino as the technical method. The user enables the information to be navigated by rotating the wheel clockwise from No.1 to No.9 and counterclockwise from No.9 to No.1. CHI attendees can experience the information ranging from history of road transport to necessity of sustainable transport system easily, interestingly and engagingly.",TRUE
int152,2725451,http://dx.doi.org/10.1145/2702613.2725451,http://dl.acm.org/citation.cfm?id=2725451,5AEDYPo46NM,www.youtube.com/watch?v=5AEDYPo46NM,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/5AEDYPo46NM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,TESSA - Toolkit for Experimentation  with Multimodal Sensory Substitution and Augmentation,"Carlos Sainz Martinez, Faustina Hwang","TESSA is a toolkit for experimenting with sensory augmentation. It includes hardware and software to facilitate rapid prototyping of interfaces that can enhance one sense using information gathered from another sense. The toolkit contains a range of sensors (e.g. ultrasonics, temperature sensors) and actuators (e.g. tactors or stereo sound), designed modularly so that inputs and outputs can be easily swapped in and out and customized using TESSA’s graphical user interface (GUI), with “real time” feedback.  The system runs on a Raspberry Pi with a built-in touchscreen, providing a compact and portable form that is amenable for field trials.  At CHI Interactivity, the audience will have the opportunity to experience sensory augmentation effects using this system, and design their own sensory augmentation interfaces.",TRUE
int154,2725452,http://dx.doi.org/10.1145/2702613.2725452,http://dl.acm.org/citation.cfm?id=2725452,V9xxa-7crDg,www.youtube.com/watch?v=V9xxa-7crDg,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/V9xxa-7crDg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,WoBo: Multisensorial travels through Oculus Rift,"Stefano Fibbi, Fabio Sorrentino, Lucio Davide Spano, Riccardo Scateni","WoBo (World in a Box) aims to provide a new experience for travellers, allowing them to visit distant or hardly reachable places through the exploitation of consumer cameras and a head mounted display. The experience consists in watching a 360-degrees video with 3D audio in a dedicated cabin. The user can select videos shot in different places, which have been created with six consumer cameras. We describe the proposed experience, the hardware and the software used for a first prototype.",TRUE
int155,2725453,http://dx.doi.org/10.1145/2702613.2725453,http://dl.acm.org/citation.cfm?id=2725453,m_JRNIemdmc,www.youtube.com/watch?v=m_JRNIemdmc,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/m_JRNIemdmc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Canvas Dance: An Interactive Dance Visualization for Large-Group Interaction,"Carla F Griggio, Mario Romero","We present Canvas Dance, a prototype of an interactive dance visualization for large-group interaction that targets non-professional dancers in informal environments such as parties or nightclubs, and uses the smartphones of the dancers as the input device for the motion signal. The visualization is composed of individual representations for each dancer, and the visual mappings designed for their dance moves have three main goals: to help the users identify their own representation, to uncover and inspire imitation among dancers, and to support unpredictable dance moves. ",TRUE
int158,2725454,http://dx.doi.org/10.1145/2702613.2725454,http://dl.acm.org/citation.cfm?id=2725454,5W7fyW7DVmM,www.youtube.com/watch?v=5W7fyW7DVmM,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/5W7fyW7DVmM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Nebula: An Interactive Garment Designed for Functional Aesthetics,"Ludvig Elblaus, Vasiliki Tsaknaki, Vincent Lewandowski, Roberto Bresin","In this paper we present Nebula, a prototype for examining the properties of textiles, fashion accessories, and digital technologies to arrive at a garment design that brings these elements together in a cohesive manner. Bridging the gap between everyday performativity and enactment, we aim at discussing aspects of the making process, interaction and functional aesthetics that emerged. \  \ Nebula is part of the Sound Clothes project that aims at exploring the expressive potential of wearable technologies creating sound from motion. \ ",TRUE
int159,2725456,http://dx.doi.org/10.1145/2702613.2725456,http://dl.acm.org/citation.cfm?id=2725456,89d_7l9vyls,www.youtube.com/watch?v=89d_7l9vyls,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/89d_7l9vyls' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Digiti Sonus v2: New Interface for Fingerprint Data Sonification using Hand Motion,"Yoon Chung Han, Byeong-jun Han","Digiti Sonus v2 is a new interface for fingerprint data sonification using audience’s biometric data and apply their hand motions to control and modify their own audiovisual contents. This interface explores users’ fingerprint data as personalized artistic materials, and allows them to rearrange and compare the data with others as pieces of a sonic puzzle by hand motion. This work expands the possibility of creating diverse audiovisual results based on users’ interaction, and enhances easier and more intuitive interaction with hand motion using short-range depth camera.",TRUE
int165,2725458,http://dx.doi.org/10.1145/2702613.2725458,http://dl.acm.org/citation.cfm?id=2725458,5RMO7qeeQjk,www.youtube.com/watch?v=5RMO7qeeQjk,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/5RMO7qeeQjk' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Filteryedping: A Dwell-Free Eye Typing Technique,"Diogo Pedrosa, Maria da Graça Pimentel, Khai N Truong","The ability to type using eye gaze only is extremely important for individuals with a severe motor disability. To eye type, the user currently must sequentially gaze at letters in a virtual keyboard and dwell on each desired letter for a specific amount of time to input that key. Dwell-based eye typing has two possible drawbacks: unwanted input if the dwell threshold is too short or slow typing rates if the threshold is long. We demonstrate an eye typing technique, which does not require the user to dwell on the letters that she wants to input. Our method automatically filters out unwanted letters from the sequence of letters gazed at while typing a word. It ranks candidate words based on their length and frequency and presents them to the user for confirmation. Spell correction and support for typing words not in the corpus are also included.",TRUE
int167,2725460,http://dx.doi.org/10.1145/2702613.2725460,http://dl.acm.org/citation.cfm?id=2725460,8HtDpDGPWGw,www.youtube.com/watch?v=8HtDpDGPWGw,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/8HtDpDGPWGw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,"_ (“Salm”, “To Live”): Gaze Reactive Typography Inspired by Ahn Sang-Soo","Monchu Chen, Bongkeum Jeong, Yoram I Chisik","This research aims to explore the concept of gaze reactive typography, in which the design changes dynamically according to how audiences view it.  Inspired by the philosophy and styles of the famous Korean typographer Ahn Sang-Soo, we created an installation to showcase and exemplify relationships in four different levels between viewing behaviors and dynamic representations of typography.",TRUE
int170,2744695,http://dx.doi.org/10.1145/2702613.2744695,http://dl.acm.org/citation.cfm?id=2744695,tj8SMddipw0,www.youtube.com/watch?v=tj8SMddipw0,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/tj8SMddipw0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,‘KIST Smart Wall’ and its Media Art Application: The Scenery Series,"Joong Ho Lee, Hyun Jhin Lee, Sanghwa Hong, Chungyo Ha, Ji-Hyung Park","The interactive large displays for use in professional \ applications such as signage, education and installation \ art have been introduced for many years. However the \ innovative technology and novel application needed to \ drive the rapid growth of the market are still sought \ after. We suggest a series of media art application with \ the KIST Smart Wall which provides robust and highly \ functional multi-touch capability on the large display at \ low cost enabling to provide perspective scene for \ users. For this interactivity exhibition, we collaborated \ with three media artists to explore the interactive wall \ as an emotional and aesthetic media art platform. ‘The \ Scenery Series’ will communicate with audiences in \ emotionally touching images and meanings.",TRUE
int172,2744697,http://dx.doi.org/10.1145/2702613.2744697,http://dl.acm.org/citation.cfm?id=2744697,hvHrtbM1K7M,www.youtube.com/watch?v=hvHrtbM1K7M,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/hvHrtbM1K7M' width='640' height='360' frameborder='0' allowfullscreen='true'/>,RGB Color Bits,Sanghwa Hong,"RGB Color bits is an animated RGB LED panel which \ represents a mutual understanding of recognition between \ analog colors and 8 bit color data of machine. We, humans \ are surrounded by digital displays in this era and high \ resolution of the digital display technology is blurring the \ lines between real and virtual world. \ Images that we’ve seen though the digital displays look \ almost real but they are obviously composed of different \ elements, being consistent of code and data. For example, \ the true red color on monitor display and colored paper \ could have the same appearance but the inside composing \ elements are totally different. RGB Color Bit tried to show \ the constituents of digital color by physical RGB LEDs and \ 8 bits dots punched out of wooden panel.",TRUE
int173,2744698,http://dx.doi.org/10.1145/2702613.2744698,http://dl.acm.org/citation.cfm?id=2744698,5H7A-0brll0,www.youtube.com/watch?v=5H7A-0brll0,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/5H7A-0brll0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Visual Liquidizer or Virtual Merge,"Tatsuo Unemi, Daniel Bisig","The authors’ latest artwork entitled Visual Liquidizer or \ Virtual Merge is a new form of audio-visual interactive \ installation that displays a deformed dynamic images of \ visitors as if their bodies become liquidized, scattered, and \ mixed. It is intended to provide a virtual experience of \ deeper contact with the other persons. The basic idea was \ inspired by a science fiction Wetware by R. Rucker. The \ authors developed an algorithm using two types of swarm \ simulations, ANT and BOIDS, in order to realize \ deformation of living fragments. Sound effects are \ generated synchronously with visuals by mixing sampled \ sounds of water flows with the visitors’ voice. It achieved \ quick response for realtime interaction utilizing parallel \ processing with CPU and GPU.",TRUE
int175,2744699,http://dx.doi.org/10.1145/2702613.2744699,http://dl.acm.org/citation.cfm?id=2744699,v0nt070fMTY,www.youtube.com/watch?v=v0nt070fMTY,CHI 2015;CHI 2015 Interactivity,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/v0nt070fMTY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,mood.cloud: Data as Art,"Younghui Kim, Geri Gay, Lindsay Reynolds, Hyuns Hong","The project “mood.cloud” is a LED light sculpture \ created through a collaborative effort among artists and \ information scientists. This light installation reflects the \ mood of people in a public space. For this exhibit, \ people selected an image on an iPad that best \ represented their current mood. The colors of the \ sculpture changed reflecting not only the individual's \ mood but the mood of others in the space. \ The “mood.cloud” platform can be re-programmed to \ not only capture represent emotional status in different \ ways, but also has the potential to track many different \ kinds of input.",TRUE
pn5101,1145/2699751,http://dx.doi.org/10.1145/2699751,http://dl.acm.org/citation.cfm?id=1145/2699751,6ov_82nxpbQ,www.youtube.com/watch?v=6ov_82nxpbQ,CHI 2015;CHI 2015 Journal,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/6ov_82nxpbQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,OverCode: Visualizing Variation in Student Solutions to Programming Problems at Scale,"Elena L. Glassman, Jeremy Scott, Rishabh Singh, Philip J. Guo, Robert C. Miller","In MOOCs, a single programming exercise may produce thousands of solutions from learners. Understanding solution variation is important for providing appropriate feedback to students at scale.  The wide variation among these solutions can be a source of pedagogically valuable examples, and can be used to refine the autograder for the exercise by exposing corner cases.  \  \ We present OverCode, a system for visualizing and exploring thousands of programming solutions. OverCode uses both static and dynamic analysis to cluster similar solutions, and lets teachers further filter and cluster solutions based on different criteria. \  \ We evaluated OverCode against a non-clustering baseline in a within-subjects study with 24 teaching assistants, and found that the OverCode interface allows teachers to more quickly develop a high-level view of students' understanding and misconceptions, and to provide feedback that is relevant to more students' solutions.",TRUE
pn5103,1145/2560016,http://dx.doi.org/10.1145/2560016,http://dl.acm.org/citation.cfm?id=1145/2560016,X-EuUXXyGwM,www.youtube.com/watch?v=X-EuUXXyGwM,CHI 2015;CHI 2015 Journal,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/X-EuUXXyGwM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,On the benefits of providing versioning support for end users: An empirical study,"Sandeep Kaur Kuttal, Anita Sarma, Gregg Rothermel","End users with little formal programming background are creating software in many different forms, including spreadsheets, web macros, and web mashups. Web mashups are particularly popular because they are relatively easy to create, and because many programming environments that support their creation are available. These programming environments, however, provide no support for tracking versions or provenance of mashups. We believe that versioning support can help end users create, understand, and debug mashups. To investigate this belief, we have added versioning support to a popular wire-oriented mashup environment, Yahoo! Pipes. Our enhanced environment, which we call “Pipes Plumber,” automatically retains versions of pipes and provides an interface with which pipe programmers can browse histories of pipes and retrieve specific versions. We have conducted two studies of this environment: an exploratory study and a larger controlled experiment. Our results provide evidence that versioning helps pipe programmers create and debug mashups. Subsequent qualitative results provide further insights into the barriers faced by pipe programmers, the support for reuse provided by our approach, and the support for debugging provided.",TRUE
pn5111,1145/2670534,http://dx.doi.org/10.1145/2670534,http://dl.acm.org/citation.cfm?id=1145/2670534,CUNSg1Kb9DA,www.youtube.com/watch?v=CUNSg1Kb9DA,CHI 2015;CHI 2015 Journal,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/CUNSg1Kb9DA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Does Distance Still Matter? Revisiting the CSCW Fundamentals on Distributed Collaboration,"Pernille Bjorn, Morten Esbensen, Rasmus Eskild Jensen, Stina Matthiessen","Does distance still matter? Reporting on a comparative analysis of four ethnographic studies of global software development, this paper analyzes the fundamental aspects of distance as depicted in the famous paper ‘Distance matters’. The results suggest that – while common ground, collaboration readiness, and organizational management are still important aspects for distributed collaboration – the arguments concerning coupling of work and collaboration technology readiness need to be refined. We argue that in working remotely, closely coupled work tasks encourage the remote workers to spend the extra effort required in articulation of work to make the collaboration function. Also we find that people in distributed software development have already made collaborative technologies part of their work and individuals are comfortable with them, thus collaboration technology readiness takes a different shape in this setting. ",TRUE
pn5113,1145/2699758,http://dx.doi.org/10.1145/2699758,http://dl.acm.org/citation.cfm?id=1145/2699758,mdgeETqdhhA,www.youtube.com/watch?v=mdgeETqdhhA,CHI 2015;CHI 2015 Journal,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/mdgeETqdhhA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,The Challenges of Using Biodata in Promotional Filmmaking,"Stuart Reeves, Sarah E Martindale, Paul Tennent, Steve Benford, Joe Marshall, Brendan Walker","We present a study of how filmmakers collected and visualised physiological data—‘biodata’—to construct a series of short promotional films depicting people undergoing ‘thrilling’ experiences. Drawing on ethnographic studies of two major advertising campaigns, we highlight key concerns for integrating sensors and sensor data into film production. Our findings address the perceived benefits of using biodata within narratives; the nature of different on-screen representations of biodata; and the challenges presented when integrating biodata into production processes. Drawing on this, we reconsider the nature of information visualisation in the filmmaking context. Further implications from our case studies provide recommendations for HCI collaborations with filmmaking and broadcast industries, focussing both on the practical matters of fitting sensor technologies into and handling data within production workflows, as well as discussing the broader implications for managing the veracity of that data within professional media production.",TRUE
pn5115,1145/2687921,http://dx.doi.org/10.1145/2687921,http://dl.acm.org/citation.cfm?id=1145/2687921,-Ou26F3EagE,www.youtube.com/watch?v=-Ou26F3EagE,CHI 2015;CHI 2015 Journal,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/-Ou26F3EagE' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Informing the Design of Novel Input Methods with Muscle Coactivation Clustering,"Myroslav Bachynskyi, Gregorio Palmas, Antti Oulasvirta, Tino Weinkauf","This paper presents a novel summarization of biomechanical and performance data for user interface designers. Previously, there was no simple way for designers to predict how the location, direction, velocity, precision, or amplitude of users' movement affects performance and fatigue. We cluster muscle coactivation data from a 3D pointing task covering the whole reachable space of the arm. We identify eleven clusters of pointing movements with distinct muscular, spatio-temporal and performance properties. We discuss their use as heuristics when designing for 3D pointing.",TRUE
pn5118,1145/2584670,http://dx.doi.org/10.1145/2584670,http://dl.acm.org/citation.cfm?id=1145/2584670,FqF8ixjL428,www.youtube.com/watch?v=FqF8ixjL428,CHI 2015;CHI 2015 Journal,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/FqF8ixjL428' width='640' height='360' frameborder='0' allowfullscreen='true'/>,User Interfaces for Smart Things - A Generative Approach with Semantic Interaction Descriptions,"Simon Mayer, Andreas Tschofen, Anind K. Dey, Friedemann Mattern","With ever more devices being connected to the Internet and everyday objects becoming “smart” due to embedded processors and communication capabilities, the provisioning of intuitive user interfaces to control smart things is quickly gaining importance. To address this issue, we present a model-based interface description scheme that enables automatic, modality-independent user interface generation. User interface description languages based on our approach carry enough information to suggest appropriate and intuitive interfaces. Still, they are simple enough to enable developers to describe the interaction semantics of a smart thing using very little, easily producible markup. This is enabled by describing the atomic interactive components of a device rather than the device as a whole, and capturing the high-level semantics of an interaction. As a concrete language based on this approach, we propose a taxonomy of abstract sensing and actuation primitives and present a smartphone application that can act as a ubiquitous device controller. An evaluation of our approach in a laboratory setup, home environments, and a lecture hall automation system as well as the results of a user study highlight the accessibility of the proposed description scheme for application developers, its suitability for controlling smart devices, and its generality with respect to describing heterogeneous smart things.",TRUE
pn5119,1145/2699735,http://dx.doi.org/10.1145/2699735,http://dl.acm.org/citation.cfm?id=1145/2699735,JlLU1l45R68,www.youtube.com/watch?v=JlLU1l45R68,CHI 2015;CHI 2015 Journal,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/JlLU1l45R68' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Motivation as a Lens to Understand Online Learners: Towards Data-Driven Design with the OLEI Scale,"René F Kizilcec, Emily Schneider","Open online learning environments attract an audience with diverse motivations who interact with structured courses in a number of ways. To systematically describe the motivations of these learners, we developed the Online Learning Enrollment Intentions (OLEI) scale, a 13-item questionnaire derived from open-ended responses to capture learners' authentic perspectives. Though motivations varied across courses, we found each motivation to predict key behavioral outcomes for learners (N=71,475 across 14 courses). From learners’ motivational and behavioral patterns, we infer a variety of needs they seek to gratify by engaging with the courses, such as meeting new people and learning English. To meet these needs, we propose multiple design directions, including virtual social spaces outside any particular course, improved support for local groups of learners, and modularization to promote accessibility and organization of course content. Motivations thus provide a lens for understanding online learners and designing online courses to better support their needs.",TRUE
pn5127,1145/2656211,http://dx.doi.org/10.1145/2656211,http://dl.acm.org/citation.cfm?id=1145/2656211,vwKq8iI17hI,www.youtube.com/watch?v=vwKq8iI17hI,CHI 2015;CHI 2015 Journal,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/vwKq8iI17hI' width='640' height='360' frameborder='0' allowfullscreen='true'/>,To Call or to Recall? That’s the Research Question,"Juan Pablo Carrascal, Rodrigo de Oliveira, Mauro Cherubini","We present findings of a study with 62 subjects who had 796 of their outgoing mobile phone calls recorded and transcribed for their later annotation—by highlighting important information shared during calls. We found that patterns in these calls (numbers, names, interrogative adverbs) as well as some contextual parameters are better indicators of annotation needs than the callers’ profile or call quality. Callers highlight information in both parties’ turns (caller and callee) more often than highlighting solely information provided by the callee, which is mostly due to annotating questions with contextual information for the highlights in the callee’s turns. We discuss how this behavior changes according to call purpose. Finally, we found that annotation needs change over time: while some annotations might not be considered relevant after weeks, others originally considered irrelevant might become important archival notes. We present implications of these findings for the design of mobile phone annotation tools.",TRUE
pn5128,1145/2699760,http://dx.doi.org/10.1145/2699760,http://dl.acm.org/citation.cfm?id=1145/2699760,nd_npJsKhJ8,www.youtube.com/watch?v=nd_npJsKhJ8,CHI 2015;CHI 2015 Journal,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/nd_npJsKhJ8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Large-Scale Educational Campaigns,"Yun-En Liu, Christy Ballweber, Eleanor O'Rourke, Eric Butler, Phonraphee Thummaphan, Zoran Popovi_","Educational technology requires a delivery mechanism in order to scale. One method which has not yet seen widespread use is the educational campaign: large-scale, short-term events focused on a specific educational topic, such as the Hour of Code campaign. These are designed to generate media coverage and lend themselves nicely to collaborative or competitive goals, thus potentially leveraging social effects and community excitement to increase engagement and reach students who would otherwise not participate. In this paper, we present a case study of three such campaigns we ran to encourage students to play an algebra game, DragonBox Adaptive: the Washington, Norway, and Minnesota Algebra Challenges. We provide several design recommendations for future campaigns based on our experience, including the effects of different incentive schemes, the insertion of “tests” to fastforward students to levels of appropriate difficulty, and the strengths and weaknesses of campaigns as a method of collecting experimental data.",TRUE
pn5137,1561/1100000028,http://dx.doi.org/10.1561/1100000028,http://dl.acm.org/citation.cfm?id=1561/1100000028,ku7e4b8ypOs,www.youtube.com/watch?v=ku7e4b8ypOs,CHI 2015;CHI 2015 Journal,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/ku7e4b8ypOs' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Choice Architecture for Human-Computer Interaction,"Anthony Jameson, Bettina Berendt, Silvia Gabrielli, Federica Cena, Cristina Gena, Fabiana Vernero, Katharina Reinecke","People in human-computer interaction have learned a great deal about how to persuade and influence users of computing technology. They have much less well-founded knowledge about how to help users choose for themselves. It's time to correct this imbalance. A first step is to organize the vast amount of relevant knowledge that has been built up in psychology and related fields in terms of two comprehensive but easy-to-remember models: The ASPECT model answers the question ""How do people make choices?"" by describing six choice patterns that choosers apply alternately or in combination, based on Attributes, Social influence, Policies, Experience, Consequences, and Trial and error. The ARCADE model answers the question ""How can we help people make better choices?"" by describing six general high-level strategies for supporting choice: Access information and experience, Represent the choice situation, Combine and compute, Advise about processing, Design the domain, and Evaluate on behalf of the chooser. These strategies can be implemented with straightforward interaction design, but for each one there are also specifically relevant technologies. Combining these two models, we can understand virtually all existing and possible approaches to choice support as the application of one or more of the ARCADE strategies to one or more of the ASPECT choice patterns. \  \ After introducing the idea of choice architecture for human-computer interaction and the key ideas of the ASPECT and ARCADE models, we discuss each of the ASPECT patterns in detail and show how the high-level ARCADE strategies can be applied to it to yield specific tactics. We then apply the two models in the domains of online communities and privacy. Most of our examples concern choices about the use of computing technology, but the models are equally applicable to everyday choices made with the help of computing technology. \ ",TRUE
pn5147,789347,http://dx.doi.org/10.1080/07370024.2013.789347,http://dl.acm.org/citation.cfm?id=789347,XZmoKTPhJUE,www.youtube.com/watch?v=XZmoKTPhJUE,CHI 2015;CHI 2015 Journal,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/XZmoKTPhJUE' width='640' height='360' frameborder='0' allowfullscreen='true'/>,"User Experience of On-Screen Interaction Techniques: An Experimental Investigation of Clicking, Sliding, Zooming, Hovering, Dragging, and Flipping","S. Shyam Sundar, Saraswathi Bellur, Jeeyun Oh, Qian Xu, Haiyan Jia","From scrolling and clicking to dragging, flipping, sliding, hovering and zooming, the wide array of interaction techniques has vastly expanded the range of user actions on an interface. Each of these interaction techniques affords a distinct action. But, do these techniques differ in their ability to engage users and contribute to their user experience? Furthermore, do they affect how users view the content and how much they learn from it? We address these questions via two between-subjects laboratory experiments. Study 1 (N = 128) investigated the relative effects of six on-screen interaction techniques (click-to-download, drag, mouseover, slide, zoom and 3D carousel) on users’ assessment of—as well as their engagement with—an informational Website. The site for each condition was identical in content and design, except for the interaction technique used, so that we could isolate the effects of each technique on various cognitive, attitudinal and behavioral outcomes. Study 2 (N = 127) examined the relative effects of four combinations of interaction techniques (slide+click, slide+mouseover, drag+mouseover and drag+zoom) on the same dependent variables. Data from Study 1 suggest that while the 3D carousel generates more user action, the slide is better at aiding memory. The zoom-in/out tool was the least favored whereas the mouseover feature fostered greater engagement among power-users. Findings from Study 2, which was conducted with a different content domain, replicated the positive effects of slide and negative effects of drag in influencing user experience. Path analyses, using structural equation modeling, revealed the importance of users’ assessment of the interface (perceived levels of natural mapping, intuitiveness and ease of use), which can have significant consequences for user engagement as well as resulting attitudes and behavioral outcomes. Design insights, theories and techniques to test and capture user experience are discussed.",TRUE
pn5148,812411,http://dx.doi.org/10.1080/07370024.2013.812411,http://dl.acm.org/citation.cfm?id=812411,sBFA9veSAQg,www.youtube.com/watch?v=sBFA9veSAQg,CHI 2015;CHI 2015 Journal,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/sBFA9veSAQg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,WallTop: Manage Overflowing Windows on a Large Display,"Xiaojun Bi, Seok-Hyung Bae, Ravin Balakrishnan","With the ever increasing amount of digital information, users desire more screen real estate to process daily desktop computing work, and might well benefit from using a large high-resolution display for information management. Unfortunately, we know very little about users’ behaviors when using such a display for daily computing, and current user interfaces are mainly designed for normal-sized desktop monitors, which might not well suit a large display. In this paper, we firstly present a longitudinal study that investigates how users manage overflowing digital information on a wall-sized display in a personal desktop computing context by comparing it with single and dual desktop monitors. Results showed users’ unanimous preferences of working on a large display, and revealed large-display users’ unique activity patterns of managing windows. Guided by the study results, we designed a set of interaction techniques that provide greater flexibility in managing multiple windows. They include facile methods for selecting, moving and resizing multiple windows using the active window boundary called Fringe, rearranging selected windows using multi- and single-window marking menus, packing/unpacking the selected windows using easily activated icons, and freely adjusting window overlapping order with a Jab-to-Lift operation. We coherently integrated these techniques with traditional operations in a large-display window management prototype called WallTop. Two rounds of usability testing showed that users can quickly and easily learn the new interaction techniques and apply them to realistic window management tasks on a large display with increased efficiency.",TRUE
pn5149,896709#,http://dx.doi.org/10.1080/07370024.2014.896709#,http://dl.acm.org/citation.cfm?id=896709#,LopXhBtU5bo,www.youtube.com/watch?v=LopXhBtU5bo,CHI 2015;CHI 2015 Journal,CHI 2015 Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/LopXhBtU5bo' width='640' height='360' frameborder='0' allowfullscreen='true'/>,What Designers Talk About When They Talk About Context,"Jared S Bauer, Mark W. Newman, Julie A Kientz","Context has long been considered an important component of design, but as technology becomes more capable of inferring the user’s behavior and environment, what constitutes context has become an increasingly pressing concern to designers. Although design frameworks and models have been proposed for context-aware computing systems, there has not yet been research that focuses on understanding context empirically from the perspective of the designer. To address this, we present an analysis of 11 in-depth interviews we conducted with designers of a variety of context-aware systems. Our analysis of the artifacts and interviews reveal five concerns designers address in their work. Furthermore, we present a process model that illustrates how context-aware system designers address these concerns. Our findings demonstrate the central role that designers’ views of context plays in (a) framing a design space, (b) encoding the relevant features of context, (c) unifying possible solutions within that design space, and (d) evaluating designs. These findings suggest that context is a dynamic concept that evolves over the course of a design project, generally from a more phenomenological perspective toward a positivist interpretation. This, and the process by which it occurs, contributes insight into context-aware design with implications for both academics and practitioners.",TRUE
sig105,2727688,http://dx.doi.org/10.1145/2702613.2727688,http://dl.acm.org/citation.cfm?id=2727688,bc6tQeUKKNE,www.youtube.com/watch?v=bc6tQeUKKNE,CHI 2015;CHI 2015 Sigs,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/bc6tQeUKKNE' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Understanding Sports-HCI by Going Jogging at CH,"Florian Mueller, Joe Marshall, Rohit Ashok Khot, Stina Nylander, Jakob Tholander","More and more technologies are emerging that aim to support sports activities, for example there are jogging apps, cycling computers and quadcopters for sportspeople to videorecord their actions. These new technologies appear to become more and more popular, yet interaction design knowledge how to support the associated exertion experiences is still limited. In order to bring practitioners and academics interested in sports-HCI together and examine the topic “in the wild”, we propose to go outside and jog around the CHI venue while using and discussing some of these new technologies. The goal is to investigate and shape the future of the field of sports-HCI.",TRUE
pn112,2702126,http://dx.doi.org/10.1145/2702123.2702126,http://dl.acm.org/citation.cfm?id=2702126,Xl2eqEMKDgg,www.youtube.com/watch?v=Xl2eqEMKDgg,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/Xl2eqEMKDgg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,"Physical Loci: Leveraging Spatial, Object and Semantic Memory for Command Selection","Simon T Perrault, Eric Lecolinet, Yoann Pascal Bourse, Shengdong Zhao, Yves Guiard","Physical Loci, a technique based on an ancient memory technique, allows users to quickly learn a large command set by leveraging spatial, object and verbal/semantic memory to create a cognitive link between individual commands and nearby physical objects in a room (called loci). We first report on an experiment that showed that for learning 25 items Physical Loci outperformed a mid-air Marking Menu baseline. A long-term retention experiment with 48 items then showed that recall was nearly perfect one week later and, surprisingly, independent of whether the command/locus mapping was one’s own choice or somebody else’s. A final study suggested that recall performance is robust to alterations of the learned mapping, whether systematic or random. ",TRUE
pn115,2702128,http://dx.doi.org/10.1145/2702123.2702128,http://dl.acm.org/citation.cfm?id=2702128,d0J7V37zQjY,www.youtube.com/watch?v=d0J7V37zQjY,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/d0J7V37zQjY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Affordance++: Allowing Objects to Communicate Dynamic Use,"Pedro Lopes, Patrik Jonell, Patrick Baudisch","We propose extending the affordance of objects by allowing them to communicate dynamic use, such as (1) motion (e.g., spray can shakes when touched), (2) multi-step processes (e.g., spray can sprays only after shaking), and (3) behaviors that change over time (e.g., empty spray can does not allow spraying anymore). Rather than enhancing objects directly, however, we implement this concept by enhancing the user. We call this affordance++. By stimulating the user’s arms using electrical muscle stimulation, our prototype allows objects not only to make the user actuate them, but also perform required movements while merely approaching the object, such as not to touch objects that do not “want” to be touched. In our user study, affordance++ helped participants to successfully operate devices of poor natural affordance, such as a multi-functional slicer tool or a magnetic nail sweeper, and to stay away from cups filled with hot liquids.",TRUE
pn123,2702129,http://dx.doi.org/10.1145/2702123.2702129,http://dl.acm.org/citation.cfm?id=2702129,ldy15WAwKqA,www.youtube.com/watch?v=ldy15WAwKqA,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/ldy15WAwKqA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,SketchSliders: Sketching Widgets for Visual Exploration on Wall Displays,"Theophanis Tsandilas, Anastasia Bezerianos, Thibaut Jacob","We introduce a mobile sketching interface for exploring multi-dimensional datasets on wall displays. We demonstrate the idea of SketchSliders, range sliders that users can freely sketch on a mobile surface to customize their exploration. A small combination of sketches and gestures allows the creation of complex interactive sliders, such as circular sliders for periodic data, slider branches for detailed interaction, and fisheye transformation sliders. We augment sliders with a suite of tools, such as markers, slider cursors, and approximate views of data distributions. Our designs are inspired by a design study with three visualization experts and validated through a user study with six experts using our system. Our findings indicate that our sketching interface accommodates a wide range of exploration strategies, helping users customize as well as focus their visual explorations.",TRUE
pn134,2702130,http://dx.doi.org/10.1145/2702123.2702130,http://dl.acm.org/citation.cfm?id=2702130,-q702OTBpT8,www.youtube.com/watch?v=-q702OTBpT8,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/-q702OTBpT8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,An Evaluation of Interactive Map Comparison Techniques,"María-Jesús Lobo, Emmanuel Pietriga, Caroline Appert","Geovisualization applications typically organize data into layers. These layers hold different types of geographical features, describe different characteristics of the same features, or represent those features at different points in time. Layers can be composited in various ways, most often employing a juxtaposition or superimposition strategy, to produce maps that users can explore interactively. From an HCI perspective, one of the main challenges is to design interactive compositions that optimize the legibility of the resulting map and that ease layer comparison. We characterize five representative techniques, and empirically evaluate them using a set of real-world maps in which we purposefully introduce six types of differences amenable to inter-layer visual comparison. We discuss the merits of these techniques in terms of visual interference, user attention and scanning strategy. Our results can help inform the design of map-based visualizations for supporting geo-analysis tasks in many application areas.",TRUE
pn139,2702132,http://dx.doi.org/10.1145/2702123.2702132,http://dl.acm.org/citation.cfm?id=2702132,zVoqyDXduCg,www.youtube.com/watch?v=zVoqyDXduCg,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/zVoqyDXduCg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Push-Edge and Slide-Edge: Scrolling by Pushing Against the Viewport Edge,"Sylvain Malacria, Jonathan Aceituno, Philip Quinn, Géry Casiez, Andy Cockburn, Nicolas Roussel","Edge-scrolling allows users to scroll a viewport while simultaneously dragging near or beyond a window’s edge. Common implementations rely on rate control, mapping the distance between the pointer and the edge of the viewport to the scrolling velocity. While ubiquitous in operating systems, edge-scrolling has received little attention, even though previous works suggest that (1) rate control may be suboptimal for isotonic pointing devices like mice and trackpads and (2) space beyond the window’s edge might be scarce, limiting scrolling control. To address these problems, we developed Push-edge scrolling (and Slide-edge scrolling, its inertial variant), two novel position-based techniques that allow scrolling by ‘pushing’ against the viewport edge. A controlled experiment shows that our techniques reduce overshoots and offer performance improvements by up to 13% over traditional edge-scrolling.",TRUE
pn140,2702133,http://dx.doi.org/10.1145/2702123.2702133,http://dl.acm.org/citation.cfm?id=2702133,_q-3bS0SvKs,www.youtube.com/watch?v=_q-3bS0SvKs,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/_q-3bS0SvKs' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Myopoint: Pointing and Clicking Using Forearm Mounted Electromyography and Inertial Motion Sensors,"Faizan Haque, Mathieu Nancel, Daniel Vogel","We describe a mid-air, barehand pointing and clicking interaction technique using electromyographic (EMG) and inertial measurement unit (IMU) input from a consumer armband device. The technique uses enhanced pointer feedback to convey state, a custom pointer acceleration function tuned for angular inertial motion, and correction and filtering techniques to minimize side-effects when combining EMG and IMU input. By replicating a previous large display study using a motion capture pointing technique, we show the EMG and IMU technique is only 430 to 790 ms slower and has acceptable error rates for targets greater than 48 mm. Our work demonstrates that consumer-level EMG and IMU sensing is practical for distant pointing and clicking on large displays.",TRUE
pn142,2702134,http://dx.doi.org/10.1145/2702123.2702134,http://dl.acm.org/citation.cfm?id=2702134,yMfR_alzPh4,www.youtube.com/watch?v=yMfR_alzPh4,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/yMfR_alzPh4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Clutching Is Not (Necessarily) the Enemy,"Mathieu Nancel, Daniel Vogel, Edward Lank","Clutching is usually assumed to be triggered by a lack of physical space and detrimental to pointing performance. We conduct a controlled experiment using a laptop trackpad where the effect of clutching on pointing performance is dissociated from the effects of control-to-display transfer functions. Participants performed a series of target acquisition tasks using typical cursor acceleration functions with and without clutching. All pointing tasks were feasible without clutching, but clutch-less movements were harder to perform, caused more errors, required more preparation time, and were not faster than clutch-enabled movements.",TRUE
pn147,2702136,http://dx.doi.org/10.1145/2702123.2702136,http://dl.acm.org/citation.cfm?id=2702136,tKEjkyIeszs,www.youtube.com/watch?v=tKEjkyIeszs,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/tKEjkyIeszs' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Investigating the Dexterity of Multi-Finger Input for Mid-Air Text Entry,"Srinath Sridhar, Anna Maria Feit, Christian Theobalt, Antti Oulasvirta","This paper investigates an emerging input method enabled by progress in hand tracking: input by free motion of fingers. The method is expressive, potentially fast, and usable across many settings as it does not insist on physical contact or visual feedback. Our goal is to inform the design of high-performance input methods by providing detailed analysis of the performance and anatomical characteristics of finger motion. We conducted an experiment using a commercially available sensor to report on the speed, accuracy, individuation, movement ranges, and individual differences of each finger. Findings show differences of up to 50% in movement times and provide indices quantifying the individuation of single fingers. We apply our findings to text entry by computational optimization of multi-finger gestures in mid-air. To this end, we define a novel objective function that considers performance, anatomical factors, and learnability. First investigations of one optimization case show entry rates of 22 words per minute (WPM). We conclude with a critical discussion of the limitations posed by human factors and performance characteristics of existing markerless hand trackers.",TRUE
pn153,2702138,http://dx.doi.org/10.1145/2702123.2702138,http://dl.acm.org/citation.cfm?id=2702138,dcM765zR2VY,www.youtube.com/watch?v=dcM765zR2VY,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/dcM765zR2VY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Exploring 3D User Interface Technologies for Improving the Gaming Experience,"Arun Kulshreshth, Joseph LaViola Jr.","We present the results of a comprehensive video game study which explores how the gaming experience is effected when several 3D user interface technologies are used simultaneously. We custom designed an air-combat game integrating several 3DUI technologies (stereoscopic 3D, head tracking, and finger-count gestures) and studied the combined effect of these technologies on the gaming experience. Our game design was based on existing design principles for optimizing the usage of these technologies in isolation. Additionally, to enhance depth perception and minimize visual discomfort, the game dynamically optimizes stereoscopic 3D parameters (convergence and separation) based on the user's look direction. We conducted a within subjects experiment where we examined performance data and self-reported data on users perception of the game. Our results indicate that participants performed significantly better when all the 3DUI technologies (stereoscopic 3D, head-tracking and finger-count gestures) were available simultaneously with head tracking as a dominant factor. We explore the individual contribution of each of these technologies to the overall gaming experience and discuss the reasons behind our findings.",TRUE
pn160,2702140,http://dx.doi.org/10.1145/2702123.2702140,http://dl.acm.org/citation.cfm?id=2702140,lOdt-pf5U8Q,www.youtube.com/watch?v=lOdt-pf5U8Q,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/lOdt-pf5U8Q' width='640' height='360' frameborder='0' allowfullscreen='true'/>,TextAlive: Integrated Design Environment for Kinetic Typography,"Jun Kato, Tomoyasu Nakano, Masataka Goto","This paper presents TextAlive, a graphical tool that allows interactive editing of kinetic typography videos in which lyrics or transcripts are animated in synchrony with the corresponding music or speech. While existing systems have allowed the designer and casual user to create animations, most of them do not take into account synchronization with audio signals. They allow predefined motions to be applied to objects and parameters to be tweaked, but it is usually impossible to extend the predefined set of motion algorithms within these systems. We therefore propose an integrated design environment featuring (1) GUIs that designers can use to create and edit animations synchronized with audio signals, (2) integrated tools that programmers can use to implement animation algorithms, and (3) a framework for bridging the interfaces for designers and programmers. A preliminary user study with designers, programmers, and casual users demonstrated its capability in authoring various kinetic typography videos.",TRUE
pn169,2702142,http://dx.doi.org/10.1145/2702123.2702142,http://dl.acm.org/citation.cfm?id=2702142,vbAKhW46NcI,www.youtube.com/watch?v=vbAKhW46NcI,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/vbAKhW46NcI' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Playing the Legal Card: Using Ideation Cards to Raise Data Protection Issues within the Design Process,"Ewa Luger, Lachlan Urquhart, Tom Rodden, Michael Golembewski","The regulatory climate is in a process of change. Design, having been implicated for some time, is now explicitly linked to law. This paper recognises the heightened role of designers in the regulation of ambient interactive technologies. Taking account of incumbent legal requirements is difficult. Legal rules are convoluted, uncertain, and not geared towards operationalisable heuristics or development guidelines for system designers. Privacy and data protection are a particular moral, social and legal concern for technologies. This paper seeks to understand how to make emerging European data protection regulation more accessible to our community. Our approach develops and tests a series of data protection ideation cards with teams of designers. We find that, whilst wishing to protect users, regulation is viewed as a compliance issue. Subsequently we argue for the use of instruments, such as our cards, as a means to engage designers in leading a human-centered approach to regulation. ",TRUE
pn234,2702149,http://dx.doi.org/10.1145/2702123.2702149,http://dl.acm.org/citation.cfm?id=2702149,PvovIEHaHTA,www.youtube.com/watch?v=PvovIEHaHTA,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/PvovIEHaHTA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,DesignScape: Design with Interactive Layout Suggestions,"Peter O'Donovan, Aseem Agarwala, Aaron Hertzmann","Creating graphic designs can be challenging for novice users.  This paper presents DesignScape, a system which aids the design process by making interactive layout suggestions, i.e., changes in the position, scale, and alignment of elements. The system uses two distinct but complementary types of suggestions: refinement suggestions, which improve the current layout, and brainstorming suggestions, which change the style. We  investigate two interfaces for interacting with suggestions. First, we develop a suggestive interface, where suggestions are previewed and can be accepted. Second, we develop an adaptive interface where elements  move automatically to improve the layout. We compare both interfaces with a baseline without suggestions, and show that for novice designers, both interfaces produce significantly better layouts, as evaluated by other novices.",TRUE
pn236,2702150,http://dx.doi.org/10.1145/2702123.2702150,http://dl.acm.org/citation.cfm?id=2702150,1rCsFzcXP2c,www.youtube.com/watch?v=1rCsFzcXP2c,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/1rCsFzcXP2c' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Display Blindness? Looking Again at the Visibility of Situated Displays using Eye-tracking,"Nicholas S Dalton, Emily Collins, Paul Marshall","Observational studies of situated displays have suggested that they are rarely looked at, and when they are it is typically only for a short period of time. Using a mobile eye tracker during a realistic shopping task in a shopping center, we show that people look at displays more than would be predicted from these observational studies, but still only short glances and often from quite far away. We characterize the patterns of eye-movements that precede looking at a display and discuss some of the design implications for the design of situated display technologies that are deployed in public space.",TRUE
pn239,2702151,http://dx.doi.org/10.1145/2702123.2702151,http://dl.acm.org/citation.cfm?id=2702151,U_Mwo1VNiFI,www.youtube.com/watch?v=U_Mwo1VNiFI,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/U_Mwo1VNiFI' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Crowdsourcing Stereotypes: Linguistic Bias in Metadata Generated via GWAP,Jahna Otterbacher,"Games with a Purpose (GWAP) is a popular approach for metadata creation, enabling institutions to collect descriptions of digital artifacts on a mass scale. Creating metadata is challenging not only because one must recognize the artifact; the description must then be encoded into natural language. Language behaviors are influenced by many social factors, particularly when we are asked to describe other people. We consider labels for images of people generated via the ESP Game. While ESP has been shown to produce relevant labels, critics claim they are obvious and stereotypical. Based on theories of linguistic biases, we examine whether there are systematic differences in the ways players describe images of men versus women. Our first analysis considers images of people generally, and reveals a tendency for women to be described with subjective adjectives. A second analysis compares images depicting men and women within each of six occupational roles. Images of women receive more labels related to appearance, whereas those depicting men receive more occupation-related labels. Our work exposes the presence of gender-based stereotypes through linguistic biases, illustrates the forms in which they manifest, and raises important implications for those who design systems or train algorithms using data produced via GWAP.",TRUE
pn243,2702153,http://dx.doi.org/10.1145/2702123.2702153,http://dl.acm.org/citation.cfm?id=2702153,BLun9CyCLAg,www.youtube.com/watch?v=BLun9CyCLAg,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/BLun9CyCLAg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,You Tweet What You Eat: Studying Food Consumption Through Twitter,"Sofiane Abbar, Yelena Mejova, Ingmar Weber","Food is an integral part of our lives, cultures, and well-being, and is of major interest to public health. The collection of daily nutritional data involves keeping detailed diaries or periodic surveys and is limited in scope and reach. Alternatively, social media is infamous for allowing its users to update the world on the minutiae of their daily lives, including their eating habits. In this work we examine the potential of Twitter to provide insight into US-wide dietary choices by linking the tweeted dining experiences of 210K users to their interests, demographics, and social networks. We validate our approach by relating the caloric values of the foods mentioned in the tweets to the state-wide obesity rates, achieving a Pearson correlation of 0.77 across the 50 US states and the District of Columbia. We then build a model to predict county-wide obesity and diabetes statistics based on a combination of demographic variables and food names mentioned on Twitter. Our results show significant improvement over previous CHI research (Culotta 2014). We further link this data to societal and economic factors, such as education and income, illustrating that areas with higher education levels tweet about food that is significantly less caloric. Finally, we address the somewhat controversial issue of the social nature of obesity (Christakis & Fowler 2007) by inducing two social networks using mentions and reciprocal following relationships.",TRUE
pn263,2702158,http://dx.doi.org/10.1145/2702123.2702158,http://dl.acm.org/citation.cfm?id=2702158,D9lXDyh5U9I,www.youtube.com/watch?v=D9lXDyh5U9I,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/D9lXDyh5U9I' width='640' height='360' frameborder='0' allowfullscreen='true'/>,THING: Introducing a Tablet-based Interaction Technique for controlling 3D Hand Models,"Merwan Achibet, Géry Casiez, Anatole Lécuyer, Maud Marchal","The hands of virtual characters are highly complex 3D models that can be tedious and time-consuming to animate with current methods. This paper introduces THING, a novel tablet-based approach that leverages multi-touch interaction for a quick and precise control of a 3D hand's pose. The flexion/extension and abduction/adduction of the virtual fingers can be controlled for each finger individually or for several fingers in parallel through sliding motions on the tablet's surface. We designed two variants of THING: (1) MobileTHING, which maps the spatial location and orientation of the tablet to that of the virtual hand, and (2) DesktopTHING, which combines multi-touch controls of fingers with traditional mouse controls for the hand's global position and orientation. We compared the usability of THING against mouse-only controls and a data glove in two controlled experiments. Results show that DesktopTHING was significantly preferred by users while providing performance similar to data gloves. Together, these results could pave the way to the introduction of novel hybrid user interfaces based on tablets and mice in future animation pipelines.",TRUE
pn271,2702160,http://dx.doi.org/10.1145/2702123.2702160,http://dl.acm.org/citation.cfm?id=2702160,TCU1Ifr5VUc,www.youtube.com/watch?v=TCU1Ifr5VUc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/TCU1Ifr5VUc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,ImmerseBoard: Immersive Telepresence Experience using a Digital Whiteboard,"Keita Higuchi, Yinpeng Chen, Philip A Chou, Zhengyou Zhang, Zicheng Liu","ImmerseBoard is a system for remote collaboration through a digital whiteboard that gives participants a 3D immersive experience, enabled only by an RGBD camera (Microsoft Kinect) mounted on the side of a large touch display. Using 3D processing of the depth images, life-sized rendering, and novel visualizations, ImmerseBoard emulates writing side-by-side on a physical whiteboard, or alternatively on a mirror. User studies involving three tasks show that compared to standard video conferencing with a digital whiteboard, ImmerseBoard \ provides participants with a quantitatively better ability to estimate their remote partners’ eye gaze direction, gesture direction, intention, and level of agreement. Moreover, these quantitative capabilities translate qualitatively into a heightened sense of being together and a more enjoyable experience. ImmerseBoard’s form factor is suitable for practical and easy installation in homes and offices.",TRUE
pn273,2702161,http://dx.doi.org/10.1145/2702123.2702161,http://dl.acm.org/citation.cfm?id=2702161,UcDSrjqJ0VU,www.youtube.com/watch?v=UcDSrjqJ0VU,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/UcDSrjqJ0VU' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Content Destabilization for Head-Mounted Displays,"Felix Lauber, Sophia Cook, Andreas Butz","With recent progress in display technology, visual see-through head-mounted displays are beginning to enter our everyday lives. Especially in cars they may replace head-up displays, as they can theoretically perfectly imitate them but are more flexible to use. However, prior work has shown that both screen- and vehicle-stabilized content suffer from drawbacks such as occlusion or technological limitations. As a potential alternative, we propose three concept alternatives, in which head rotation is used to manipulate the displayed content differently from both of the known stabilization techniques. In a qualitative user study, we identify the best concept proposal and then evaluate it against the established content stabilization techniques. The presented concept is perceived to be more applicable for the proposed use case and effectively reduces some of the known problems of both stabilization techniques.",TRUE
pn302,2702166,http://dx.doi.org/10.1145/2702123.2702166,http://dl.acm.org/citation.cfm?id=2702166,-Pen2H2IsAM,www.youtube.com/watch?v=-Pen2H2IsAM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/-Pen2H2IsAM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Using Game Principles in UX Research:  A Board Game for Eliciting Future User Needs,"Karin Slegers, Sanne Ruelens, Jorick Vissers, Pieter Duysburgh","This paper presents a board game approach as a UX research technique to assess potential user experiences regarding a future product. It discusses how the use of a board game may provide a) a safe research environment in which participants feel comfortable to share their thoughts and experiences in a group setting, and b) a tool to facilitate users to think about their needs regarding a future product. The use of the board game approach is illustrated by a case study in the context of developing a new train information system. The design of the board game that was used is described in detail, as well as how the game was used to elicit potential future experiences. A survey amongst the participants showed that the board game was appreciated as a surprising, pleasant and ‘safe’ research method. ",TRUE
pn306,2702167,http://dx.doi.org/10.1145/2702123.2702167,http://dl.acm.org/citation.cfm?id=2702167,me5j5OIHVGk,www.youtube.com/watch?v=me5j5OIHVGk,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/me5j5OIHVGk' width='640' height='360' frameborder='0' allowfullscreen='true'/>,To Beep or Not to Beep? Comparing Abstract versus Language-Based Multimodal Driver Displays,"Ioannis Politis, Stephen A Brewster, Frank Pollick","Multimodal displays are increasingly being utilized as driver warnings. Abstract warnings, without any semantic association to the signified event, and language-based warnings are examples of such displays. This paper presents a first comparison between these two types, across all combinations of audio, visual and tactile modalities. Speech, text and Speech Tactons (a novel form of tactile warnings synchronous to speech) were compared to abstract pulses in two experiments. Results showed that recognition times of warning urgency during a non-critical driving situation were shorter for abstract warnings, highly urgent warnings and warnings including visual feedback. Response times during a critical situation were shorter for warnings including audio. We therefore suggest abstract visual feedback when informing drivers during a non-critical situation and audio in a highly critical one. Language-based warnings during a critical situation performed equally well as abstract ones, so they are suggested as less annoying vehicle alerts.",TRUE
pn312,2702169,http://dx.doi.org/10.1145/2702123.2702169,http://dl.acm.org/citation.cfm?id=2702169,wUgFwCqH5eo,www.youtube.com/watch?v=wUgFwCqH5eo,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/wUgFwCqH5eo' width='640' height='360' frameborder='0' allowfullscreen='true'/>,"SpecTrans: Versatile Material Classification for Interaction with Textureless, Specular and Transparent Surfaces","Munehiko Sato, Shigeo Yoshida, Alex Olwal, Boxin Shi, Atsushi Hiyama, Tomohiro Tanikawa, Michitaka Hirose, Ramesh Raskar","Surface and object recognition is of significant importance in ubiquitous and wearable computing. While various techniques exist to infer context from material properties and appearance, they are typically neither designed for real-time applications nor for optically complex surfaces that may be specular, textureless, and even transparent. These materials are, however, becoming increasingly relevant in HCI for transparent displays, interactive surfaces, and ubiquitous computing. \  \ We present SpecTrans, a new sensing technology for surface classification of exotic materials, such as glass, transparent plastic, and metal. The proposed technique extracts optical features by employing laser and multi-directional, multi-spectral LED illumination that leverages the material's optical properties. The sensor hardware is small in size, and the proposed classification method requires significantly lower computational cost than conventional image-based methods, which use texture features or reflectance analysis, thereby providing real-time performance for ubiquitous computing. \  \ Our evaluation of the sensing technique for nine different transparent materials, including air, shows a promising recognition rate of 99.0%. We demonstrate a variety of possible applications using SpecTrans' capabilities.",TRUE
pn327,2702171,http://dx.doi.org/10.1145/2702123.2702171,http://dl.acm.org/citation.cfm?id=2702171,UJjonJRa3Lg,www.youtube.com/watch?v=UJjonJRa3Lg,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/UJjonJRa3Lg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,XHELP: Design of a Cross-Platform Social-Media Application  to Support Volunteer Moderators in Disasters,"Christian Reuter, Thomas Ludwig, Marc-André Kaufhold, Volkmar Pipek","Recent disasters have shown an increase in the significance of social media for both affected citizens and volunteers alike in the coordination of information and organization of relief activities, often independently of and in addition to the official emergency response. Existing research mainly focuses on the way in which individual platforms are used by volunteers in response to disasters. This paper examines the use of social media during the European Floods of 2013 and proposes a novel cross-social-media application for volunteers. Besides comprehensive analysis of volunteer communities, interviews were conducted with “digital volunteers” such as Facebook moderators of disaster-related groups. Based on the challenges identified, we designed and implemented the cross-social-media application “XHELP”, which allows information to be both, acquired and distributed cross-media and cross-channel. The evaluation with 20 users leads to further design requirements for applications aiming to support volunteer moderators during disasters. ",TRUE
pn328,2702172,http://dx.doi.org/10.1145/2702123.2702172,http://dl.acm.org/citation.cfm?id=2702172,YW31lmzQzpc,www.youtube.com/watch?v=YW31lmzQzpc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/YW31lmzQzpc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Lightweight Relief Shearing for Enhanced Terrain Perception on Interactive Maps,"Wesley Willett, Bernhard Jenny, Tobias Isenberg, Pierre Dragicevic","We explore interactive relief shearing, a set of non-intrusive, direct manipulation interactions that expose depth and shape information in terrain maps using ephemeral animations. Reading and interpreting topography and relief on terrain maps is an important aspect of map use, but extracting depth information from 2D maps is notoriously difficult. Modern mapping software attempts to alleviate this limitation by presenting digital terrain using 3D views. However, 3D views introduce occlusion, complicate distance estimations, and typically require more complex interactions. In contrast, our approach reveals depth information via shearing animations on 2D maps, and can be paired with existing interactions such as pan and zoom. We examine explicit, integrated, and hybrid interactions for triggering relief shearing and present a version that uses device tilt to control depth effects. Our evaluation shows that these interactive techniques improve depth perception when compared to standard 2D and perspective views.",TRUE
pn332,2702173,http://dx.doi.org/10.1145/2702123.2702173,http://dl.acm.org/citation.cfm?id=2702173,TiuUuoVlKhg,www.youtube.com/watch?v=TiuUuoVlKhg,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/TiuUuoVlKhg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Color Portraits : From Color Picking to Interacting with Color,"Ghita Jalal, Nolwenn Maudet, Wendy E. Mackay","Although ubiquitous, color pickers have remained largely \ unchanged for 25 years. Based on contextual interviews \ with artists and designers, we created the Color Portraits \ design space to characterize five key color manipulation \ activities: sampling and tweaking individual colors, \ manipulating color relationships, combining colors with \ other elements, revisiting previous color choices, and \ revealing a design process through color. We found similar \ color manipulation requirements with scientists and \ engineers. We designed novel color interaction tools \ inspired by the design space, and used them as probes to \ identify specific design requirements, including: interactive \ palettes for sampling colors and exploring relationships; \ color composites for blending and decomposing colors with \ other elements; interactive histories to enable reuse of \ previous color choices; and providing color as a way to \ reveal underlying processes. We argue that color tools \ should allow users to interact with colors, not just pick or \ sample them.",TRUE
pn359,2702177,http://dx.doi.org/10.1145/2702123.2702177,http://dl.acm.org/citation.cfm?id=2702177,-yU3H3kEwrk,www.youtube.com/watch?v=-yU3H3kEwrk,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/-yU3H3kEwrk' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Visual Grouping in Menu Interfaces,"Duncan P Brumby, Susan Zhuang","Menu interfaces often arrange options into semantic groups. This semantic structure is then usually conveyed to the user by supplementary visual grouping cues. We investigate whether these visual grouping cues actually help users locate items in menus faster, and whether there is potential for these powerful grouping cues to impede search when used inappropriately. Thirty-six participants performed known-item searches of word menus. These menus differed along three dimensions: (1) whether visual grouping cues were used, (2) whether items were semantically organized, and (3) the number of items belonging to each semantic group. Results show that the usefulness of visual grouping entirely depends on the underlying semantic structure of the menu. When menus were semantically organized, having visual grouping cues delineate the boundaries between large semantic groups resulted in the fastest search times. But when semantically unrelated items were visually grouped together, participants took far longer to locate targets. Menu designers should therefore take great care to avoid visually grouping semantically unrelated items as this has the potential to hinder menu interactions.",TRUE
pn361,2702178,http://dx.doi.org/10.1145/2702123.2702178,http://dl.acm.org/citation.cfm?id=2702178,Z4kXs5trp_c,www.youtube.com/watch?v=Z4kXs5trp_c,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/Z4kXs5trp_c' width='640' height='360' frameborder='0' allowfullscreen='true'/>,IDSense: A Human Object Interaction Detection System Based on Passive UHF RFID,"Hanchuan Li, Can Ye, Alanson P Sample","In order to enable unobtrusive human object interaction detection, we propose a minimalistic approach to instrumenting everyday objects with passive (i.e. battery-free) UHF RFID tags. By measuring the changes in the physical layer of the communication channel between the RFID tag and reader (such as RSSI, RF phase, and read rate) we are able to classify, in real time, tag/object motion events along with two types of touch events. \ Through a user study, we demonstrate that our real-time classification engine is able to simultaneously track 20 objects and identify four movement classes with 93% accuracy. To demonstrate how robust this general-purpose interaction mechanism is, we investigate three usage scenarios 1) interactive storytelling with toys 2) inference of daily activities in the home 3) identification of customer browsing habits in a retail setting.  \ ",TRUE
pn365,2702180,http://dx.doi.org/10.1145/2702123.2702180,http://dl.acm.org/citation.cfm?id=2702180,-ITadxbL8Wk,www.youtube.com/watch?v=-ITadxbL8Wk,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/-ITadxbL8Wk' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Opportunities and Challenges for Data Physicalization,"Yvonne Jansen, Pierre Dragicevic, Petra Isenberg, Jason Alexander, Abhijit Karnik, Johan Kildal, Sriram Subramanian, Kasper Hornbæk","Physical representations of data have existed for thousands of years. Yet it is now that advances in digital fabrication, actuated tangible interfaces, and shape-changing displays are spurring an emerging area of research that we call Data Physicalization. It aims to help people explore, understand, and communicate data using computer-supported physical data representations. We call these representations physicalizations, analogously to visualizations – their purely visual counterpart. In this article, we go beyond the focused research questions addressed so far by delineating the research area, synthesizing its open challenges and laying out a research agenda.",TRUE
pn366,2702181,http://dx.doi.org/10.1145/2702123.2702181,http://dl.acm.org/citation.cfm?id=2702181,X4qk5AX5dQc,www.youtube.com/watch?v=X4qk5AX5dQc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/X4qk5AX5dQc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,The Social Impact of a Robot Co-Worker in Industrial Settings,"Allison Sauppé, Bilge Mutlu","Across history and cultures, robots have been envisioned as assistants working alongside people. Following this vision, an emerging family of products-collaborative manufacturing robots-is enabling human and robot workers to work side by side as collaborators in manufacturing tasks. Their introduction presents an opportunity to better understand people's interactions with and perceptions of a robot ""co-worker"" in a real-world setting to guide the design of these products. In this paper, we present findings from an ethnographic field study at three manufacturing sites and a Grounded Theory analysis of observations and interviews. Our results show that, even in this safety-critical manufacturing setting, workers relate to the robot as a social entity and rely on cues to understand the robot's actions, which we observed to be critical for workers to feel safe when near the robot. These findings contribute to our understanding of interactions with robotic products in real-world settings and offer important design implications.",TRUE
pn382,2702186,http://dx.doi.org/10.1145/2702123.2702186,http://dl.acm.org/citation.cfm?id=2702186,e2SDLVNG8Jc,www.youtube.com/watch?v=e2SDLVNG8Jc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/e2SDLVNG8Jc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,RIMES: Embedding Interactive Multimedia Exercises in Lecture Videos,"Juho Kim, Elena L Glassman, Andres Monroy-Hernandez, Meredith Ringel Morris","Teachers in conventional classrooms often ask learners to express themselves and show their thought processes by speaking out loud, drawing on a whiteboard, or even using physical objects. Despite the pedagogical value of such activities, interactive exercises available in most online learning platforms are constrained to multiple-choice and short answer questions. We introduce RIMES, a system for easily authoring, recording, and reviewing interactive multimedia exercises embedded in lecture videos. With RIMES, teachers can prompt learners to record their responses to an activity using video, audio, and inking while watching lecture videos. Teachers can then review and interact with all the learners’ responses in an aggregated gallery. We evaluated RIMES with 19 teachers and 25 students. Teachers created a diverse set of activities across multiple subjects that tested deep conceptual and procedural knowledge. Teachers found the exercises useful for capturing students’ thought processes, identifying misconceptions, and engaging students with content.",TRUE
pn399,2702190,http://dx.doi.org/10.1145/2702123.2702190,http://dl.acm.org/citation.cfm?id=2702190,JSfnm_HoUv4,www.youtube.com/watch?v=JSfnm_HoUv4,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/JSfnm_HoUv4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Cruise Control for Pedestrians: Controlling Walking Direction using Electrical Muscle Stimulation,"Max Pfeiffer, Tim Dünte, Stefan Schneegass, Florian Alt, Michael Rohs","Pedestrian navigation systems require users to perceive, interpret, \ and react to navigation information. This can tax cognition \ as navigation information competes with information \ from the real world. We propose actuated navigation, a new \ kind of pedestrian navigation in which the user does not need \ to attend to the navigation task at all. An actuation signal is \ directly sent to the human motor system to influence walking \ direction. To achieve this goal we stimulate the sartorius \ muscle using electrical muscle stimulation. The rotation occurs \ during the swing phase of the leg and can easily be counteracted. \ The user therefore stays in control. We discuss the \ properties of actuated navigation and present a lab study on \ identifying basic parameters of the technique as well as an \ outdoor study in a park. The results show that our approach \ changes a user’s walking direction by about 16°/m on average \ and that the system can successfully steer users in a park with \ crowded areas, distractions, obstacles, and uneven ground.",TRUE
pn409,2702193,http://dx.doi.org/10.1145/2702123.2702193,http://dl.acm.org/citation.cfm?id=2702193,k5EQTeuIkTQ,www.youtube.com/watch?v=k5EQTeuIkTQ,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/k5EQTeuIkTQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Modeling Ideology and Predicting Policy Change with Social Media: Case of Same-Sex Marriage,"Amy X. Zhang, Scott Counts","Social media has emerged as a prominent platform where people can express their feelings about social and political issues of our time. We study the many voices discussing an issue within a constituency and how they reflect ideology and may signal the outcome of important policy decisions. Focusing on the issue of same-sex marriage legalization, we examine almost 2 million public Twitter posts related to same-sex marriage in the U.S. states over the course of 4 years starting from 2011. Among other findings, we find evidence of moral culture wars between ideologies and show that constituencies that express higher levels of emotion and have fewer actively engaged participants often precede legalization efforts that fail. From our measures, we build statistical models to predict the outcome of potential policy changes, with our best model achieving 87% accuracy. We also achieve accuracies of 70%, comparable to public opinion surveys, many months before a policy decision. We discuss how these analyses can augment traditional political science techniques as well as assist activists and policy analysts in understanding discussions on important issues at a population scale.",TRUE
pn410,2702194,http://dx.doi.org/10.1145/2702123.2702194,http://dl.acm.org/citation.cfm?id=2702194,-t0U7-BiWHw,www.youtube.com/watch?v=-t0U7-BiWHw,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/-t0U7-BiWHw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,"Mailing Lists: Why Are They Still Here, What's Wrong With Them, and How Can We Fix Them?","Amy X. Zhang, Mark S. Ackerman, David R. Karger","Mailing lists have existed since the early days of email and are still widely used today, even as more sophisticated online forums and social media websites proliferate. The simplicity of mailing lists can be seen as a reason for their endurance, a source of dissatisfaction, and an opportunity for improvement. Using a mixed-method approach, we studied two community mailing lists in depth with interviews and surveys, and surveyed a broader spectrum of 28 lists. We report how members of the different communities use their lists and their goals and desires for them. We explore why members prefer mailing lists to other group communication tools. But we also identify several tensions around mailing list usage that appear to contribute to dissatisfaction with them. We conclude with design implications, discussing ways to alleviate these tensions while preserving mailing lists’ appeal.",TRUE
pn414,2702197,http://dx.doi.org/10.1145/2702123.2702197,http://dl.acm.org/citation.cfm?id=2702197,RRKR0dekPxo,www.youtube.com/watch?v=RRKR0dekPxo,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/RRKR0dekPxo' width='640' height='360' frameborder='0' allowfullscreen='true'/>,TastyBeats: Designing Palatable Representations of Physical Activity,"Rohit Ashok Khot, Jeewon Lee, Deepti Aggarwal, Larissa Hjorth, Florian 'Floyd' Mueller","In this paper, we introduce palatable representations that besides improving the understanding of physical activity through abstract visualization also provide an appetizing drink to celebrate the experience of being physically active. By designing such palatable representations, our aim is to offer novel opportunities for reflection on one’s physical activities. We present TastyBeats, a fountain-based interactive system that creates a fluidic spectacle of mixing sport drinks based on heart rate data of physical activity, which the user can later consume to replenish the loss of body fluids due to the physical activity. We articulate our experiences in designing the system as well as learning gained through field deployments of the system in participants’ homes for a period of two weeks. We found that our system increased participants’ awareness of physical activity and facilitated a shared social experience, while the prepared drink was treated as a hedonic reward that motivated participants to exercise more. Ultimately, with this work, we aim to inspire and guide design thinking on palatable representations, which we believe opens up new interaction possibilities to support physical activity experience.",TRUE
pn416,2702198,http://dx.doi.org/10.1145/2702123.2702198,http://dl.acm.org/citation.cfm?id=2702198,8qLmWETHkwM,www.youtube.com/watch?v=8qLmWETHkwM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/8qLmWETHkwM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,GACA: Group-Aware Command-based Arrangement of Graphic Elements,"Pengfei Xu, Hongbo Fu, Chiew-Lan Tai, Takeo Igarashi","Many graphic applications rely on command-based arrangement tools to achieve precise layouts. Traditional tools are designed to operate on a single group of elements that are distributed consistently with the arrangement axis implied by a command. This often demands a process with repeated element selections and arrangement commands to achieve 2D layouts involving multiple rows and/or columns of well aligned and/or distributed elements. Our work aims to reduce the numbers of selection operation and command invocation, since such reductions are particularly beneficial to professional designers who design lots of layouts. Our key idea is that an issued arrangement command is in fact very informative, instructing how to automatically decompose a 2D layout into multiple 1D groups, each of which is compatible with the command. We present a parameter-free, command-driven grouping approach so that users can easily predict our grouping results. We also design a simple user interface with pushpins to enable explicit control of grouping and arrangement. Our user study confirms the intuitiveness of our technique and its performance improvement over traditional command-based arrangement tools. \ ",TRUE
pn420,2702199,http://dx.doi.org/10.1145/2702123.2702199,http://dl.acm.org/citation.cfm?id=2702199,7i4FVfWdJxg,www.youtube.com/watch?v=7i4FVfWdJxg,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/7i4FVfWdJxg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Texting while Parenting: How Adults Use Mobile Phones while Caring for Children at the Playground,"Alexis Hiniker, Kiley Sobel, Hyewon Suh, Yi-Chen Sung, Charlotte P. Lee, Julie A Kientz","Child development research suggests that using phones while caring for children can be problematic, but limited prior work in this space makes defining appropriate use challenging. We conducted the first exploration of whether adults feel pressure to limit phone use in this context and whether they choose to do so. Through mixed methods, we collected data from 466 adult caregivers at playgrounds. We found that phone use was a small part of playground time, yet a notable source of guilt. Adults engaged in systematic and specific phone-use and phone-non-use behaviors in order to prioritize their children above themselves. Our results indicate that caregiver values and self-control together predict behavior and can be used to model phone use in this context. Users’ mixed success with engaging in intentional periods of non-use suggests that a design agenda which prioritizes cycles of engagement, disengagement, and re-engagement may be of value to this group. ",TRUE
pn439,2702203,http://dx.doi.org/10.1145/2702123.2702203,http://dl.acm.org/citation.cfm?id=2702203,xC3-oZ0YEoo,www.youtube.com/watch?v=xC3-oZ0YEoo,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/xC3-oZ0YEoo' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Beyond Participatory Production: Digitally Supporting Grassroots Documentary,"David Philip Green, Simon J Bowen, Christopher Newell, Guy Schofield, Tom Bartindale, Clara Crivellaro, Alia Sheikh, Peter C Wright, Patrick Olivier","We conducted a study to explore the values and qualities of ‘grassroots documentaries’, framed around the production of two parallel documentary films with a London-based opera company. A team of professional filmmakers produced one film and the other was an exploratory form of grassroots documentary. We studied the different production activities through observations, interviews and a reflective workshop at the end of the study and evaluated the resulting films. Our analysis reveals critical insights that could inform the next generation of technological systems to support user-generated video content (UGVC) production, particularly in collaborative contexts such as grassroots communities.",TRUE
pn448,2702204,http://dx.doi.org/10.1145/2702123.2702204,http://dl.acm.org/citation.cfm?id=2702204,dKAN_71aorY,www.youtube.com/watch?v=dKAN_71aorY,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/dKAN_71aorY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Moving Beyond Fun: Evaluating Serious Experience in Digital Games,"Ioanna Iacovides, Anna L Cox","Games are normally considered to be “fun”, though recently there is growing interest in how gameplay can promote empathy and encourage reflection through “serious experience”. However, when looking beyond enjoyment, it is not clear how to actually evaluate serious experience. We present an evaluation of four games that were submitted to a student game design competition; the competition challenged teams to design a game that inspired curiosity around human error and blame culture within the context of healthcare. The entries were judged by a panel of six experts and subjected to a round of play testing by twelve participants. Methods included gameplay observation, questionnaires, post-play interviews and follow-up email questions. We discuss the utility of these methods, with particular emphasis on how they enabled a consideration of the immediate and longer term impact of serious experience on players. ",TRUE
pn451,2702206,http://dx.doi.org/10.1145/2702123.2702206,http://dl.acm.org/citation.cfm?id=2702206,8U5yLcGBQ0M,www.youtube.com/watch?v=8U5yLcGBQ0M,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/8U5yLcGBQ0M' width='640' height='360' frameborder='0' allowfullscreen='true'/>,FugaciousFilm: Exploring Attentive Interaction with Ephemeral Material,"Hyosun Kwon, Shashank Jaiswal, Steve Benford, Sue Ann Seah, Peter Bennett, Boriana Koleva, Holger Schnädelbach","This paper introduces FugaciousFilm, a soap film based touch display, as a platform for Attentive Interaction that encourages the user to be highly focused throughout the use of the interface. Previous work on ephemeral user interfaces has primarily focused on the development of ambient and peripheral displays. In contrast, FugaciousFilm is an ephemeral display that aims to promote highly attentive interaction. We present the iterative process of developing this interface, spanning technical explorations, prototyping and a user study. We report lessons learnt when designing the interface; ranging from the soap film mixture to the impact of frames and apertures. We then describe developing the touch, push, pull and pop interactions. Our user study shows how FugaciousFilm led to focused and attentive interactions during a tournament of enhanced Tic-Tac-Toe. We then finish by discussing how the principles of vulnerability and delicacy can motivate the design of attentive ephemeral interfaces.  ",TRUE
pn453,2702207,http://dx.doi.org/10.1145/2702123.2702207,http://dl.acm.org/citation.cfm?id=2702207,DZn0LVZsBUo,www.youtube.com/watch?v=DZn0LVZsBUo,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/DZn0LVZsBUo' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Lamello: Passive Acoustic Sensing for Tangible Input Components,"Valkyrie Savage, Andrew Head, Björn Hartmann, Dan B Goldman, Gautham Mysore, Wilmot Li","We describe Lamello, an approach for creating tangible input components that recognize user interaction via passive acoustic sensing. Lamello employs comb-like structures with varying-length tines at interaction points (e.g., along slider paths). Moving a component generates tine strikes; a real-time audio processing pipeline analyzes the resultant sounds and emits high-level interaction events. Our main contributions are in the co-design of the tine structures, information encoding schemes, and audio analysis. We demonstrate 3D printed Lamello-powered buttons, sliders, and dials. ",TRUE
pn464,2702209,http://dx.doi.org/10.1145/2702123.2702209,http://dl.acm.org/citation.cfm?id=2702209,oeAGe5lEewM,www.youtube.com/watch?v=oeAGe5lEewM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/oeAGe5lEewM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Making Software Tutorial Video Responsive,"Cuong Nguyen, Feng Liu","Tutorial videos are widely available to help people use software. These videos, however, are viewed by users as captured and offer little direct interaction between users and software. This paper presents a video navigation method that allows users to interact with software tutorial video as if they were using the software. To make the tutorial video responsive, our method records the user interaction events like mouse click and drag during capturing the video. Our method then analyzes, selects, and visualizes these user interaction events at the event locations. When a user directly interacts with an event visualization, our method automatically navigates to the proper video frame to provide the visual feedback as if the software were responding to the user input. Thus, our method provides the experience of interacting with the software through directly manipulating the tutorial video. Our study shows our method can better help users follow tutorial videos to complete tasks than the baseline timeline interface.",TRUE
pn466,2702210,http://dx.doi.org/10.1145/2702123.2702210,http://dl.acm.org/citation.cfm?id=2702210,Taa5ADLsToM,www.youtube.com/watch?v=Taa5ADLsToM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/Taa5ADLsToM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,"Your Location has been Shared 5,398 Times! A Field Study on Mobile App Privacy Nudging","Hazim Almuhimedi, Florian Schaub, Norman Sadeh, Idris Adjerid, Alessandro Acquisti, Joshua Gluck, Lorrie Cranor, Yuvraj Agarwal","Smartphone users are often unaware of the data collected by apps running on their devices. We report on a study that evaluates the benefits of giving users an app permission manager and sending them nudges intended to raise their awareness of the data collected by their apps. Our study provides both qualitative and quantitative evidence that these approaches are complementary and can each play a significant role in empowering users to more effectively control their privacy. For instance, even after a week with access to the permission manager, participants benefited from nudges showing them how often some of their sensitive data was being accessed by apps, with 95% of participants reassessing their permissions, and 58% of them further restricting some of their permissions. We discuss how participants interacted both with the permission manager and the privacy nudges, analyze the effectiveness of both solutions, and derive some recommendations.",TRUE
pn479,2702211,http://dx.doi.org/10.1145/2702123.2702211,http://dl.acm.org/citation.cfm?id=2702211,VEgNxj2JgaU,www.youtube.com/watch?v=VEgNxj2JgaU,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/VEgNxj2JgaU' width='640' height='360' frameborder='0' allowfullscreen='true'/>,A Diary Study on Combining Multiple Information Devices in Everyday Activities and Tasks,"Tero Jokela, Jarno Ojala, Thomas Olsson","As people possess increasing numbers of information devices, situations where several devices are combined and used together have become more common. We present a user study on people’s current practices in combining multiple information devices in their everyday lives, ranging from pragmatic tasks to leisure activities. Based on diaries and interviews of 14 participants, we characterize the usage practices of the most common devices, including smartphones, computers, tablets, and home media centers. We analyze 123 real-life multi-device use cases and identify the main usage patterns, including Sequential Use, Resource Lending, Related Parallel Use, and Unrelated Parallel Use. We discuss the practical challenges of using several information devices together. Finally, we identify three levels of decisions that determine which devices are used in a particular situation, including acquiring, making available, and selecting the devices for use.",TRUE
pn480,2702212,http://dx.doi.org/10.1145/2702123.2702212,http://dl.acm.org/citation.cfm?id=2702212,5gKjcFwb55c,www.youtube.com/watch?v=5gKjcFwb55c,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/5gKjcFwb55c' width='640' height='360' frameborder='0' allowfullscreen='true'/>,SwiPIN - Fast and Secure PIN-Entry on Smartphones,"Emanuel von Zezschwitz, Alexander De Luca, Bruno Brunkow, Heinrich Hussmann","In this paper, we present SwiPIN, a novel authentication system that allows input of traditional PINs using simple touch gestures like up or down and makes it secure against human observers. We present two user studies which evaluated different designs of SwiPIN and compared it against traditional PIN. The results show that SwiPIN performs adequately fast (3.7 s) to serve as an alternative input method for risky situations. Furthermore, SwiPIN is easy to use, significantly more secure against shoulder surfing attacks and switching between PIN and SwiPIN feels natural.",TRUE
pn481,2702213,http://dx.doi.org/10.1145/2702123.2702213,http://dl.acm.org/citation.cfm?id=2702213,tYg_xJdAjls,www.youtube.com/watch?v=tYg_xJdAjls,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/tYg_xJdAjls' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Patina Engraver: Visualizing Activity Logs as Patina in Fashionable Trackers,"Moon-Hwan Lee, Seijin Cha, Tek-Jin Nam","Despite technological improvements in commercial activity trackers, little attention has been given to their emotional, social, or fashion-related qualities, such as their visual aesthetics and their relationship to self-expression and social connection. As an alternative integrated approach incorporating HCI, fashion, and product design, our project made use of the characteristics of patina to improve activity trackers as fashionable wearables. We developed the Patina Engraving System, which engraves patina-like patterns on an activity tracker according to a user’s activity logs. Using a piercing technique, the patina of activity logs has been made abstract, visually rich, gradually emerging, and historically accumulated. During the field trial, we found that the patina motivated the participants to increase exercises for engraving aesthetic patinas. A tracker with patina triggered spontaneous social interactions in face-to-face situations. The participants also cherished the trackers that held their own history. Based on the field trial, we discuss design implications for utilizing patina in designing future fashionable technologies.",TRUE
pn488,2702215,http://dx.doi.org/10.1145/2702123.2702215,http://dl.acm.org/citation.cfm?id=2702215,u4js7V0-Uq0,www.youtube.com/watch?v=u4js7V0-Uq0,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/u4js7V0-Uq0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,WatchConnect: A Toolkit for Prototyping Smartwatch-Centric Cross-Device Applications,"Steven Houben, Nicolai Marquardt","People increasingly use smartwatches in tandem with other devices such as smartphones, laptops or tablets. This allows for novel cross-device applications that use the watch as both input device and output display. However, despite the increasing availability of smartwatches, prototyping cross-device watch-centric applications remains a challenging task. Developers are limited in the applications they can explore as available toolkits provide only limited access to different types of input sensors for cross-device interactions. To address this problem, we introduce WatchConnect, a toolkit for rapidly prototyping cross-device applications and interaction techniques with smartwatches. The toolkit provides developers with (i) an extendable hardware platform that emulates a smartwatch, (ii) a UI framework that integrates with an existing UI builder, and (iii) a rich set of input and output events using a range of built-in sensor mappings. We demonstrate the versatility and design space of the toolkit with five interaction techniques and applications.",TRUE
pn504,2702218,http://dx.doi.org/10.1145/2702123.2702218,http://dl.acm.org/citation.cfm?id=2702218,KWn5mJL14Hs,www.youtube.com/watch?v=KWn5mJL14Hs,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/KWn5mJL14Hs' width='640' height='360' frameborder='0' allowfullscreen='true'/>,uCap: An Internet Data Management Tool for the Home,"Marshini Chetty, Hyojoon Kim, Srikanth Sundaresan, Sam Burnett, Nick Feamster, W. Keith Edwards","Internet Service Providers (ISPs) have introduced “data caps”, or quotas on the amount of data that a customer can download during a billing cycle. Under this model, Internet users who reach a data cap can be subject to degraded performance, extra fees, or even temporary interruption of Internet service. For this reason, users need better visibility into and control over their Internet usage to help them understand what uses up data and control how these quotas are reached. In this paper, we present the design and implementation of a tool, called uCap, to help home users manage Internet data. We conducted a field trial of uCap in 21 home networks in three countries and performed an in-depth qualitative study of ten of these homes. We present the results of the evaluation and implications for the design of future Internet data management tools.",TRUE
pn507,2702219,http://dx.doi.org/10.1145/2702123.2702219,http://dl.acm.org/citation.cfm?id=2702219,HFmJRbaML_E,www.youtube.com/watch?v=HFmJRbaML_E,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/HFmJRbaML_E' width='640' height='360' frameborder='0' allowfullscreen='true'/>,In the Heat of the Moment: Subjective Interpretations of Thermal Feedback During Interaction,"Graham Wilson, Gavin Davidson, Stephen Brewster","Research has shown that thermal feedback can be an engaging and convincing means of conveying experimenter-predefined meanings, e.g., material properties or message types. However, thermal perception is subjective and its meaning in interaction can be ambiguous. Interface designers may not be sure how users could naïvely interpret thermal feedback during interaction. Little is also known about how users would choose thermal cues to convey their own meanings. The research in this paper tested subjective interpretations of thermal stimuli in three different scenarios: social media activity, a colleague’s presence and the extent of use of digital content. Participants were also asked to assign their own thermal stimuli to personal experiences, to help us understand what kinds of stimuli people associate with different meanings. The results showed strong agreement among participants concerning what warmth (presence, activity, quality) and cool mean (absence, poor quality). Guidelines for the design of thermal feedback are presented to help others create effective thermal interfaces.",TRUE
pn517,2702220,http://dx.doi.org/10.1145/2702123.2702220,http://dl.acm.org/citation.cfm?id=2702220,eixmJqiRVMw,www.youtube.com/watch?v=eixmJqiRVMw,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/eixmJqiRVMw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Trap it! : A Playful Human-Biology Interaction for a Museum Installation,"Seung Ah Lee, Engin Bumbacher, Alice M Chung, Nate Cira, Byron Walker, Ji Young Park, Barry Starr, Paulo Blikstein, Ingmar H Riedel-Kruse","We developed Trap it!, a human-biology interaction (HBI) medium encompassing a touchscreen interface, microscopy, and light projection. Users can interact with living cells by drawing on a touchscreen displaying the microscope view of the cells. These drawings are projected onto the microscopy field as light patterns, prompting observable movement in phototactic responses. The system design enables stable and robust HBI and a wide variety of programmed activities (art, games, and experiments). We investigated its affordances as an exhibit in a science museum in both facilitated and unfacilitated contexts. Overall, it had a low barrier of entry and fostered rich communication among visitors. Visitors were particularly excited upon realizing that the interaction involved real organisms, an understanding that was facilitated by the eyepiece on the physical system. With the results from user study, we provide our observations, insights and guidelines for designing HBI as a permanent museum exhibit.",TRUE
pn525,2702222,http://dx.doi.org/10.1145/2702123.2702222,http://dl.acm.org/citation.cfm?id=2702222,3x9qtJjXkuY,www.youtube.com/watch?v=3x9qtJjXkuY,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/3x9qtJjXkuY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,The Semantic Paintbrush: Interactive 3D Mapping and Recognition in Large Outdoor Spaces,"Ondrej Miksik, Vibhav Vineet, Morten Lidegaard, Ram Prasaath, Matthias Niessner, Stuart Golodetz, Stephen L Hicks, Patrick Perez, Shahram Izadi, Philip HS Torr","We present an augmented reality system for large scale 3D reconstruction and recognition in outdoor scenes. Unlike existing prior work, which tries to reconstruct scenes using active depth cameras, we use a purely passive stereo setup, allowing for outdoor use and extended sensing range. Our system not only produces a map of the 3D environment in real-time, it also allows the user to draw (or `paint') with a laser pointer directly onto the reconstruction to segment the model into objects. Given these examples our system then learns to segment other parts of the 3D map during online acquisition. Unlike typical object recognition systems, ours therefore very much places the user `in the loop' to segment particular objects of interest, rather than learning from predefined databases. The laser pointer additionally helps to `clean up' the stereo reconstruction and final 3D map, interactively. Using our system, within minutes, a user can capture a full 3D map, segment it into objects of interest, and refine parts of the model during capture. We provide full technical details of our system to aid replication, as well as quantitative evaluation of system components. We demonstrate the possibility of using our system for helping the visually impaired navigate through spaces. Beyond this use, our system can be used for playing large-scale augmented reality games, shared online to augment streetview data, and used for more detailed car and person navigation.",TRUE
pn532,2702224,http://dx.doi.org/10.1145/2702123.2702224,http://dl.acm.org/citation.cfm?id=2702224,V8mF4nqXbMo,www.youtube.com/watch?v=V8mF4nqXbMo,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/V8mF4nqXbMo' width='640' height='360' frameborder='0' allowfullscreen='true'/>,DynamicMaps: Similarity-based Browsing through a Massive Set of Images,"Yanir Kleiman, Joel Lanir, Dov Danon, Yasmin Felberbaum, Daniel Cohen-Or","We present a novel system for browsing through a very large set of images according to similarity. The images are dynamically placed on a 2D canvas next to their nearest neighbors in a high-dimensional feature space. The layout and choice of images is generated on-the-fly during user interaction, reflecting the user's navigation tendencies and interests. This intuitive solution for image browsing provides a continuous experience of navigating through an infinite 2D grid arranged by similarity. In contrast to common multidimensional embedding methods, our solution does not entail an upfront creation of a full global map. Image map generation is dynamic, fast and scalable, independent of the number of images in the dataset, and seamlessly supports online updates to the dataset. Thus, the technique is a viable solution for massive and constantly varying datasets consisting of millions of images. Evaluation of our approach shows that when using DynamicMaps, users viewed many more images per minute compared to a standard relevance feedback interface, suggesting that it supports more fluid and natural interaction that enables easier and faster movement in the image space. Most users preferred DynamicMaps, indicating it is more exploratory, better supports serendipitous browsing and more fun to use",TRUE
pn545,2702225,http://dx.doi.org/10.1145/2702123.2702225,http://dl.acm.org/citation.cfm?id=2702225,Sn2R8ElOxoo,www.youtube.com/watch?v=Sn2R8ElOxoo,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/Sn2R8ElOxoo' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Platener: Low-Fidelity Fabrication of 3D Objects by Substituting 3D Print with Laser-Cut Plates,"Dustin Beyer, Serafima Gurevich, Stefanie Mueller, Hsiang-Ting Chen, Patrick Baudisch","This paper presents Platener, a system that allows quickly fabricating intermediate design iterations of 3D models, a process also known as low-fidelity fabrication. Platener achieves its speed-up by extracting straight and curved plates from the 3D model and substituting them with laser cut parts of the same size and thickness. Only the regions that are of relevance to the current design iteration are executed as full-detail 3D prints. Platener connects the parts it has created by automatically inserting joints. To help fast assembly it engraves instructions. Platener allows users to customize substitution results by (1) specifying fidelity-speed tradeoffs, (2) choosing whether or not to convert curved surfaces to plates bent using heat, and (3) specifying the conversion of individual plates and joints interactively.  \ Platener is designed to best preserve the fidelity of func-tional objects, such as casings and mechanical tools, all of which contain a large percentage of straight/rectilinear elements. Compared to other low-fab systems, such as faBrickator and WirePrint, Platener better preserves the stability and functionality of such objects: the resulting assemblies have fewer parts and the parts have the same size and thickness as in the 3D model.  \ To validate our system, we converted 2.250 3D models downloaded from a 3D model site (Thingiverse). Platener achieves a speed-up of 10 or more for 39.5% of all objects. \ ",TRUE
pn546,2702226,http://dx.doi.org/10.1145/2702123.2702226,http://dl.acm.org/citation.cfm?id=2702226,7Dkbfv_JQD0,www.youtube.com/watch?v=7Dkbfv_JQD0,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/7Dkbfv_JQD0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Beats: Tapping Gestures for Smart Watches,"Ian Oakley, DoYoung Lee, MD. Rasel Islam, Augusto Esteves","Interacting with smartwatches poses new challenges. Although capable of displaying complex content, their extremely small screens poorly match many of the touchscreen interaction techniques dominant on larger mobile devices. Addressing this problem, this paper presents beating gestures, a novel form of input based on pairs of simultaneous or rapidly sequential and overlapping screen taps made by the index and middle finger of one hand. Distinguished simply by their temporal sequence and relative left/right position these gestures are designed explicitly for the very small screens (approx. 40mm square) of smartwatches and to operate without interfering with regular single touch input. This paper presents the design of beating gestures and a rigorous empirical study that characterizes how users perform them – in a mean of 355ms and with an error rate of 5.5%. We also derive thresholds for reliably distinguishing between simultaneous (under 30ms) and sequential (under 400ms) pairs of screen touches or releases. We then present five interface designs and evaluate them in a qualitative study in which users report valuing the speed and ready availability of beating gestures.",TRUE
pn548,2702227,http://dx.doi.org/10.1145/2702123.2702227,http://dl.acm.org/citation.cfm?id=2702227,6d8AExgELPo,www.youtube.com/watch?v=6d8AExgELPo,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/6d8AExgELPo' width='640' height='360' frameborder='0' allowfullscreen='true'/>,An Experimental Comparison of Vertical and Horizontal Dynamic Peephole Navigation,"Jens Müller, Roman Rädle, Hans-Christian Jetter, Harald Reiterer","Dynamic peephole navigation represents a technique for navigating large information spaces in an egocentric way. Studies have shown cognitive benefits for a vertical peephole orientation, when compared to non-egocentric interaction styles. To see how the aspect of canvas orientation effects user performance, we conducted a study (N=16) which revealed that canvas orientation has no significant effect on either navigation performance or spatial memory. We also found a significantly lower physical demand and a higher mental demand in the horizontal orientation. For short-term activities we therefore propose a vertical orientation, while for long-term activities horizontal dynamic peephole navigation is more suitable.",TRUE
pn555,2702229,http://dx.doi.org/10.1145/2702123.2702229,http://dl.acm.org/citation.cfm?id=2702229,QnssXRTBE9k,www.youtube.com/watch?v=QnssXRTBE9k,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/QnssXRTBE9k' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Bootlegger: Turning Fans into Film Crew,"Guy Schofield, Tom Bartindale, Peter Wright","Bootlegger is a system for creating multi-camera films of live music events using mobile devices. Using readily available technology and a synthesis of film-making conventions, the system coordinates music fans at live shows into an improvised film crew, suggesting shots, collating footage and generating rich metadata in real time. Bootlegger is part of a research project exploring adapting professional media workflows to amateur contexts in order to lower the bar to entry for media production. By enabling concert-goers to contribute to high-quality concert films, the system leverages mobile phone ‘bootlegging’ practices to support emerging musicians.",TRUE
pn564,2702231,http://dx.doi.org/10.1145/2702123.2702231,http://dl.acm.org/citation.cfm?id=2702231,OSKJWUukxCs,www.youtube.com/watch?v=OSKJWUukxCs,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/OSKJWUukxCs' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Fluid Grouping: Quantifying Group Engagement around Interactive Tabletop Exhibits in the Wild,"Florian Block, James Hammerman, Michael Horn, Amy Spiegel, Jonathan Christiansen, Brenda Phillips, Judy Diamond, E. Margaret Evans, Chia Shen","Interactive surfaces are increasingly common in museums and other informal learning environments where they are seen as a medium for promoting social engagement. However, despite their increasing prevalence, we know very little about factors that contribute to collaboration and learning around interactive surfaces. In this paper we present analyses of visitor engagement around several multi-touch tabletop science exhibits. Observations of 629 visitors were collected through two widely used techniques: video study and shadowing. We make four contributions: 1) we present an algorithm for identifying groups within a dynamic flow of visitors through an exhibit hall; 2) we present measures of group-level engagement along with methods for statistically analyzing these measures; 3) we assess the effect of observational techniques on visitors’ engagement, demonstrating that consented video studies do not necessarily reflect visitor behavior in more naturalistic circumstances; and 4) we present an analysis showing that groups of two, groups with both children and adults, and groups that take turns spend longer at the exhibits and engage more with scientific concepts.",TRUE
pn569,2702232,http://dx.doi.org/10.1145/2702123.2702232,http://dl.acm.org/citation.cfm?id=2702232,M-rM8Quhjac,www.youtube.com/watch?v=M-rM8Quhjac,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/M-rM8Quhjac' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Beyond the Individual: The Contextual Wheel of Practice as a Research Framework for Sustainable HCI,"Johanne Mose Entwistle, Mia Kruse Rasmussen, Nervo Verdezoto, Robert S Brewer, Mads Schaarup Andersen","Addressing human impact on the environment by focusing on shared everyday practices, rather than just individual behavior is an approach that shows promise. However, it can be challenging to put this approach into concrete use, especially in teams unfamiliar with the practice orientation. To support the practice approach, we introduce the Contextual Wheel of Practice (COWOP), a framework that can: 1) help researchers and designers to better understand practices, 2) design effective interventions, and 3) facilitate collaboration between team members from different disciplines, who may not be familiar with the practice orientation. We describe how COWOP was developed, and our experiences using COWOP in three different cases. We then position COWOP as part of the “turn to practice” in HCI, and discuss how it can be useful to HCI researchers and be applied in domains beyond sustainability, such as healthcare and privacy.",TRUE
pn587,2702236,http://dx.doi.org/10.1145/2702123.2702236,http://dl.acm.org/citation.cfm?id=2702236,Sbb1EBbNf0c,www.youtube.com/watch?v=Sbb1EBbNf0c,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/Sbb1EBbNf0c' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Sculpting a Mobile Musical Soundtrack,"Adrian Hazzard, Steve Benford, Gary Burnett","We present an in-the-wild project to design and study a mobile musical soundtrack that enhances the experience of visiting a sculpture park. As with soundtracks for films and games, the goal was to enhance the emotional and narrative aspects of the experience while remaining in the background. We describe a compositional approach in which we first established a broad musical landscape before treating specific exhibits with detailed musical trajectories. Our study reveals how our soundtrack dramatically shaped visitors’ experiences while they remained largely unaware of its operation. We distil seven experiential factors to be addressed by mobile soundtracks alongside ten compositional guidelines.",TRUE
pn592,2702237,http://dx.doi.org/10.1145/2702123.2702237,http://dl.acm.org/citation.cfm?id=2702237,ZuLbEWXAIlI,www.youtube.com/watch?v=ZuLbEWXAIlI,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/ZuLbEWXAIlI' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Investigating the Direct Manipulation of Ranking Tables for Time Navigation,"Romain Vuillemot, Charles Perin","We introduce a novel time navigation technique to update ranking tables by direct manipulation. The technique allows users to drag a table's cells to change the time period, while a line chart overlays on top of the table to provide an overview of the changes. The line chart is also a visual hint to control the pace at which data are updated. We explore the design and usability of this technique for table variations in size, time spans and data variability. We report the results of a usability study, using academic citation rankings and economic complexity datasets, and discuss design implications coming with real-world scenarios such as missing data and affordance.",TRUE
pn598,2702240,http://dx.doi.org/10.1145/2702123.2702240,http://dl.acm.org/citation.cfm?id=2702240,fDJ_gEgGxqQ,www.youtube.com/watch?v=fDJ_gEgGxqQ,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/fDJ_gEgGxqQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Resilience Mitigates the Negative Effects of Adolescent Internet Addiction and Online Risk Exposure,"Pamela J Wisniewski, Haiyan Jia, Na Wang, Saijing Zheng, Heng Xu, Mary Beth Rosson, John M Carroll","We cannot fully protect adolescents from experiencing online risks; however, we can aim to better understand how online risk experiences impact teens, factors that contribute to or prevent teens from exposure to risk, as well as factors that can protect teens from psychological harm in spite of online risk exposure. Through a web-based survey study of 75 adolescents in the US, we develop and empirically validate a theoretical model of adolescent resilience in the presence of online risks. We show evidence that resilience is a key factor in protecting teens from experiencing online risks, even when teens exhibit high levels of Internet addiction. Resilience also neutralizes the negative psychological effects associated with Internet addiction and online risk exposure. Therefore, we emphasize the importance of design solutions that foster teen resilience and strength building, as opposed to solutions targeted toward parents that often focus on restriction and risk prevention.",TRUE
pn602,2702241,http://dx.doi.org/10.1145/2702123.2702241,http://dl.acm.org/citation.cfm?id=2702241,MgaEPkIYQa8,www.youtube.com/watch?v=MgaEPkIYQa8,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/MgaEPkIYQa8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Towards Making Random Passwords Memorable: Leveraging Users' Cognitive Ability Through Multiple Cues,"Mahdi Nasrullah Al-Ameen, Matthew Wright, Shannon Scielzo","Given the choice, users produce passwords reflecting common strategies and patterns that ease recall but offer uncertain and often weak security. System-assigned passwords provide measurable security but suffer from poor memorability. To address this usability-security tension, we argue that systems should assign random passwords but also help with memorization and recall. We investigate the feasibility of this approach with CuedR, a novel cued-recognition authentication scheme that provides users with multiple cues (visual, verbal, and spatial) and lets them choose the cues that best fit their learning process for later recognition of system-assigned keywords. In our lab study, all 37 of our participants could log in within three attempts one week after registration (mean login time: 38.0 seconds). A pilot study on using multiple CuedR passwords also showed 100% recall within three attempts. Based on our results, we suggest appropriate applications for CuedR, such as financial and e-commerce accounts.",TRUE
pn605,2702242,http://dx.doi.org/10.1145/2702123.2702242,http://dl.acm.org/citation.cfm?id=2702242,k4CFGMBvhBQ,www.youtube.com/watch?v=k4CFGMBvhBQ,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/k4CFGMBvhBQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Now You Can Compete With Anyone: Balancing Players of Different Skill Levels in a First-Person Shooter Game,"Rodrigo Vicencio-Moreira, Regan L. Mandryk, Carl Gutwin","When player skill levels differ widely in a competitive First-Person Shooter (FPS) game, enjoyment suffers: weaker players become frustrated and stronger players become less engaged. Player balancing techniques attempt to assist the weaker player and make games more competitive, but these techniques have limitations for deployment when skill levels vary substantially. We developed new player balancing schemes to deal with a range of FPS skill difference, and tested these techniques in one-on-one deathmatches using a commercial-quality FPS game developed with the UDK engine. Our results showed that the new balancing schemes are extremely effective at balancing, even for players with large skill differences. Surprisingly, the techniques that were most effective at balancing were also rated as most enjoyable by both players – even though these schemes were the most noticeable. Our study is the first to show that player balancing can work well in realistic FPS games, providing developers with a way to increase the audience for this popular genre. In addition, our results demonstrate the idea that successful balancing is as much about the way the technique is applied as it is about the specific manipulation.",TRUE
pn611,2702243,http://dx.doi.org/10.1145/2702123.2702243,http://dl.acm.org/citation.cfm?id=2702243,kFFmUn0mKQc,www.youtube.com/watch?v=kFFmUn0mKQc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/kFFmUn0mKQc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Keepin’ it Real: Challenges when Designing Sports-Training Games,"Mads Møller Jensen, Majken K Rasmussen, Florian ""Floyd"" Mueller, Kaj Grønbæk","Using game elements and mechanics in sports training holds great potential for increasing player enjoyment, but also introduces a risk of reducing training relevance. This paper describes a novel training installation for individual handball training, called “The Bouncer”, and the design process behind three training games. In order to investigate how game elements can affect the training experience, we conducted a study with 10 experienced amateur handball players, eliciting responses regarding the training relevance of the games. Based on the study and our design insights, we propose three challenges that designers of interactive sports-training games need to consider: 1) Maintaining relevance when translating physical elements into digital representations. 2) Choosing an appropriate level of sensing as game input. 3) Introducing points in training exercises without reducing sport relevance. For the three challenges, we propose strategies to help future designers of training games. ",TRUE
pn631,2702245,http://dx.doi.org/10.1145/2702123.2702245,http://dl.acm.org/citation.cfm?id=2702245,1bMWAS9Fp-o,www.youtube.com/watch?v=1bMWAS9Fp-o,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/1bMWAS9Fp-o' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Data-Things: Digital Fabrication Situated within Participatory Data Translation Activities,"Bettina Nissen, John Bowers","This paper explores a design-led approach to digital fabrication which situates it in participatory data translation activities to demonstrate that this technology can find application beyond its use as tool for manufacture. We present two contrasting design contexts in which, respectively, data from conference twitter conversations and craft practitioners’ movements are translated into interactively generated and fabricated physical artefacts. We argue that direct involvement in such digital fabrication activities can help people invest meaning into artefacts and facilitate social interaction and reflection upon their activities, while encouraging practitioners to incorporate new forms into their own work. On this basis, we reconsider digital fabrication within data translation activities as situated along an extended ‘trajectory of use’ in which reflective, meaningful ‘data-things’ can be created.",TRUE
pn638,2702246,http://dx.doi.org/10.1145/2702123.2702246,http://dl.acm.org/citation.cfm?id=2702246,xXl3F5AoeQU,www.youtube.com/watch?v=xXl3F5AoeQU,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/xXl3F5AoeQU' width='640' height='360' frameborder='0' allowfullscreen='true'/>,BaseLase: An Interactive Focus+Context Laser Floor,"Jörg Müller, Dieter Eberle, Constantin Schmidt","We present BaseLase, an interactive laser projected focus + context floor display. In order to provide a transportable system that works in areas where there are no ceilings, we provide an integrated unit (1.3m height) that stands on the floor. One unsolved challenge for laser projectors is to cover large projection areas while providing high resolution at the same time. Our focus + context laser projector solves this problem. BaseLase can cover a large context area in low resolution, while providing three movable high-resolution focus spots. We provide a convex mirror design that enables the laser to reach a large area (75m2) with low resolution while decreasing the beam divergence compared to spherical or parabolic mirrors. This hyperboloidal mirror shape approximately equalizes the point size on the floor independent from the projected location. We propose to add a number of planar mirrors on pan-tilt units to create dynamic zones of high resolution that can adjust to the user behavior. We provide example applications for BaseLase and report on user experience in preliminary trials.",TRUE
pn643,2702247,http://dx.doi.org/10.1145/2702123.2702247,http://dl.acm.org/citation.cfm?id=2702247,Ytv32TfuLyQ,www.youtube.com/watch?v=Ytv32TfuLyQ,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/Ytv32TfuLyQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,It's About Time: Smartwatches as Public Displays,"Jennifer Pearson, Simon Robinson, Matt Jones","Current uses of smartwatches are focused solely around the wearer's content, viewed by the wearer alone. When worn on a wrist, however, watches are often visible to many other people, making it easy to quickly glance at their displays. We explore the possibility of extending smartwatch interactions to turn personal wearables into more public displays. We begin opening up this area by investigating fundamental aspects of this interaction form, such as the social acceptability and noticeability of looking at someone else's watch, as well as the likelihood of a watch face being visible to others. We then sketch out interaction dimensions as a design space, evaluating each aspect via a web-based study and a deployment of three potential designs. We conclude with a discussion of the findings, implications of the approach and ways in which designers in this space can approach public wrist-worn wearables.",TRUE
pn650,2702248,http://dx.doi.org/10.1145/2702123.2702248,http://dl.acm.org/citation.cfm?id=2702248,i_-Q3uhiob8,www.youtube.com/watch?v=i_-Q3uhiob8,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/i_-Q3uhiob8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Evaluating the Memorability of Physical Visualizations,"Simon Stusak, Jeannette Schwarz, Andreas Butz","Physical Visualizations are currently mostly used in casual contexts, e.g., as artistic data sculptures. However, their measurable benefits for traditional information visualization are largely unexplored. As a step in this direction, we compared the memorability of physical visualizations to that of digital visualizations. We conducted a user study with 40 participants in which we measured the recall of three types of information immediately after exploration and with a delay of two weeks. The results show that the physical visualization led to significantly less information decay within this time span. Our results build on known effects from cognitive psychology and provide a first indicator for measurable benefits of physical visualizations regarding memorability.",FALSE
pn654,2702250,http://dx.doi.org/10.1145/2702123.2702250,http://dl.acm.org/citation.cfm?id=2702250,NsPuu5ck0k0,www.youtube.com/watch?v=NsPuu5ck0k0,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/NsPuu5ck0k0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Exploring Expressive Augmented Reality: The FingAR Puppet System for Social Pretend Play,"Zhen Bai, Alan F Blackwell, George Coulouris","We present ""FingAR Puppet"", an Augmented Reality (AR) system enhancing social pretend play by young children. Unlike goal-oriented AR systems that augment reality with informative instructions, FingAR Puppet helps children associate expressive interpretations with immediate reality. Empirical results show that FingAR Puppet promotes reasoning about emotional states, communication and divergent thinking during social pretend play for children 4-6 years old. We suggest that this study opens an interesting space for future AR systems to support complex cognitive and social development in early childhood. We also identify broader implications from using theories of cognitive development to guide the design of tangible and augmented interactions.",TRUE
pn665,2702253,http://dx.doi.org/10.1145/2702123.2702253,http://dl.acm.org/citation.cfm?id=2702253,UhqYIMG6nWE,www.youtube.com/watch?v=UhqYIMG6nWE,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/UhqYIMG6nWE' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Level-Ups: Motorized Stilts that Simulate Stair Steps in Virtual Reality,"Dominik Schmidt, Rob Kovacs, Vikram Mehta, Udayan Umapathi, Sven Köhler, Lung-Pan Cheng, Patrick Baudisch","We present “Level-Ups”, computer-controlled stilts that allow virtual reality users to experience walking up and down steps. Each Level-Up unit is a self-contained device worn like a boot. Its main functional element is a vertical actuation mechanism mounted to the bottom of the boot that extends vertically. Unlike traditional solutions that are integrated with locomotion devices, Level-Ups allow users to walk around freely (“real-walking”). We present Level-Ups in a demo environment based on a head-mounted display, optical motion capture, and integrated with two different game engines. In a user study, participants rated the realism of stepping onto objects 6.0 out of 7.0 when wearing Level-Ups compared to 3.5 without.",TRUE
pn667,2702254,http://dx.doi.org/10.1145/2702123.2702254,http://dl.acm.org/citation.cfm?id=2702254,jC4BbqfovGc,www.youtube.com/watch?v=jC4BbqfovGc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/jC4BbqfovGc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Ergonomic Interaction for Touch Floors,"Dominik Schmidt, Johannes Frohnhofen, Sven Knebel, Florian Meinel, Mariya Perchyk, Julian Risch, Jonathan Striebel, Julia Wachtel, Patrick Baudisch","The main appeal of touch floors is that they are the only direct touch form factor that scales to arbitrary size, therefore allowing direct touch to scale to very large numbers of display objects. In this paper, however, we argue that the price for this benefit is bad physical ergonomics: prolonged standing, especially in combination with looking down, quickly causes fatigue and repetitive strain. We propose addressing this issue by allowing users to operate touch floors in any pose they like, including sitting and lying. To allow users to transition between poses seamlessly, we present a simple pose-aware view manager that supports users by adjusting the entire view to the new pose. We support the main assumption behind the work with a simple study that shows that several poses are indeed more ergonomic for touch floor interaction than standing. We ground the design of our view manager by analyzing, which screen regions users can see and touch in each of the respective poses. ",TRUE
pn681,2702256,http://dx.doi.org/10.1145/2702123.2702256,http://dl.acm.org/citation.cfm?id=2702256,8ApARSat2wI,www.youtube.com/watch?v=8ApARSat2wI,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/8ApARSat2wI' width='640' height='360' frameborder='0' allowfullscreen='true'/>,First Person vs. Third Person Perspective in Digital Games: Do Player Preferences Affect Immersion?,"Alena Denisova, Paul Cairns","Contemporary digital game developers offer a variety of games for the diverse tastes of their customers. Although the gaming experience often depends on one’s preferences, the same may not apply to the level of their immersion. It has been argued whether the player perspective can influence the level of player’s involvement with the game. The aim of this study was to research whether interacting with a game in first person perspective is more immersive than playing in the third person point of view (POV). The set up to test the theory involved participants playing a role-playing game in either mode, naming their preferred perspective, and subjectively evaluating their immersive experience. The results showed that people were more immersed in the game play when viewing the game world through the eyes of the character, regardless of their preferred perspectives.",FALSE
pn682,2702257,http://dx.doi.org/10.1145/2702123.2702257,http://dl.acm.org/citation.cfm?id=2702257,kpQU7uytAvc,www.youtube.com/watch?v=kpQU7uytAvc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/kpQU7uytAvc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,I’d Hide You: Performing Live Broadcasting in Public,"Stuart Reeves, Christian Greiffenhagen, Martin Flintham, Steve Benford, Matt Adams, Ju Row Farr, Nicholas Tandavantij","We present a study of a mixed reality game called 'I'd Hide You' that involves live video streaming from the city streets. We chart the significant challenges facing performers on the streets who must simultaneously engage in the game, stream compelling video footage featuring themselves, and interact with a remote online audience. We reveal how these street performers manage four key tensions: between their body and camera; between the demands of online audiences and what takes place on-the-street; between what appears 'frontstage' on camera versus what happens 'backstage'; and balancing being a player of the game with being a performer. By reflecting on how they achieve this, we are able to draw out wider lessons for future interfaces aimed at supporting people broadcasting video of themselves to online audiences while engaged in games, sports and other demanding real-world activities.",TRUE
pn697,2702262,http://dx.doi.org/10.1145/2702123.2702262,http://dl.acm.org/citation.cfm?id=2702262,aesPApLe8YI,www.youtube.com/watch?v=aesPApLe8YI,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/aesPApLe8YI' width='640' height='360' frameborder='0' allowfullscreen='true'/>,(s|qu)eries: Visual Regular Expressions for Querying and Exploring Event Sequences,"Emanuel Zgraggen, Steven M. Drucker, Danyel Fisher, Robert DeLine","Many different domains collect event sequence data and rely on finding and analyzing patterns within it to gain meaningful insights. Current systems that support such queries either provide limited expressiveness, hinder exploratory workflows or present interaction and visualization models which do not scale well to large and multi-faceted data sets. In this paper we present (s|qu)eries (pronounced ""Squeries""), a visual query interface for creating queries on sequences (series) of data, based on regular expressions. (s|qu)eries is a touch-based system that exposes the full expressive power of regular expressions in an approachable way and interleaves query specification with result visualizations. Being able to visually investigate the results of different query-parts supports debugging and encourages iterative query-building as well as exploratory work-flows. We validate our design and implementation through a set of informal interviews with data scientists that analyze event sequences on a daily basis. ",TRUE
pn699,2702263,http://dx.doi.org/10.1145/2702123.2702263,http://dl.acm.org/citation.cfm?id=2702263,Ypk10Rb65no,www.youtube.com/watch?v=Ypk10Rb65no,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/Ypk10Rb65no' width='640' height='360' frameborder='0' allowfullscreen='true'/>,“Everyone Is Talking about It!”: A Distributed Approach to Urban Voting Technology and Visualisations,"Lisa Koeman, Vaiva Kalnikait_, Yvonne Rogers","The deployment of technology interventions, such as public displays and mobile apps, in community settings has been found to engage people in sharing and comparing their opinions. Our research is concerned with how to extend this to community-wide participation by devising and deploying multiple voting devices and visualisations. We present an in-the-wild study where a number of shopkeepers along a street participated by placing a novel voting device in their shops to collect locals' opinions. Results were displayed outside the shops, on the pavement. This distributed set-up was found to promote public debate on local issues, particularly around the perceived divide between people on either end of the street. We outline our design process and describe the impact of distributing voting devices and situated visualisations in a local community. \ ",TRUE
pn710,2702265,http://dx.doi.org/10.1145/2702123.2702265,http://dl.acm.org/citation.cfm?id=2702265,dJmy-pFwxKA,www.youtube.com/watch?v=dJmy-pFwxKA,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/dJmy-pFwxKA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,CrowdMonitor: Mobile Crowd Sensing for Assessing  Physical and Digital Activities of Citizens during Emergencies,"Thomas Ludwig, Christian Reuter, Tim Siebigteroth, Volkmar Pipek","Emergencies such as the 2013 Central European flood or the 2013 typhoon Haiyan in Philippines have shown how citizens can organize themselves and coordinate private relief activities. These activities can be found in (physical) groups of affected people, but also within (digital) social media communities. There is an evident need, however, for a clearer picture of what exactly is going on to be available for use by the official emergency services: to enlist them, to keep them safe, to support their efforts and to avoid needless duplications or conflicts. Aligning emergency services and volunteer activities is, then, crucial. In this paper we present a mobile crowd sensing based concept, which was designed as well as implemented as the application CrowdMonitor and facilitates the detection of physical and digital activities and the assignment of specific tasks to citizens. Finally we outline the findings of its evaluation.",TRUE
pn727,2702267,http://dx.doi.org/10.1145/2702123.2702267,http://dl.acm.org/citation.cfm?id=2702267,pntF2Diu3G8,www.youtube.com/watch?v=pntF2Diu3G8,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/pntF2Diu3G8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Wait-Learning: Leveraging Wait Time for Second Language Education,"Carrie J. Cai, Philip J. Guo, James R Glass, Robert C. Miller","Competing priorities in daily life make it difficult for those with a casual interest in learning to set aside time for regular practice. In this paper, we explore wait-learning: leveraging brief moments of waiting during a person’s existing conversations for second language vocabulary practice, even if the conversation happens in the native language. We present an augmented version of instant messaging, WaitChatter, that supports the notion of wait-learning by displaying contextually relevant foreign language vocabulary and micro-quizzes just-in-time while the user awaits a response from her conversant. Through a two week field study of WaitChatter with 20 people, we found that users were able to learn 57 new words on average during casual instant messaging. Furthermore, we found that users were most receptive to learning opportunities immediately after sending a chat message, and that this timing may be critical given user tendency to multi-task during waiting periods.",TRUE
pn762,2702273,http://dx.doi.org/10.1145/2702123.2702273,http://dl.acm.org/citation.cfm?id=2702273,_RbI_FxreH4,www.youtube.com/watch?v=_RbI_FxreH4,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/_RbI_FxreH4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,SplitBoard: A Simple Split Soft Keyboard for Wristwatch-sized Touch Screens,"Jonggi Hong, Seongkook Heo, Poika Isokoski, Geehyuk Lee","Text entry on a smartwatch is a challenging problem due to the device's limited screen area. In this paper, we introduce the SplitBoard, which is a soft keyboard designed for a smartwatch. As the user flicks left or right on the keyboard, it switches between the left and right halves of a QWERTY keyboard. We report the results of two user experiments where the SplitBoard was compared to an ordinary QWERTY keyboard, the ZoomBoard, SlideBoard, and Qwerty-like keypad. We measured the initial performance with new users for each method. The SplitBoard outperformed all other techniques in the experiments. The SplitBoard is expected to be a viable option for smartwatch text entry because of its light processing requirements, good performance, and immediate learnability.",TRUE
pn763,2702274,http://dx.doi.org/10.1145/2702123.2702274,http://dl.acm.org/citation.cfm?id=2702274,ch-6TPqk9Rg,www.youtube.com/watch?v=ch-6TPqk9Rg,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/ch-6TPqk9Rg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Can an Algorithm Know the “Real You”?: Understanding People’s Reactions to Hyper-personal Analytics Systems,"Jeffrey Warshaw, Tara Matthews, Steve Whittaker, Chris Kau, Mateo Bengualid, Barton A Smith","Recent research has developed analytics that threaten online self-presentation and privacy by automatically generating profiles of individuals’ most personal traits—their personality, values, motivations, and so on. But we know little about people's reactions to personal traits profiles of themselves, or what influences their decisions to share such profiles. We present an early qualitative study of people’s reactions to a working hyper-personal analytics system. The system lets them see their personality and values profile derived from their own social media text. Our results reveal a paradox. Participants found their personal traits profiles creepily accurate and did not like sharing them in many situations. However, they felt pressured by the social risks of not sharing and showed signs of learned helplessness, leading them to share despite their misgivings. Further, they felt unqualified to significantly modify their profile contents due to a surprising trust in the “expert” algorithm. We explore design implications for hyper-personal analytics systems that consider the needs and preferences of the people being profiled, suggesting ways to enhance the control they feel and the benefits they reap.",TRUE
pn783,2702277,http://dx.doi.org/10.1145/2702123.2702277,http://dl.acm.org/citation.cfm?id=2702277,1uv07nd5iD0,www.youtube.com/watch?v=1uv07nd5iD0,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/1uv07nd5iD0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,HaptiCase: Back-of-Device Tactile Landmarks for Eyes-Free Absolute Indirect Touch,"Christian Corsten, Christian Cherek, Thorsten Karrer, Jan Borchers","Using a smartphone for touch input to control apps and games mirrored to a distant screen is difficult, as the user cannot see where she is touching while looking at the distant display. We present HaptiCase, an interaction technique that provides back-of-device tactile landmarks that the user senses with her fingers to estimate the location of her finger in relation to the touchscreen. By pinching the thumb resting above the touch- screen to a finger at the back, the finger position is transferred to the front as the thumb touches the screen. In a study, we compared touch performance of different landmark layouts with a regular landmark-free mobile device. Using a land- mark design of dots on a 3x5 grid significantly improves eyes-free tapping accuracy and allows targets to be as small as 17.5 mm---a 14% reduction in target size---to cover 99% of all touches. When users can look at the touchscreen, land- marks have no significant effect on performance. HaptiCase is low-cost, requires no electronics, and works with unmodified software.",TRUE
pn787,2702278,http://dx.doi.org/10.1145/2702123.2702278,http://dl.acm.org/citation.cfm?id=2702278,uXxo75QxOw0,www.youtube.com/watch?v=uXxo75QxOw0,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/uXxo75QxOw0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Mediating Attention for Second Screen Companion Content,"Timothy Neate, Matt Jones, Michael Evans","There is increasing interest in providing content to users on secondary devices while they watch TV. This material, termed companion content, can be anything from textual information, to interactive quiz games. It can be delivered throughout a broadcast and often directly relates to specific scenes in a show. This new scenario has exposed a challenging design space for creators of both the content and the enabling technology.   A key question when introducing content on a secondary device is how much it detracts from, or enhances, the show the user is currently engaged with. To examine this, we investigated methods for mediating attention from the TV and onto a secondary device. By examining a typical use case we have been able to gain new insights into how best to design additional stimuli to alert users to companion content from both a broadcasting, and an HCI perspective. ",TRUE
pn815,2702281,http://dx.doi.org/10.1145/2702123.2702281,http://dl.acm.org/citation.cfm?id=2702281,8TOeQoiYVhY,www.youtube.com/watch?v=8TOeQoiYVhY,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/8TOeQoiYVhY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,ArtMaps: Interpreting the Spatial Footprints of Artworks,"Tim Coughlan, Laura Carletti, Gabriella Giannachi, Steve Benford, Derek McAuley, Dominic Price, Cristina Locatelli, Rebecca Sinker, John Stack","Creating and utilizing simple links between items and locations in map-based systems has become a mainstream component of modern computing. In this paper, we explore support for ‘art mapping’, an activity that requires consideration of more complex interpretations of spatial relationships as users engage with identifying locations of relevance to artworks. Through a user study of the ArtMaps platform, and an exploratory study with professional artists, we identify diverse interpretations of spatial meaning in relation to art. We find that art mapping highlights potential for more active engagement with art through technology, but challenges existing systems for spatial representation. Through connecting our findings with work on designing for interpretation, and on space and place in HCI, we contribute new understanding of creating engagement through the spatial interpretation of art, and define potential characteristics and uses of holistic ‘footprints’ for artworks.",TRUE
pn833,2702284,http://dx.doi.org/10.1145/2702123.2702284,http://dl.acm.org/citation.cfm?id=2702284,5aC6coEAZjA,www.youtube.com/watch?v=5aC6coEAZjA,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/5aC6coEAZjA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Why and what did we throw out? Probing on Reflection through the Food Waste Diary,"Eva Ganglbauer, Geraldine Fitzpatrick, Florian Güldenpfennig","Issues of consumer food waste in industrialised countries are becoming an increasing concern and this is paralleled by a growing interest in HCI to support more sustainable consumption practices. In this paper we report on a mobile food waste diary application that was made available on app stores, with the aim of enabling motivated people to reflect on their moments of food waste and to explore rationales. Through analysis of the entries submitted by users of the diary application, we identify instances of reflection located on different levels. The intention of supporting reflection was visible in instances of submitted diary entries where deeper in- sights about the relationships between food waste, previous experiences, habits, knowledge, occurrences and intentions to change were offered.",FALSE
pn849,2702285,http://dx.doi.org/10.1145/2702123.2702285,http://dl.acm.org/citation.cfm?id=2702285,9PNvu0J4BDk,www.youtube.com/watch?v=9PNvu0J4BDk,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/9PNvu0J4BDk' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Tiree Energy Pulse: Exploring Renewable Energy Forecasts on the Edge of the Grid.,"Will Simm, Maria Angela Ferrario, Adrian Friday, Peter Newman, Stephen Forshaw, Mike Hazas, Alan Dix","In many parts of the world, the electricity supply industry makes the task of dealing with unpredictable spikes and dips in production and demand invisible to consumers, maintaining a seemingly unlimited supply. A future increase in reliance on time-variable renewable sources of electricity may lead to greater fluctuations in supply. We engaged remote islanders as equal partners in a research project that investigated through technology-mediated enquiry the topic of synchronising energy consumption with supply, and together built a prototype renewable energy forecast display. A number of participants described a change in their practices, saving high energy tasks for times when local renewable energy was expected to be available, despite having no financial incentive to do so. The main contributions of this paper are in: 1) the results of co-development sessions exploring systems supporting synchronising consumption with supply and 2) the findings arising from the deployment of the prototype.",TRUE
pn851,2702286,http://dx.doi.org/10.1145/2702123.2702286,http://dl.acm.org/citation.cfm?id=2702286,YXx_5E4CPho,www.youtube.com/watch?v=YXx_5E4CPho,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/YXx_5E4CPho' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Flexible Ecologies And Incongruent Locations,"Paul K Luff, Naomi Yamashita, Hideaki Kuzuoka, Christian Heath","In this paper we report on some experiments with a high fidelity media space, t-Room, an immersive system that presents full scale, real-time images of co-participants. The system has been enhanced to provide more flexibility in the ways participants could organise themselves and the materials they are working on. Drawing on some quasi-naturalistic experiments, where the participants were required to undertake a range of complex tasks, we consider the formations they adopt and the issues and problems that arise when they attempt to establish and preserve a common focus and alignment. We conclude by briefly discussing the consequences for developing advanced spaces to support collaborative work and understanding complex video-mediated interaction. ",FALSE
pn855,2702287,http://dx.doi.org/10.1145/2702123.2702287,http://dl.acm.org/citation.cfm?id=2702287,y_XQjD8Uar4,www.youtube.com/watch?v=y_XQjD8Uar4,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/y_XQjD8Uar4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Spatially-aware or spatially-agnostic? Elicitation and Evaluation of User-Defined Cross-Device Interactions,"Roman Rädle, Hans-Christian Jetter, Mario Schreiner, Zhihao Lu, Harald Reiterer, Yvonne Rogers","Cross-device interaction between multiple mobile devices is a popular field of research in HCI. However, the appropriate design of this interaction is still an open question, with competing approaches such as spatially-aware vs. spatially-agnostic techniques. In this paper, we present the results of a two-phase user study that explores this design space: In phase 1, we elicited gestures for typical mobile cross-device tasks from 4 focus groups (N=17). The results show that 71% of the elicited gestures were spatially-aware and that participants strongly associated cross-device tasks with interacting and thinking in space. In phase 2, we implemented one spatially-agnostic and two spatially-aware techniques from phase 1 and compared them in a controlled experiment (N=12). The results indicate that spatially-aware techniques are preferred by users and can decrease mental demand, effort, and frustration, but only when they are designed with great care. We conclude with a summary of findings to inform the design of future cross-device interactions.",TRUE
pn859,2702288,http://dx.doi.org/10.1145/2702123.2702288,http://dl.acm.org/citation.cfm?id=2702288,Cw5AqSmHkMk,www.youtube.com/watch?v=Cw5AqSmHkMk,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/Cw5AqSmHkMk' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Towards Multimodal Affective Feedback - Interaction between Visual and Haptic Modalities,"Akshita Akshita, Harini Alagarai Sampath, Bipin Indurkhya, Eunhwa Lee, Yudong Bae","We explored how emotional cues presented in visual and haptic modalities interact. We constructed an affective haptic dataset, and used the emotional visual stimuli from the International Affective Picture System (IAPS). Participants were asked to rate the visual stimuli, haptic stimuli and visualhaptic stimuli. Analysis of the results indicates that the presence of haptic stimulus affects the arousal of the visual stimulus, but does not affect the valence significantly. We further explored this interaction in terms of the intensity, frequency, waveform and rhythm of the haptic stimuli. We then provide a set of guidelines on visual-haptic interaction that could be used in design of multimodal affective feedback.",FALSE
pn875,2702290,http://dx.doi.org/10.1145/2702123.2702290,http://dl.acm.org/citation.cfm?id=2702290,s87lbqdv6gM,www.youtube.com/watch?v=s87lbqdv6gM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/s87lbqdv6gM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Investigation of Material Properties for Thermal Imaging-Based Interaction,"Yomna Abdelrahman, Alireza Sahami Shirazi, Niels Henze, Albrecht Schmidt","Recent work demonstrated the exciting opportunities that thermal imaging offers for the development of interactive systems. It was shown that a thermal camera can sense when a user touches a surface, performs gestures in the camera's direct field of view and, in addition, performs gestures outside the camera's direct field of view through thermal reflection. In this  paper, we investigate the material properties that should be considered for detecting interaction using thermal imaging considering both in- and outdoor settings. We conducted a study to analyze the recognition performance for different gestures and different surfaces. Using the results, we derive guidelines on material properties of surfaces for detecting on-surface as well as mid-air interaction using a thermal camera. We  discuss the constrains that should be taken into account using thermal imaging as the sensing technology. Finally, we present a material space based on our findings. The space depicts surfaces and the required properties that enable the different interaction techniques.",TRUE
pn895,2702293,http://dx.doi.org/10.1145/2702123.2702293,http://dl.acm.org/citation.cfm?id=2702293,FzuKiP4B1Tg,www.youtube.com/watch?v=FzuKiP4B1Tg,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/FzuKiP4B1Tg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,VeilMe: An Interactive Visualization Tool for Privacy Configuration of Using Personality Traits,"Yang Wang, Liang Gou, Anbang Xu, Michelle X. Zhou, Huahai Yang, Hernan Badenes","With the recent advances in using data analytics to automatically infer one's personality traits from their social media data, users are facing a growing tension between the use of the technology to aid self development in workplace and the privacy concerns of such use. Given the richness of personality data that can be derived today and the varied sensitivity of revealing such data, it is a non-trivial task for users to configure their privacy settings for sharing and protecting their derived personality data. Here we present the design, development, and evaluation of an interactive visualization tool, VeilMe, which helps users configure the privacy settings for the use of their personality portraits derived from social media. Unlike other privacy configuration tools, our tool offers two distinct advantages. First, it presents a novel and intuitive visual interface that aids users in understanding and exploring their own personality traits derived from their social media data, and configuring their privacy preferences. Second, our tool helps users to jump start their privacy settings by suggesting initial sharing strategies based on a set of factors, including the users' personality and target audience. We have evaluated the use of our tool with 124 participants in an enterprise context. Our results show that VeilMe effectively supports various user privacy configuration tasks, and also suggest several design implications, including the approaches to personalized privacy configurations.",TRUE
pn898,2702294,http://dx.doi.org/10.1145/2702123.2702294,http://dl.acm.org/citation.cfm?id=2702294,hhIs6VpHOG4,www.youtube.com/watch?v=hhIs6VpHOG4,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/hhIs6VpHOG4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Success & Scale in a Data-Producing Organization: The Socio-Technical Evolution of OpenStreetMap in Response to Humanitarian Events,"Leysia Palen, Robert Soden, T. Jennings Anderson, Mario Barrenechea","OpenStreetMap (OSM) is a volunteer-driven, globally distributed organization whose members work to create a common digital map of the world. OSM embraces ideals of open data, and to that end innovates both socially and technically to develop practices and processes for coordinated operation. This paper provides a brief history of OSM and then, through quantitative and qualitative examination of the OSM database and other sites of articulation work, examines organizational growth through the lens of two catastrophes that spurred enormous humanitarian relief responses—the 2010 Haiti Earthquake and the 2013 Typhoon Yolanda. The temporally- and geographically- constrained events scope analysis for what is a rapidly maturing, whole-planet operation. The first disaster identified how OSM could support other organizations responding to the event. However, to achieve this, OSM has had to refine mechanisms of collaboration around map creation, which were tested again in Typhoon Yolanda. The transformation of work between these two events yields insights into the organizational development of large, data-producing online organizations.",TRUE
pn906,2702296,http://dx.doi.org/10.1145/2702123.2702296,http://dl.acm.org/citation.cfm?id=2702296,t098GS9G3xQ,www.youtube.com/watch?v=t098GS9G3xQ,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/t098GS9G3xQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Mobile Gamification for Crowdsourcing Data Collection: Leveraging the Freemium Model,"Kristen Dergousoff, Regan Mandryk","Classic ways of gathering data on human behaviour are time-consuming, costly and are subject to limited participant pools. Crowdsourcing offers a reduction in operating costs and access to a diverse and large participant pool; however issues arise concerning low worker pay and questions about data quality. Gamification provides a motivation to participate, but also requires the development of specialized, research-question specific games that can be costly to produce. Our solution combines gamification and crowdsourcing in a smartphone-based system that emulates the popular Freemium model of play to motivate voluntary participation through in-game rewards, using a robust framework to study multiple unrelated research questions within the same system. We deployed our game on the Android store and compared it to a gamified laboratory version and a non-gamified laboratory version, and found that players who used the in-game rewards were motivated to do experimental tasks. There was no difference between the systems for performance on a motor task; however, performance on the cognitive task was worse for the crowdsourced game. We discuss options for improving performance on tasks requiring attention. ",TRUE
pn919,2702299,http://dx.doi.org/10.1145/2702123.2702299,http://dl.acm.org/citation.cfm?id=2702299,dLTvezrHLLQ,www.youtube.com/watch?v=dLTvezrHLLQ,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/dLTvezrHLLQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,BodyVis: A New Approach to Body Learning Through Wearable Sensing and Visualization,"Leyla Norooz, Matthew Louis Mauriello, Anita Jorgensen, Brenna McNally, Jon E Froehlich","Internal organs are hidden and untouchable, making it difficult for children to learn their size, position, and function. Traditionally, human anatomy (body form) and physiology (body function) are taught using techniques ranging from worksheets to three-dimensional models. We present a new approach called BodyVis, an e-textile shirt that combines biometric sensing and wearable visualizations to reveal otherwise invisible body parts and functions. We describe our 15-month iterative design process including lessons learned through the development of three prototypes using participatory design and two evaluations of the final prototype: a design probe interview with seven elementary school teachers and three single-session deployments in after-school programs. Our findings have implications for the growing area of wearables and tangibles for learning.",TRUE
pn922,2702300,http://dx.doi.org/10.1145/2702123.2702300,http://dl.acm.org/citation.cfm?id=2702300,1dKlMZrM_sw,www.youtube.com/watch?v=1dKlMZrM_sw,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/1dKlMZrM_sw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,How Much Faster is Fast Enough? User Perception of Latency & Latency Improvements in Direct and Indirect Touch,"Jonathan Deber, Ricardo Jota, Clifton Forlines, Daniel Wigdor","This paper reports on two experiments designed to further \ our understanding of users’ perception of latency in touch- \ based systems. The first experiment extends previous \ efforts to measure latency perception by reporting on a \ unified study in which direct and indirect form-factors are \ compared for both tapping and dragging tasks. Our results \ show significant effects from both form-factor and task, and \ inform system designers as to what input latencies they \ should aim to achieve in a variety of system types. A \ follow-up experiment investigates peoples’ ability to \ perceive small improvements to latency in direct and \ indirect form-factors for tapping and dragging tasks. Our \ results provide guidance to system designers of the relative \ value of making improvements in latency that reduce but do \ not fully eliminate lag from their systems.",TRUE
pn930,2702301,http://dx.doi.org/10.1145/2702123.2702301,http://dl.acm.org/citation.cfm?id=2702301,HT5RNr1RNmU,www.youtube.com/watch?v=HT5RNr1RNmU,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/HT5RNr1RNmU' width='640' height='360' frameborder='0' allowfullscreen='true'/>,The Effect of Signal Expense and Dependability on Family Communication in Rural and Northern Canada,"Roberta M Melvin, Andrea Bunt, Erick Oduor, Carman Neustaedter","Family communication and technology designed to support it is a widely studied topic. However, most research that focuses on family communication in North America tends to assume high degrees of connectivity and Internet access. We present a study of family communication practices in rural and northern areas of Manitoba, Canada where Internet connectivity is intermittent or severely limited in some communities. Our results show the ways in which individuals stay connected with outside relatives can be hampered by communication infrastructure challenges. In particular, these challenges can dictate how, where and how often conversations with loved ones take place. Our results also indicate that these experiences, many of which are negative, can create lasting impressions that may be difficult to alter as infrastructure improves. This suggests opportunities for designing family communication technologies for outdoor locations with better connectivity, scheduling communication during times with better connectivity, and combating social isolation.",TRUE
pn932,2702302,http://dx.doi.org/10.1145/2702123.2702302,http://dl.acm.org/citation.cfm?id=2702302,eoilYq-jtBM,www.youtube.com/watch?v=eoilYq-jtBM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/eoilYq-jtBM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Polymorphic Blocks: Formalism-Inspired UI for Structured Connectors,"Sorin Lerner, Stephen R Foster, William G Griswold","We present a novel block-based UI called Polymorphic Blocks, in \ which a connector's shape visually represents the structure of the \ data being passed through the connector. We use Polymorphic Blocks to \ add visual type information to block-based programming environments \ like Blockly or Scratch. We also use Polymorphic Blocks to represent \ logical proofs. In this context, if we erase all symbols, our UI \ becomes a puzzle game, where solving the puzzle amounts to building a \ proof. We show through a user study that our Logical Puzzle Game is \ faster, more fun, and more engaging than an equivalent pen-and-paper \ interface. \ ",TRUE
pn933,2702303,http://dx.doi.org/10.1145/2702123.2702303,http://dl.acm.org/citation.cfm?id=2702303,3WrW_7lz31s,www.youtube.com/watch?v=3WrW_7lz31s,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/3WrW_7lz31s' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Designing a Physical Aid to Support Active Reading on Tablets,"Andrea Bianchi, So-Ryang Ban, Ian Oakley","Tablet computers and portable eReaders are gradually becoming the preferred platform for the consumption of textual materials. However, although these technologies are powerful, it is widely acknowledged that print documents better support the advanced active reading tasks necessary to gain a deep understanding of a text. While prior work to address this issue has aimed improve digital eReaders by either leveraging familiar physical affordances or by extending paper’s capabilities with digital tools, in this paper we propose a juncture of these two approaches. We first present a formative study that captures the needs and requirements of users during active reading tasks with tablets. We instantiate the findings in the design of a simple physical aid to support active reading: a smart bookmark. We then define an interaction space for this device, describe a set of interfaces designed to facilitate active reading and close with a user study that assesses the potential of the bookmark device and interaction techniques.",TRUE
pn936,2702304,http://dx.doi.org/10.1145/2702123.2702304,http://dl.acm.org/citation.cfm?id=2702304,WX8SM28bfnk,www.youtube.com/watch?v=WX8SM28bfnk,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/WX8SM28bfnk' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Mudslide: A Spatially Anchored Census of Student Confusion for Online Lecture Videos,"Elena L Glassman, Juho Kim, Andres Monroy-Hernandez, Meredith Ringel Morris","Educators have developed an effective technique to get feedback after in-person lectures, called “muddy cards.” Students are given time to reflect and write the “muddiest” (least clear) point on an index card, to hand in as they leave class. This practice of assigning end-of-lecture reflection tasks to generate explicit student feedback is well suited for adaptation to the challenge of supporting feedback in online video lectures. We describe the design and evaluation of Mudslide, a prototype system that translates the practice of muddy cards into the realm of online lecture videos. Based on an in-lab study of students and teachers, we find that spatially contextualizing students’ muddy point feedback with respect to particular lecture slides is advantageous to both students and teachers. We also reflect on further opportunities for enhancing this feedback method based on teachers’ and students’ experiences with our prototype.",TRUE
pn954,2702305,http://dx.doi.org/10.1145/2702123.2702305,http://dl.acm.org/citation.cfm?id=2702305,02mSH2lh1lg,www.youtube.com/watch?v=02mSH2lh1lg,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/02mSH2lh1lg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Eye-Wearable Technology for Machine Maintenance: Effects of Display Position and Hands-free Operation,"Xianjun  Sam Zheng, Cedric Foucault, Patrik Matos da Silva , Siddharth Dasari, Tao Yang, Stuart Goose","Exciting developments in eye-wearable technology and its potential industrial applications warrant a thorough understanding of its advantages and drawbacks through empirical evidence. We conducted an experiment to investigate what characteristics of eye-wearable technology impact user performance in machine maintenance, which included a representative set of car maintenance tasks involving Locate, Manipulate, and Compare actions. Participants were asked to follow instructions displayed on one of four technologies: a peripheral eye-wearable display, a central eye-wearable display, a tablet, or a paper manual. We found a significant effect of display position: the peripheral eye-wearable display resulted in longer completion time than the central display; but no effect of hands-free operation. The technology effects were also modulated by different Tasks and Action types. We discuss the human factors implications for designing more effective eye-wearable technology, including display position, issues of monocular display, and how the physical proximity of the technology affects users’ reliance level.  ",TRUE
pn979,2702308,http://dx.doi.org/10.1145/2702123.2702308,http://dl.acm.org/citation.cfm?id=2702308,CMPD-eZYOO0,www.youtube.com/watch?v=CMPD-eZYOO0,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/CMPD-eZYOO0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Exploring Subtle Foot Plantar-based Gestures with Sock-placed Pressure Sensors,"Koumei Fukahori, Daisuke Sakamoto, Takeo Igarashi","We propose subtle foot-based gestures named foot plantar-based (FPB) gestures (FPB gestures) that are usingused with sock-placed pressure sensors. In this system, the user can control a computing device by changing his or her foot plantar distributions, (e.g., pressing a the floor with his/her toe). Because such foot movement is subtle, it is suitable for use especially in a public space such as a crowdinged train. In this study, we first conduct a guessability study to design a user-defined gesture set for interaction with a computing device. Then, we implement a gesture recognizer with a machine learning technique. To avoid unexpected gesture activations, we also collect foot plantar pressure patterns made during daily activities (such as walking), as negative training data. Additionally, we evaluate the unobservabililtyty of FPB gestures by using crowdsourcing. Finally, we conclude with several applications to further illustrate the utility of FPB gestures.",TRUE
pn982,2702309,http://dx.doi.org/10.1145/2702123.2702309,http://dl.acm.org/citation.cfm?id=2702309,0iK7cwYKLgY,www.youtube.com/watch?v=0iK7cwYKLgY,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/0iK7cwYKLgY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Analysis of Recycling Capabilities of Individuals and Crowds to Encourage and Educate People to Separate Their Garbage Playfully,"Pascal Lessel, Maximilian Altmeyer, Antonio Krüger","Sorting garbage is a relevant topic in many countries as it contributes to environmental protection. Empirical evidence suggests that not all people separate waste, potentially because they do not know how to do it correctly or are simply not motivated enough. We present the results of an online study (N=184) investigating people's capabilities for classifying waste, their capabilities to improve in this task over time and their current garbage separation behavior. The study confirms that the Wisdom of Crowds is applicable in this context as the crowd produces only half as many errors as the individual and feedback helps participants to improve. Based on this, we introduce the idea of a crowd classifying waste in a game, with their classification result then being used as feedback on gamified public trash cans to educate both the crowd playing the game and people using the trash can playfully.",TRUE
pn1010,2702311,http://dx.doi.org/10.1145/2702123.2702311,http://dl.acm.org/citation.cfm?id=2702311,qn0CVhy8bE8,www.youtube.com/watch?v=qn0CVhy8bE8,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/qn0CVhy8bE8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,ClimbSense - Automatic Climbing Route Recognition using Wrist-worn Inertia Measurement Units,"Felix Kosmalla, Florian Daiber, Antonio Krüger","Today, sports and activity trackers are ubiquitous. Especially runners and cyclists have a variety of possibilities to record and analyze their workouts. In contrast, climbing did not find much attention in consumer electronics and human-computer interaction. If quantified data similar to cycling or running data were available for climbing, several applications would be possible, ranging from simple training diaries to virtual  coaches or usage analytics for gym operators. \  \ This paper introduces a system that automatically recognizes climbed routes using wrist-worn inertia measurement units (IMUs). This is achieved by extracting features of a recorded ascent and use them as training data for the recognition system. To verify the recognition system, cross-validation methods were applied to a set of ascent recordings that were assessed during a user study with eight climbers in a local climbing gym. The evaluation resulted in a high recognition rate, thus proving that our approach is possible and operational.",TRUE
pn1018,2702313,http://dx.doi.org/10.1145/2702123.2702313,http://dl.acm.org/citation.cfm?id=2702313,FSIgiUhn9m8,www.youtube.com/watch?v=FSIgiUhn9m8,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/FSIgiUhn9m8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Building a Birds Eye View: Collaborative Work in Disaster Response,"Joel E Fischer, Stuart Reeves, Tom Rodden, Steve Reece, Sarvapali D Ramchurn, David Jones","Command and control environments ranging from transport control rooms to disaster response have long been of interest to HCI and CSCW as rich sites of interactive technology use embedded in work practice. Drawing on our engagement with disaster response teams, including ethnography of their training work, we unpack the ways in which situational uncertainty is managed while a shared operational ‘picture’ is constituted through various practices around tabletop work. Our analysis reveals how this picture is collaboratively assembled as a socially shared object and displayed by drawing on digital and physical resources. Accordingly, we provide a range of principles implicated by our study that guide the design of systems augmenting and enriching disaster response work practices. In turn, we propose the Augmented Bird Table to illustrate how our principles can be implemented to support tabletop work. ",TRUE
pn1023,2702314,http://dx.doi.org/10.1145/2702123.2702314,http://dl.acm.org/citation.cfm?id=2702314,TXLkqMypces,www.youtube.com/watch?v=TXLkqMypces,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/TXLkqMypces' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Augmenting Social Interactions: Realtime Behavioural Feedback using Social Signal Processing Techniques,"Ionut Damian, Chiew Seng Sean Tan, Tobias Baur, Johannes Schöning, Kris Luyten, Elisabeth Andre","Nonverbal and unconscious behaviour is an important component of daily human-human interaction. This is especially true in situations such as public speaking, job interviews or information sensitive conversations, where researchers have shown that an increased awareness of one's behaviour can improve the outcome of the interaction. \ With wearable technology, such as Google Glass, we now have the opportunity to augment social interactions and provide realtime feedback on one's behaviour in an unobtrusive way. \ In this paper we present Logue, a system that provides realtime feedback on the presenters' openness, body energy and speech rate during public speaking. The system analyses the user's nonverbal behaviour using social signal processing techniques and gives visual feedback on a head-mounted display. We conducted two user studies with a staged and a real presentation scenario which yielded that Logue's feedback was perceived helpful and had a positive impact on the speaker's performance. ",TRUE
pn1031,2702316,http://dx.doi.org/10.1145/2702123.2702316,http://dl.acm.org/citation.cfm?id=2702316,oaIkmS0nP64,www.youtube.com/watch?v=oaIkmS0nP64,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/oaIkmS0nP64' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Glass Unlock: Enhancing Security of Smartphone Unlocking through Leveraging a Private Near-eye Display,"Christian Winkler, Jan Gugenheimer, Alexander De Luca, Gabriel Haas, Philipp Speidel, David Dobbelstein, Enrico Rukzio","This paper presents Glass Unlock, a novel concept using smart glasses for smartphone unlocking, which is theoretically secure against smudge attacks, shoulder-surfing, and camera attacks. By introducing an additional temporary secret like the layout of digits that is only shown on the private near-eye display, attackers cannot make sense of the observed input on the almost empty phone screen. We report a user study with three alternative input methods and compare them to current state-of-the-art systems. Our findings show that Glass Unlock only moderately increases authentication times and that users favor the input method yielding the slowest input times as it avoids focus switches between displays.",TRUE
pn1038,2702319,http://dx.doi.org/10.1145/2702123.2702319,http://dl.acm.org/citation.cfm?id=2702319,x_QdgBQ43OI,www.youtube.com/watch?v=x_QdgBQ43OI,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/x_QdgBQ43OI' width='640' height='360' frameborder='0' allowfullscreen='true'/>,An Interactive System for Data Structure Development,"Jibin Ou, Martin Vechev, Otmar Hilliges","Data structure algorithms are of fundamental importance in teaching and software development, yet are difficult to understand. We propose a new approach for understanding, debugging and developing heap manipulating data structures. \  \ The key technical idea of our work is to combine deep parametric abstraction techniques emerging from the area of static analysis with interactive abstraction manipulation. Our approach bridges program analysis with HCI and enables new capabilities not possible before: i) online automatic visualization of the data structure in a way which captures its essential operation, thus enabling powerful local reasoning, and ii) fine grained pen and touch gestures allowing for interactive control of the abstraction -- at any point the developer can pause the program, graphically interact with the data, and continue program execution. These features address some of the most pressing challenges in developing data structures. \  \ We implemented our approach in a Java-based system called FluiEdt and evaluated it with $27$ developers. The results indicate that FluiEdt is more effective in helping developers find data structure errors than existing state of the art IDEs (e.g. Eclipse) or pure visualization based approaches.",TRUE
pn1047,2702322,http://dx.doi.org/10.1145/2702123.2702322,http://dl.acm.org/citation.cfm?id=2702322,XzR6SYGEAEI,www.youtube.com/watch?v=XzR6SYGEAEI,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/XzR6SYGEAEI' width='640' height='360' frameborder='0' allowfullscreen='true'/>,How Polymorphic Warnings Reduce Habituation in the Brain—Insights from an fMRI Study,"Bonnie Brinton Anderson, C. Brock Kirwan, David Eargle, Jeffrey L. Jenkins, Seth Howard, Anthony Vance","Research on security warnings consistently points to habituation as a key reason why users ignore security warnings. However, because habituation as a mental state is difficult to observe, previous research has examined habituation indirectly by observing its influence on security behaviors. This study addresses this gap by using functional magnetic resonance imaging (fMRI) to open the “black box” of the brain to observe habituation as it develops in response to security warnings. Our results show a dramatic drop in the visual processing centers of the brain after only the second exposure to a warning, with further decreases with subsequent exposures. To combat the problem of habituation, we designed a polymorphic warning that changes its appearance. We show in two separate experiments using fMRI and mouse cursor tracking that our polymorphic warning is substantially more resistant to habituation than conventional warnings. Together, our neurophysiological findings illustrate the considerable influence of human biology on users’ habituation to security warnings.",TRUE
pn1054,2702326,http://dx.doi.org/10.1145/2702123.2702326,http://dl.acm.org/citation.cfm?id=2702326,XobWS3ccxWg,www.youtube.com/watch?v=XobWS3ccxWg,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/XobWS3ccxWg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,The Trial of Bendi in a Coffeehouse: Use of a Shape-Changing Device for a Tactile-Visual Phone Conversation,"Young-Woo Park, Joohee Park, Tek-Jin Nam","We present Bendi, a shape-changing device for a tactile-visual phone conversation. Bendi enables users to deliver shape-changing movements (e.g., upward or downward bending, left or right tilting, and shrinking) from the user’s joystick input to the other party’s device in real time during phone conversations. We conducted a user study to observe how seven couples used it over three days in a coffeehouse. Our field trial of Bendi in a coffeehouse showed the private and natural uses, and integrated uses of tactile and visual expressions along with the uses of the vocabularies developed through Bendi. In addition, there were active uses even in negative and serious conversational context with its pleasant tactile feelings and movement representations. Lastly, we discuss issues for the future designs and real-world deployment of shape-changing mobile devices for daily use.",TRUE
pn1066,2702331,http://dx.doi.org/10.1145/2702123.2702331,http://dl.acm.org/citation.cfm?id=2702331,QsfQWZpiR18,www.youtube.com/watch?v=QsfQWZpiR18,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/QsfQWZpiR18' width='640' height='360' frameborder='0' allowfullscreen='true'/>,MultiFi: Multi Fidelity Interaction with Displays On and Around the Body,"Jens Grubert, Matthias Heinisch, Aaron Quigley, Dieter Schmalstieg","Display devices on and around the body such as smartwatches, head-mounted displays or tablets enable users to interact on the go. However, diverging input and output fidelities of these devices can lead to interaction seams that can inhibit efficient mobile interaction, when users employ multiple devices at once. We present MultiFi, an interactive system that combines the strengths of multiple displays and overcomes the seams of mobile interaction with widgets distributed over multiple devices. A comparative user study indicates that combined head-mounted display and smartwatch interfaces can outperform interaction with single wearable devices.",TRUE
pn1069,2702332,http://dx.doi.org/10.1145/2702123.2702332,http://dl.acm.org/citation.cfm?id=2702332,f8NOERrhWfA,www.youtube.com/watch?v=f8NOERrhWfA,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/f8NOERrhWfA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Modeling Distant Pointing for Compensating Systematic Displacements,"Sven Mayer, Katrin Wolf, Stefan Schneegass, Niels Henze","Distant pointing at objects and persons is a highly expressive gesture that is widely used in human communication. Pointing is also used to control a range of interactive systems. For determining where a user is pointing at, different ray casting methods have been proposed. In this paper we assess how accurately humans point over distance and how to improve it. Participants pointed at projected targets from 2m and 3m while standing and sitting. Testing three common ray casting methods, we found that even with the most accurate one the average error is 61.3cm. We found that all tested ray casting methods are affected by systematic displacements. Therefore, we trained a polynomial to compensate this displacement. We show that using a user-, pose-, and distant-independent quartic polynomial can reduce the average error by 37.3\\%",TRUE
pn1073,2702333,http://dx.doi.org/10.1145/2702123.2702333,http://dl.acm.org/citation.cfm?id=2702333,fsBt6YfkFWI,www.youtube.com/watch?v=fsBt6YfkFWI,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/fsBt6YfkFWI' width='640' height='360' frameborder='0' allowfullscreen='true'/>,LeviPath: Modular Acoustic Levitation for 3D Path Visualisations,"Themis Omirou, Asier Marzo, Sue Ann Seah, Sriram Subramanian","LeviPath is a modular system to levitate objects across 3D paths. It consists of two opposed arrays of transducers that create a standing wave capable of suspending objects in mid-air. To control the standing wave, the system employs a novel algorithm based on combining basic patterns of movement. Our approach allows the control of multiple beads simultaneously along different 3D paths. Due to the patterns and the use of only two opposed arrays, the system is modular and can scale its interaction space by joining several LeviPaths. In this paper, we describe the hardware architecture, the basic patterns of movement and how to combine them to produce 3D path visualisations.",TRUE
pn1086,2702336,http://dx.doi.org/10.1145/2702123.2702336,http://dl.acm.org/citation.cfm?id=2702336,x02Rq7_0Lhg,www.youtube.com/watch?v=x02Rq7_0Lhg,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/x02Rq7_0Lhg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Supporting Subtlety with Deceptive Devices and Illusory Interactions,"Fraser Anderson, Tovi Grossman, Daniel Wigdor, George Fitzmaurice","Mobile devices offer constant connectivity to the world, which can negatively affect in-person interaction. Current approaches to minimizing the social disruption and improving the subtlety of interactions tend to focus on the development of inconspicuous devices that provide basic input or output. This paper presents a more general approach to subtle interaction and demonstrates how a number of principles from magic can be leveraged to improve subtlety. It also presents a framework that can be used to classify subtle interfaces along with a modular set of novel interfaces that fit within this framework. Lastly, the paper presents a new evaluation paradigm specifically designed to assess the subtlety of interactions. This paradigm is used to compare traditional approaches to our new subtle approaches. We find our new approaches are over five times more subtle than traditional interactions, even when participants are aware of the technologies being used.",TRUE
pn1088,2702337,http://dx.doi.org/10.1145/2702123.2702337,http://dl.acm.org/citation.cfm?id=2702337,RVEzAYkByFI,www.youtube.com/watch?v=RVEzAYkByFI,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/RVEzAYkByFI' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Foundations of Materials Experience: An Approach for HCI,"Elisa Giaccardi, Elvin Karana","A growing number of HCI scholars have started to take materiality as an entry point for acquiring a deeper understanding of the possibilities and constraints of design. Steadily moving beyond a distinction between the physical and the digital, a few have also started to look at materials as part of the unfolding of social and cultural practices. Yet, to date, relatively little is known about how these practices develop within the situated experience of materials, and how this situational whole can be supported by design. By contributing to both growing materiality scholarship and emerging practice-oriented approaches in HCI, this paper articulates a framework of materials experience that discusses how materials shape ways of doing and ultimately, practice, and how this is rooted in the experience of those materials. ",TRUE
pn1095,2702339,http://dx.doi.org/10.1145/2702123.2702339,http://dl.acm.org/citation.cfm?id=2702339,4wHQqeRUupo,www.youtube.com/watch?v=4wHQqeRUupo,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/4wHQqeRUupo' width='640' height='360' frameborder='0' allowfullscreen='true'/>,New Interaction Tools for Preserving an Old Language,"Beryl Plimmer, Liang He, Tariq Zaman, Kasun Karunanayaka, Alvin W Yeo, Garen Jengan, Rachel Blagojevic, Ellen Yi-Luen Do","The Penan people of Malaysian Borneo were traditionally nomads of the rainforest. They would leave messages in the jungle for each other by shaping natural objects into language tokens and arranging these symbols in specific ways – much like words in a sentence. With settlement, the language is being lost as it is not being used by the younger generation. We report here, a tangible system designed to help the Penan preserve their unique object writing language. The key features of the system are that: its tangibles are made of real objects; it works in the wild; and new tangibles can be fabricated and added to the system by the users. Our evaluations show that the system is engaging and encourages intergenerational knowledge transfer and thus has the potential to help preserve this language. ",TRUE
pn1103,2702340,http://dx.doi.org/10.1145/2702123.2702340,http://dl.acm.org/citation.cfm?id=2702340,HVJYLiyxmmI,www.youtube.com/watch?v=HVJYLiyxmmI,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/HVJYLiyxmmI' width='640' height='360' frameborder='0' allowfullscreen='true'/>,EyeBookmark: Assisting Recovery from Interruption during Reading,"Jaemin Jo, Bohyoung Kim, Jinwook Seo","In this paper, we present gaze-based bookmarking, EyeBookmark, to mitigate the deleterious effect of interruption during reading. The key idea of EyeBookmark is to provide a visual cue to help people decide where to resume reading. We design four highlighting methods and conduct a controlled user study with a proof-of-concept design to verify the usefulness of EyeBookmark. The user study demonstrates not only that participants preferred our highlighting methods but also that such highlighting methods significantly reduced the time taken to resume reading after interruption regardless of the difficulty of text.",TRUE
pn1114,2702341,http://dx.doi.org/10.1145/2702123.2702341,http://dl.acm.org/citation.cfm?id=2702341,u7VzV93AGFw,www.youtube.com/watch?v=u7VzV93AGFw,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/u7VzV93AGFw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,OmniVib: Towards Cross-body Spatiotemporal Vibrotactile Notifications for Mobile Phones,"Jessalyn Alvina, Simon T Perrault, Thijs Roumen, Shengdong Zhao, Maryam Azh, Morten Fjeld","Previous works illustrate that one’s palm can reliably recognize 10 or more spatiotemporal vibrotactile patterns. However, recognition of the same patterns on other body parts is unknown. In this paper, we investigate how users perceive spatiotemporal vibrotactile patterns on the arm, palm, thigh, and waist. Results of the first two experiments indicate that precise recognition of either position or orientation is difficult across multiple body parts. Nonetheless, users were able to distinguish whether two vibration pulses were from the same location when played in quick succession. Based on this finding, we designed eight spatiotemporal vibrotactile patterns and evaluated them in two additional experiments. The results demonstrate that these patterns can be reliably recognized (>80%) across the four tested body parts, both in the lab and in a more realistic context.",TRUE
pn1122,2702343,http://dx.doi.org/10.1145/2702123.2702343,http://dl.acm.org/citation.cfm?id=2702343,AF6WQdyAtaw,www.youtube.com/watch?v=AF6WQdyAtaw,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/AF6WQdyAtaw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Making Social Matching Context-Aware - Design Concepts and Open Challenges,"Julia M Mayer, Starr Roxanne Hiltz, Quentin Jones","Social matching systems recommend people to people. In an ideal world, such systems could be context-aware, in that they would introduce users to each other in situations where they are mutually interested, available and open to meeting (i.e., facilitate a valuable encounter). Unfortunately, today’s systems primarily match individuals based on simple similarity and proximity metrics. This paper explores how contextual information available on today’s mobile phones could be used to identify opportunities for people to make valuable new connections. Three types of context that are relevant for this work are: relational, social and personal. We present insights gained from several iterations of semi-structured interviewing (N=58) exploring these three types of contexts and propose novel context-aware social matching concepts such as: sociability of others as an indicator of opportune social context; activity involvement as an indicator of opportune personal context; and contextual rarity as an indicator of opportune relational context.",TRUE
pn1129,2702345,http://dx.doi.org/10.1145/2702123.2702345,http://dl.acm.org/citation.cfm?id=2702345,YPq6xdA_vRk,www.youtube.com/watch?v=YPq6xdA_vRk,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/YPq6xdA_vRk' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Mechanics of Camera Work in Mobile Video Collaboration,"Brennan Jones, Anna Witcraft, Scott Bateman, Carman Neustaedter, Anthony Tang","Mobile video conferencing, where one or more participants are moving about in the real world, enables entirely new interaction scenarios (e.g., asking for help to construct or repair an object, or showing a physical location). While we have a good understanding of the challenges of video conferencing in office or home environments, we do not fully understand the mechanics of camera work—how people use mobile devices to communicate with one another—during mobile video calls. To provide an understanding of what people do in mobile video collaboration, we conducted an observational study where pairs of participants completed tasks using a mobile video conferencing system. Our analysis suggests that people use the camera view deliberately to support their interactions—for example, to convey a message or to ask questions—but the limited field of view, and the lack of camera control can make it a frustrating experience.",FALSE
pn1142,2702347,http://dx.doi.org/10.1145/2702123.2702347,http://dl.acm.org/citation.cfm?id=2702347,IiWG3u1p3-s,www.youtube.com/watch?v=IiWG3u1p3-s,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/IiWG3u1p3-s' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Statsplorer: Guiding Novices in Statistical Analysis,"Chat Wacharamanotham, Krishna Subramanian, Sarah Theres Völkel, Jan Borchers","Each step of statistical analysis requires researchers to make decisions based on both statistical knowledge and the knowledge of their own data. For novice analysts, this is cognitively demanding and can lead to mistakes and misinterpretations of the results. We present Statsplorer, a software that helps novices learn and perform inferential statistical tests. It lets the user kick-start data analysis from their research questions. Statsplorer automatically tests necessary statistical assumptions and uses visualizations to guide the user in both selecting statistical tests and interpreting the results. We compared Statsplorer with a statistics lecture and investigated how Statsplorer prepares novices for learning statistics in an AB/BA crossover experiment. The results indicates that using Statsplorer prior to the lecture leads to significantly better test scores in understanding statistical assumptions and choosing appropriate statistical tests. Statsplorer is open-source and is available online at: http://hci.rwth-aachen.de/statsplorer. \ ",TRUE
pn1147,2702349,http://dx.doi.org/10.1145/2702123.2702349,http://dl.acm.org/citation.cfm?id=2702349,X34Xp8NY7dM,www.youtube.com/watch?v=X34Xp8NY7dM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/X34Xp8NY7dM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Using Time-Anchored Peer Comments to Enhance Social Interaction in Online Educational Videos,"Yi-Chieh Lee, Wen-Chieh Lin, Fu-Yin Cherng, Hao-Chuan Wang, Ching-Ying Sung, Jung-Tai King","Online learning is increasingly prevalent as an option for self-learning and as a resource for instructional design. Prerecorded video is currently the main medium of online education content delivery and instruction; this affords asynchronicity and flexibility, and enables the dissemination of lecture content in a distributed and scalable manner. However, the same properties may impede learners' engagement due to the lack of social interaction and peer support. In this paper, we propose a time-anchored commenting interface to allow online learners who watch the same video clips to exchange comments on them. Comments left by previous learners at specific time points of a video are displayed to new learners when they watch the same video and reach those time points. We investigated how the display of time-anchored comments (dynamic or static) and type of comments (content-related or social-oriented) influenced users' perceived engagement, perceived social interactivity, and learning outcomes. Our results show that dynamically displaying time-anchored comments can indeed enhance learners' perceived social interactivity.  Moreover, the content of comments would further affect learners' intention of commenting.  Based on our findings, we make various recommendations for the improvement of social interaction and learning experience in online education.",TRUE
pn1149,2702350,http://dx.doi.org/10.1145/2702123.2702350,http://dl.acm.org/citation.cfm?id=2702350,kOaphlSryf4,www.youtube.com/watch?v=kOaphlSryf4,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/kOaphlSryf4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,NotiRing: A Comparative Study of Notification Channels for Wearable Interactive Rings,"Thijs Roumen, Simon T Perrault, Shengdong Zhao","We conducted an empirical investigation of wearable interactive rings on the noticeability of four instantaneous notification channels (light, vibration, sound, poke) and a channel with gradually increased temperature (thermal) during five levels of physical activity (laying down, sitting, standing, walking, and running). Results showed that vibration was the most reliable and fastest channel to convey notification, followed by poke and sound which shared similar noticeability. The noticeability of these three channels was not affected by the level of physical activity. The other two channels, light and thermal, were less noticeable and were affected by the level of physical activity. Our post-experimental survey indicates that while noticeability has a significant influence on user preference, each channel has its own unique advantages that make it suitable for different notification scenarios.",TRUE
pn1156,2702352,http://dx.doi.org/10.1145/2702123.2702352,http://dl.acm.org/citation.cfm?id=2702352,l8FcYQoBb4I,www.youtube.com/watch?v=l8FcYQoBb4I,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/l8FcYQoBb4I' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Factful: Engaging Taxpayers in the Public Discussion of a Government Budget,"Juho Kim, Eun-Young Ko, Jonghyuk Jung, Chang Won Lee, Nam Wook Kim, Jihee Kim","While a government budget determines how taxpayers’ money is allocated to various programs and stakeholders that compete for limited resources, the extensiveness and complexity of the budget and its process hinder taxpayers from understanding the budget information and participating in the public discussion. To engage taxpayers in the public discussion around budgetary issues, we leverage news articles containing budgetary information for design opportunities. We present Factful, a web-based annotative article reading interface that enhances the article with fact-checking support and contextual budgetary information by processing open government data. In our lab study, participants using Factful discussed more critically with more fact-based supporting statements. They built a rich context surrounding the relevant budget facts beyond what was presented in the article. Factful presents a simple yet powerful model for supporting fact-oriented budgetary discussions online by leveraging open government data.",TRUE
pn1167,2702354,http://dx.doi.org/10.1145/2702123.2702354,http://dl.acm.org/citation.cfm?id=2702354,UV9Es86xT5k,www.youtube.com/watch?v=UV9Es86xT5k,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/UV9Es86xT5k' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Interactive Cloud Experimentation for Biology: An Online Education Case Study,"Zahid Hossain, Xiaofan Jin, Engin W Bumbacher, Alice M Chung, Stephen Koo, Jordan D Shapiro, Cynthia Y Truong, Sean Choi, Nathan D Orloff, Paulo Blikstein, Ingmar H Riedel-Kruse","Interacting with biological systems via experiments is important for academia, industry, and education, but access barriers exist due to training, costs, safety, logistics, and spatial separation. High-throughput equipment combined with web streaming could enable interactive biology experiments online, but no such platform currently exists. We present a cloud experimentation architecture (paralleling cloud computation), which is optimized for a class of domain-specific equipments (biotic processing units - BPU) to share and execute many experiments in parallel remotely and interactively at all time. We implemented an instance of this architecture that enables chemotactic experiments with a slime mold Physarum Polycephelum. A user study in the blended teaching and research setting of a graduate-level biophysics class demonstrated that this platform lowers the access barrier for non-biologists, enables discovery, and facilitates learning analytics. This architecture is flexible for integration with various biological specimens and equipments to facilitate scalable interactive online education, collaborations, research, and citizen science.",TRUE
pn1170,2702355,http://dx.doi.org/10.1145/2702123.2702355,http://dl.acm.org/citation.cfm?id=2702355,FZa29K7BKsQ,www.youtube.com/watch?v=FZa29K7BKsQ,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/FZa29K7BKsQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Gaze+RST: Integrating Gaze and Multitouch for Remote Rotate-Scale-Translate Tasks,"Jayson Turner, Jason Alexander, Andreas Bulling, Hans Gellersen","Our work investigates the use of gaze and multitouch to fluidly perform rotate-scale-translate (RST) tasks on large displays. The work specifically aims to understand if gaze can provide benefit in such a task, how task complexity affects performance, and how gaze and multitouch can be combined to create an integral input structure suited to the task of RST. We present four techniques that individually strike a different balance between gaze-based and touch-based translation while maintaining concurrent rotation and scaling operations. A 16 participant empirical evaluation revealed that three of our four techniques present viable options for this scenario, and that larger distances and rotation/scaling operations can significantly affect a gaze-based translation configuration. Furthermore we uncover new insights regarding multimodal integrality, finding that gaze and touch can be combined into configurations that pertain to integral or separable input structures.",TRUE
pn1187,2702358,http://dx.doi.org/10.1145/2702123.2702358,http://dl.acm.org/citation.cfm?id=2702358,FmOcNE8Ir6s,www.youtube.com/watch?v=FmOcNE8Ir6s,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/FmOcNE8Ir6s' width='640' height='360' frameborder='0' allowfullscreen='true'/>,AnnoTone: Record-time Audio Watermarking for Context-aware Video Editing,"Ryohei Suzuki, Daisuke Sakamoto, Takeo Igarashi","We present a video annotation system called ``AnnoTone'', which can embed various contextual information describing a scene, such as geographical location. Then the system allows the user to edit the video using this contextual information, enabling one to, for example, overlay with map or graphical annotations. AnnoTone converts annotation data into high-frequency audio signals (which are inaudible to the human ear), and then transmits them from a smartphone speaker placed near a video camera. \ This scheme makes it possible to add annotations using standard video cameras with no requirements for specific equipment other than a smartphone. We designed the audio watermarking protocol using dual-tone multi-frequency signaling, and developed a general-purpose annotation framework including an annotation generator and extractor. We conducted a series of performance tests to understand the reliability and the quality of the watermarking method. We then created several examples of video-editing applications using annotations to demonstrate the usefulness of Annotone, including an After Effects plug-in.",TRUE
pn1188,2702359,http://dx.doi.org/10.1145/2702123.2702359,http://dl.acm.org/citation.cfm?id=2702359,ub6MMwpJyi8,www.youtube.com/watch?v=ub6MMwpJyi8,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/ub6MMwpJyi8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,The Transfer of Learning as HCI Similarity: Towards an Objective Assessment of the Sensory-Motor Basis of Naturalness,"François Bérard, Amélie Rochet-Capellan","Human-computer interaction should be natural. However, the notion of natural is questioned due to a lack of theoretical background and methods to objectively measure the naturalness of a HCI. A frequently cited aspect of natural HCIs is their ability to benefit from knowledge and skills that users develop in their interaction with the real (non-digital) world. Among these skills, sensory-motor abilities are essential to operate many HCIs. This suggests that the transfer of these abilities between physical and digital interactions could be used as an experimental tool to assess the sensory-motor similarity between interactions, and could be considered as an objective measurement of the sensory-motor grounding of naturalness. \  \ In this framework, we introduce a new experimental paradigm inspired by motor learning research to assess sensory-motor similarity, as revealed by the transfer of learning. We tested this paradigm in an empirical study to question the naturalness of three HCIs: direct-touch, mouse pointing and absolute indirect-touch. The study revealed how skill learning transfers from these three digital interactions towards an equivalent physical interaction. We observed strong transfer of skill between direct-touch and physical interaction, but no transfer from the other two interactions. This work provides a first objective assessment of the sensory-motor basis of direct-touch naturalness, and a new empirical path to question HCI similarity and naturalness. \ ",TRUE
pn1195,2702361,http://dx.doi.org/10.1145/2702123.2702361,http://dl.acm.org/citation.cfm?id=2702361,54qBUH0ktxU,www.youtube.com/watch?v=54qBUH0ktxU,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/54qBUH0ktxU' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Emotions Mediated Through Mid-Air Haptics,"Marianna Obrist, Sriram Subramanian, Elia Gatti, Benjamin Long, Thomas Carter","Touch is a powerful vehicle for communication between humans. The way we touch (how) embraces and mediates certain emotions such as anger, joy, fear, or love. While this phenomenon is well explored for human interaction, HCI research is only starting to uncover the fine granularity of sensory stimulation and responses in relation to certain emotions. Within this paper we present the findings from a study exploring the communication of emotions through a haptic system that uses tactile stimulation in mid-air. Here, haptic descriptions for specific emotions (e.g., happy, sad, excited, afraid) were created by one group of users to then be reviewed and validated by two other groups of users. We demonstrate the non-arbitrary mapping between emotions and haptic descriptions across three groups. This points to the huge potential for mediating emotions through mid-air haptics. We discuss specific design implications based on the spatial, directional, and haptic parameters of the created haptic descriptions and illustrate their design potential for HCI based on two design ideas.",TRUE
pn1217,2702363,http://dx.doi.org/10.1145/2702123.2702363,http://dl.acm.org/citation.cfm?id=2702363,VlQILrifzPs,www.youtube.com/watch?v=VlQILrifzPs,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/VlQILrifzPs' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Control of Non-Solid Diffusers by Electrostatic Charging,"Deepak Ranjan Sahoo, Diego Martinez Plasencia, Sriram Subramanian","The form factors of displays using fog or water surface are limited by our ability to control the non-solid substances used as the diffuser. We propose a charging technique for polar aerosols (e.g., mist or fog) that allows control of the shape and trajectory of such non-solid diffusers using electric fields. We report experiments that allowed us to design a charging mechanism that produces charged fog aerosols with homogeneous electrical mobility. We illustrate our idea by demonstrating how electric fields can be used to control the shape of a fog display and the trajectory of a bubble display.",TRUE
pn1221,2702365,http://dx.doi.org/10.1145/2702123.2702365,http://dl.acm.org/citation.cfm?id=2702365,M2HGE3Se3t4,www.youtube.com/watch?v=M2HGE3Se3t4,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/M2HGE3Se3t4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,On the Effectiveness of Pattern Lock Strength Meters - Measuring the Strength of Real World Pattern Locks,"Youngbae Song, Geumhwan Cho, Seongyeol Oh, Hyoungshick Kim, Jun Ho Huh","We propose an effective pattern lock strength meter to help users choose stronger pattern locks on Android devices.  \ To evaluate the effectiveness of the proposed meter with a real world dataset (i.e., with complete ecological validity), we created an Android application called EnCloud that allows users to encrypt their Dropbox files. 101 pattern locks generated by real EnCloud users were collected and analyzed, where some portion of the users were provided with the meter support. \ Our statistical analysis indicates that about 10% of the pattern locks that were generated without the meter support could be compromised through just 16 guessing attempts. As for the pattern locks that were generated with the meter support, that number goes up to 48 guessing attempts, showing significant improvement in security. Our recommendation is to implement a strength meter in the next version of Android.",TRUE
pn1256,2702367,http://dx.doi.org/10.1145/2702123.2702367,http://dl.acm.org/citation.cfm?id=2702367,R2CEE89EN14,www.youtube.com/watch?v=R2CEE89EN14,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/R2CEE89EN14' width='640' height='360' frameborder='0' allowfullscreen='true'/>,The Effects of Chronic Multitasking on Analytical Writing,"Danielle M. Lottridge, Christine Rosakranse, Catherine S. Oh, Sean J. Westwood, Katherine A. Baldoni, Abrey S. Mann, Clifford I. Nass","Chronic multitaskers perform worse on core multitasking skills: memory management, cognitive filtering and task switching, likely due to their inability to filter irrelevant stimuli [17]. Our experiment examines effects of chronic multitasking with task-relevant and irrelevant distractors on analytical writing quality. We found a general switch cost and, when controlling for that cost, effects of chronic multitasking habits: heavy multitaskers write worse essays in the irrelevant condition and better essays in the relevant condition. Our study changes multitasking research paradigms in two fundamental ways: it studied a realistic writing scenario including access to both irrelevant and relevant distractors. We found that the effect of chronic multitasking is complex; heavy multitaskers are seduced by unrelated distractors but able to integrate multiple sources of relevant information.",TRUE
pn1258,2702369,http://dx.doi.org/10.1145/2702123.2702369,http://dl.acm.org/citation.cfm?id=2702369,oHcVndXQt5o,www.youtube.com/watch?v=oHcVndXQt5o,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/oHcVndXQt5o' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Study on Gaze Direction Perception of Face Image Displayed on Rotatable Flat Display,"Ikkaku KAWAGUCHI, Hideaki Kuzuoka, Yusuke SUZUKI","A long-standing challenge of video-mediated communication systems is to correctly represent remote participant gaze direction in local environments. A telepresence robot with a movable display that shows the face of a remote participant is a promising approach for solving this issue. Researchers generally consider that display orientation is effective for local participants to properly estimate the gaze direction of remote participants. We investigate how subjects estimate gaze direction of a remote participant (“Looker”) when his/her face is displayed on a rotatable flat display. Our experiment reveals that both the Looker’s head-eye rotation in the display and display rotation affect subject estimation, but the effect of the display rotation is relatively small. Furthermore, we reveal that subjects tend to overestimate Looker gaze direction. Based on our results, we propose a design implication for a telepresence robot to reduce overestimation and properly represent the remote participant gaze direction.",TRUE
pn1268,2702371,http://dx.doi.org/10.1145/2702123.2702371,http://dl.acm.org/citation.cfm?id=2702371,fQobwL8eSU4,www.youtube.com/watch?v=fQobwL8eSU4,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/fQobwL8eSU4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,zSense: Enabling Shallow Depth Gesture Recognition for Greater Input Expressivity on Smart Wearables,"Anusha Withana, Roshan Peiris, Nipuna Samarasekara, Suranga Nanayakkara","In this paper we present zSense, which provides greater input expressivity for spatially limited devices such as smart wearables through a shallow depth gesture recognition system using non-focused infrared sensors. To achieve this, we introduce a novel Non-linear Spatial Sampling (NSS) technique that significantly cuts down the number of required infrared sensors and emitters. These can be arranged in many different configurations; for example, number of sensor emitter units can be as minimal as one sensor and two emitters. We implemented different configurations of zSense on smart wearables such as smartwatches, smartglasses and smart rings. These configurations naturally fit into the flat or curved surfaces of such devices, providing a wide scope of zSense enabled application scenarios. Our evaluations reported over 94.8% gesture recognition accuracy across all configurations.",TRUE
pn1273,2702372,http://dx.doi.org/10.1145/2702123.2702372,http://dl.acm.org/citation.cfm?id=2702372,tLDNDGMnxek,www.youtube.com/watch?v=tLDNDGMnxek,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/tLDNDGMnxek' width='640' height='360' frameborder='0' allowfullscreen='true'/>,The CADENCE Corpus: A New Resource for Inclusive Voice Interface Design,"Maria K Wolters, Jonathan Kilgour, Sarah E MacPherson, Myroslava Dzikovska, Johanna D Moore","Papers on voice interfaces for people with cognitive impairment or demenita only provide small snapshots of actual interactions, if at all. This is a major obstacle to the development of better interfaces. Transcripts of interactions between users and systems contain rich evidence of typical language patterns, indicate how users conceptualise their computer interlocutor, and highlight key design issues. In this paper, we introduce the CADENCE corpus and outline how it can be used to stimulate replicable research on inclusive voice interfaces. The CADENCE  corpus is first data set of its kind to include rich data from people with cognitive impairment and free for research use. The corpus consists of transcribed spoken interactions between older people with and without cognitive impairment and a simulated Intelligent Cognitive Assistant and includes comprehensive data on users' cognitive abilities. ",TRUE
pn1275,2702373,http://dx.doi.org/10.1145/2702123.2702373,http://dl.acm.org/citation.cfm?id=2702373,q2AfjMdCnoc,www.youtube.com/watch?v=q2AfjMdCnoc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/q2AfjMdCnoc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,TabLETS Get Physical: Non-Visual Text Entry on Tablet Devices,"João Guerreiro, André Rodrigues, Kyle Montague, Tiago Guerreiro, Hugo Nicolau, Daniel Gonçalves","Tablet devices can display full-size QWERTY keyboards similar to the physical ones. Yet, the lack of tactile feedback and the inability to rest the fingers on the home keys result in a highly demanding and slow exploration task for blind users. We present SpatialTouch, an input system that leverages previous experience with physical QWERTY keyboards, by supporting two-handed interaction through multitouch exploration and spatial, simultaneous audio feedback. We conducted a user study, with 30 novice touchscreen participants entering text under one of two conditions: (1) SpatialTouch or (2) mainstream accessibility method Explore by Touch. We show that SpatialTouch enables blind users to leverage previous experience as they do a better use of home keys and perform more efficient exploration paths. Results suggest that although SpatialTouch did not result in faster input rates overall, it was indeed able to leverage previous QWERTY experience in contrast to Explore by Touch.",TRUE
pn1280,2702374,http://dx.doi.org/10.1145/2702123.2702374,http://dl.acm.org/citation.cfm?id=2702374,6Tcx6F5y6Rw,www.youtube.com/watch?v=6Tcx6F5y6Rw,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/6Tcx6F5y6Rw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,"As Light as your Footsteps: Altering Walking Sounds to Change Perceived Body Weight, Emotional State and Gait","Ana Tajadura-Jiménez, Maria Basia, Ophelia Deroy, Merle Fairhurst, Nicolai Marquardt, Nadia Bianchi-Berthouze","An ever more sedentary lifestyle is a serious problem in our society. Enhancing people’s exercise adherence through technology remains an important research challenge. We propose a novel approach for a system supporting walking that draws from basic findings in neuroscience research. Our shoe-based prototype senses a person’s footsteps and alters in real-time the frequency spectra of the sound they produce while walking. The resulting sounds are consistent with those produced by either a lighter or heavier body. Our user study showed that modified walking sounds change one’s own perceived body weight and lead to a related gait pattern. In particular, augmenting the high frequencies of the sound leads to the perception of having a thinner body and enhances the motivation for physical activity inducing a more dynamic swing and a shorter heel strike. We here discuss the opportunities and the questions our findings open. ",TRUE
pn1284,2702375,http://dx.doi.org/10.1145/2702123.2702375,http://dl.acm.org/citation.cfm?id=2702375,jV3VkukDM9U,www.youtube.com/watch?v=jV3VkukDM9U,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/jV3VkukDM9U' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Investigating Visual Feedforward  for Target Expansion Techniques,"Maxime Guillon, François Leitner, Laurence Nigay","Target expansion techniques facilitate the pointing task by enlarging the effective sizes of targets. When the target expansion is applied to both the motor and visual spaces, the visual feedforward mechanism is key: Indeed it provides a visual aid to the user on the effective expanded targets prior to the execution or completion of the pointing task, enabling the user to take full advantage of the target expansion technique. Focusing on feedforward mechanisms, we introduce a design space that allows us to describe, classify and design target expansion techniques. To do so we first introduce and characterize the concept of atomic feedforward mechanism along three design axes. We then describe a target expansion technique as a combination of atomic feedforward mechanisms using a matrix-based notation. We provide an analytical exploration of the design space by classifying existing techniques and by designing six new techniques. We also provide a first experimental exploration of the design space in the context of distant pointing. The experimental protocol includes an innovative target layout for handling non-centroidal target expansion. The results show that feedforward dynamicity increases movement time and decreases subjective usability, while explicit expansion observability efficiently supports error prevention for distant pointing.",TRUE
pn1296,2702377,http://dx.doi.org/10.1145/2702123.2702377,http://dl.acm.org/citation.cfm?id=2702377,_E7vx0BCRiA,www.youtube.com/watch?v=_E7vx0BCRiA,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/_E7vx0BCRiA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,The Data Driven Lives of Wargaming Miniatures,"Dimitrios Paris Darzentas, Michael A Brown, Martin Flintham, Steve Benford","We present an ethnographic study of the practice of miniature wargaming in order to shed light onto the complex lives of physical things and the ways in which they acquire data footprints. We take an extended view of the practice, revealing how people invest great effort into crafting miniatures, playing with them, curating and telling stories about them, and passing them on. Throughout, we emphasise the use of both traditional and digital technologies to build rich data footprints. In discussing our findings, we adopt a ‘thing-centric’ perspective that focuses on the extended lifetimes of the miniatures themselves. This enables us to identify opportunities for digital augmentation in support of capturing ‘life away from the table’ and a need for HCI to focus on designing trajectories of things. ",TRUE
pn1323,2702382,http://dx.doi.org/10.1145/2702123.2702382,http://dl.acm.org/citation.cfm?id=2702382,_PESkwbCwgc,www.youtube.com/watch?v=_PESkwbCwgc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/_PESkwbCwgc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,A Dose of Reality: Overcoming Usability Challenges in VR Head-Mounted Displays,"Mark McGill, Daniel Boland, Roderick Murray-Smith, Stephen A Brewster","We identify usability challenges facing consumers adopting Virtual Reality (VR) head-mounted displays (HMDs) in a survey of 108 VR HMD users. Users reported significant issues in interacting with, and being aware of their real-world context when using a HMD. Building upon existing work on blending real and virtual environments, we performed three design studies to address these usability concerns. In a typing study, we show that augmenting VR with a view of reality significantly corrected the performance impairment of typing in VR. We then investigated how much reality should be incorporated and when, so as to preserve users' sense of presence in VR. For interaction with objects and peripherals, we found that selectively presenting reality as users engaged with it was optimal in terms of performance and users' sense of presence. Finally, we investigated how this selective, engagement-dependent approach could be applied in social environments, to support the user's awareness of the proximity and presence of others.",TRUE
pn1336,2702384,http://dx.doi.org/10.1145/2702123.2702384,http://dl.acm.org/citation.cfm?id=2702384,OZwW4Cj9Eiw,www.youtube.com/watch?v=OZwW4Cj9Eiw,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/OZwW4Cj9Eiw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Contextual Influences on the Use and Non-Use of Digital Technology While Exercising at the Gym,"Misha Patel, Aisling Ann O'Kane","The use of wearable technology will become significantly more prevalent in the coming years, with major companies releasing devices such as the Samsung Gear Fit. With sensors, such as pedometers and heart rate monitors, embedded in these devices it is possible to use them for fitness purposes. However, little is known about how wearable adopters actually use wearable and existing technologies during exercise. In an exploratory situated study of technology use and non-use in the context of the gym, fitness informatics adopters showed varied practices related to distraction, appropriating technology into their routines, and information needs. We discuss this variance in relation to individual differences and the impact of the physical nature of the gym. Although further research might show other influencing factors such as the social context, we make a case for the use of situated studies to uncover tensions that lead to use and non-use of technology that arise in the different unfolding situations of using wearables in everyday life, including at the gym, which is a surprisingly complex context.",TRUE
pn1337,2702385,http://dx.doi.org/10.1145/2702123.2702385,http://dl.acm.org/citation.cfm?id=2702385,xjRUASJ7xP4,www.youtube.com/watch?v=xjRUASJ7xP4,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/xjRUASJ7xP4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Designing Social and Emotional Skills Training: The Challenges and Opportunities for Technology Support,"Petr Slovák, Ran Gilad-Bachrach, Geraldine Fitzpatrick","Social and emotional skills are crucial for all aspects of our everyday life. However, understanding how digital technology can facilitate the development and learning of such skills is yet an under-researched area in HCI. To start addressing this gap, this paper reports on a series of interviews and design workshops with the leading researchers and developers of 'Social and Emotional Learning' (SEL) curricula. SEL is a subfield of educational psychology with a long history of teaching such skills, and a range of evidence based curricula that are widely deployed in  primary and secondary schools. We identify the shared challenges across existing curricula that digital technology might help address: the support for out-of-session learning, scaffolding for parental engagement, and feedback for the curricula developers. We argue how this presents an opportunity for mutually beneficial collaborations, with the potential for significant real-world impact of novel HCI systems, and can inform HCI work on supporting social and emotional skills development in other domains. \ ",FALSE
pn1356,2702388,http://dx.doi.org/10.1145/2702123.2702388,http://dl.acm.org/citation.cfm?id=2702388,10njaEv-Pi0,www.youtube.com/watch?v=10njaEv-Pi0,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/10njaEv-Pi0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Text Entry on Tiny QWERTY Soft Keyboards,"Luis A. Leiva, Alireza Sahami, Alejandro Catala, Niels Henze, Albrecht Schmidt","The advent of wearables (e.g., smartwatches, smartglasses, and digital jewelry) anticipates the need for text entry methods on very small devices. We conduct fundamental research on this topic using 3 qwerty-based soft keyboards for 3 different screen sizes, motivated by the extensive training that users have with qwerty keyboards. In addition to ZoomBoard (a soft keyboard for diminutive screens), we propose a callout-based soft keyboard and ZShift, a novel extension of the Shift pointing technique. We conducted a comprehensive user study followed by extensive analyses on performance, usability, and short-term learning. Our results show that different small screen sizes demand different types of assistance. In general, manufacturers can benefit from these findings by selecting an appropriate qwerty soft keyboard for their devices. Ultimately, this work provides designers, researchers, and practitioners with new understanding of qwerty soft keyboard design space and its scalability for tiny touchscreens.",TRUE
pn1357,2702389,http://dx.doi.org/10.1145/2702123.2702389,http://dl.acm.org/citation.cfm?id=2702389,SuIgD2Iaaiw,www.youtube.com/watch?v=SuIgD2Iaaiw,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/SuIgD2Iaaiw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Substitutional Reality: Using the Physical Environment to Design Virtual Reality Experiences,"Adalberto L. Simeone, Eduardo Velloso, Hans Gellersen","Experiencing Virtual Reality in domestic and other uncontrolled settings is challenging due to the presence of physical objects and furniture that are not usually defined in the Virtual Environment. To address this challenge, we explore the concept of Substitutional Reality in the context of Virtual Reality: a class of Virtual Environments where every physical object surrounding a user is paired, with some degree of discrepancy, to a virtual counterpart. We present a model of potential substitutions and validate it in two user studies. In the first study we investigated factors that affect participants' suspension of disbelief and ease of use. We systematically altered the virtual representation of a physical object and recorded responses from 20 participants. The second study investigated users' levels of engagement as the physical proxy for a virtual object varied. From the results, we derive a set of guidelines for the design of future Substitutional Reality experiences.",TRUE
pn1361,2702390,http://dx.doi.org/10.1145/2702123.2702390,http://dl.acm.org/citation.cfm?id=2702390,EH0iKvXFKdE,www.youtube.com/watch?v=EH0iKvXFKdE,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/EH0iKvXFKdE' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Subjective and Objective Effects of Tablet's Pixel Density,"Lars Lischke, Sven Mayer, Katrin Wolf, Alireza Sahami, Niels Henze","Pixel densities are increasing rapidly. We can observe this trend in particular for mobile devices like smartphones and tablets. Previous work revealed an effect of pixel density on subjective feedback and objective performance only for low resolution cathode ray tube screens. It is unclear if this effect persists for the four times higher pixel densities of current mobile devices. Therefore, we conducted a study to compare four pixel densities with 359, 180, 120, and 90 pixels per inch. While participants performed three tasks involving images, text and videos on a tablet, we measured perceived effort, perceived visual quality, task completion time, error rate, and body pose. Our results show that the effect of the pixel density highly depends on the content. We found that only for text, the four pixel densities have clearly different perceived media qualities. Pixel density seems to have a smaller effect on perceived media quality for images and videos and we found no effect on objective measures. Results show that text should be displayed in high resolution, while this is less important for images and videos.",TRUE
pn1367,2702391,http://dx.doi.org/10.1145/2702123.2702391,http://dl.acm.org/citation.cfm?id=2702391,-muK9kJKgfQ,www.youtube.com/watch?v=-muK9kJKgfQ,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/-muK9kJKgfQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,"iSkin: Flexible, Stretchable and Visually Customizable On-Body Touch Sensors for Mobile Computing","Martin Weigel, Tong Lu, Gilles Bailly, Antti Oulasvirta, Carmel Majidi, Jürgen Steimle","We propose iSkin, a novel class of skin-worn sensors for touch input on the body.  \ iSkin is a very thin sensor overlay, made of biocompatible materials, and is flexible and stretchable. It can be produced in different shapes and sizes to suit various locations of the body such as the finger, forearm, or ear. \ Integrating capacitive and resistive touch sensing, the sensor is capable of detecting touch input with two levels of pressure, even when stretched  by 30% or when bent with a radius of 0.5cm. Furthermore, iSkin supports single or multiple touch areas of custom shape and arrangement, as well as more complex widgets, such as sliders and click wheels. \ Recognizing the social importance of skin, we show visual design patterns to customize functional touch sensors and allow for a visually aesthetic appearance. \ Taken together, these contributions enable new types of on-body devices. This includes finger-worn devices, extensions to conventional wearable devices, and touch input stickers, all fostering direct, quick, and discreet input for mobile computing.",TRUE
pn1373,2702393,http://dx.doi.org/10.1145/2702123.2702393,http://dl.acm.org/citation.cfm?id=2702393,DCPtCNREZjY,www.youtube.com/watch?v=DCPtCNREZjY,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/DCPtCNREZjY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Head-Mounted Display Visualizations to Support Sound Awareness for the Deaf and Hard of Hearing,"Dhruv Jain, Leah Findlater, Jamie Gilkeson, Benjamin Holland, Ramani Duraiswami, Dmitry Zotkin, Christian Vogler, Jon Froehlich","Persons with hearing loss use visual signals such as gestures and lip movement to interpret speech. While hearing aids and cochlear implants can improve sound recognition, they generally do not help the wearer localize sound necessary to leverage these visual cues. In this paper, we design and evaluate visualizations for spatially locating sound on a head-mounted display (HMD). To investigate this design space, we developed eight high-level visual sound feedback dimensions. For each dimension, we created 3-12 example visualizations and evaluated these as a design probe with 24 deaf and hard of hearing participants (Study 1). We then implemented a real-time proof-of-concept HMD prototype and solicited feedback from 4 new participants (Study 2). Study 1 findings reaffirm past work on challenges faced by persons with hearing loss in group conversations, provide support for the general idea of sound awareness visualizations on HMDs, and reveal preferences for specific design options. Although preliminary, Study 2 further contextualizes the design probe and uncovers directions for future work.",TRUE
pn1390,2702396,http://dx.doi.org/10.1145/2702123.2702396,http://dl.acm.org/citation.cfm?id=2702396,ec-cNlmMPxM,www.youtube.com/watch?v=ec-cNlmMPxM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/ec-cNlmMPxM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,FeelSleeve: Haptic Feedback to Enhance Early Reading,"Nesra Yannier, Ali Israr, Jill Fain Lehman, Roberta L. Klatzky","Engaging children with traditional approaches in education, especially reading, grows ever more difficult in the face of their attachment to tablets and computer games. We explore the possibility of making the story reading experience more interesting and memorable for children using haptic augmentation. In this paper, we present FeelSleeve, an interface that allows children to feel story events in their hands while they are reading on a mobile device. FeelSleeve uses transducers and audio output from the tablet within a gloved attachment to create vibratory effects that are meaningfully related to story content. We describe a study investigating whether embedding such haptic feedback into stories enhances reading for six to nine year olds. Our results indicate that story events accompanied by haptic feedback are better comprehended and appear to be more salient in memory. These results provide evidence that haptic effects have the potential to improve children’s reading experience and make it more memorable.",TRUE
pn1391,2702397,http://dx.doi.org/10.1145/2702123.2702397,http://dl.acm.org/citation.cfm?id=2702397,4M31Zh7t9eA,www.youtube.com/watch?v=4M31Zh7t9eA,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/4M31Zh7t9eA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Learning from Mixed-Reality Games:  Is Shaking a Tablet as Effective as Physical Observation?,"Nesra Yannier, Kenneth R. Koedinger, Scott E. Hudson","The possibility of leveraging technology to support children’s learning in the real world is both appealing and technically challenging. We have been exploring factors in tangible games that may contribute to both learning and enjoyment with an eye toward technological feasibility and scalability. Previous research found that young children learned early physics principles better when interactively predicting and observing experimental comparisons on a physical earthquake table than when seeing a video of the same. Immersing children in the real world with computer vision-based feedback appears to evoke embodied cognition that enhances learning. In the current experiment, we replicated this intriguing result of the mere difference between observing the real world versus a flat-screen. Further, we explored whether a simple and scalable addition of physical control (such as shaking a tablet) would yield an increase in learning and enjoyment. Our 2x2 experiment found no evidence that adding simple forms of hands-on control enhances learning, while demonstrating a large impact of physical observation. A general implication for educational game design is that affording physical observation in the real world accompanied by interactive feedback may be more important than affording simple hands-on control on a tablet.",TRUE
pn1419,2702398,http://dx.doi.org/10.1145/2702123.2702398,http://dl.acm.org/citation.cfm?id=2702398,88vJlCWp-4k,www.youtube.com/watch?v=88vJlCWp-4k,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/88vJlCWp-4k' width='640' height='360' frameborder='0' allowfullscreen='true'/>,GEM-NI: A System for Creating and Managing Alternatives In Generative Design,"Loutfouz Zaman, Wolfgang Stuerzlinger, Christian Neugebauer, Rob Woodbury, Maher Elkhaldi, Naghmi Shireen, Michael Terry","We present GEM-NI – a graph-based generative-design tool that supports parallel exploration of alternative designs. Producing alternatives is a key feature of creative work, yet it is not strongly supported in most extant tools. GEM-NI enables various forms of exploration with alternatives such as parallel editing, recalling history, branching, merging, comparing, and Cartesian products of and for alternatives. Further, GEM-NI provides a modal graphical user interface and a design gallery, which both allow designers to control and manage their design exploration. We conducted an exploratory user study followed by in-depth one-on-one interviews with moderately and highly skills participants and obtained positive feedback for the system features, showing that GEM-NI supports creative design work well.",TRUE
pn1439,2702401,http://dx.doi.org/10.1145/2702123.2702401,http://dl.acm.org/citation.cfm?id=2702401,V91HzzQZZRA,www.youtube.com/watch?v=V91HzzQZZRA,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/V91HzzQZZRA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Physio@Home: Exploring Visual Guidance and Feedback Techniques for Physiotherapy Exercises,"Richard Tang, Xing-Dong Yang, Scott Bateman, Joaquim Jorge, Anthony Tang","Physiotherapy patients exercising at home alone are at risk of re-injury since they do not have corrective guidance from a therapist. To explore solutions to this problem, we designed Physio@Home, a prototype that guides people through pre-recorded physiotherapy exercises using real-time visual guides and multi-camera views. Our design ad-dresses several aspects of corrective guidance, including: plane and range of movement, joint positions and angles, and extent of movement. We evaluated our design, com-paring how closely people could follow exercise movements under various feedback conditions. Participants were most accurate when using our visual guide and multi-views. We provide suggestions for exercise guidance systems drawn from qualitative findings on visual feedback complexity.",FALSE
pn1492,2702406,http://dx.doi.org/10.1145/2702123.2702406,http://dl.acm.org/citation.cfm?id=2702406,H5mQIhdi_z4,www.youtube.com/watch?v=H5mQIhdi_z4,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/H5mQIhdi_z4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Effects of Display Size and Resolution on User Behavior and Insight Acquisition in Visual Exploration,"Khairi Reda, Andrew E Johnson, Michael E Papka, Jason Leigh","Large high-resolution displays are becoming increasingly common in research settings, providing data scientists with visual interfaces for the analysis of large datasets. Numerous studies have demonstrated unique perceptual and cognitive benefits afforded by these displays in visual analytics and information visualization tasks. However, the effects of these displays on knowledge discovery in exploratory visual analysis are still poorly understood. We present the results of a small-scale study to better understand how display size and resolution affect insight. Analyzing participants' verbal statements, we find preliminary evidence that larger displays with more pixels can significantly increase the number of discoveries reported during visual exploration, while yielding broader, more integrative insights. Furthermore, we find important differences in how participants performed the same visual exploration task using displays of varying sizes. We tie these results to extant work and propose explanations by considering the cognitive and interaction costs associated with visual exploration.",TRUE
pn1528,2702412,http://dx.doi.org/10.1145/2702123.2702412,http://dl.acm.org/citation.cfm?id=2702412,WWOUI6CTEIE,www.youtube.com/watch?v=WWOUI6CTEIE,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/WWOUI6CTEIE' width='640' height='360' frameborder='0' allowfullscreen='true'/>,From User-Centered to Adoption-Centered Design: A Case Study of an HCI Research Innovation Becoming a Product,"Parmit K Chilana, Andrew J Ko, Jacob Wobbrock","As we increasingly strive for scientific rigor and generalizability in HCI research, should we entertain any hope that by doing good science, our discoveries will eventually be more transferrable to industry? We present an in-depth case study of how an HCI research innovation goes through the process of transitioning from a university project to a revenue-generating startup financed by venture capital. The innovation is a novel contextual help system for the Web, and we reflect on the different methods used to evaluate it and how research insights endure attempted dissemination as a commercial product. Although the extent to which any innovation succeeds commercially depends on a number of factors like market forces, we found that our HCI innovation with user-centered origins was in a unique position to gain traction with customers and garner buy-in from investors. However, since end users were not the buyers of our product, a strong user-centered focus obfuscated other critical needs of the startup and pushed out perspectives of non-user-centered stakeholders. To make the research-to-product transition, we had to focus on adoption-centered design, the process of understanding and designing for adopters and stakeholders of the product. Our case study raises questions about how we evaluate the novelty and research contributions of HCI innovations with respect to their potential for commercial impact. ",TRUE
pn1533,2702414,http://dx.doi.org/10.1145/2702123.2702414,http://dl.acm.org/citation.cfm?id=2702414,C2d1pB1qlvA,www.youtube.com/watch?v=C2d1pB1qlvA,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/C2d1pB1qlvA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,"Acoustruments: Passive, Acoustically-Driven, Interactive Controls for Handheld Devices","Gierad Laput, Eric Brockmeyer, Scott E Hudson, Chris Harrison","We introduce Acoustruments: low-cost, passive, and power-less mechanisms, made from plastic, that can bring rich, tangible functionality to handheld devices. Through a structured exploration, we identified an expansive vocabulary of design primitives, providing building blocks for the construction of tangible interfaces utilizing smartphones’ exist-ing audio functionality. By combining design primitives, familiar physical mechanisms can all be constructed from passive elements. On top of these, we can create end-user applications with rich, tangible interactive functionalities. Our experiments show that Acoustruments can achieve 99% accuracy with minimal training, is robust to noise, and can be rapidly prototyped. Acoustruments adds a new method to the toolbox HCI practitioners and researchers can draw upon, while introducing a cheap and passive method for adding interactive controls to consumer products.",TRUE
pn1539,2702416,http://dx.doi.org/10.1145/2702123.2702416,http://dl.acm.org/citation.cfm?id=2702416,aYHzG9uXQ6k,www.youtube.com/watch?v=aYHzG9uXQ6k,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/aYHzG9uXQ6k' width='640' height='360' frameborder='0' allowfullscreen='true'/>,"Zensors: Adaptive, Rapidly Deployable, Human-Intelligent Sensor Feeds","Gierad Laput, Walter S Lasecki, Jason Wiese, Robert Xiao, Jeffrey P. Bigham, Chris Harrison","The promise of “smart” homes, workplaces, schools, and other environments has long been championed. Unattractive, however, has been the cost to run wires and install sensors. More critically, raw sensor data tends not to align with the types of questions humans wish to ask, e.g., do I need to restock my pantry? Although techniques like computer vision can answer some of these questions, it requires significant effort to build and train appropriate classifiers. Even then, these systems are often brittle, with limited ability to handle new or unexpected situations, including being repositioned and environmental changes (e.g., lighting, furniture, seasons). We propose Zensors, a new sensing approach that fuses real-time human intelligence from online crowd workers with automatic approaches to provide robust, adaptive, and readily deployable intelligent sensors. With Zensors, users can go from question to live sensor feed in less than 60 seconds. Through our API, Zensors can enable a variety of rich end-user applications and moves us closer to the vision of responsive, intelligent environments.",TRUE
pn1552,2702419,http://dx.doi.org/10.1145/2702123.2702419,http://dl.acm.org/citation.cfm?id=2702419,mNzodpnke2M,www.youtube.com/watch?v=mNzodpnke2M,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/mNzodpnke2M' width='640' height='360' frameborder='0' allowfullscreen='true'/>,MatrixWave: Visual Comparison of Event Sequence Data,"Jian Zhao, Zhicheng Liu, Mira Dontcheva, Aaron Hertzmann, Alan Wilson","Event sequence data analysis is common in many domains, including web and software development, transportation, and medical care. Few have investigated visualization techniques for comparative analysis of multiple event sequence datasets. Grounded in the real-world characteristics of web clickstream data, we explore visualization techniques for comparison of two clickstream datasets collected on different days or from users with different demographics. Through iterative design with web analysts, we designed MatrixWave, a matrix-based representation that allows analysts to get an overview of differences in traffic patterns and interactively explore paths through the website. We use color to encode differences and size to offer context over traffic volume. User feedback on MatrixWave is positive. Our study participants made fewer errors with MatrixWave and preferred it over the more familiar Sankey diagram. ",TRUE
pn1558,2702420,http://dx.doi.org/10.1145/2702123.2702420,http://dl.acm.org/citation.cfm?id=2702420,LmmcEHUhErA,www.youtube.com/watch?v=LmmcEHUhErA,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/LmmcEHUhErA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Designing for Citizen Data Analysis: A Cross-Sectional Case Study of a Multi-Domain Citizen Science Platform,"Ramine Tinati, Max Van Kleek, Elena Simperl, Markus Luczak-Rösch, Robert Simpson, Nigel Shadbolt","Designing an effective and sustainable citizen science (CS)project requires consideration of a great number of factors. This makes the overall process unpredictable,  even when a sound, user-centred design approach is followed by an experienced  team  of  UX  designers.   Moreover,  when  such  systems  are  deployed,  the  complexity  of  the  resulting  interactions challenges any attempt to generalisation from retrospective analysis.   In this paper,  we present a case study of the largest single platform of citizen driven data analysis projects to date, the Zooniverse.  By eliciting, through structured reflection, experiences of core members of its design team, our grounded analysis yielded four sets of themes,  focusing on Task Specificity, Community Development, Task Design and Public Relations and Engagement, supported by two-to-four specific design claims each. For each, we propose a set of design claims (DCs), drawing comparisons to the literature on crowdsourcing and online communities to contextualise our findings.",TRUE
pn1559,2702421,http://dx.doi.org/10.1145/2702123.2702421,http://dl.acm.org/citation.cfm?id=2702421,25uPK2POLwc,www.youtube.com/watch?v=25uPK2POLwc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/25uPK2POLwc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,FingerReader: A Wearable Device to Explore Printed Text on the Go,"Roy Shilkrot, Jochen Huber, Wong Meng Ee, Pattie Maes, Suranga Nanayakkara","Accessing printed text in a mobile context is a major challenge for the blind. A preliminary study with blind people reveals numerous difficulties with existing state-of-the-art technologies including problems with alignment, focus, accuracy, mobility and efficiency. In this paper, we present a finger-worn device, FingerReader, that assists blind users with reading printed text on the go. We introduce a novel computer vision algorithm for local-sequential text scanning that enables reading single lines, blocks of text or skimming the text with complementary, multimodal feedback. This system is implemented in a small finger-worn form factor, that enables a more manageable eyes-free operation with trivial setup. We offer findings from three studies performed to determine the usability of the FingerReader.",TRUE
pn1573,2702423,http://dx.doi.org/10.1145/2702123.2702423,http://dl.acm.org/citation.cfm?id=2702423,faxuHmdP3gU,www.youtube.com/watch?v=faxuHmdP3gU,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/faxuHmdP3gU' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Remote Paper Prototype Testing,"Kevin Chen, Haoqi Zhang","To test paper prototypes of mobile applications, we have been experimenting with remote paper prototype testing as an approach and tool for enabling a designer to wizard a paper prototype from afar while a user tests the prototype out of the lab. This paper presents a system for remote paper prototype testing that consists of (1) a video camera placed over a paper prototype, which streams a live audio-visual feed via Google Hangouts to a tester, and (2) Google Glass on the tester, which streams a live audio-visual-data feed to the facilitator and wizard. Results from a pilot study found that remote paper prototype testing helped designers gain valuable insights through use in realistic scenarios.",TRUE
pn1574,2702424,http://dx.doi.org/10.1145/2702123.2702424,http://dl.acm.org/citation.cfm?id=2702424,gyzVerduLLk,www.youtube.com/watch?v=gyzVerduLLk,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/gyzVerduLLk' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Providing Adaptive Support in an Interactive Simulation for Learning: an Experimental Evaluation,"Samad Kardan, Cristina Conati","Recent rise of Massive Open Online Courses (MOOCs) with unlimited participants, makes employing learning tools such as interactive simulations all but inevitable. Interactive simulations give students the opportunity to experiment with concrete examples and develop better understanding of concepts they have learned. However, some students do not learn well from this relatively unstructured form of interaction, suggesting the provision of adaptive support as a way to address this issue.  \ This paper presents a formal evaluation of providing support to facilitate open exploration. We describe the process of designing an intervention delivery mechanism for adding adaptive support to an exploratory interactive simulation.  The experimental evaluation of the adaptive version of the simulation indicates that the adaptive support provided to students significantly improved their learning performance. Quantitative and qualitative evaluations of users’ acceptance of the system are generally positive but pinpoint areas for improvement.      \ ",TRUE
pn1577,2702425,http://dx.doi.org/10.1145/2702123.2702425,http://dl.acm.org/citation.cfm?id=2702425,IAkKTGIkPiU,www.youtube.com/watch?v=IAkKTGIkPiU,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/IAkKTGIkPiU' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Understanding Users’ Touch Behavior on Large Mobile Touch-Screens and Assisted Targeting by Tilting Gesture,"Youli Chang, Sehi L'Yi, Kyle Koh, Jinwook Seo","As large-screen smartphones are trending, they bring a new set of challenges such as acquiring unreachable screen targets using one hand. To understand users’ touch behavior on large mobile touchscreens, we conducted an empirical experiment to discover their usage patterns of tilting devices toward their thumbs to touch screen regions. Exploiting this natural tilting behavior, we designed three novel mobile interaction techniques: TiltSlide, TiltReduction, and TiltCursor. We conducted a controlled experiment to compare our methods with other existing methods, and then evaluated them in real mobile phone scenarios such as sending an e-mail and web surfing. We constructed a design space for one-hand targeting interactions and proposed design considerations for one-hand targeting in real mobile phone circumstances.",TRUE
pn1580,2702426,http://dx.doi.org/10.1145/2702123.2702426,http://dl.acm.org/citation.cfm?id=2702426,CKwwwIh5y_I,www.youtube.com/watch?v=CKwwwIh5y_I,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/CKwwwIh5y_I' width='640' height='360' frameborder='0' allowfullscreen='true'/>,STRATOS: Using Visualization to Support Decisions in Strategic Software Release Planning,"Bon Adriel Aseniero, Tiffany Wun, David Ledo, Guenther Ruhe, Anthony Tang, Sheelagh Carpendale","Software is typically developed incrementally and released in stages. Planning these releases involves deciding which features of the system should be implemented for each  \ release. This is a complex planning process involving  \ numerous trade-offs—constraints and factors that often make decisions difficult. Since the success of a product  \ depends on this plan, it is important to understand the trade-offs between different release plans in order to make an  \ informed choice. We present STRATOS, a tool that simulta-neously visualizes several software release plans. The  \ visualization shows several attributes about each plan that are important to planners. Multiple plans are shown in a single layout to help planners find and understand the trade-offs  \ between alternative plans. We evaluated our tool via a  \ qualitative study and found that STRATOS enables a range of  \ decision-making processes, helping participants decide on which plan is most optimal.",TRUE
pn1583,2702427,http://dx.doi.org/10.1145/2702123.2702427,http://dl.acm.org/citation.cfm?id=2702427,HEzZLJPyzGE,www.youtube.com/watch?v=HEzZLJPyzGE,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/HEzZLJPyzGE' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Exploring Time-Dependent Concerns about Pregnancy and Childbirth from Search Logs,"Adam Fourney, Ryen W White, Eric Horvitz","We study time-dependent patterns of information seeking about pregnancy, birth, and the first several weeks of caring for newborns via analyses of queries drawn from anonymized search engine logs. We show how we can detect and align web search behavior for a population of searchers with the natural clock of gestational physiology via proxies for ground truth based on searchers’ self-report queries (e.g., [I am 30 weeks pregnant and my baby is moving a lot]). Then, we present a methodology for performing additional alignments, that are valuable for learning about the concerns, curiosities, and needs that arise over time with pregnancy and early parenting. Our findings have implications for learning about the temporal dynamics of pregnancy-related interests and concerns, and also for the design of systems that tailor their responses to point estimates of each searcher’s current stage in pregnancy.",TRUE
pn1596,2702428,http://dx.doi.org/10.1145/2702123.2702428,http://dl.acm.org/citation.cfm?id=2702428,G_t9yMaElxw,www.youtube.com/watch?v=G_t9yMaElxw,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/G_t9yMaElxw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Survival Analysis: Objective assessment of Wait Time in HCI,"Siddhartha Asthana, Pushpendra Singh, Parul Gupta","Waiting for the completion of a system process is an everyday experience. While waiting, system provides feedback to  the user about ongoing process through temporal metaphors (Progress bar, Busy icons, etc.). One of the key performance requirement for temporal metaphors is to retain the user till the process completes. Researchers have evaluated these metaphors through subjective means, and objective assessment has not been well explored. In this paper, we present survival analysis as objective assessment method to evaluate temporal metaphors. Through a field experiment, we demonstrate the application of survival analysis and empirically establish that auditory progress bar (temporal metaphor for audio interfaces) works for callers of a distress helpline. To the best of our knowledge, it is the first study on distress callers. The paper further discusses the applicability of survival analysis for evaluating temporal metaphors and wait time experiments for other applications, tasks, and settings.",TRUE
pn1599,2702429,http://dx.doi.org/10.1145/2702123.2702429,http://dl.acm.org/citation.cfm?id=2702429,WPN0g7M8E9c,www.youtube.com/watch?v=WPN0g7M8E9c,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/WPN0g7M8E9c' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Masters of Control: Behavioral Patterns of Simultaneous Unit Group Manipulation in StarCraft 2,"Eddie Q Yan, Jeff Huang, Gifford K Cheung","Most user interfaces require the user to focus on one element at a time, but  StarCraft 2 is a game where players often control more than a hundred units simultaneously. The game interface provides an optional mechanism called ""control groups"" that allows players to select multiple units and assign them to a group in order to quickly recall previous selections of units. From an analysis of over 3,000 replays, we show that the usage of control groups is a key differentiator of individual players as well as players of different skill levels---novice users rarely use control groups while experts nearly always do. But players also behave differently in how they use their control groups, especially in time-pressured situations. While certain control group behaviors are common across all skill levels, expert players appear to be better at remaining composed and sustaining control group use in battle. We also qualitatively analyze discussions on web forums from players about how they use control groups to provide context about how such a simple interface mechanic has produced numerous ways of optimizing unit control.",TRUE
pn1606,2702431,http://dx.doi.org/10.1145/2702123.2702431,http://dl.acm.org/citation.cfm?id=2702431,ddEB5Ck_16A,www.youtube.com/watch?v=ddEB5Ck_16A,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/ddEB5Ck_16A' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Understanding Data Videos: Looking at Narrative Visualization through the Cinematography Lens,"Fereshteh Amini, Nathalie Henry Riche, Bongshin Lee, Christophe Hurter, Pourang Irani","Data videos, motion graphics that incorporate visualizations about facts, are increasingly gaining popularity as a means of telling stories with data. However, very little is systematically recorded about (a) what elements are featured in data videos and (b) the processes used to create them. In this article, we provide initial insights to build this knowledge. We first report on a qualitative analysis of 50 professionally designed data videos, extracting and exposing their most salient constituents. Second, we report on a series of workshops with experienced storytellers from cinematography, graphics design and screenplay writing. We provided them with a set of data facts and visualizations and observed them create storyboards for data videos. From these exploratory studies, we derive broader implications for the design of an authoring tool to enable a wide audience to create data videos. Our findings highlight the importance of providing a flexible tool supporting a non-linear creation process and allowing users to iteratively go back to different phases of the process.",TRUE
pn1618,2702433,http://dx.doi.org/10.1145/2702123.2702433,http://dl.acm.org/citation.cfm?id=2702433,VXlMYyL3g20,www.youtube.com/watch?v=VXlMYyL3g20,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/VXlMYyL3g20' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Helping Users Bootstrap Ontologies: An Empirical Investigation,"Yuhao Zhang, Tania Tudorache, Matthew Horridge, Mark A. Musen","An ontology is a machine processable artifact that captures knowledge about some domain of interest. Ontologies are used in various domains including healthcare, science, and commerce. In this paper we examine the ontology bootstrapping problem. Specifically, we look at an approach that uses both competency questions and knowledge source reuse via recommendations to address the ""cold start problem"" - that is, the task of creating an ontology from scratch. We describe this approach, an implementation of it, and we present an evaluation in the form of a controlled user study. We find that the approach leads users into creating significantly more detailed initial ontologies that have a greater domain coverage than ontologies produced without this support. Furthermore, in spite of a more involved workflow, the usability and user satisfaction of the bootstrapping approach is as good as a state-of-the-art ontology editor with no additional support.",TRUE
pn1620,2702434,http://dx.doi.org/10.1145/2702123.2702434,http://dl.acm.org/citation.cfm?id=2702434,VoDn8mqukdE,www.youtube.com/watch?v=VoDn8mqukdE,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/VoDn8mqukdE' width='640' height='360' frameborder='0' allowfullscreen='true'/>,WonderLens: Optical Lenses and Mirrors for Tangible Interactions on Printed Paper,"Rong-Hao Liang, Chao Shen, Yu-Chien Chan, Guan-Ting Chou, Liwei Chan, De-Nian Yang, Mike Y. Chen, Bing-Yu Chen","This work presents WonderLens, a system of optical lenses and mirrors for enabling tangible interactions on printed paper. When users perform spatial operations on the optical components, they deform the visual content that is printed on paper, and thereby provide dynamic visual feedback on user interactions without any display devices. The magnetic unit that is embedded in each lens and mirror allows the unit to be identified and tracked using an analog Hall-sensor grid that is placed behind the paper, so the system provides additional auditory and visual feedback through different levels of embodiment, further enhancing the interactivity with the printed content on the physical paper. \ ",TRUE
pn1626,2702436,http://dx.doi.org/10.1145/2702123.2702436,http://dl.acm.org/citation.cfm?id=2702436,38sxgD1PK60,www.youtube.com/watch?v=38sxgD1PK60,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/38sxgD1PK60' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Societal Controversies in Wikipedia Articles,"Erik Borra, Esther Weltevrede, Paolo Ciuccarelli, Andreas Kaltenbrunner, David Laniado, Giovanni Magni, Michele Mauri, Richard Rogers, Tommaso Venturini","Collaborative content creation inevitably reaches situations where different points of view lead to conflict. We focus on Wikipedia, the free encyclopedia anyone may edit, where disputes about content in controversial articles often reflect larger societal debates. While Wikipedia has a public edit history and discussion section for every article, the substance of these sections is difficult to phantom for Wikipedia users interested in the development of an article and in locating which topics were most controversial. In this paper we present Contropedia, a tool that augments Wikipedia articles and gives insight into the development of controversial topics. Contropedia uses an efficient language agnostic measure based on the edit history that focuses on wiki links to easily identify which topics within a Wikipedia article have been most controversial and when.",TRUE
pn1647,2702440,http://dx.doi.org/10.1145/2702123.2702440,http://dl.acm.org/citation.cfm?id=2702440,_nB2AdnlAoc,www.youtube.com/watch?v=_nB2AdnlAoc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/_nB2AdnlAoc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,ScanShot: Detecting Document Capture Moments and Correcting Device Orientation,"Jeungmin Oh, Woohyeok Choi, Joohyun Kim, Uichin Lee","Document capturing with smartphone cameras is performed increasingly often in our daily lives. However, our user study results (n=10) showed that more than 80% of landscape tasks had incorrect orientations. To solve this problem, we systematically analyzed user behavior of document capturing and proposed a novel solution called ScanShot that detects document capturing moments to help users correct the orientation errors. ScanShot tracks the gravity direction to capture document capturing moments, analyzes logged gyroscope data to automatically update orientation changes, and provides visual feedback of the inferred orientation for manual correction. Our user study results (n=20) confirmed that capturing moments can be recognized with accuracy of 97.5%, our update mechanism can reduce the orientation errors by 59 percentage points.",TRUE
pn1682,2702445,http://dx.doi.org/10.1145/2702123.2702445,http://dl.acm.org/citation.cfm?id=2702445,zxr5_-sgFYc,www.youtube.com/watch?v=zxr5_-sgFYc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/zxr5_-sgFYc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Inferring Employee Engagement from Social Media,"N. Sadat Shami, Michael Muller, Aditya Pal, Mikhil Masli, Werner Geyer","Employees increasingly are expressing ideas and feelings through enterprise social media. Recent work in CHI and CSCW has applied linguistic analysis towards understanding employee experiences. In this paper, we apply dictionary based linguistic analysis to measure ‘Employee Engagement’. Employee engagement is a measure of employee willingness to apply discretionary effort towards organizational goals, and plays an important role in organizational outcomes such as financial or operational results. Organizations typically use surveys to measure engagement. This paper describes an approach to model employee engagement based on word choice in social media. This method can potentially complement surveys, thus providing more real-time insights into engagement and allowing organizations to address engagement issues faster. Our results predicting engagement scores on a survey by combining demographics with social media text demonstrate that social media text has significant predictive power compared to demographic data alone. We also find that engagement may be a state than a stable trait since social media posts closer to the administration of the survey had the most predictive power. We further identify the minimum number of social media posts required per employee for the best prediction. ",TRUE
pn1684,2702446,http://dx.doi.org/10.1145/2702123.2702446,http://dl.acm.org/citation.cfm?id=2702446,4NrNckjFsr8,www.youtube.com/watch?v=4NrNckjFsr8,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/4NrNckjFsr8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,g-Miner: Interactive Visual Group Mining on Multivariate Graphs,"Nan Cao, Yu-Ru Lin, Liangyue Li, Hanghang Tong","With the rapid growth of rich network data available through various  sources  such  as  social  media  and  digital  archives,there is a growing interest in more powerful network visual analysis tools and methods.  The rich information about the network nodes and links can be represented as multivariate graphs, in which the nodes are accompanied with attributes to represent the properties of individual nodes. An important task often encountered in multivariate network analysis is to uncover link structure with groups, e.g., to understand why a person fits a specific job or certain role in a social group well.The task usually involves complex considerations including specific requirement of node attributes and link structure, and hence a fully automatic solution is typically not satisfactory.In  this  work,  we  identify  the  design  challenges  for  min-ing groups with complex criteria and present an interactive system, “g-Miner,” that enables visual mining of groups on multivariate  graph  data.   We  demonstrate  the  effectiveness of our system through case study and in-depth expert inter-views.   This  work  contributes  to  understanding  the  design of  systems  for  leveraging  users’  knowledge  progressively with algorithmic capacity for tackling massive heterogeneous information.",TRUE
pn1688,2702448,http://dx.doi.org/10.1145/2702123.2702448,http://dl.acm.org/citation.cfm?id=2702448,EcFFP2bQSW0,www.youtube.com/watch?v=EcFFP2bQSW0,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/EcFFP2bQSW0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Accuracy of Deictic Gestures to Support Telepresence on Wall-sized Displays,"Ignacio Avellino, Cédric Fleury, Michel Beaudouin-Lafon","This paper presents a controlled experiment assessing the accuracy when interpreting remote users showing a shared object on a large wall-sized display, either by looking at it or by looking and pointing at it. We analyze both distance and angle errors and how they are sensitive to the relative position be- tween the remote viewer and the video feed. We show that the remote user can accurately determine the target, that eye gaze alone is more accurate than combined with the hand, and that the relative position between the viewer and the video feed has little effect on accuracy. These findings can inform the design of future telepresence systems for wall-sized displays.",TRUE
pn1689,2702449,http://dx.doi.org/10.1145/2702123.2702449,http://dl.acm.org/citation.cfm?id=2702449,j1LFJeMkM0I,www.youtube.com/watch?v=j1LFJeMkM0I,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/j1LFJeMkM0I' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Practice-based Design of a Neighborhood Portal: Focusing on Elderly Tenants in a City Quarter Living Lab,"Claudia Müller, Dominik Hornung, Theodor Hamm, Volker Wulf","This paper contributes to the current discourse on practice-based research in HCI paying particular attention to the overall temporal and situational conditions which frame an R&D project. We present a Living Lab study situated in an arbitrary neighborhood of a German city which develops ICT support to foster informal help and social interaction with a special, but not exclusive, focus on elderly tenants. We demonstrate that practice-based, long-term research in a city quarter goes beyond those challenges already described in the current Living Lab and PD literature. The long-term study’s positioning in a real-world context is contoured not only by a high diversity of stakeholders and their individual interests and motivation for participation but also by their individual skill sets and learning needs. These distinct and often contradictive perspectives have to be permanently counterbalanced. Thus attention has to be focused on how related strategies and decisions impact on the design of the project as well as on the final ICT product. To enable all tenants, irrespective of age and technical skill, to participate in a long-term ICT-based community development project, we applied the format of ‘experience-based PD workshops’ to foster confidence in ICT usage and encourage the competency of the elderly and non-tech-savvy tenants.   ",TRUE
pn1709,2702450,http://dx.doi.org/10.1145/2702123.2702450,http://dl.acm.org/citation.cfm?id=2702450,y8Ub3u2IhsA,www.youtube.com/watch?v=y8Ub3u2IhsA,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/y8Ub3u2IhsA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Belt: An Unobtrusive Touch Input Device for Head-worn Displays,"David Dobbelstein, Philipp Hock, Enrico Rukzio","Belt is a novel unobtrusive input device for wearable displays that incorporates a touch surface encircling the user's hip. The wide input space is leveraged for a horizontal spatial mapping of quickly accessible information and applications. We discuss social implications and interaction capabilities for unobtrusive touch input and present our hardware implementation and a set of applications that benefit from the quick access time. In a qualitative user study with 14 participants we found out that for short interactions (2-4 seconds), most of the surface area is considered as appropriate input space, while for longer interactions (up to 10 seconds), the front areas above the trouser pockets are preferred.",TRUE
pn1715,2702451,http://dx.doi.org/10.1145/2702123.2702451,http://dl.acm.org/citation.cfm?id=2702451,xGqn1FQRQPQ,www.youtube.com/watch?v=xGqn1FQRQPQ,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/xGqn1FQRQPQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Weave: Scripting Cross-Device Wearable Interaction,"Pei-Yu Chi, Yang Li","We present Weave, a framework for developers to create cross-device wearable interaction by scripting. Weave provides a set of high-level APIs, based on JavaScript, for developers to easily distribute UI output and combine sensing events and user input across mobile and wearable devices. Weave allows developers to focus on their target interaction behaviors and manipulate devices regarding their capabilities and affordances, rather than low-level specifications. Weave also contributes an integrated authoring environment for developers to program and test cross-device behaviors, and when ready, deploy these behaviors to its runtime environment on users’ ad-hoc network of devices. An evaluation of Weave with 12 participants on a range of tasks revealed that Weave significantly reduced the effort of developers for creating and iterating on cross-device interaction. ",TRUE
pn1717,2702452,http://dx.doi.org/10.1145/2702123.2702452,http://dl.acm.org/citation.cfm?id=2702452,zDJwOdR8d3Q,www.youtube.com/watch?v=zDJwOdR8d3Q,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/zDJwOdR8d3Q' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Storytelling in Information Visualizations: Does it Engage Users to Explore Data?,"Jeremy Boy, Jean-Daniel Fekete, Francoise Detienne","We present the results of three web-based field experiments, in which we evaluate the impact of using initial narrative visualization techniques and storytelling on user-engagement with exploratory information visualizations. We conducted these experiments on a popular news and opinion outlet, and on a popular visualization gallery website. While data-journalism exposes visualizations to a large public, we do not know how effectively this public makes sense of interactive graphics, and in particular if people explore them to gain additional insight to that provided by the journalists. In contrast to our hypotheses, our results indicate that augmenting exploratory visualizations with introductory `stories' does not seem to increase user-engagement in exploration.",TRUE
pn1722,2702453,http://dx.doi.org/10.1145/2702123.2702453,http://dl.acm.org/citation.cfm?id=2702453,cMu_Yg1H2gY,www.youtube.com/watch?v=cMu_Yg1H2gY,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/cMu_Yg1H2gY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Concealing or Revealing Mobile Medical Devices? Designing for Onstage and Offstage Presentation,"Aisling Ann O'Kane, Yvonne Rogers, Ann E Blandford","Adults with Type 1 Diabetes have choices regarding the technology they use to self-manage their chronic condition. They can use glucose meters, insulin pumps, smartphone apps, and other technologies to support their everyday care. However, little is known about how their social lives might influence what they adopt or how they use technologies. A multi-method study was conducted to examine contextual factors that influence their technology use. While individual differences play a large role in everyday use, social factors were also found to influence use. For example, people can hide their devices in uncertain social situations or show them off to achieve a purpose. We frame these social behaviours using Goffman’s theatre metaphor of onstage and offstage behaviour, and discuss how this kind of analysis can inform the design of future mobile medical devices for self-management of chronic conditions.",TRUE
pn1727,2702455,http://dx.doi.org/10.1145/2702123.2702455,http://dl.acm.org/citation.cfm?id=2702455,3evfboFgZ5M,www.youtube.com/watch?v=3evfboFgZ5M,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/3evfboFgZ5M' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Provenance for the People: An HCI Perspective on the W3C PROV Standard through an Online Game,"Khaled Bachour, Richard Wetzel, Martin Flintham, Trung Dong Huynh, Tom Rodden, Luc Moreau","In the information age, tools for examining the validity of data are invaluable. Provenance is one such tool, and the PROV model proposed by the World Wide Web Consortium in 2013 offers a means of expressing provenance in a machine readable format. In this paper, we examine from a user’s standpoint notions of provenance, the accessibility of the PROV model, and the general attitudes towards history and the verifiability of information in modern data society. We do this through the medium of an online-game designed to explore these issues and present the findings of the study along with a discussion of some of its implications.",TRUE
pn1742,2702456,http://dx.doi.org/10.1145/2702123.2702456,http://dl.acm.org/citation.cfm?id=2702456,1PVtHuDUXXY,www.youtube.com/watch?v=1PVtHuDUXXY,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/1PVtHuDUXXY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Regulating Access to Adult Content (with Privacy Preservation),"Karen Renaud, Joseph Maguire","In the physical world we have well-established mechanisms \ for keeping children out of adult-only areas. In the virtual \ world this is generally replaced by self declaration. Some \ service providers resort to using heavy-weight identification \ mechanisms, judging adulthood as a side effect thereof. Collection of identification data arguably constitutes an unwarranted privacy invasion in this context, if carried out merely to perform adulthood estimation. This paper presents a mechanism that exploits the adult's more extensive exposure to public media, relying on the likelihood that they will \ be able to recall details if cued by a carefully chosen picture. \  \ We conducted an online study to gauge the viability of this \ scheme. With our prototype we were able to predict that \ the user was a child 99% of the time. Unfortunately the \ scheme also misclassified too many adults. We discuss our \ results and suggest directions for future research.",TRUE
pn1743,2702457,http://dx.doi.org/10.1145/2702123.2702457,http://dl.acm.org/citation.cfm?id=2702457,hssYkAKIZpE,www.youtube.com/watch?v=hssYkAKIZpE,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/hssYkAKIZpE' width='640' height='360' frameborder='0' allowfullscreen='true'/>,ActivPass: Your Daily Activity is Your Password,"Sourav Kumar Dandapat, Swadhin Pradhan, Bivas Mitra, Romit Roy Choudhury, Niloy Ganguly","This paper explores the feasibility of automatically extracting passwords from a user's daily activity logs, such as her Facebook activity, phone activity etc. As an example, a smartphone might ask the user: ""Today morning from whom did you receive an SMS ?"" In this paper, we observe that infrequent activities (i.e., outliers) can be memorable and unpredictable. Building on this observation, we have developed an end to end system ActivPass and experimented with 70 users. With activity logs from Facebook, browsing history, call logs, and SMSs, the system achieves 95% success (authenticates legitimate users) and is compromised in 5.5% cases (authenticates impostors). While this level of security is obviously inadequate for serious authentication systems, certain practices such as password sharing can immediately be thwarted from the dynamic nature of passwords. With security improvements in the future, activity-based authentication could fill in for the inadequacies in today's password-based systems.",TRUE
pn1763,2702459,http://dx.doi.org/10.1145/2702123.2702459,http://dl.acm.org/citation.cfm?id=2702459,H-megrNfqDo,www.youtube.com/watch?v=H-megrNfqDo,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/H-megrNfqDo' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Skin Drag Displays: Dragging a Physical Tactor across the User’s Skin Produces a Stronger Tactile Stimulus than Vibrotactile,"Alexandra Ion, Edward Jay Wang, Patrick Baudisch","We propose a new type of tactile displays that drag a physical tactor across the skin in 2D. We call this skin drag. We demonstrate how this allows us to communicate geometric shapes or characters to users. The main benefit of our approach is that it simultaneously produces two types of stimuli, i.e., (1) it moves a tactile stimulus across skin locations and (2) it stretches the user’s skin. Skin drag thereby combines the essential stimuli produced by vibrotactile and skin stretch. In our study, skin drag allowed participants to recognize tactile shapes significantly better than a vibrotactile array of comparable size. We present two arm-worn prototype devices that implement our concept.",TRUE
pn1764,2702460,http://dx.doi.org/10.1145/2702123.2702460,http://dl.acm.org/citation.cfm?id=2702460,KRZnPcyg-oE,www.youtube.com/watch?v=KRZnPcyg-oE,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/KRZnPcyg-oE' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Things That Make Us Reminisce: Everyday Memory Cues as Opportunities for Interaction Design,"Doménique van Gennip, Elise van den Hoven, Panos Markopoulos","Interactive devices can support personal remembering to benefit well-being. These designs require insight into what brings the past to mind, and how people relate to such cues. Prior work focused on mementos in the home; instead, this paper presents a diary and interview study of involuntary memory cueing in everyday life. Data was collected from fifteen adult individuals, using sentence completion diaries, combined with debriefing interviews. Qualitative analysis of the data showed that these participants were relying on everyday physical objects like food items for cueing memories during everyday life, locations and (repeated) activities, while digital items and photos were shown to be less frequent stimulants. Meaningful relations to memory cues can be partially explained from a memory cueing perspective. We discuss how design for remembering can benefit from our insights, through careful trade-offs in timing, exposure to cues, and supporting a process of personal attachment with items invoking memories.",TRUE
pn1766,2702461,http://dx.doi.org/10.1145/2702123.2702461,http://dl.acm.org/citation.cfm?id=2702461,BUemx3lXJjU,www.youtube.com/watch?v=BUemx3lXJjU,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/BUemx3lXJjU' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Proprioceptive Interaction,"Pedro Lopes, Alexandra Ion, Willi Mueller, Daniel Hoffmann, Patrik Jonell, Patrick Baudisch","We propose a new way of eyes-free interaction for wearables. It is based on the user’s proprioceptive sense, i.e., rather than seeing, hearing, or feeling an outside stimulus, users feel the pose of their own body. \ We have implemented a wearable device called Pose-IO that offers input and output based on proprioception. Users communicate with Pose-IO through the pose of their wrists. Users enter information by performing an input gesture by flexing their wrist, which the device senses using a 3-axis accelerometer. Users receive output from Pose-IO by find-ing their wrist posed in an output gesture, which Pose-IO actuates using electrical muscle stimulation. This mechanism allows users to interact with Pose-IO without visual or auditory senses, but through the proprioceptive sense alone. \ We developed three simple applications that demonstrate symmetric proprioceptive interaction, where input and output occur through the same limb, as well as asymmetric interaction, where input and output occur through different limbs. In a first user study, participants using a symmetric proprioceptive interface re-entered poses received from Pose-IO with an average accuracy of 5.8° despite the minimal bandwidth offered by the device. In a second, exploratory study, we investigated participants’ emotional response to asymmetric proprioceptive interaction and the concept of the user’s body serving as interface. Participants reported to enjoy the experience (4.6 out of 5). \ ",TRUE
pn1809,2702464,http://dx.doi.org/10.1145/2702123.2702464,http://dl.acm.org/citation.cfm?id=2702464,_aefLE7K0qY,www.youtube.com/watch?v=_aefLE7K0qY,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/_aefLE7K0qY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Cyclops: Wearable and Single-Piece Full-Body Gesture Input Devices,"Liwei Chan, Chi-Hao Hsieh, Yi-Ling Chen, Shuo Yang, Da-Yuan Huang, Rong-Hao Liang, Bing-Yu Chen","This paper presents Cyclops, a single-piece wearable device that sees its user's whole body postures through an ego-centric view of the user that is obtained through a fisheye lens at the center of the user's body, allowing it to see only the user’s limbs and interpret body postures effectively. Unlike currently available body gesture input systems that depend on external cameras or distributed motion sensors across the user's body, Cyclops is a single-piece wearable device that is worn as a pendant or a badge. The main idea proposed in this paper is the observation of limbs from a central location of the body. Owing to the ego-centric view, Cyclops turns posture recognition into a highly controllable computer vision problem. This paper demonstrates a proof-of-concept device, and an algorithm for recognizing static and moving bodily gestures based on motion history images (MHI) and a random decision forest (RDF). Four example applications of interactive bodily workout, a mobile racing game that involves hands and feet, a full-body virtual reality system, and interaction with a tangible toy are presented. The experiment on the bodily workout demonstrates that, from a database of 20 body workout gestures that were collected from 20 participants, Cyclops achieved a recognition rate of 79% using MHI and simple template matching, which increased to 92% with the more advanced machine learning approach of RDF. \ ",TRUE
pn1828,2702465,http://dx.doi.org/10.1145/2702123.2702465,http://dl.acm.org/citation.cfm?id=2702465,yjddOjLrZ5s,www.youtube.com/watch?v=yjddOjLrZ5s,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/yjddOjLrZ5s' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Using an Interactive Avatar's Facial Expressiveness to Increase Persuasiveness and Socialness,"Jennifer Hyde, Elizabeth J Carter, Sara Kiesler, Jessica K Hodgins","Research indicates that the facial expressions of animated characters and agents can influence people's perceptions and interactions with these entities.   We designed an experiment to examine how an interactive animated avatar's facial expressiveness influences dyadic conversations between adults and the avatar.  We animated the avatar in realtime using the tracked facial motion of a confederate. To adjust facial expressiveness, we damped and exaggerated the avatar's facial motion. We found that ratings of the avatar's extroversion were positively related to its expressiveness.  However, impressions of the avatar's realism and naturalness worsened with increased expressiveness. We also found that the confederate was more influential when she appeared as the damped or exaggerated avatar. Adjusting the expressiveness of interactive animated avatars may be a simple way to influence people's social judgments and willingness to collaborate with animated avatars. These results have implications for using avatar facial expressiveness to improve the effectiveness of avatars in various contexts. Adjusting the expressiveness of interactive animated avatars may be a simple way to influence people's social judgments and willingness to collaborate with animated avatars.",TRUE
pn1834,2702467,http://dx.doi.org/10.1145/2702123.2702467,http://dl.acm.org/citation.cfm?id=2702467,xO1m5p3auCI,www.youtube.com/watch?v=xO1m5p3auCI,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/xO1m5p3auCI' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Walking by Drawing,"Daniela K Rosner, Allison Chambliss, Jeremy Friedland, Hidekazu Saegusa","This paper describes a study of algorithmic living with Trace, a mobile mapping application that generates walking routes based on digital sketches people create and annotate without a map. In addition to creating walking paths, Trace enables people to send the paths to others. We designed Trace to explore the possibility of emphasizing guided wandering over precise, destination-oriented navigation. Studies of sixteen people’s use of Trace over roughly one week reveal how walkers find Trace both delightful and disorienting, highlighting moments of surprise, frustration, and identification with GIS routing algorithms. We conclude by discussing how design interventions offers possibilities for understanding the work of mapping and how it might be done differently in HCI. ",TRUE
pn1840,2702470,http://dx.doi.org/10.1145/2702123.2702470,http://dl.acm.org/citation.cfm?id=2702470,8PIfMwpx2Qc,www.youtube.com/watch?v=8PIfMwpx2Qc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/8PIfMwpx2Qc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Crowdsourced Feedback With Imagery Rather Than Text: Would Designers Use It?,"David A. Robb, Stefano Padilla, Britta Kalkreuter, Mike J. Chantler","Cognitive styles theories suggest that we divide into visual and verbal thinkers. In this paper we describe a method designed to encourage visual communication between designers and their audiences. This new visual feedback method is based on enabling fast intuitive selections by the crowd from image banks when responding to an idea. Visual summarization reduces the massed image choices to a small number of representative images. These summaries are then consumed at a glance by designers receiving the feedback leading to thoughtful reflection on their designs. We report an evaluation using two types of imagery for feedback. Twelve designers took part, receiving visual feedback in response to their designs. In semi-structured interviews they described their interpretation of the feedback, how it inspired them to change their designs and contrasted it with text feedback. Eleven of the twelve designers revealed that they would be enthusiastic users of a service providing this new mode of feedback. ",TRUE
pn1856,2702472,http://dx.doi.org/10.1145/2702123.2702472,http://dl.acm.org/citation.cfm?id=2702472,u6HVwOCq3as,www.youtube.com/watch?v=u6HVwOCq3as,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/u6HVwOCq3as' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Jogging with a Quadcopter,"Florian Mueller, Matthew Muirhead","Jogging is a popular exertion activity. The abundance of jogging apps suggests to us that joggers can appreciate the opportunity for technology to support the jogging experience. We want to take this investigation a step further by exploring if, and how, robotic systems can support the jogging experience. We designed and built a flying robotic system, a quadcopter, as a jogging companion and studied its use with 13 individual joggers. By analyzing their experiences, we derived three design dimensions that describe a design space for flying robotic jogging companions: Perceived Control, Focus and Bodily Interaction. Additionally, we articulate a series of design tactics, described by these dimensions, to guide the design of future systems. With this work we hope to inspire and guide designers interested in creating robotic systems to support exertion experiences.",TRUE
pn1886,2702476,http://dx.doi.org/10.1145/2702123.2702476,http://dl.acm.org/citation.cfm?id=2702476,cd7FN8ZuTbY,www.youtube.com/watch?v=cd7FN8ZuTbY,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/cd7FN8ZuTbY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Trajectory Bundling for Animated Transitions,"Fan Du, Nan Cao, Jian Zhao, Yu-Ru Lin","Animated transition has been a popular design choice for smoothly switching between different visualization views or layouts, in which movement trajectories are created as cues for tracking objects during location shifting. Tracking moving objects, however, becomes difficult when their movement paths overlap or the number of tracking targets increases. We propose a novel design to facilitate tracking moving objects in animated transitions. Instead of simply animating an object along a straight line, we create ""bundled"" movement trajectories for a group of objects that have spatial proximity and share similar moving directions. To study the effect of bundled trajectories, we untangle variations due to different aspects of tracking complexity in a comprehensive controlled user study. The results indicate that using bundled trajectories is particularly effective when tracking more targets (six vs. three targets) or when the object movement involves a high degree of occlusion or deformation. Based on the study, we discuss the advantages and limitations of the new technique, as well as provide design implications.",TRUE
pn1892,2702480,http://dx.doi.org/10.1145/2702123.2702480,http://dl.acm.org/citation.cfm?id=2702480,iKrPvpeWi_Y,www.youtube.com/watch?v=iKrPvpeWi_Y,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/iKrPvpeWi_Y' width='640' height='360' frameborder='0' allowfullscreen='true'/>,TerraGuide: Design and Evaluation of a Multi-Surface Environment for Terrain Visibility Analysis,"Matthew Oskamp, Christophe Bortolaso, Robin Harrap, T.C. Nicholas Graham","Terrain visibility analysis is a challenging task that is currently supported by complex digital tools with cumbersome interfaces. In this paper, we present TerraGuide, a novel multi-surface environment for exploratory terrain analysis. TerraGuide provides three tightly coupled displays including a real-time viewshed, a 3D panoramic view, and a helicopter view controlled by an optically tracked tablet. A user study compared these techniques and identified users’ strategies in solving a complex terrain analysis problem. Users overwhelmingly adopted a bi-manual use of the tabletop viewshed and tablet-based helicopter techniques. This paper gives insight into how multi-surface environments can be designed to allow complementary use of and fluid switching between techniques.",TRUE
pn1911,2702487,http://dx.doi.org/10.1145/2702123.2702487,http://dl.acm.org/citation.cfm?id=2702487,sTuc4joTDPI,www.youtube.com/watch?v=sTuc4joTDPI,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/sTuc4joTDPI' width='640' height='360' frameborder='0' allowfullscreen='true'/>,PaperPulse: An Integrated Approach for Embedding Electronics in Paper Designs,"Raf Ramakers, Kashyap Todi, Kris Luyten","We present PaperPulse, a design and fabrication approach that enables designers without a technical background to produce standalone interactive paper artifacts by augmenting them with electronics. With PaperPulse, designers overlay pre-designed visual elements with widgets available in our design tool. PaperPulse provides designers with three families of widgets designed for smooth integration with paper, for an overall of 20 different interactive components. We also contribute a logic demonstration and recording approach, Pulsation, that allows for specifying functional relationships between widgets. Using the final design and the recorded Pulsation logic, PaperPulse generates layered electronic circuit designs, and code that can be deployed on a microcontroller. By following automatically generated assembly instructions, designers can seamlessly integrate the microcontroller and widgets in the final paper artifact.",TRUE
pn1927,2702489,http://dx.doi.org/10.1145/2702123.2702489,http://dl.acm.org/citation.cfm?id=2702489,zRJEhb0y050,www.youtube.com/watch?v=zRJEhb0y050,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/zRJEhb0y050' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Designing for Exploratory Search on Touch Devices,"Khalil Klouche, Tuukka Ruotsalo, Diogo Cabral, Salvatore Andolina, Andrea Bellucci, Giulio Jacucci","Exploratory search confront users with challenges in expressing search intents as the current search interfaces require investigating result listings to identify search directions, iterative typing, and reformulating queries. We present the design of Exploration Wall, a touch-based search user interface that allows incremental exploration and sense-making of large information spaces by combining entity search, flexible use of result entities as query parameters, and spatial configuration of search streams that are visualized for interaction. Entities can be flexibly reused to modify and create new search streams, and manipulated to inspect their relationships with other entities. Data comprising of task-based experiments comparing Exploration Wall with conventional search user interface indicate that Exploration Wall achieves significantly improved recall for exploratory search tasks while preserving precision. Subjective feedback supports our design choices and indicates improved user satisfaction and engagement. Our findings can help to design user interfaces that can effectively support exploratory search on touch devices.",TRUE
pn1936,2702490,http://dx.doi.org/10.1145/2702123.2702490,http://dl.acm.org/citation.cfm?id=2702490,UnMbK-gY_kM,www.youtube.com/watch?v=UnMbK-gY_kM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/UnMbK-gY_kM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Retargeting Technical Documentation to Augmented Reality,"Peter Mohr, Bernhard Kerbl, Michael Donoser, Dieter Schmalstieg, Denis Kalkofen","We present a system which automatically transfers printed technical documentation, such as handbooks, to three-dimensional Augmented Reality. Our system identifies the most frequent forms of instructions found in printed documentation, such as image sequences, explosion diagrams, textual annotations and arrows indicating motion. The analysis of the printed documentation works automatically, with minimal user input. The system only requires the documentation itself and a CAD model or 3D scan of the object described in the documentation. \  \ The output is a fully interactive Augmented Reality application, presenting the information from the printed documentation in 3D, registered to the real object.",TRUE
pn1942,2702492,http://dx.doi.org/10.1145/2702123.2702492,http://dl.acm.org/citation.cfm?id=2702492,ZCLNu9IKpZw,www.youtube.com/watch?v=ZCLNu9IKpZw,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/ZCLNu9IKpZw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Deformable Interfaces for Performing Music,"Giovanni Maria Troiano, Esben W. Pedersen, Kasper Hornbæk","Deformable interfaces offer new possibilities for gestures, some of which have been shown effective in controlled laboratory studies. Little work, however, has attempted to match deformable interfaces to a demanding domain and evaluate them out of the lab. We investigate how musicians use deformable interfaces to perform electronic music. We invited musicians to three workshops, where they explored 10 deformable objects and generated ideas on how to use these objects to perform music. Based on the results from the workshops, we implemented sensors in the five preferred objects and programmed them for controlling sounds. Next, we ran a performance study where six musicians performed music with these objects at their studios. Our results show that (1) musicians systematically map deformations to certain musical parameters, (2) musicians use deformable interfaces especially to filter and modulate sounds, and (3) musicians think that deformable interfaces embody the parameters that they control. We discuss what these results mean to research in deformable interfaces.",TRUE
pn1958,2702496,http://dx.doi.org/10.1145/2702123.2702496,http://dl.acm.org/citation.cfm?id=2702496,Fr-o3a3XgRs,www.youtube.com/watch?v=Fr-o3a3XgRs,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/Fr-o3a3XgRs' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Blended Recommending: Integrating Interactive Information Filtering and Algorithmic Recommender Techniques,"Benedikt Loepp, Katja Herrmanny, Juergen Ziegler","We present a novel approach that integrates algorithmic recommender techniques with interactive faceted filtering methods. We refer to this approach as blended recommending. It allows users to interact with a set of filter facets representing criteria that can serve as input for different recommendation methods including both collaborative and content-based filtering. Users can select filter criteria from these facets and weight them to express their preferences and to exert control over the hybrid recommendation process. In contrast to hard Boolean filtering, the method aggregates the weighted criteria and calculates a ranked list of recommendations that is visualized and immediately updated when users change the filter settings. Based on this approach, we implemented an interactive movie recommender, MyMovieMixer. In a user study, we compared the system with a conventional faceted filtering system that served as a baseline to obtain insights into user interaction behavior and to assess recommendation quality for our system. The results indicate, among other findings, a higher level of perceived user control, more detailed preference settings, and better suitability when the search goal is vague.",TRUE
pn1966,2702497,http://dx.doi.org/10.1145/2702123.2702497,http://dl.acm.org/citation.cfm?id=2702497,lfj5ruis5jk,www.youtube.com/watch?v=lfj5ruis5jk,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/lfj5ruis5jk' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Exploring Gesture Sonification to Support Reflective Craft Practice,"Thomas Smith, Simon J Bowen, Bettina Nissen, Jonathan Hook, Arno Verhoeven, John Bowers, Peter Wright, Patrick Olivier","Much of the knowing employed in skilled craft practice is difficult to communicate solely through written or verbal description. Consequently, the reflection and development of a craft practice in this manner may miss important nuances of practitioners’ skills and experiences. We created digital technologies to sonify (using audio to perceptualize data) a group of craft practitioners' gestures to explore how we can aid their reflection in and on their craft, and consequently develop it. Over a number of workshops, the design of these sonifications were iterated based on how the practitioners responded to them. We found that direct sonification of gesture (sounds generated directly from motion sensor data) helped practitioners understand and reflect upon their own and each other’s practice, encouraged discussion and enabled modification of craft technique.",TRUE
pn1979,2702500,http://dx.doi.org/10.1145/2702123.2702500,http://dl.acm.org/citation.cfm?id=2702500,x3RcAKr_z-s,www.youtube.com/watch?v=x3RcAKr_z-s,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/x3RcAKr_z-s' width='640' height='360' frameborder='0' allowfullscreen='true'/>,ExtensionSticker: A Proposal for a Striped Pattern Sticker to Extend Touch Interfaces and its Assessment,"Kunihiro Kato, Homei Miyashita","In this study, we propose a striped pattern sticker called ExtensionSticker that allows a touch input to be transferred from an external source by simply attaching the sticker to a touch panel.  \ This allows the user to input touches or continuous scrolling actions by touching a sticker printed with stripes of conductive ink, without directly touching the touch panel. This method could be applied to the sides or back of a touch panel, or even the surface upon which a device is located as a touch interface, allowing us to freely construct interfaces in shapes matching the demands of the user. This paper also reports the results of evaluation experiments conducted to assess the recognition accuracy of scroll and tap actions using the proposed method.",TRUE
pn1990,2702502,http://dx.doi.org/10.1145/2702123.2702502,http://dl.acm.org/citation.cfm?id=2702502,tK57eMmj_3o,www.youtube.com/watch?v=tK57eMmj_3o,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/tK57eMmj_3o' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Balancing Accuracy and Fun: Designing Camera Based Mobile Games for Implicit Heart Rate Monitoring,"Teng Han, Xiang Xiao, Lanfei Shi, John Canny, Jingtao Wang","Heart rate monitoring is widely used in clinical care, fitness training, and stress management. However, tracking individuals' heart rates faces two major challenges, namely equipment availability and user motivation. In this paper, we present a novel technique, LivePulse Games (LPG), to measure users' heart rates in real time by having them play games on unmodified mobile phones. With LPG, the heart rate is calculated by detecting changes in transparency of users' fingertips via the built-in camera of a mobile device. More importantly, LPG integrate users' camera lens covering actions as an essential control mechanism in game play, and detect heart rates implicitly from intermittent lens covering actions. We explore the design space and trade-offs of LPG through three rounds of iterative design. In a 12-subject user study, we found that LPG are fun to play and can measure heart rates accurately. We also report the insights for balancing measurement speed, accuracy, and entertainment value in LPG. ",TRUE
pn1991,2702503,http://dx.doi.org/10.1145/2702123.2702503,http://dl.acm.org/citation.cfm?id=2702503,ZFQrQo3ejU0,www.youtube.com/watch?v=ZFQrQo3ejU0,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/ZFQrQo3ejU0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Effects of Language Modeling and its Personalization on Touchscreen Typing Performance,"Andrew Fowler, Kurt Partridge, Ciprian Chelba, Xiaojun Bi, Tom Ouyang, Shumin Zhai","Modern smartphones correct typing errors and learn user-specific words (such as proper names). Both techniques are useful, yet little has been published about their technical specifics and concrete benefits. \   \ One reason is that typing accuracy is difficult to measure empirically on a large scale. We describe a closed-loop, smart touch keyboard (STK) evaluation system that we have implemented to solve this problem. It includes a principled typing simulator for generating human-like noisy touch input, a simple-yet-effective decoder for reconstructing typed words from such spatial data, a large web-scale background language model (LM), and a method for incorporating LM personalization. Using the Enron email corpus as a personalization test set, we show for the first time at this scale that a combined spatial/language model reduces word error rate from a pre-model baseline of 38.4% down to 5.7%, and that LM personalization can improve this further to 4.6%.",TRUE
pn2048,2702509,http://dx.doi.org/10.1145/2702123.2702509,http://dl.acm.org/citation.cfm?id=2702509,ZDyErvFmT-Y,www.youtube.com/watch?v=ZDyErvFmT-Y,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/ZDyErvFmT-Y' width='640' height='360' frameborder='0' allowfullscreen='true'/>,ModelTracker: Redesigning Performance Analysis Tools for Machine Learning,"Saleema Amershi, Max Chickering, Steven M. Drucker, Bongshin Lee, Patrice Simard, Jina Suh","Model building in machine learning is an iterative process. The performance analysis and debugging step typically involves a disruptive cognitive switch from model building to error analysis, discouraging an informed approach to model building. We present ModelTracker, an interactive visualization that subsumes information contained in numerous traditional summary statistics and graphs while displaying example-level performance and enabling direct error examination and debugging. Usage analysis from machine learning practitioners building real models with ModelTracker over six months shows ModelTracker is used often and throughout model building. A controlled experiment focusing on ModelTracker’s debugging capabilities shows participants prefer ModelTracker over traditional tools without a loss in model performance.",TRUE
pn2050,2702510,http://dx.doi.org/10.1145/2702123.2702510,http://dl.acm.org/citation.cfm?id=2702510,HgiwXWmU-u8,www.youtube.com/watch?v=HgiwXWmU-u8,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/HgiwXWmU-u8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,EnviroPulse: Providing Feedback about the Expected Affective Valence of the Environment,"Deltcho Valtchanov, Mark Hancock","Interacting with nature is beneficial to a person’s mental-state, but it can sometimes be difficult to find environments that will induce positive affect (e.g., when planning a run). In this paper, we describe EnviroPulse—a system for auto-matically determining and communicating the expected affective valence (EAV) of environments to individuals. We describe a prototype that allows this to be used in real-time on a smartphone, but EnviroPulse could easily be incorporated into GPS systems, mapping services, or image-based systems. Our work differs from existing work in af-fective computing in that, rather than detecting a user’s affect directly, we automatically determine the EAV of the environment through visual analysis. We present results that suggest our system can determine the EAV of envi-ronments. We also introduce real-time affective visual feedback of the calculated EAV of the images, and present results from an informal study suggesting that real-time visual feedback can be used for induction of affect.",TRUE
pn2085,2702512,http://dx.doi.org/10.1145/2702123.2702512,http://dl.acm.org/citation.cfm?id=2702512,pvcbsDp_jms,www.youtube.com/watch?v=pvcbsDp_jms,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/pvcbsDp_jms' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Finding the Adaptive Sweet Spot: Balancing Compliance and Achievement in Automated Stress Reduction,"Artie Konrad, Victoria Bellotti, Nicole Crenshaw, Simon Tucker, Les Nelson, Honglu Du, Peter Pirolli, Steve Whittaker","Automated coaching systems offer a convenient, cost-effective way to reduce stress, which can be a serious health issue. However, one concern with such systems is compliance; users fail to achieve daily stress reduction goals because goals are too easy or too difficult. To address this, we built DStress (Design for Stress), a theoretically grounded system that sets adaptive goals in three coaching dimensions: Exercise, Meditation and Accessibility. DStress modifies goal-difficulty based on the individual’s immediately previous performance. In a 28-day deployment with 65 users, DStress reduced scores on one direct measure of stress almost in half, significantly more than two other non-adaptive coaching strategies. However, on a second direct stress measure, no improvement was found. There were also no improvements on other indirect stress measures. Analysis of 2842 user-generated reports suggests our findings were the result of DStress balancing compliance against the degree of challenge of the goals it would set.  ",TRUE
pn2102,2702513,http://dx.doi.org/10.1145/2702123.2702513,http://dl.acm.org/citation.cfm?id=2702513,pStLrlkLZhE,www.youtube.com/watch?v=pStLrlkLZhE,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/pStLrlkLZhE' width='640' height='360' frameborder='0' allowfullscreen='true'/>,One-Handed Bend Interactions with Deformable Smartphones,"Audrey Girouard, Jessica Lo, Md Riyadh, Farshad Daliri, Alexander Keith Eady, Jerome Pasquero","Smartphones are becoming larger, mainly because bigger screens offer a better experience for viewing content. One drawback of larger screens is that they make single-hand interactions difficult because of hard to reach touch targets and of the need to re-grip the device, both factors significantly reducing their usability. Flexible smartphones offer an opportunity for addressing this issue. We first set out to determine the use of common single-hand mobile interactions through an online survey. Then, we designed and evaluated one-handed deformable gestures that offer the potential for addressing the finger reach limitation on large smartphones. We identified that the top right up bend and the center squeeze up gestures are the fastest and preferred gestures. We found no hand preference, which indicates that the gestures could be implemented to fit the needs of a wider range of the population, instead of favoring right-handed users. Finally, we discuss the impact on deformable gestures on one-handed interactions issues.",FALSE
pn2111,2702515,http://dx.doi.org/10.1145/2702123.2702515,http://dl.acm.org/citation.cfm?id=2702515,yHEB7arGOQs,www.youtube.com/watch?v=yHEB7arGOQs,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/yHEB7arGOQs' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Form Follows Sound: Designing Interactions from Sonic Memories,"Baptiste Caramiaux, Alessandro Altavilla, Scott G. Pobiner, Atau Tanaka","Sonic interaction is the continuous relationship between user actions and sound, mediated by some technology. Because interaction with sound may be task oriented or experience-based it is important to understand the nature of action-sound relationships in order to design rich sonic interactions. We propose a participatory approach to sonic interaction design that first considers the affordances of sounds in order to imagine embodied interaction, and based on this, generates interaction models for interaction designers wishing to work with sound. We describe a series of workshops, called Form Follows Sound, where participants ideate imagined sonic interactions, and then realize working interactive sound prototypes.  We introduce the Sonic Incident technique, as a way to recall memorable sound experiences. We identified three interaction models for sonic interaction design: conducting; manipulating; substituting. These three interaction models offer interaction designers and developers a framework on which they can build richer sonic interactions.",TRUE
pn2122,2702516,http://dx.doi.org/10.1145/2702123.2702516,http://dl.acm.org/citation.cfm?id=2702516,4L_ulzhhnE0,www.youtube.com/watch?v=4L_ulzhhnE0,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/4L_ulzhhnE0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,FluxPaper: Reinventing Paper with Dynamic Actuation Powered by Magnetic Flux,"Masa Ogata, Masaaki Fukumoto","FluxPaper is a new paper-based medium that enables physical movement and dynamic interaction between a high-power magnetized paper and a programmable magnetic field. FluxPaper has a very thin patterned magnetic layer (0.1 mm) pasted behind the paper. A thin but strong neodymium-based magnet realizes fast, powerful, and precise physical actions while retaining the original characteristics of the paper that is widely used in our daily lives. Owing to an effective magnetic pattern and a computer-controlled magnetic field, FluxPaper can add new interaction modality to ordinary paper. We describe the functions of magnetized paper; challenges through realization; and the interaction scenarios in several applications, such as self-alignment, self-construction, floating on the board, and quickly picking out a target card from a stack.",FALSE
pn2126,2702517,http://dx.doi.org/10.1145/2702123.2702517,http://dl.acm.org/citation.cfm?id=2702517,TwXm9oS4CgY,www.youtube.com/watch?v=TwXm9oS4CgY,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/TwXm9oS4CgY' width='640' height='360' frameborder='0' allowfullscreen='true'/>,DocuViz:  Visualizing Collaborative Writing,"Dakuo Wang, Judith S. Olson, Jingwen Zhang, Trung Nguyen, Gary M. Olson","Collaborative writing is on the increase. In order to write well together, authors often need to be aware of who has done what recently. We offer a new tool, DocuViz, that displays the entire revision history of Google Docs, showing more than the one-step-at–a-time view now shown in revision history and tracking changes in Word. We introduce the tool and present cases in which the tool has the potential to be useful: To authors themselves to see recent “seismic activity,” indicating where in particular a co-author might want to pay attention, to instructors to see who has contributed what and which changes were made to comments from them, and to researchers interested in the new patterns of collaboration made possible by simultaneous editing capabilities. ",TRUE
pn2146,2702520,http://dx.doi.org/10.1145/2702123.2702520,http://dl.acm.org/citation.cfm?id=2702520,xeZherjrfSE,www.youtube.com/watch?v=xeZherjrfSE,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/xeZherjrfSE' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Unequal Representation and Gender Stereotypes in Image Search Results for Occupations,"Matthew Kay, Cynthia Matuszek, Sean A Munson","Information environments have the power to affect people’s perceptions and behaviors. In this paper, we present the results of studies in which we characterize the gender bias present in image search results for a variety of occupations. We experimentally evaluate the effects of bias in image search results on the images people choose to represent those careers and on people’s perceptions of the prevalence of men and women in each occupation. We find evidence for both stereotype exaggeration and systematic underrepresentation of women in search results. We also find that people rate search results higher when they are consistent with stereotypes for a career, and shifting the representation of gender in image search results can shift people’s perceptions about real-world distributions. We also discuss tensions between desires for high-quality results and broader societal goals for equality of representation in this space.",TRUE
pn2185,2702524,http://dx.doi.org/10.1145/2702123.2702524,http://dl.acm.org/citation.cfm?id=2702524,-XJ0yYhNuI8,www.youtube.com/watch?v=-XJ0yYhNuI8,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/-XJ0yYhNuI8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Effects of Public Commitments and Accountability in a Technology-Supported Physical Activity Intervention,"Sean A Munson, Erin Krupka, Caroline Richardson, Paul Resnick","Walking and other forms of physical activity have many health benefits, but people often fail to follow through on their own goals of being more active. To address gaps in current understanding of how to design technology-supported physical activity interventions, we conducted a randomized field experiment of a commitment device: making public announcements. In a control condition, weekly commitments were kept private. In two treatment conditions, they were announced on Facebook and by email. In one of the two, the announcements also included results: whether the previous week’s commitment was kept.  We find that, with or without public results, these posts can elicit supportive replies from the poster’s social networks. People in both public announcements conditions were less likely to make commitments. We conclude that the prospect of public accountability may suppress the making of commitments in a way that counteracts the benefits of that accountability. Designers will need to address this limitation in order to make effective use of public accountability as a commitment device.",TRUE
pn2191,2702525,http://dx.doi.org/10.1145/2702123.2702525,http://dl.acm.org/citation.cfm?id=2702525,oAOt33Q7Skk,www.youtube.com/watch?v=oAOt33Q7Skk,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/oAOt33Q7Skk' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Sharing is Caring: Assistive Technology Designs on Thingiverse,"Erin Buehler, Stacy Branham, Abdullah Ali, Jeremy J Chang, Megan Kelly Hofmann, Amy Hurst, Shaun K Kane","An increasing number of online communities support the open-source sharing of designs that can be built using rapid prototyping to construct physical objects. In this paper, we examine the designs and motivations for assistive technology found on Thingiverse.com, the largest of these communities at the time of this writing. We present results from a survey of all assistive technology that has been posted to Thingiverse since 2008 and a questionnaire distributed to the designers exploring their relationship with assistive technology and the motivation for creating these designs. The majority of these designs are intended to be manufactured on a 3D printer and include assistive devices and modifications for individuals with disabilities, older adults, and medication management. Many of these designs are created by the end-users themselves or on behalf of friends and loved ones. These designers frequently have no formal training or expertise in the creation of assistive technology. This paper discusses trends within this community as well as future opportunities and challenges.",TRUE
pn2196,2702526,http://dx.doi.org/10.1145/2702123.2702526,http://dl.acm.org/citation.cfm?id=2702526,mh2QnFopvqw,www.youtube.com/watch?v=mh2QnFopvqw,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/mh2QnFopvqw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Can You See Me Now? How Field of View Affects Collaboration in Robotic Telepresence,"Steven Johnson, Irene Rae, Bilge Mutlu, Leila Takayama","Robotic telepresence systems-videoconferencing systems that allow a remote user to drive around in another location-are an emerging technology for supporting geographically-distributed teams. Thus far, many of these systems rely on affordances designed for stationary systems, such as a single, narrow-view camera to provide vision for the remote user. Teleoperation has offered some solutions to this via an augmented field-of-view, but how these solutions support task outcomes in collaborative mobile telepresence tasks has yet to be understood. To investigate this, we conducted a three condition (field-of-view: narrow (45°) vs. wide-angle (180°) vs. panoramic (360°)) between-participants controlled laboratory experiment. We asked participants (N=24) to collaborate with a confederate via a robotic telepresence system while using one of these views in a redecoration task.  Our results showed that wider views supported task efficiency and fewer collisions, but were perceived as more difficult to use.",TRUE
pn2212,2702528,http://dx.doi.org/10.1145/2702123.2702528,http://dl.acm.org/citation.cfm?id=2702528,_99FLD8xxnM,www.youtube.com/watch?v=_99FLD8xxnM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/_99FLD8xxnM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Understanding the Role of Thermography in Energy Auditing: Current Practices and the Potential for Automated Solutions,"Matthew Louis Mauriello, Leyla Norooz, Jon E Froehlich","The building sector accounts for 41% of primary energy consumption in the US, contributing an increasing portion of the country’s carbon dioxide emissions. With recent sensor improvements and falling costs, auditors are increasingly using thermography—infrared (IR) cameras—to detect thermal defects and analyze building efficiency. Research in automated thermography has grown commensurately, aimed at reducing manual labor and improving thermal models. Though promising, we could find no prior work exploring the professional auditor’s perspectives of thermography or reactions to emerging automation. To address this gap, we present results from two studies: a semi-structured interview with 10 professional energy auditors, which includes design probes of five automated thermography scenarios, and an observational case study of a residential audit. We report on common perspectives, concerns, and benefits related to thermography and summarize reactions to our automated scenarios. Our findings have implications for thermography tool designers as well as researchers working on automated solutions in robotics, computer science, and engineering.",TRUE
pn2218,2702530,http://dx.doi.org/10.1145/2702123.2702530,http://dl.acm.org/citation.cfm?id=2702530,BNt1xC9wwLs,www.youtube.com/watch?v=BNt1xC9wwLs,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/BNt1xC9wwLs' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Investigating the Information Transfer Efficiency of a 3x3 Watch-back Tactile Display,"Jaeyeon Lee, Jaehyun Han, Geehyuk Lee","A watch-back tactile display (WBTD) is expected to be a viable supplement to the user interface limitations of a smartwatch. However, its design requires that many design parameters such as tactor types and stimulus patterns be determined. We conducted a series of experiments to explore the design space of a WBTD consisting of 3_3 tactors. We demonstrated that tactor types and the temporal patterns and locus of a stimulus produce statistically significant effects on the efficiency of a WBTD. The experimental results can act as a practical guideline for the design of an efficient WBTD.",TRUE
pn2244,2702535,http://dx.doi.org/10.1145/2702123.2702535,http://dl.acm.org/citation.cfm?id=2702535,ngA0UmIJIro,www.youtube.com/watch?v=ngA0UmIJIro,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/ngA0UmIJIro' width='640' height='360' frameborder='0' allowfullscreen='true'/>,"""I Saw Images I Didn't Even Know I Had"" -- Understanding User Perceptions of Cloud Storage Privacy","Jason W. Clark, Peter Snyder, Damon McCoy, Chris Kanich","Billions of people use cloud-based storage for personal files.  While many \ are likely aware of the extent to which they store information \ in the cloud, it is unclear whether users are fully aware of what they are storing online. \ We recruited 30 research subjects from Craigslist to investigate how users \ interact with and understand the  privacy issues of cloud storage.  We studied \ this phenomenon through surveys, an interview, and custom software which lets \ users see and delete their photos  stored in the cloud.  We found that a \ majority of users stored private photos in the cloud that they did not \ intend to upload, and a large portion also chose to permanently delete some of \ the offending images. \ We believe our study highlights a mismatch between user expectation and \ reality. As cloud storage is plentiful and ubiquitous, effective tools for \ enabling risk self-assessment are necessary to protect users' privacy.",FALSE
pn2247,2702537,http://dx.doi.org/10.1145/2702123.2702537,http://dl.acm.org/citation.cfm?id=2702537,SXuxCFQUlyo,www.youtube.com/watch?v=SXuxCFQUlyo,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/SXuxCFQUlyo' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Working 9-5? Professional Differences in Email and Boundary Management Practices,"Marta E. Cecchinato, Anna L Cox, Jon Bird","Technology not only brings benefits such as flexible working practices but can also have negative stressful consequences such as increasing email overload and the blurring of work-home boundaries. We report on an exploratory study that extends the current understanding of email usage by investigating how different professions at a university manage work and personal emails using different devices and how this impacts their work-home boundary management. Our findings lead us to identify two user groups: those with permeable boundaries (primarily academics) and those who have more rigid ones (primarily professional services employees) and that there are differences in when, where and how they manage their work and personal emails. In particular we find that some participants use micro-boundary strategies to manage transitions between work and personal life. Based on these novel findings we propose improvements of email software design to facilitate effective email, work-home boundary management, and support micro-boundary practices.",TRUE
pn2272,2702538,http://dx.doi.org/10.1145/2702123.2702538,http://dl.acm.org/citation.cfm?id=2702538,UpUXYf_Bzek,www.youtube.com/watch?v=UpUXYf_Bzek,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/UpUXYf_Bzek' width='640' height='360' frameborder='0' allowfullscreen='true'/>,The Smartphone Project - An Augmented Dance Performance,"Leif Oppermann, Clemens Putschli, Constantin Brosda, Oleksandr Lobunets, Fabien Prioville","The Smartphone Project (TSP) is an interactive dance-performance in a professional setting that exploits the communication channels provided by smartphone-apps as a new material in the dance-theatre domain. We present an account of the experience and its staging. Based on an initial study with 36 participants from the audience, we present results and discuss lessons learned from this project that might guide similar future work. ",TRUE
pn2282,2702540,http://dx.doi.org/10.1145/2702123.2702540,http://dl.acm.org/citation.cfm?id=2702540,REYLPOVKd6o,www.youtube.com/watch?v=REYLPOVKd6o,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/REYLPOVKd6o' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Investigating Genres and Perspectives in HCI Research on the Home,"Audrey Desjardins, Ron Wakkary, William Odom","The home and domestic experiences have been studied from multiple points of view and disciplines, with an array of methodologies in the past twenty-five years in HCI. Given the attention to the home and the volume of research, what further areas of research might there be? Based on a critical analysis of 121 works on the topic, we present seven genres of domestic technology research in HCI: social routines in the home, ongoing domestic practices, the home as a testing ground, smart homes, contested values of a home, the home as a site for interpretation, and speculative visions of the home. We articulate dominant research perspectives in HCI, and we offer two complementary perspectives about how to investigate the domestic experience in future research: the material perspective and the first person perspective.",TRUE
pn2296,2702543,http://dx.doi.org/10.1145/2702123.2702543,http://dl.acm.org/citation.cfm?id=2702543,qUHnZudq7ws,www.youtube.com/watch?v=qUHnZudq7ws,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/qUHnZudq7ws' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Selective Undo Support for Painting Applications,"Brad A Myers, Ashley Lai, Tam Minh Le, YoungSeok Yoon, Andrew Faulring, Joel Brandt","Today’s widely deployed painting applications use a linear undo model that allows users to backtrack previous operations in reverse chronological order. This undo model is not useful if the user has performed desired operations after undesired ones. Selective undo, in contrast, allows users to select specific operations in the past and only undo those, while keeping the remaining operations intact. Although selective undo has been widely explored in the context of text editing and object-oriented drawing, we explore selective undo for painting (bitmap) editing, which has received less attention and introduces many interesting user interface design challenges. Our system, called Aquamarine, explores the script model for selective undo, where selectively undone operations are skipped in the history, rather than the more explored inverse model, which puts an inverse of the selected operations at the end of the history. We discuss the design implications and show through two informal user studies that selective undo is usable and desirable",TRUE
pn2312,2702547,http://dx.doi.org/10.1145/2702123.2702547,http://dl.acm.org/citation.cfm?id=2702547,ilRIKCR405g,www.youtube.com/watch?v=ilRIKCR405g,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/ilRIKCR405g' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Being the Machine: Reconfiguring Agency and Control in Hybrid Fabrication,"Laura Devendorf, Kimiko Ryokai","This paper details the design and evaluation of Being the Machine, a portable digital fabrication system that places digital fabrication activity outside of the traditional fab lab environment. Being the Machine invites people to (re)consider materials found in their everyday and personal environment as part of the fabrication activity. We expand the design space involving hybrid (physical-digital) fabrication by describing how our system draws from art to support critical and reflective modes of making. In interaction with our system, participants distributed control between human and machine actors to support their preferred mode of making. These patterns reveal new opportunities and challenges for future hybrid fabrication systems, and suggest that designing for qualities of experience, like meditation and reflection, could support meaningful making experiences for many different kinds of makers.",TRUE
pn2313,2702548,http://dx.doi.org/10.1145/2702123.2702548,http://dl.acm.org/citation.cfm?id=2702548,haCclIai86w,www.youtube.com/watch?v=haCclIai86w,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/haCclIai86w' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Working with Machines: The Impact of Algorithmic and Data-Driven Management on Human Workers,"Min Kyung Lee, Daniel Kusbit, Evan Metsky, Laura Dabbish","Software algorithms are changing how people work in an ever-growing number of fields, managing distributed human workers at a large scale. In these work settings, human jobs are assigned, optimized, and evaluated through algorithms and tracked data. We explore the impact of this algorithmic, data-driven management on human workers and work practices in the context of Uber and Lyft, new ridesharing services. Our findings from a qualitative study describe how drivers responded when algorithms assigned work, provided informational support, and evaluated their performance, and how drivers used online forums to socially make sense of the algorithm features. Implications and future work are discussed.",TRUE
pn2327,2702551,http://dx.doi.org/10.1145/2702123.2702551,http://dl.acm.org/citation.cfm?id=2702551,3XL9ZzfTvK8,www.youtube.com/watch?v=3XL9ZzfTvK8,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/3XL9ZzfTvK8' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Mixed-Initiative Approaches to Global Editing in Slideware,"Darren Edge, Sumit Gulwani, Natasa Milic-Frayling, Mohammad Raza, Reza Adhitya Saputra, Chao Wang, Koji Yatani","Good alignment and repetition of objects across presentation slides can facilitate visual processing and contribute to audience understanding. However, creating and maintaining such consistency during slide design is difficult. To solve this problem, we present two complementary tools: (1) StyleSnap, which increases the alignment and repetition of objects by adaptively clustering object edge positions and allowing parallel editing of all objects snapped to the same spatial extent; and (2) FlashFormat, which infers the least-general generalization of editing examples and applies it throughout the selected range. In user studies of repetitive styling task performance, StyleSnap and FlashFormat were 4-5 times and 2-3 times faster respectively than conventional editing. Both use a mixed-initiative approach to improve the consistency of slide decks and generalize to any situations involving direct editing across disjoint visual spaces.",TRUE
pn2328,2702552,http://dx.doi.org/10.1145/2702123.2702552,http://dl.acm.org/citation.cfm?id=2702552,REEgBzvcjMQ,www.youtube.com/watch?v=REEgBzvcjMQ,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/REEgBzvcjMQ' width='640' height='360' frameborder='0' allowfullscreen='true'/>,"Robots, Pancakes, and Computer Games: Designing Serious Games for Robot Imitation Learning","Benjamin Walther-Franks, Jan Smeddinck, Peter Szmidt, Andrei Haidu, Michael Beetz, Rainer Malaka","Autonomous manipulation robots can be valuable aids as interactive agents in the home, yet it has proven extremely difficult to program their behavior. Imitation learning uses data on human demonstrations to build behavioral models for robots. In order to cover a wide range of action strategies, data from many individuals is needed. Acquiring such large amounts of data can be a challenge. Tools for data capturing in this domain must thus implement a good user experience. We propose to use human computation games in order to gather data on human manual behavior. We demonstrate the idea with a strategy game that is operated via a natural user interface. A comparison between using the game for action execution and demonstrating actions in a virtual environment shows that people interact longer and have a better experience when playing the game.",TRUE
pn2341,2702556,http://dx.doi.org/10.1145/2702123.2702556,http://dl.acm.org/citation.cfm?id=2702556,XQRJI5BcLMM,www.youtube.com/watch?v=XQRJI5BcLMM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/XQRJI5BcLMM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,“I always assumed that I wasn’t really that close to [her]”: Reasoning about Invisible Algorithms in the News Feed,"Motahhare Eslami, Aimee Rickman, Kristen Vaccaro, Amirhossein Aleyasen, Andy Vuong, Karrie Karahalios, Kevin Hamilton, Christian Sandvig","Our daily digital life is full of algorithmically selected content such as social media feeds,  recommendations and personalized search results. These algorithms have great power to shape users' experiences, yet users are often unaware of their presence.  Whether it is useful to give users insight into these algorithms' existence or functionality and how such insight might affect their experience are open questions. To address them, we conducted a user study with 40 Facebook users to examine their perceptions of the Facebook News Feed curation algorithm. Surprisingly, more than half of the participants (62.5%) were not aware of the News Feed curation algorithm's existence at all. Initial reactions for these previously unaware participants were surprise and anger. We developed a system, FeedVis, to reveal the difference between the algorithmically curated and an unadulterated News Feed to users, and used it to study how users perceive this difference. Participants were most upset when close friends and family were not shown in their feeds. We also found participants often attributed missing stories to their friends' decisions to exclude them rather than to Facebook News Feed algorithm.  By the end of the study, however, participants were mostly satisfied with the content on their feeds. Following up with participants two to six months after the study, we found that for most, satisfaction levels remained similar before and after becoming aware of the algorithm's presence, however, algorithmic awareness led to more active engagement with Facebook and bolstered overall feelings of control on the site.",TRUE
pn2370,2702559,http://dx.doi.org/10.1145/2702123.2702559,http://dl.acm.org/citation.cfm?id=2702559,QZrx0Wn_nLM,www.youtube.com/watch?v=QZrx0Wn_nLM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/QZrx0Wn_nLM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,How Activists Are Both Born and Made: An Analysis of Users on Change.org,"Shih-Wen Huang, Minhyang (Mia) Suh, Benjamin Mako Hill, Gary Hsieh","E-petitioning has become one of the most important and popular forms of online activism. Although e-petition success is driven by user behavior, users have received relatively little study by HCI and social computing researchers. Drawing from theoretical and empirical work in analogous social computing systems, we identify two potentially competing theories about the trajectories of users in e-petition platforms: (1) “power” users in social computing systems are born, not made; and (2) users mature into “power” users. In a quantitative analysis of data from Change.org, one of the largest online e-petition platforms, we test and find support for both theories. A follow-up qualitative analysis shows that not only do users learn from their experience, systems also “learn” from users to make better recommendations. In this sense, we find that although power users are “born,” they are also “made” through both processes of personal growth and improved support from the system.",TRUE
pn2412,2702562,http://dx.doi.org/10.1145/2702123.2702562,http://dl.acm.org/citation.cfm?id=2702562,t12gXUzlCJU,www.youtube.com/watch?v=t12gXUzlCJU,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/t12gXUzlCJU' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Re-Centering Multispecies Practices: A Canine Interface for Cancer Detection Dogs,"Clara Mancini, Rob Harris, Brendan Aengenheister, Claire Guest","We report on participatory design research where interaction designers, and canine behavioral specialists, together with their cancer detection dogs, teamed up to better support the dogs’ life-saving work. We discuss interspecies communication challenges in cancer detection training, requiring the dogs to use human signaling conventions that perturb their detection work. We describe our effort to develop a technology that could resolve those challenges, and how in the process our design focus gradually shifted from a human-centered to a canine-centered interaction model. The resulting interface, based on honest signaling, re-centers cancer detection practices on the dogs themselves, enabling them to better express their potential as cancer detection workers; it also provides a model for re-thinking human-computer interactions.",TRUE
pn2464,2702569,http://dx.doi.org/10.1145/2702123.2702569,http://dl.acm.org/citation.cfm?id=2702569,-4gFYvhkz0Y,www.youtube.com/watch?v=-4gFYvhkz0Y,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/-4gFYvhkz0Y' width='640' height='360' frameborder='0' allowfullscreen='true'/>,3D Printing Pneumatic Device Controls with Variable Activation Force Capabilities,"Marynel Vázquez, Eric Brockmeyer, Ruta Desai, Chris Harrison, Scott E. Hudson","We explore 3D printing physical controls whose tactile response can be manipulated programmatically through pneumatic actuation. In particular, by manipulating the internal air pressure of various pneumatic elements, we can create mechanisms that require different levels of actuation force and can also change their shape. We introduce and discuss a series of example 3D printed pneumatic controls, which demonstrate the feasibility of our approach. This includes conventional controls, such as buttons, knobs and sliders, but also extends to domains such as toys and deformable interfaces. We describe the challenges that we faced and the methods that we used to overcome some of the limitations of current 3D printing technology. We conclude with example applications and thoughts on future avenues of research.",TRUE
pn2473,2702572,http://dx.doi.org/10.1145/2702123.2702572,http://dl.acm.org/citation.cfm?id=2702572,jzEUxUzWPqc,www.youtube.com/watch?v=jzEUxUzWPqc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/jzEUxUzWPqc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,NailO: Fingernails as an Input Surface,"Hsin-Liu (Cindy) Kao, Artem Dementyev, Joseph A Paradiso, Chris Schmandt","We present NailO, a nail-mounted gestural input surface. Using capacitive sensing on printed electrodes, the interface can distinguish on-nail finger swipe gestures with high accuracy (>92%). NailO works in real-time: we miniaturized the system to fit on the fingernail, while wirelessly transmitting the sensor data to a mobile phone or PC. NailO allows one-handed and always-available input, while being unobtrusive and discrete. Inspired by commercial nail stickers, the device blends into the user's body, is customizable, fashionable and even removable. We show example applications of using the device as a remote controller when hands are busy and using the system to increase the input space of mobile phones. ",TRUE
pn2476,2702573,http://dx.doi.org/10.1145/2702123.2702573,http://dl.acm.org/citation.cfm?id=2702573,EeXBB0Yx8gA,www.youtube.com/watch?v=EeXBB0Yx8gA,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/EeXBB0Yx8gA' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Residual Mobilities: Infrastructural Displacement and Post-Colonial Computing in Bangladesh,"Syed Ishtiaque Ahmed, Nusrat Jahan Mim, Steven J Jackson","This paper explores discrepancies between the founding assumptions of mobile and ubiquitous computing in the western world, and the starkly different experiences of mobility and infrastructure to be found in many post-colonial environments. Based on a field study of forced mobility and technology use among populations displaced by the Hatirjheel waterfront development project in Dhaka, Bangladesh, we make two basic arguments. First, we point to the partial nature of assumptions around mobility that frame the imagination of mainstream HCI research, and argue that different and heretofore residual experiences of mobility must also be accounted for in post-colonial and other marginal computing environments. Second, we document four forms of infrastructural experience – dispossession, reconstitution, collaboration, and repair – that characterize real-world engagements with infrastructure in such settings. We conclude with implications for HCI research and design, and reflections on how HCI researchers might better account for such experiences in their work. ",TRUE
pn2478,2702574,http://dx.doi.org/10.1145/2702123.2702574,http://dl.acm.org/citation.cfm?id=2702574,m9-vTvfRil4,www.youtube.com/watch?v=m9-vTvfRil4,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/m9-vTvfRil4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,From Third to Surveilled Place: The Mobile in Irish Pubs,"Norman Makoto Su, Lulu Wang","A home away from home, the pub is synonymous with good conversation.  Yet, the art of conversation in pubs is changing with the ubiquity of mobile phones.  We present a qualitative study spanning over three years describing experiences and rhetoric surrounding the relationship that mobiles have and should have with our conversation in the pub. We found that mobile phones are able to enhance conversation but can also cause a disruption to the informal and adhoc nature of pubs. The use of Facebook on mobile phones has also changed pubs from what Oldenburg terms a third space to a space that is potentially being surveilled.  We suggest future designs should not necessarily discourage or encourage mobile use in pubs, but rather provoke us into reflecting on how intertwined modern conversation is with mobile technology in the context of the pub space.",TRUE
pn2480,2702575,http://dx.doi.org/10.1145/2702123.2702575,http://dl.acm.org/citation.cfm?id=2702575,Mt5ZO16FPpo,www.youtube.com/watch?v=Mt5ZO16FPpo,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/Mt5ZO16FPpo' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Computation of Interface Aesthetics,"Aliaksei Miniukovich, Antonella De Angeli","People prefer attractive interfaces. Designers strive to outmatch competitors, and create apps and websites that stand out. However, significant expenses on design are unaffordable to small companies; instead, they could adopt automatic tools of interface aesthetics evaluation, a cheaper strategy to good design. This paper describes an important step towards such a tool; it presents eight automatic metrics of graphical user interface (GUI) aesthetics. We tested the metrics in two exploratory studies – on desktop webpages (N = 62) and on iPhone apps (N = 53) – and found them to function on both GUI types and for both immediate (150ms exposure) and deliberate (4s exposure) aesthetics impressions. Our best-fit regression models explained up to 49% of variance in webpage aesthetics and up to 32% (if app genre is considered) of variance in iPhone app aesthetics. These results confirm past results and suggest the metrics are valid and reliable enough to be widely discussed, and possibly, to be embedded in our prospective GUI evaluation tool, tLight.",TRUE
pn2483,2702577,http://dx.doi.org/10.1145/2702123.2702577,http://dl.acm.org/citation.cfm?id=2702577,YPXfkwJo4Ns,www.youtube.com/watch?v=YPXfkwJo4Ns,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/YPXfkwJo4Ns' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Pass the Ball: Enforced Turn-Taking in Activity Tracking,"John Rooksby, Mattias Rost, Alistair Morrison, Matthew Chalmers","We have developed a mobile application called Pass The Ball that enables users to track, reflect on, and discuss physical activity with others. We followed an iterative design process, trialling a first version of the app with 20 people and a second version with 31. The trials were conducted in the wild, on users’ own devices. The second version of the app enforced a turn-taking system that meant only one member of a group of users could track their activity at any one time. This constrained tracking at the individual level, but more successfully led users to communicate and interact with each other. We discuss the second trial with reference to two concepts: social-relatedness and individual-competence. We discuss six key lessons from the trial, and identify two high-level design implications: attend to “practices” of tracking; and look within and beyond “collaboration” and “competition” in the design of activity trackers.",TRUE
pn2492,2702580,http://dx.doi.org/10.1145/2702123.2702580,http://dl.acm.org/citation.cfm?id=2702580,GhFLKsy5uqM,www.youtube.com/watch?v=GhFLKsy5uqM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/GhFLKsy5uqM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,A Framework for Automatically Generating Interactive Instructional Scaffolding,"Eleanor O'Rourke, Erik Andersen, Sumit Gulwani, Zoran Popovic","Interactive learning environments such as intelligent tutoring systems and software tutorials often teach procedures with step-by-step demonstrations. This instructional scaffolding is typically authored by hand, and little can be reused across problem domains. In this work, we present a framework for generating interactive tutorials from an algorithmic representation of the problem-solving thought process. Given a set of mappings between programming language constructs and user interface elements, we step through this algorithm line-by-line to trigger visual explanations of each step. This approach allows us to automatically generate tutorials for any example problem that can be solved with this algorithm. We describe two prototype implementations in the domains of K-12 mathematics and educational games, and present results from two user studies showing that educational technologists can author thought-process procedures and that generated tutorials can effectively teach a new procedure to students.",TRUE
pn2494,2702581,http://dx.doi.org/10.1145/2702123.2702581,http://dl.acm.org/citation.cfm?id=2702581,2_U4oaZ850I,www.youtube.com/watch?v=2_U4oaZ850I,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/2_U4oaZ850I' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Tactum: A Skin-Centric Approach to  Digital Design and Fabrication,"Madeline Gannon, Tovi Grossman, George Fitzmaurice","Skin-based input has become an increasingly viable interaction model for user interfaces, however it has yet to be explored outside the domain of mobile computing.  In this paper, we examine skin as an interactive input surface for gestural 3D modeling-to-fabrication systems. When used as both the input surface and base canvas for digital design, skin-input can enable non-experts users to intuitively create precise forms around highly complex physical contexts: our own bodies. In this paper, we outline design considerations when creating interfaces for such systems.  We then discuss interaction techniques for three different modes of skin-centric modeling: direct, parametric, and generative. We also present Tactum, a new fabrication-aware design system that captures a user’s skin-centric gestures for 3D modeling directly on the body.  Lastly, we show sample artifacts generated with our system, and share a set of observations from design professionals.",TRUE
pn2495,2702582,http://dx.doi.org/10.1145/2702123.2702582,http://dl.acm.org/citation.cfm?id=2702582,kGpnxgDT2M4,www.youtube.com/watch?v=kGpnxgDT2M4,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/kGpnxgDT2M4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,FlickBoard: Enabling Trackpad Interaction with Automatic Mode Switching on a Capacitive-sensing Keyboard,"Ying-Chao Tung, Ta Yang Cheng, Neng-Hao Yu, Mike Y. Chen","We present FlickBoard, which combines a touchpad and a keyboard into the same interaction area to reduce hand movement between a separate keyboard and touchpad. Our main contribution is automatic mode switching between typing and pointing, and the first system capable of combining a trackpad and a keyboard into an single interaction area without the need for external switches. We developed a prototype by embedding a 58x20 capacitive sensing grid into a soft keyboard cover, and used machine learning to distinguish between moving a cursor (touchpad mode) and entering text (keyboard mode). We conducted experimental studies that show automatic mode switching classification accuracies of 98% are achievable with our technology. Finally, our prototype has a thin profile and can be placed over existing keyboards.",TRUE
pn2504,2702583,http://dx.doi.org/10.1145/2702123.2702583,http://dl.acm.org/citation.cfm?id=2702583,_-fmT4N2yK0,www.youtube.com/watch?v=_-fmT4N2yK0,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/_-fmT4N2yK0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Soft-Constraints to Reduce Legacy and Performance Bias to Elicit Whole-body Gestures with Low Arm Fatigue,"Jaime Ruiz, Daniel Vogel","Participant biases can influence proposed gestures in elicitation studies. There is a legacy bias from previous experience with, or even knowledge of, existing input devices, interfaces, and technologies. There is also a performance bias, where the artificial study setting does not encourage consideration of long-term aspects such as fatigue. These biases make it especially difficult to uncover gestures appropriate for whole-body gestural input. We propose using soft constraints to correct for legacy and performance biases by penalizing physical movements. We use wrist weights as a soft constraint to elicit whole-body gestures with low arm fatigue. We show soft constraints encourage a wider range of gestures using subtler arm movements or alternate body parts and lower consumed endurance for arm movements.",TRUE
pn2536,2702584,http://dx.doi.org/10.1145/2702123.2702584,http://dl.acm.org/citation.cfm?id=2702584,Hxjz3PqcvdE,www.youtube.com/watch?v=Hxjz3PqcvdE,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/Hxjz3PqcvdE' width='640' height='360' frameborder='0' allowfullscreen='true'/>,DynamicDuo: Co-presenting with Virtual Agents,"Ha Trinh, Lazlo Ring, Timothy Bickmore","The quality of most professional oral presentations is often poor, owing to a number of factors, including public speaking anxiety. We present DynamicDuo, a system that uses an automated, life-sized, animated agent to help inexperienced speakers deliver their presentations in front of an audience. The design of the system was informed by an analysis of TED talks given by two human presenters to identify the most common dual-presentation formats and transition behaviors used. In a within-subjects study (N=12) comparing co-presenting with DynamicDuo against solo-presenting with conventional presentation software, we demonstrated that our system led to significant improvements in public speaking anxiety and speaking confidence for non-native English speakers. Judges who viewed videotapes of these presentations rated those with DynamicDuo significantly higher on speech quality and overall presentation quality for all presenters.",TRUE
pn2539,2702585,http://dx.doi.org/10.1145/2702123.2702585,http://dl.acm.org/citation.cfm?id=2702585,JP80ajFX9o4,www.youtube.com/watch?v=JP80ajFX9o4,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/JP80ajFX9o4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Dynamic Opacity Optimization for Scatter Plots,"Justin Matejka, Fraser Anderson, George Fitzmaurice","Scatterplots are an effective and commonly used technique to show the relationship between two variables. However, as the number of data points increases, the chart suffers from “over-plotting” which obscures data points and makes the underlying distribution of the data difficult to discern. Reducing the opacity of the data points is an effective way to address over-plotting, however, setting the individual point opacity is a manual task performed by the chart designer. We present a user-driven model of opacity scaling for scatter plots built from crowd-sourced responses to opacity scaling tasks using several synthetic data distributions, and then test our model on a collection of real-world data sets.",TRUE
pn2548,2702586,http://dx.doi.org/10.1145/2702123.2702586,http://dl.acm.org/citation.cfm?id=2702586,uBSEx51-ecM,www.youtube.com/watch?v=uBSEx51-ecM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/uBSEx51-ecM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,A Spoonful of Sugar? The Impact of Guidance and Feedback on Password-Creation Behavior,"Richard Shay, Lujo Bauer, Nicolas Christin, Lorrie Faith Cranor, Alain Forget, Saranga Komanduri, Michelle L. Mazurek, William Melicher, Sean M. Segreti, Blase Ur","Users often struggle to create passwords under strict requirements. To make this process easier, some providers present real-time feedback during password creation, indicating which requirements are not yet met. Other providers guide users through a multi-step password-creation process. Our 6,435-participant online study examines how feedback and guidance affect password security and usability. We find that real-time password-creation feedback can help users create strong passwords with fewer errors. We also find that although guiding participants through a three-step password-creation process can make creation easier, it may result in weaker passwords. Our results suggest that service providers should present password requirements with feedback to increase usability. However, the presentation of feedback and guidance must be carefully considered, since identical requirements can have different security and usability effects depending on presentation.",TRUE
pn2560,2702587,http://dx.doi.org/10.1145/2702123.2702587,http://dl.acm.org/citation.cfm?id=2702587,js5T6NSnLjw,www.youtube.com/watch?v=js5T6NSnLjw,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/js5T6NSnLjw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,A Spreadsheet Model for Handling Streaming Data,"Kerry Shih-Ping Chang, Brad A. Myers","We present a spreadsheet model for working with streaming data. Our prototype tool presents techniques to let the user stream data from web services and web input elements to a spreadsheet without preprogramming those sources into the tool. Spreadsheet cells record metadata about where and when the data came from, allowing the user to view and manipulate streaming data using temporal information. Starting and pausing a data stream in the spreadsheet can be controlled programmatically using values computed by spreadsheet cells, making the spreadsheet program highly dynamic and interactive. We demonstrate the range of our design with a series of examples highlighting its ability to create different kinds of applications that process real-time data from the web using simple spreadsheet formulas. ",TRUE
pn2575,2702589,http://dx.doi.org/10.1145/2702123.2702589,http://dl.acm.org/citation.cfm?id=2702589,D2yvrMtOqWc,www.youtube.com/watch?v=D2yvrMtOqWc,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/D2yvrMtOqWc' width='640' height='360' frameborder='0' allowfullscreen='true'/>,StructJumper: A Tool to Help Blind Programmers Navigate and Understand the Structure of Code,"Catherine M Baker, Lauren R Milne, Richard E Ladner","It can be difficult for a blind developer to understand and navigate through a large amount of code quickly, as they are unable to skim as easily as their sighted counterparts. To help blind developers overcome this problem, we present StructJumper, an Eclipse plugin that creates a hierarchical tree based on the nesting structure of a Java class. The programmer can use the TreeView to get an overview of the code structure of the class (including all the methods and control flow statements) and can quickly switch between the TreeView and the Text Editor to get an idea of where they are within the nested structure. To evaluate StructJumper, we had seven blind programmers complete three tasks with and without our tool. We found that the users thought they would use StructJumper and there was a trend that they were faster completing the tasks with StructJumper.",TRUE
pn2586,2702592,http://dx.doi.org/10.1145/2702123.2702592,http://dl.acm.org/citation.cfm?id=2702592,zHCmz4hNoR0,www.youtube.com/watch?v=zHCmz4hNoR0,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/zHCmz4hNoR0' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Look Like Me: Matching Robot Personality via Gaze to Increase Motivation,"Sean Andrist, Bilge Mutlu, Adriana Tapus","Socially assistive robots are envisioned to provide social and cognitive assistance where they will seek to motivate and engage people in therapeutic activities. Due to their physicality, robots serve as a powerful technology for motivating people. Prior work has shown that effective motivation requires adaption to user needs and characteristics, but how robots might successfully achieve such adaptation is still unknown. In this paper, we present work on matching a robot's personality-expressed via its gaze behavior-to that of its users. We confirmed in an online study with 22 participants that the robot's gaze behavior can successfully express either an extroverted or introverted personality. In a laboratory study with 40 participants, we demonstrate the positive effect of personality matching on a user's motivation to engage in a repetitive task. These results have important implications for the design of adaptive robot behaviors in assistive human-robot interaction.",TRUE
pn2603,2702598,http://dx.doi.org/10.1145/2702123.2702598,http://dl.acm.org/citation.cfm?id=2702598,Y6Ku6elg2Yg,www.youtube.com/watch?v=Y6Ku6elg2Yg,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/Y6Ku6elg2Yg' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Exergames for Physiotherapy and Rehabilitation: A Medium-term Situated Study of Motivational Aspects and Impact on Functional Reach,"Jan David Smeddinck, Marc Herrlich, Rainer Malaka","Exergames are increasingly considered as an exercise instruction modality in health applications. Studies are typically conducted in non-situated contexts and capture short-term effects. We present first results from a medium-scale study conducted over the course of 5 weeks and integrated into a normal rehabilitation program. The study features three groups, comparing manually adjustable exergames with the identical games in adaptive versions and manual physiotherapy interventions without games. The results indicate that the exergames and traditional therapy are comparable regarding measures of competence and enjoyment, while exergames led to significantly higher scores for autonomy, presence, and in a functional reach test. With traditional therapy, scores for tension-pressure and effort-importance were significantly higher. The initial results of the broader study presented in this paper deliver insights regarding motivational aspects of exergames and traditional therapy and point out which motivational aspects could be strengthened in future implementations.",TRUE
pn2604,2702599,http://dx.doi.org/10.1145/2702123.2702599,http://dl.acm.org/citation.cfm?id=2702599,FhnSkhxR2uw,www.youtube.com/watch?v=FhnSkhxR2uw,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/FhnSkhxR2uw' width='640' height='360' frameborder='0' allowfullscreen='true'/>,ShapeClip: Towards Rapid Prototyping with Shape-Changing Displays for Designers,"John Hardy, Christian Weichel, Faisal Taher, John Vidler, Jason Alexander","This paper presents ShapeClip: a modular tool capable of transforming any computer screen into a z-actuating shape-changing display. This enables designers to produce dynamic physical forms by ‘clipping’ actuators onto screens. ShapeClip displays are portable, scalable, fault-tolerant, and support runtime re-arrangement. Users are not required to have knowledge of electronics or programming, and can develop motion designs with presentation software, image editors, or web-technologies. To evaluate ShapeClip we carried out a full-day workshop with expert designers. Participants were asked to generate shape-changing designs and then construct them using ShapeClip. ShapeClip enabled participants to rapidly and successfully transform their ideas into functional systems.",TRUE
pn2607,2702601,http://dx.doi.org/10.1145/2702123.2702601,http://dl.acm.org/citation.cfm?id=2702601,JuwGLnCHvag,www.youtube.com/watch?v=JuwGLnCHvag,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Thursday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/JuwGLnCHvag' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Joint Estimation of 3D Hand Position and Gestures from Monocular Video for Mobile Interaction,"Jie Song, Fabrizio Pece, Gábor Sörös, Marion Koelle, Otmar Hilliges","We present a machine learning technique to recognize gestures and estimate metric depth of hands for 3D interaction, relying only on monocular RGB video input. We aim to enable spatial interaction with small, body-worn devices where rich 3D input is desired but the usage of conventional depth sensors is prohibitive due to their power consumption and size. We propose a hybrid classification-regression approach to learn and predict a mapping of RGB colors to absolute, metric depth in real time. We also classify distinct hand gestures, allowing for a variety of 3D interactions. We demonstrate our technique with three mobile interaction scenarios and evaluate the method quantitatively and qualitatively.",TRUE
pn2620,2702603,http://dx.doi.org/10.1145/2702123.2702603,http://dl.acm.org/citation.cfm?id=2702603,CD6_YkXh-8Q,www.youtube.com/watch?v=CD6_YkXh-8Q,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/CD6_YkXh-8Q' width='640' height='360' frameborder='0' allowfullscreen='true'/>,How Good is 85%? A Survey Tool to Connect Classifier Evaluation to Acceptability of Accuracy,"Matthew Kay, Shwetak N Patel, Julie A Kientz","Many HCI and ubiquitous computing systems are characterized by two important properties: their output is uncertain—it has an associated accuracy that researchers attempt to optimize—and this uncertainty is user-facing—it directly affects the quality of the user experience. Novel classifiers are typically evaluated using measures like the F1 score—but given an F-score of (e.g.) 0.85, how do we know whether this performance is good enough? Is this level of uncertainty actually tolerable to users of the intended application—and do people weight precision and recall equally? We set out to develop a survey instrument that can systematically answer such questions. We introduce a new measure, acceptability of accuracy, and show how to predict it based on measures of classifier accuracy. Out tool allows us to systematically select an objective function to optimize during classifier evaluation, but can also offer new insights into how to design feedback for user-facing classification systems (e.g., by combining a seemingly-low-performing classifier with appropriate feedback to make a highly usable system). It also reveals potential issues with the ubiquitous F1-measure as applied to user-facing systems.",TRUE
pn2625,2702604,http://dx.doi.org/10.1145/2702123.2702604,http://dl.acm.org/citation.cfm?id=2702604,TIKuE6GT_P4,www.youtube.com/watch?v=TIKuE6GT_P4,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Wednesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/TIKuE6GT_P4' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Exploring Interactions with Physically Dynamic Bar Charts,"Faisal Taher, John Hardy, Abhijit Karnik, Christian Weichel, Yvonne Jansen, Kasper Hornbæk, Jason Alexander","Visualizations such as bar charts help users reason about data, but are mostly screen-based, rarely physical, and almost never physical and dynamic. This paper investigates the role of physically dynamic bar charts and evaluates new interactions for exploring and working with datasets rendered in dynamic physical form. To facilitate our exploration we constructed a 10x10 interactive bar chart and designed interactions that supported fundamental visualisation tasks, specifically; annotation, filtering, organization, and navigation. The interactions were evaluated in a user study with 17 participants. Our findings identify the preferred methods of working with the data for each task i.e. directly tapping rows to hide bars, highlight the strengths and limitations of working with physical data, and discuss the challenges of integrating the proposed interactions together into a larger data exploration system. In general, physical interactions were intuitive, informative, and enjoyable, paving the way for new explorations in physical data visualizations.",TRUE
pn2629,2702607,http://dx.doi.org/10.1145/2702123.2702607,http://dl.acm.org/citation.cfm?id=2702607,TIDoc1nkbSo,www.youtube.com/watch?v=TIDoc1nkbSo,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/TIDoc1nkbSo' width='640' height='360' frameborder='0' allowfullscreen='true'/>,Performance and Ergonomics of Touch Surfaces: A Comparative Study using Biomechanical Simulation,"Myroslav Bachynskyi, Gregorio Palmas, Antti Oulasvirta, Jürgen Steimle, Tino Weinkauf","Although different types of touch surfaces have gained extensive attention in HCI, this is the first work to directly compare them for two critical factors: performance and ergonomics. Our data come from a pointing task (N=40) carried out on five common touch surface types: public display (large, vertical, standing), tabletop (large, horizontal, seated), laptop (medium, adjustably tilted, seated), tablet (seated, in hand), and smartphone (single- and two-handed input). Ergonomics indices were calculated from biomechanical simulations of motion capture data combined with recordings of external forces. We provide an extensive dataset for researchers and report the first analyses of similarities and differences that are attributable to the different postures and movement ranges.",TRUE
pn2637,2702608,http://dx.doi.org/10.1145/2702123.2702608,http://dl.acm.org/citation.cfm?id=2702608,GKCrrdnIVvM,www.youtube.com/watch?v=GKCrrdnIVvM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Tuesday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/GKCrrdnIVvM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,How Deceptive are Deceptive Visualizations?: An Empirical Analysis of Common Distortion Techniques,"Anshul Vikram Pandey, Katharina Rall, Margaret L Satterthwaite, Oded Nov, Enrico Bertini","In this paper, we present an empirical analysis of deceptive visualizations. We start with an in-depth analysis of what deception means in the context of data visualization, and categorize deceptive visualizations based on the type of deception they lead to. We identify popular distortion techniques and the type of visualizations those distortions can be applied to, and formalize why deception occurs with those distortions. We create four deceptive visualizations using the selected distortion techniques, and run a crowdsourced user study to identify the deceptiveness of those visualizations. We then present the findings of our study and show how deceptive each of these visual distortion techniques are, and for what kind of questions the misinterpretation occurs. We also analyze individual differences among participants and present the effect of some of those variables on participants' responses. This paper presents a first step in empirically studying deceptive visualizations, and will pave the way for more research in this direction.",TRUE
pn2680,2702611,http://dx.doi.org/10.1145/2702123.2702611,http://dl.acm.org/citation.cfm?id=2702611,VZQYn_uh9GM,www.youtube.com/watch?v=VZQYn_uh9GM,CHI 2015;CHI 2015 Papers and Notes,CHI 2015 Video Previews;CHI 2015 Monday Video Previews,private,<iframe type='text/html' src='http://www.youtube.com/embed/VZQYn_uh9GM' width='640' height='360' frameborder='0' allowfullscreen='true'/>,bioLogic: Natto Cells as Nanoactuators for Shape Changing Interfaces,"Lining Yao, Jifei Ou, Chin-Yi Cheng, Helene Steiner, Wen Wang, Guanyun Wang, Hiroshi Ishii","Based on the natural phenomenon of cells’ hygromorphic transformation, we introduce living Bacillus Subtilis natto cell as a humidity sensitive nanoactuator. In this paper, we unfold the process of exploring and comparing cell types that are proper for HCI use, the development of the composite biofilm, the development of the responsive structures, the control setup for actuating biofilms, and a simulation and fabrication platform. Finally, we provide a variety of application designs, with and without computer control to demonstrate the potential of our bio actuators. Through this paper, we intend to enable the use of natto cells and our platform technologies for HCI researchers, designers and bio-hackers. And more generally, we try to encourage the use and research of biological materials and interdisciplinary research in HCI.",TRUE